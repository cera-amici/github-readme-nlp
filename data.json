[{"repo": "donnemartin/system-design-primer", "language": "Python", "readme_contents": "*[English](README.md) \u2219 [\u65e5\u672c\u8a9e](README-ja.md) \u2219 [\u7b80\u4f53\u4e2d\u6587](README-zh-Hans.md) \u2219 [\u7e41\u9ad4\u4e2d\u6587](README-zh-TW.md) | [\u0627\u0644\u0639\u064e\u0631\u064e\u0628\u0650\u064a\u064e\u0651\u0629\u200e](https://github.com/donnemartin/system-design-primer/issues/170) \u2219 [\u09ac\u09be\u0982\u09b2\u09be](https://github.com/donnemartin/system-design-primer/issues/220) \u2219 [Portugu\u00eas do Brasil](https://github.com/donnemartin/system-design-primer/issues/40) \u2219 [Deutsch](https://github.com/donnemartin/system-design-primer/issues/186) \u2219 [\u03b5\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac](https://github.com/donnemartin/system-design-primer/issues/130) \u2219 [\u05e2\u05d1\u05e8\u05d9\u05ea](https://github.com/donnemartin/system-design-primer/issues/272) \u2219 [Italiano](https://github.com/donnemartin/system-design-primer/issues/104) \u2219 [\u97d3\u570b\u8a9e](https://github.com/donnemartin/system-design-primer/issues/102) \u2219 [\u0641\u0627\u0631\u0633\u06cc](https://github.com/donnemartin/system-design-primer/issues/110) \u2219 [Polski](https://github.com/donnemartin/system-design-primer/issues/68) \u2219 [\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a](https://github.com/donnemartin/system-design-primer/issues/87) \u2219 [Espa\u00f1ol](https://github.com/donnemartin/system-design-primer/issues/136) \u2219 [\u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22](https://github.com/donnemartin/system-design-primer/issues/187) \u2219 [T\u00fcrk\u00e7e](https://github.com/donnemartin/system-design-primer/issues/39) \u2219 [ti\u1ebfng Vi\u1ec7t](https://github.com/donnemartin/system-design-primer/issues/127) \u2219 [Fran\u00e7ais](https://github.com/donnemartin/system-design-primer/issues/250) | [Add Translation](https://github.com/donnemartin/system-design-primer/issues/28)*\n\n# \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u5165\u9580\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/jj3A5N8.png\"/>\n  <br/>\n</p>\n\n## \u52d5\u6a5f\u30fb\u76ee\u7684\n\n> \u5927\u898f\u6a21\u30b7\u30b9\u30c6\u30e0\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u3092\u5b66\u3076\n>\n> \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u306b\u5099\u3048\u308b\n\n### \u5927\u898f\u6a21\u30b7\u30b9\u30c6\u30e0\u306e\u8a2d\u8a08\u3092\u5b66\u3076\n\n\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u306a\u30b7\u30b9\u30c6\u30e0\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u3092\u5b66\u3076\u3053\u3068\u306f\u3001\u3088\u308a\u826f\u3044\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u306a\u308b\u3053\u3068\u306b\u8cc7\u3059\u308b\u3067\u3057\u3087\u3046\u3002\n\n\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306f\u3068\u3066\u3082\u5e83\u7bc4\u306a\u30c8\u30d4\u30c3\u30af\u3092\u542b\u307f\u307e\u3059\u3002\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u539f\u7406\u306b\u3064\u3044\u3066\u306f **\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u4e0a\u306b\u306f\u81a8\u5927\u306a\u91cf\u306e\u6587\u732e\u304c\u6563\u3089\u3070\u3063\u3066\u3044\u307e\u3059\u3002**\n\n\u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306f\u5927\u898f\u6a21\u30b7\u30b9\u30c6\u30e0\u69cb\u7bc9\u306b\u5fc5\u8981\u306a\u77e5\u8b58\u3092\u5b66\u3076\u3053\u3068\u304c\u3067\u304d\u308b **\u6587\u732e\u30ea\u30b9\u30c8\u3092\u4f53\u7cfb\u7684\u306b\u307e\u3068\u3081\u305f\u3082\u306e** \u3067\u3059\u3002\n\n### \u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u304b\u3089\u5b66\u3076\n\n\u3053\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f\u3001\u3053\u308c\u304b\u3089\u3082\u305a\u3063\u3068\u66f4\u65b0\u3055\u308c\u3066\u3044\u304f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u521d\u671f\u6bb5\u968e\u306b\u3059\u304e\u307e\u305b\u3093\u3002\n\n[Contributions](#contributing) \u306f\u5927\u6b53\u8fce\u3067\u3059\uff01\n\n### \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u306b\u5099\u3048\u308b\n\n\u30b3\u30fc\u30c9\u6280\u8853\u9762\u63a5\u306b\u52a0\u3048\u3066\u3001\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306b\u95a2\u3059\u308b\u77e5\u8b58\u306f\u3001\u591a\u304f\u306e\u30c6\u30c3\u30af\u4f01\u696d\u306b\u304a\u3051\u308b **\u6280\u8853\u63a1\u7528\u9762\u63a5\u30d7\u30ed\u30bb\u30b9** \u3067 **\u5fc5\u8981\u4e0d\u53ef\u6b20\u306a\u8981\u7d20** \u3067\u3059\u3002\n\n**\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u3067\u306e\u983b\u51fa\u8cea\u554f\u306b\u5099\u3048**\u3001\u81ea\u5206\u306e\u89e3\u7b54\u3068*\u6a21\u7bc4\u89e3\u7b54*:\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u3001\u30b3\u30fc\u30c9\u305d\u3057\u3066\u56f3\u8868\u306a\u3069\u3092*\u6bd4\u8f03*\u3057\u3066\u5b66\u3073\u307e\u3057\u3087\u3046\u3002\n\n\u9762\u63a5\u6e96\u5099\u306b\u5f79\u7acb\u3064\u305d\u306e\u4ed6\u306e\u30c8\u30d4\u30c3\u30af:\n\n* [\u5b66\u7fd2\u6307\u91dd](#\u5b66\u7fd2\u6307\u91dd)\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u306b\u3069\u306e\u3088\u3046\u306b\u6e96\u5099\u3059\u308b\u304b](#\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u306b\u3069\u306e\u3088\u3046\u306b\u3057\u3066\u81e8\u3081\u3070\u3044\u3044\u304b)\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u8ab2\u984c\u4f8b **\u3068\u305d\u306e\u89e3\u7b54**](#\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u8ab2\u984c\u4f8b\u3068\u305d\u306e\u89e3\u7b54)\n* [\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u8a2d\u8a08\u8ab2\u984c\u4f8b\u3001 **\u3068\u305d\u306e\u89e3\u7b54**](#\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u8a2d\u8a08\u554f\u984c\u3068\u89e3\u7b54)\n* [\u305d\u306e\u4ed6\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u4f8b](#\u4ed6\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u4f8b\u984c)\n\n## \u6697\u8a18\u30ab\u30fc\u30c9\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/zdCAkB3.png\"/>\n  <br/>\n</p>\n\n\u3053\u306e[Anki\u7528\u30d5\u30e9\u30c3\u30b7\u30e5\u30ab\u30fc\u30c9\u30c7\u30c3\u30ad](https://apps.ankiweb.net/) \u306f\u3001\u9593\u9694\u53cd\u5fa9\u3092\u6d3b\u7528\u3057\u3066\u3001\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306e\u30ad\u30fc\u30b3\u30f3\u30bb\u30d7\u30c8\u306e\u5b66\u7fd2\u3092\u652f\u63f4\u3057\u307e\u3059\u3002\n\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c7\u30c3\u30ad](resources/flash_cards/System%20Design.apkg)\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u7df4\u7fd2\u8ab2\u984c\u30c7\u30c3\u30ad](resources/flash_cards/System%20Design%20Exercises.apkg)\n* [\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u7df4\u7fd2\u8ab2\u984c\u30c7\u30c3\u30ad](resources/flash_cards/OO%20Design.apkg)\n\n\u5916\u51fa\u5148\u3084\u79fb\u52d5\u4e2d\u306e\u52c9\u5f37\u306b\u5f79\u7acb\u3064\u3067\u3057\u3087\u3046\u3002\n\n### \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u6280\u8853\u8ab2\u984c\u7528\u306e\u554f\u984c: \u7df4\u7fd2\u7528\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n\u30b3\u30fc\u30c9\u6280\u8853\u9762\u63a5\u7528\u306e\u554f\u984c\u3092\u63a2\u3057\u3066\u3044\u308b\u5834\u5408\u306f[**\u3053\u3061\u3089**](https://github.com/donnemartin/interactive-coding-challenges)\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/b4YtAEN.png\"/>\n  <br/>\n</p>\n\n\u59c9\u59b9\u30ea\u30dd\u30b8\u30c8\u30ea\u306e [**Interactive Coding Challenges**](https://github.com/donnemartin/interactive-coding-challenges)\u3082\u898b\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\u8ffd\u52a0\u306e\u6697\u8a18\u30c7\u30c3\u30ad\u30ab\u30fc\u30c9\u3082\u5165\u3063\u3066\u3044\u307e\u3059\u3002\n\n* [Coding deck](https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg)\n\n## \u30b3\u30f3\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\n\n> \u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u304b\u3089\u5b66\u3076\n\n\u30d7\u30eb\u30ea\u30af\u30a8\u30b9\u30c8\u7b49\u306e\u8ca2\u732e\u306f\u7a4d\u6975\u7684\u306b\u304a\u9858\u3044\u3057\u307e\u3059:\n\n* \u30a8\u30e9\u30fc\u4fee\u6b63\n* \u30bb\u30af\u30b7\u30e7\u30f3\u5185\u5bb9\u6539\u5584\n* \u65b0\u898f\u30bb\u30af\u30b7\u30e7\u30f3\u8ffd\u52a0\n* [\u7ffb\u8a33\u3059\u308b](https://github.com/donnemartin/system-design-primer/issues/28)\n\n\u73fe\u5728\u3001\u5185\u5bb9\u306e\u6539\u5584\u304c\u5fc5\u8981\u306a\u4f5c\u696d\u4e2d\u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u306f[\u3053\u3061\u3089](#\u9032\u884c\u4e2d\u306e\u4f5c\u696d)\u3067\u3059\u3002\n\n\u30b3\u30f3\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\u306e\u524d\u306b[Contributing Guidelines](CONTRIBUTING.md)\u3092\u8aad\u307f\u307e\u3057\u3087\u3046\u3002\n\n## \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u76ee\u6b21\n\n> \u8cdb\u5426\u3082\u542b\u3081\u305f\u69d8\u3005\u306a\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306e\u5404\u30c8\u30d4\u30c3\u30af\u306e\u6982\u8981\u3002 **\u5168\u3066\u306f\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306e\u95a2\u4fc2\u306b\u3042\u308a\u307e\u3059\u3002**\n>\n> \u305d\u308c\u305e\u308c\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306f\u3088\u308a\u5b66\u3073\u3092\u6df1\u3081\u308b\u3088\u3046\u306a\u4ed6\u306e\u6587\u732e\u3078\u306e\u30ea\u30f3\u30af\u304c\u8cbc\u3089\u308c\u3066\u3044\u307e\u3059\u3002\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/jrUBAF7.png\"/>\n  <br/>\n</p>\n\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c8\u30d4\u30c3\u30af: \u307e\u305a\u306f\u3053\u3053\u304b\u3089](#\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c8\u30d4\u30c3\u30af\u30b9-\u307e\u305a\u306f\u3053\u3053\u304b\u3089)\n    * [Step 1: \u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306b\u95a2\u3059\u308b\u52d5\u753b\u3092\u898b\u308b](#\u30b9\u30c6\u30c3\u30d7-1-\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306b\u95a2\u3059\u308b\u52d5\u753b\u3092\u89b3\u3066\u5fa9\u7fd2\u3059\u308b)\n    * [Step 2: \u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306b\u95a2\u3059\u308b\u8a18\u4e8b\u3092\u8aad\u3080](#\u30b9\u30c6\u30c3\u30d7-2-\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306b\u95a2\u3059\u308b\u8cc7\u6599\u3092\u8aad\u3093\u3067\u5fa9\u7fd2\u3059\u308b)\n    * [\u6b21\u306e\u30b9\u30c6\u30c3\u30d7](#\u6b21\u306e\u30b9\u30c6\u30c3\u30d7)\n* [\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9 vs \u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3](#\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9-vs-\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3)\n* [\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc vs \u30b9\u30eb\u30fc\u30d7\u30c3\u30c8](#\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc-vs-\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8)\n* [\u53ef\u7528\u6027 vs \u4e00\u8cab\u6027](#\u53ef\u7528\u6027-vs-\u4e00\u8cab\u6027)\n    * [CAP\u7406\u8ad6](#cap-\u7406\u8ad6)\n        * [CP - \u4e00\u8cab\u6027(consistency)\u3068\u5206\u5272\u6027(partition)\u8010\u6027](#cp---\u4e00\u8cab\u6027\u3068\u5206\u65ad\u8010\u6027consistency-and-partition-tolerance)\n        * [AP - \u53ef\u7528\u6027(availability)\u3068\u5206\u5272\u6027(partition)\u8010\u6027](#ap---\u53ef\u7528\u6027\u3068\u5206\u65ad\u8010\u6027availability-and-partition-tolerance)\n* [\u4e00\u8cab\u6027 \u30d1\u30bf\u30fc\u30f3](#\u4e00\u8cab\u6027\u30d1\u30bf\u30fc\u30f3)\n    * [\u5f31\u3044\u4e00\u8cab\u6027](#\u5f31\u3044\u4e00\u8cab\u6027)\n    * [\u7d50\u679c\u6574\u5408\u6027](#\u7d50\u679c\u6574\u5408\u6027)\n    * [\u5f37\u3044\u4e00\u8cab\u6027](#\u5f37\u3044\u4e00\u8cab\u6027)\n* [\u53ef\u7528\u6027 \u30d1\u30bf\u30fc\u30f3](#\u53ef\u7528\u6027\u30d1\u30bf\u30fc\u30f3)\n    * [\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc](#\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc)\n    * [\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](#\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3)\n* [\u30c9\u30e1\u30a4\u30f3\u30cd\u30fc\u30e0\u30b7\u30b9\u30c6\u30e0(DNS)](#\u30c9\u30e1\u30a4\u30f3\u30cd\u30fc\u30e0\u30b7\u30b9\u30c6\u30e0)\n* [\u30b3\u30f3\u30c6\u30f3\u30c4\u30c7\u30ea\u30d0\u30ea\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(CDN)](#\u30b3\u30f3\u30c6\u30f3\u30c4\u30c7\u30ea\u30d0\u30ea\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30afcontent-delivery-network)\n    * [\u30d7\u30c3\u30b7\u30e5CDN](#\u30d7\u30c3\u30b7\u30e5cdn)\n    * [\u30d7\u30ebCDN](#\u30d7\u30ebcdn)\n* [\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc](#\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc)\n    * [\u30a2\u30af\u30c6\u30a3\u30d6/\u30d1\u30c3\u30b7\u30d6\u69cb\u6210](#\u30a2\u30af\u30c6\u30a3\u30d6\u30d1\u30c3\u30b7\u30d6)\n    * [\u30a2\u30af\u30c6\u30a3\u30d6/\u30a2\u30af\u30c6\u30a3\u30d6\u69cb\u6210](#\u30a2\u30af\u30c6\u30a3\u30d6\u30a2\u30af\u30c6\u30a3\u30d6)\n    * [Layer 4 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0](#layer-4-\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0)\n    * [Layer 7 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0](#layer-7-\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0)\n    * [\u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0](#\u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0)\n* [\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7 (WEB\u30b5\u30fc\u30d0\u30fc)](#\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7web\u30b5\u30fc\u30d0\u30fc)\n    * [\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc vs \u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7](#\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc-vs-\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7)\n* [\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ec\u30a4\u30e4\u30fc](#\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64)\n    * [\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9](#\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9)\n    * [\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc](#service-discovery)\n* [\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](#\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9)\n    * [\u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30de\u30cd\u30b8\u30e1\u30f3\u30c8\u30b7\u30b9\u30c6\u30e0 (RDBMS)](#\u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30de\u30cd\u30b8\u30e1\u30f3\u30c8\u30b7\u30b9\u30c6\u30e0-rdbms)\n        * [\u30de\u30b9\u30bf\u30fc/\u30b9\u30ec\u30fc\u30d6 \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](#\u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6-\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3)\n        * [\u30de\u30b9\u30bf\u30fc/\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](#\u30de\u30b9\u30bf\u30fc\u30de\u30b9\u30bf\u30fc-\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3)\n        * [\u30d5\u30a7\u30c7\u30ec\u30fc\u30b7\u30e7\u30f3](#federation)\n        * [\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0](#\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0)\n        * [\u30c7\u30ce\u30fc\u30de\u30e9\u30a4\u30bc\u30fc\u30b7\u30e7\u30f3](#\u975e\u6b63\u898f\u5316)\n        * [SQL \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0](#sql\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0)\n    * [NoSQL](#nosql)\n        * [\u30ad\u30fc/\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2](#\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2)\n        * [\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2](#\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2)\n        * [\u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2](#\u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2)\n        * [\u30b0\u30e9\u30d5 \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](#\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9)\n    * [SQL or NoSQL](#sql\u304bnosql\u304b)\n* [\u30ad\u30e3\u30c3\u30b7\u30e5](#\u30ad\u30e3\u30c3\u30b7\u30e5)\n    * [\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0](#\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0)\n    * [CDN\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0](#cdn\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0)\n    * [Web\u30b5\u30fc\u30d0\u30fc\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0](#web\u30b5\u30fc\u30d0\u30fc\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0)\n    * [\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0](#\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0)\n    * [\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0](#\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0)\n    * [\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30af\u30a8\u30ea\u30ec\u30d9\u30eb\u3067\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3059\u308b](#\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30af\u30a8\u30ea\u30ec\u30d9\u30eb\u3067\u306e\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0)\n    * [\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30ec\u30d9\u30eb\u3067\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3059\u308b](#\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30ec\u30d9\u30eb\u3067\u306e\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0)\n    * [\u3044\u3064\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u66f4\u65b0\u3059\u308b\u306e\u304b](#\u3044\u3064\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u66f4\u65b0\u3059\u308b\u304b)\n        * [\u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30b5\u30a4\u30c9](#\u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30b5\u30a4\u30c9)\n        * [\u30e9\u30a4\u30c8\u30b9\u30eb\u30fc](#\u30e9\u30a4\u30c8\u30b9\u30eb\u30fc)\n        * [\u30e9\u30a4\u30c8\u30d3\u30cf\u30a4\u30f3\u30c9 (\u30e9\u30a4\u30c8\u30d0\u30c3\u30af)](#\u30e9\u30a4\u30c8\u30d3\u30cf\u30a4\u30f3\u30c9-\u30e9\u30a4\u30c8\u30d0\u30c3\u30af)\n        * [\u30ea\u30d5\u30ec\u30c3\u30b7\u30e5\u30a2\u30d8\u30c3\u30c9](#\u30ea\u30d5\u30ec\u30c3\u30b7\u30e5\u30a2\u30d8\u30c3\u30c9)\n* [\u975e\u540c\u671f\u51e6\u7406](#\u975e\u540c\u671f\u51e6\u7406)\n    * [\u30e1\u30c3\u30bb\u30fc\u30b8\u30ad\u30e5\u30fc](#\u30e1\u30c3\u30bb\u30fc\u30b8\u30ad\u30e5\u30fc)\n    * [\u30bf\u30b9\u30af\u30ad\u30e5\u30fc](#\u30bf\u30b9\u30af\u30ad\u30e5\u30fc)\n    * [\u30d0\u30c3\u30af\u30d7\u30ec\u30c3\u30b7\u30e3\u30fc](#\u30d0\u30c3\u30af\u30d7\u30ec\u30c3\u30b7\u30e3\u30fc)\n* [\u901a\u4fe1](#\u901a\u4fe1)\n    * [\u4f1d\u9001\u5236\u5fa1\u30d7\u30ed\u30c8\u30b3\u30eb (TCP)](#\u4f1d\u9001\u5236\u5fa1\u30d7\u30ed\u30c8\u30b3\u30eb-tcp)\n    * [\u30e6\u30fc\u30b6\u30c7\u30fc\u30bf\u30b0\u30e9\u30e0\u30d7\u30ed\u30c8\u30b3\u30eb (UDP)](#\u30e6\u30fc\u30b6\u30c7\u30fc\u30bf\u30b0\u30e9\u30e0\u30d7\u30ed\u30c8\u30b3\u30eb-udp)\n    * [\u9060\u9694\u624b\u7d9a\u547c\u51fa (RPC)](#\u9060\u9694\u624b\u7d9a\u547c\u51fa-rpc)\n    * [Representational state transfer (REST)](#representational-state-transfer-rest)\n* [\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3](#\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3)\n* [\u88dc\u907a](#\u88dc\u907a)\n    * [2\u306e\u4e57\u6570\u8868](#2\u306e\u4e57\u6570\u8868)\n    * [\u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u308b\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u5024](#\u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u308b\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u5024)\n    * [\u4ed6\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u4f8b\u984c](#\u4ed6\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u4f8b\u984c)\n    * [\u5b9f\u4e16\u754c\u3067\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](#\u5b9f\u4e16\u754c\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3)\n    * [\u5404\u4f01\u696d\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](#\u5404\u4f01\u696d\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3)\n    * [\u4f01\u696d\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u30d6\u30ed\u30b0](#\u4f01\u696d\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u30d6\u30ed\u30b0)\n* [\u4f5c\u696d\u4e2d](#\u9032\u884c\u4e2d\u306e\u4f5c\u696d)\n* [\u30af\u30ec\u30b8\u30c3\u30c8](#\u30af\u30ec\u30b8\u30c3\u30c8)\n* [\u9023\u7d61\u60c5\u5831](#contact-info)\n* [\u30e9\u30a4\u30bb\u30f3\u30b9](#license)\n\n## \u5b66\u7fd2\u6307\u91dd\n\n> \u5b66\u7fd2\u30b9\u30d1\u30f3\u306b\u5fdc\u3058\u3066\u307f\u308b\u3079\u304d\u30c8\u30d4\u30c3\u30af\u30b9 (short, medium, long)\n\n![Imgur](http://i.imgur.com/OfVllex.png)\n\n**Q: \u9762\u63a5\u306e\u305f\u3081\u306b\u306f\u3001\u3053\u3053\u306b\u3042\u308b\u3082\u306e\u3059\u3079\u3066\u3092\u3084\u3089\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u306e\u3067\u3057\u3087\u3046\u304b\uff1f**\n\n**A: \u3044\u3048\u3001\u3053\u3053\u306b\u3042\u308b\u3059\u3079\u3066\u3092\u3084\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093\u3002**\n\n\u9762\u63a5\u3067\u4f55\u3092\u805e\u304b\u308c\u308b\u304b\u306f\u4ee5\u4e0b\u306e\u6761\u4ef6\u306b\u3088\u3063\u3066\u5909\u308f\u3063\u3066\u304d\u307e\u3059:\n\n* \u3069\u308c\u3060\u3051\u306e\u6280\u8853\u7d4c\u9a13\u304c\u3042\u308b\u304b\n* \u3042\u306a\u305f\u306e\u6280\u8853\u80cc\u666f\u304c\u4f55\u3067\u3042\u308b\u304b\n* \u3069\u306e\u30dd\u30b8\u30b7\u30e7\u30f3\u306e\u305f\u3081\u306b\u9762\u63a5\u3092\u53d7\u3051\u3066\u3044\u308b\u304b\n* \u3069\u306e\u4f01\u696d\u306e\u9762\u63a5\u3092\u53d7\u3051\u3066\u3044\u308b\u304b\n* \u904b\n\n\u3088\u308a\u7d4c\u9a13\u306e\u3042\u308b\u5019\u88dc\u8005\u306f\u4e00\u822c\u7684\u306b\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306b\u3064\u3044\u3066\u3088\u308a\u6df1\u3044\u77e5\u8b58\u3092\u6709\u3057\u3066\u3044\u308b\u3053\u3068\u3092\u8981\u6c42\u3055\u308c\u308b\u3067\u3057\u3087\u3046\u3002\u30b7\u30b9\u30c6\u30e0\u30a2\u30fc\u30ad\u30c6\u30af\u30c8\u3084\u30c1\u30fc\u30e0\u30ea\u30fc\u30c0\u30fc\u306f\u5404\u30e1\u30f3\u30d0\u30fc\u306e\u6301\u3064\u3088\u3046\u306a\u77e5\u8b58\u3088\u308a\u306f\u6df1\u3044\u898b\u8b58\u3092\u6301\u3063\u3066\u3044\u308b\u3079\u304d\u3067\u3057\u3087\u3046\u3002\u4e00\u6d41\u30c6\u30c3\u30af\u4f01\u696d\u3067\u306f\u8907\u6570\u56de\u306e\u8a2d\u8a08\u9762\u63a5\u3092\u8ab2\u3055\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u3002\n\n\u307e\u305a\u306f\u5e83\u304f\u59cb\u3081\u3066\u3001\u305d\u3053\u304b\u3089\u3044\u304f\u3064\u304b\u306e\u5206\u91ce\u306b\u7d5e\u3063\u3066\u6df1\u3081\u3066\u3044\u304f\u306e\u304c\u3044\u3044\u3067\u3057\u3087\u3046\u3002\u69d8\u3005\u306a\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306e\u30c8\u30d4\u30c3\u30af\u306b\u3064\u3044\u3066\u5c11\u3057\u305a\u3064\u77e5\u3063\u3066\u304a\u304f\u3053\u3068\u306f\u3044\u3044\u3053\u3068\u3067\u3059\u3002\u4ee5\u4e0b\u306e\u5b66\u7fd2\u30ac\u30a4\u30c9\u3092\u81ea\u5206\u306e\u5b66\u7fd2\u306b\u5f53\u3066\u3089\u308c\u308b\u6642\u9593\u3001\u6280\u8853\u7d4c\u9a13\u3001\u3069\u306e\u8077\u4f4d\u3001\u3069\u306e\u4f1a\u793e\u306b\u5fdc\u52df\u3057\u3066\u3044\u308b\u304b\u306a\u3069\u3092\u52a0\u5473\u3057\u3066\u81ea\u5206\u7528\u306b\u8abf\u6574\u3057\u3066\u4f7f\u3046\u3068\u3044\u3044\u3067\u3057\u3087\u3046\u3002\n\n* **\u77ed\u671f\u9593** - **\u5e45\u5e83\u304f** \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c8\u30d4\u30c3\u30af\u3092\u5b66\u3076\u3002**\u3044\u304f\u3064\u304b\u306e** \u9762\u63a5\u8ab2\u984c\u3092\u89e3\u304f\u3053\u3068\u3067\u5bfe\u7b56\u3059\u308b\u3002\n* **\u4e2d\u671f\u9593** - **\u5e45\u5e83\u304f** \u305d\u3057\u3066 **\u305d\u308c\u306a\u308a\u306b\u6df1\u304f**\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c8\u30d4\u30c3\u30af\u3092\u5b66\u3076\u3002**\u591a\u304f\u306e** \u9762\u63a5\u8ab2\u984c\u3092\u89e3\u304f\u3053\u3068\u3067\u5bfe\u7b56\u3059\u308b\u3002\n* **\u9577\u671f\u9593** - **\u5e45\u5e83\u304f** \u305d\u3057\u3066 **\u3082\u3063\u3068\u6df1\u304f**\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c8\u30d4\u30c3\u30af\u3092\u5b66\u3076\u3002**\u307b\u307c\u5168\u3066\u306e** \u9762\u63a5\u8ab2\u984c\u3092\u89e3\u304f\u3053\u3068\u3067\u5bfe\u7b56\u3059\u308b\u3002\n\n| | \u77ed\u671f\u9593 | \u4e2d\u671f\u9593 | \u9577\u671f\u9593 |\n|---|---|---|---|\n| [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c8\u30d4\u30c3\u30af](#\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u76ee\u6b21) \u3092\u8aad\u307f\u3001\u30b7\u30b9\u30c6\u30e0\u52d5\u4f5c\u6a5f\u5e8f\u306b\u3064\u3044\u3066\u5e83\u304f\u77e5\u308b | :+1: | :+1: | :+1: |\n| \u6b21\u306e\u30ea\u30f3\u30af\u5148\u306e\u3044\u304f\u3064\u304b\u306e\u30da\u30fc\u30b8\u3092\u8aad\u3093\u3067 [\u5404\u4f01\u696d\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0\u30d6\u30ed\u30b0](#\u4f01\u696d\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u30d6\u30ed\u30b0) \u5fdc\u52df\u3059\u308b\u4f1a\u793e\u306b\u3064\u3044\u3066\u77e5\u308b | :+1: | :+1: | :+1: |\n| \u6b21\u306e\u30ea\u30f3\u30af\u5148\u306e\u3044\u304f\u3064\u304b\u306e\u30da\u30fc\u30b8\u3092\u8aad\u3080 [\u5b9f\u4e16\u754c\u3067\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](#\u5b9f\u4e16\u754c\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3) | :+1: | :+1: | :+1: |\n| \u5fa9\u7fd2\u3059\u308b [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u306b\u3069\u306e\u3088\u3046\u306b\u6e96\u5099\u3059\u308b\u304b](#\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u306b\u3069\u306e\u3088\u3046\u306b\u3057\u3066\u81e8\u3081\u3070\u3044\u3044\u304b) | :+1: | :+1: | :+1: |\n| \u3068\u308a\u3042\u3048\u305a\u4e00\u5468\u3059\u308b [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u8ab2\u984c\u4f8b](#\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u8ab2\u984c\u4f8b\u3068\u305d\u306e\u89e3\u7b54) | Some | Many | Most |\n| \u3068\u308a\u3042\u3048\u305a\u4e00\u5468\u3059\u308b [\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u8a2d\u8a08\u554f\u984c\u3068\u89e3\u7b54](#\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u8a2d\u8a08\u554f\u984c\u3068\u89e3\u7b54) | Some | Many | Most |\n| \u5fa9\u7fd2\u3059\u308b [\u305d\u306e\u4ed6\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u3067\u306e\u8cea\u554f\u4f8b](#\u4ed6\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u4f8b\u984c) | Some | Many | Most |\n\n## \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u306b\u3069\u306e\u3088\u3046\u306b\u3057\u3066\u81e8\u3081\u3070\u3044\u3044\u304b\n\n> \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8a66\u9a13\u554f\u984c\u306b\u3069\u306e\u3088\u3046\u306b\u53d6\u308a\u7d44\u3080\u304b\n\n\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u306f **open-ended conversation(Yes/No\u3067\u306f\u7b54\u3048\u3089\u308c\u306a\u3044\u53e3\u982d\u8cea\u554f)\u3067\u3059**\u3002 \u81ea\u5206\u3067\u4f1a\u8a71\u3092\u7d44\u307f\u7acb\u3066\u308b\u3053\u3068\u3092\u6c42\u3081\u3089\u308c\u307e\u3059\u3002\n\n\u4ee5\u4e0b\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u5f93\u3063\u3066\u8b70\u8ad6\u3092\u7d44\u307f\u7acb\u3066\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3067\u3057\u3087\u3046\u3002\u3053\u306e\u904e\u7a0b\u3092\u78ba\u304b\u306a\u3082\u306e\u306b\u3059\u308b\u305f\u3081\u306b\u3001\u6b21\u306e\u30bb\u30af\u30b7\u30e7\u30f3[\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u8ab2\u984c\u4f8b\u3068\u305d\u306e\u89e3\u7b54](#system-design-interview-questions-with-solutions) \u3092\u4ee5\u4e0b\u306e\u6307\u91dd\u306b\u5f93\u3063\u3066\u8aad\u307f\u8fbc\u3080\u3068\u3044\u3044\u3067\u3057\u3087\u3046\u3002\n\n### \u30b9\u30c6\u30c3\u30d7 1: \u305d\u306e\u30b7\u30b9\u30c6\u30e0\u4f7f\u7528\u4f8b\u306e\u6982\u8981\u3001\u5236\u7d04\u3001\u63a8\u8a08\u5024\u7b49\u3092\u805e\u304d\u51fa\u3057\u3001\u307e\u3068\u3081\u308b\n\n\u30b7\u30b9\u30c6\u30e0\u4ed5\u69d8\u306e\u8981\u6c42\u4e8b\u9805\u3092\u805e\u304d\u51fa\u3057\u3001\u554f\u984c\u7b87\u6240\u3092\u7279\u5b9a\u3057\u307e\u3057\u3087\u3046\u3002\u4f7f\u7528\u4f8b\u3068\u5236\u7d04\u3092\u660e\u78ba\u306b\u3059\u308b\u305f\u3081\u306e\u8cea\u554f\u3092\u6295\u3052\u304b\u3051\u307e\u3057\u3087\u3046\u3002\u8981\u6c42\u3059\u308b\u63a8\u8a08\u5024\u306b\u3064\u3044\u3066\u3082\u8b70\u8ad6\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046\u3002\n\n* \u8ab0\u304c\u305d\u306e\u30b5\u30fc\u30d3\u30b9\u3092\u4f7f\u3046\u306e\u304b\uff1f\n* \u3069\u306e\u3088\u3046\u306b\u4f7f\u3046\u306e\u304b\uff1f\n* \u4f55\u4eba\u306e\u30e6\u30fc\u30b6\u30fc\u304c\u3044\u308b\u306e\u304b\uff1f\n* \u30b7\u30b9\u30c6\u30e0\u306f\u3069\u306e\u3088\u3046\u306a\u6a5f\u80fd\u3092\u679c\u305f\u3059\u306e\u304b\uff1f\n* \u30b7\u30b9\u30c6\u30e0\u3078\u306e\u5165\u529b\u3068\u51fa\u529b\u306f\uff1f\n* \u3069\u308c\u3060\u3051\u306e\u5bb9\u91cf\u306e\u30c7\u30fc\u30bf\u3092\u634c\u304f\u5fc5\u8981\u304c\u3042\u308b\u306e\u304b\uff1f\n* \u4e00\u79d2\u9593\u306b\u4f55\u30ea\u30af\u30a8\u30b9\u30c8\u306e\u9001\u4fe1\u304c\u60f3\u5b9a\u3055\u308c\u308b\u304b\uff1f\n* \u8aad\u307f\u66f8\u304d\u6bd4\u7387\u306e\u63a8\u5b9a\u5024\u306f\u3044\u304f\u3089\u7a0b\u5ea6\u304b\uff1f\n\n### \u30b9\u30c6\u30c3\u30d7 2: \u3088\u308a\u9ad8\u30ec\u30d9\u30eb\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u3092\u7d44\u307f\u7acb\u3066\u308b\n\n\u91cd\u8981\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u5168\u3066\u8003\u616e\u3057\u305f\u9ad8\u30ec\u30d9\u30eb\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u6982\u8981\u3092\u7d44\u307f\u7acb\u3066\u308b\u3002\n\n* \u4e3b\u8981\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3068\u63a5\u7d9a\u3092\u30b9\u30b1\u30c3\u30c1\u3057\u3066\u66f8\u304d\u51fa\u3059\n* \u8003\u3048\u306e\u88cf\u4ed8\u3051\u3092\u3059\u308b\n\n### \u30b9\u30c6\u30c3\u30d7 3: \u6838\u3068\u306a\u308b\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u8a2d\u8a08\u3059\u308b\n\n\u305d\u308c\u305e\u308c\u306e\u4e3b\u8981\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306b\u3064\u3044\u3066\u306e\u8a73\u7d30\u3092\u5b66\u3076\u3002\u4f8b\u3048\u3070\u3001[url\u77ed\u7e2e\u30b5\u30fc\u30d3\u30b9](solutions/system_design/pastebin/README.md)\u306e\u8a2d\u8a08\u3092\u554f\u308f\u308c\u305f\u969b\u306b\u306f\u6b21\u306e\u3088\u3046\u306b\u3059\u308b\u3068\u3044\u3044\u3067\u3057\u3087\u3046:\n\n* \u5143\u306eURL\u306e\u30cf\u30c3\u30b7\u30e5\u5316\u3057\u305f\u3082\u306e\u3092\u4f5c\u308a\u3001\u305d\u308c\u3092\u4fdd\u5b58\u3059\u308b\n    * [MD5](solutions/system_design/pastebin/README.md) \u3068 [Base62](solutions/system_design/pastebin/README.md)\n    * \u30cf\u30c3\u30b7\u30e5\u885d\u7a81\n    * SQL \u3082\u3057\u304f\u306f NoSQL\n    * \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30b9\u30ad\u30fc\u30de\n* \u30cf\u30c3\u30b7\u30e5\u5316\u3055\u308c\u305fURL\u3092\u5143\u306eURL\u306b\u518d\u7ffb\u8a33\u3059\u308b\n    * \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u53c2\u7167\n* API & \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u306e\u8a2d\u8a08\n\n### \u30b9\u30c6\u30c3\u30d7 4: \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306e\u30b9\u30b1\u30fc\u30eb\n\n\u4e0e\u3048\u3089\u308c\u305f\u5236\u7d04\u6761\u4ef6\u304b\u3089\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u3068\u306a\u308a\u305d\u3046\u306a\u3068\u3053\u308d\u3092\u5272\u308a\u51fa\u3057\u3001\u660e\u78ba\u5316\u3059\u308b\u3002  \u4f8b\u3048\u3070\u3001\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306e\u554f\u984c\u89e3\u6c7a\u306e\u305f\u3081\u306b\u4ee5\u4e0b\u306e\u8981\u7d20\u3092\u8003\u616e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3060\u308d\u3046\u304b\uff1f\n\n* \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\n* \u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\n* \u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n* \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\n\n\u53d6\u308a\u3046\u308b\u89e3\u6c7a\u7b56\u3068\u305d\u306e\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306b\u3064\u3044\u3066\u8b70\u8ad6\u3092\u3057\u3088\u3046\u3002\u5168\u3066\u306e\u3053\u3068\u306f\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306e\u95a2\u4fc2\u306b\u3042\u308b\u3002\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u306b\u3064\u3044\u3066\u306f[\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u306a\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306e\u539f\u7406](#\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u76ee\u6b21)\u3092\u8aad\u3080\u3068\u3044\u3044\u3067\u3057\u3087\u3046\u3002\n\n### \u3061\u3087\u3063\u3068\u3057\u305f\u6697\u7b97\u554f\u984c\n\n\u3061\u3087\u3063\u3068\u3057\u305f\u63a8\u8a08\u5024\u3092\u624b\u8a08\u7b97\u3067\u3059\u308b\u3053\u3068\u3092\u6c42\u3081\u3089\u308c\u308b\u3053\u3068\u3082\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002[\u88dc\u907a](#\u88dc\u907a)\u306e\u4ee5\u4e0b\u306e\u9805\u76ee\u304c\u5f79\u306b\u7acb\u3064\u3067\u3057\u3087\u3046:\n\n* [\u30c1\u30e9\u88cf\u8a08\u7b97\u3067\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u3059\u308b](http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html)\n* [2\u306e\u4e57\u6570\u8868](#2\u306e\u4e57\u6570\u8868)\n* [\u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u3063\u3066\u304a\u304f\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u306e\u53c2\u8003\u5024](#\u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u308b\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u5024)\n\n### \u6587\u732e\u3068\u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\n\n\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u5148\u30da\u30fc\u30b8\u3092\u898b\u3066\u3069\u306e\u3088\u3046\u306a\u8cea\u554f\u3092\u6295\u3052\u304b\u3051\u3089\u308c\u308b\u304b\u6982\u8981\u3092\u982d\u306b\u5165\u308c\u3066\u304a\u304d\u307e\u3057\u3087\u3046:\n\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u3067\u6210\u529f\u3059\u308b\u306b\u306f\uff1f](https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/)\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5](http://www.hiredintech.com/system-design)\n* [\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3001\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u3078\u306e\u5c0e\u5165](https://www.youtube.com/watch?v=ZgdS0EUmn70)\n\n## \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u8ab2\u984c\u4f8b\u3068\u305d\u306e\u89e3\u7b54\n\n> \u983b\u51fa\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u3068\u53c2\u8003\u89e3\u7b54\u3001\u30b3\u30fc\u30c9\u53ca\u3073\u30c0\u30a4\u30a2\u30b0\u30e9\u30e0\n>\n> \u89e3\u7b54\u306f `solutions/` \u30d5\u30a9\u30eb\u30c0\u4ee5\u4e0b\u306b\u30ea\u30f3\u30af\u304c\u8cbc\u3089\u308c\u3066\u3044\u308b\n\n| \u554f\u984c | |\n|---|---|\n| Pastebin.com (\u3082\u3057\u304f\u306f Bit.ly) \u3092\u8a2d\u8a08\u3059\u308b| [\u89e3\u7b54](solutions/system_design/pastebin/README.md) |\n| Twitter\u30bf\u30a4\u30e0\u30e9\u30a4\u30f3 (\u3082\u3057\u304f\u306fFacebook\u30d5\u30a3\u30fc\u30c9)\u3092\u8a2d\u8a08\u3059\u308b<br/>Twitter\u691c\u7d22(\u3082\u3057\u304f\u306fFacebook\u691c\u7d22)\u6a5f\u80fd\u3092\u8a2d\u8a08\u3059\u308b | [\u89e3\u7b54](solutions/system_design/twitter/README.md) |\n| \u30a6\u30a7\u30d6\u30af\u30ed\u30fc\u30e9\u30fc\u3092\u8a2d\u8a08\u3059\u308b | [\u89e3\u7b54](solutions/system_design/web_crawler/README.md) |\n| Mint.com\u3092\u8a2d\u8a08\u3059\u308b | [\u89e3\u7b54](solutions/system_design/mint/README.md) |\n| SNS\u30b5\u30fc\u30d3\u30b9\u306e\u30c7\u30fc\u30bf\u69cb\u9020\u3092\u8a2d\u8a08\u3059\u308b | [\u89e3\u7b54](solutions/system_design/social_graph/README.md) |\n| \u691c\u7d22\u30a8\u30f3\u30b8\u30f3\u306e\u30ad\u30fc/\u30d0\u30ea\u30e5\u30fc\u69cb\u9020\u3092\u8a2d\u8a08\u3059\u308b | [\u89e3\u7b54](solutions/system_design/query_cache/README.md) |\n| Amazon\u306e\u30ab\u30c6\u30b4\u30ea\u6bce\u306e\u58f2\u308a\u4e0a\u3052\u30e9\u30f3\u30ad\u30f3\u30b0\u3092\u8a2d\u8a08\u3059\u308b | [\u89e3\u7b54](solutions/system_design/sales_rank/README.md) |\n| AWS\u4e0a\u3067100\u4e07\u4eba\u898f\u6a21\u306e\u30e6\u30fc\u30b6\u30fc\u3092\u634c\u304f\u30b5\u30fc\u30d3\u30b9\u3092\u8a2d\u8a08\u3059\u308b | [\u89e3\u7b54](solutions/system_design/scaling_aws/README.md) |\n| \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u554f\u984c\u3092\u8ffd\u52a0\u3059\u308b | [Contribute](#contributing) |\n\n### Pastebin.com (\u3082\u3057\u304f\u306f Bit.ly) \u3092\u8a2d\u8a08\u3059\u308b\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/pastebin/README.md)\n\n![Imgur](http://i.imgur.com/4edXG0T.png)\n\n### Twitter\u30bf\u30a4\u30e0\u30e9\u30a4\u30f3&\u691c\u7d22 (\u3082\u3057\u304f\u306fFacebook\u30d5\u30a3\u30fc\u30c9&\u691c\u7d22)\u3092\u8a2d\u8a08\u3059\u308b\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/twitter/README.md)\n\n![Imgur](http://i.imgur.com/jrUBAF7.png)\n\n### \u30a6\u30a7\u30d6\u30af\u30ed\u30fc\u30e9\u30fc\u306e\u8a2d\u8a08\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/web_crawler/README.md)\n\n![Imgur](http://i.imgur.com/bWxPtQA.png)\n\n### Mint.com\u306e\u8a2d\u8a08\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/mint/README.md)\n\n![Imgur](http://i.imgur.com/V5q57vU.png)\n\n### SNS\u30b5\u30fc\u30d3\u30b9\u306e\u30c7\u30fc\u30bf\u69cb\u9020\u3092\u8a2d\u8a08\u3059\u308b\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/social_graph/README.md)\n\n![Imgur](http://i.imgur.com/cdCv5g7.png)\n\n### \u691c\u7d22\u30a8\u30f3\u30b8\u30f3\u306e\u30ad\u30fc/\u30d0\u30ea\u30e5\u30fc\u69cb\u9020\u3092\u8a2d\u8a08\u3059\u308b\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/query_cache/README.md)\n\n![Imgur](http://i.imgur.com/4j99mhe.png)\n\n### Amazon\u306e\u30ab\u30c6\u30b4\u30ea\u6bce\u306e\u58f2\u308a\u4e0a\u3052\u30e9\u30f3\u30ad\u30f3\u30b0\u3092\u8a2d\u8a08\u3059\u308b\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/sales_rank/README.md)\n\n![Imgur](http://i.imgur.com/MzExP06.png)\n\n### AWS\u4e0a\u3067100\u4e07\u4eba\u898f\u6a21\u306e\u30e6\u30fc\u30b6\u30fc\u3092\u634c\u304f\u30b5\u30fc\u30d3\u30b9\u3092\u8a2d\u8a08\u3059\u308b\n\n[\u554f\u984c\u3068\u89e3\u7b54\u3092\u898b\u308b](solutions/system_design/scaling_aws/README.md)\n\n![Imgur](http://i.imgur.com/jj3A5N8.png)\n\n## \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u8a2d\u8a08\u554f\u984c\u3068\u89e3\u7b54\n\n> \u983b\u51fa\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u3068\u53c2\u8003\u89e3\u7b54\u3001\u30b3\u30fc\u30c9\u53ca\u3073\u30c0\u30a4\u30a2\u30b0\u30e9\u30e0\n>\n> \u89e3\u7b54\u306f `solutions/` \u30d5\u30a9\u30eb\u30c0\u4ee5\u4e0b\u306b\u30ea\u30f3\u30af\u304c\u8cbc\u3089\u308c\u3066\u3044\u308b\n\n>**\u5099\u8003: \u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306f\u4f5c\u696d\u4e2d\u3067\u3059**\n\n| \u554f\u984c | |\n|---|---|\n| \u30cf\u30c3\u30b7\u30e5\u30de\u30c3\u30d7\u306e\u8a2d\u8a08 | [\u89e3\u7b54](solutions/object_oriented_design/hash_table/hash_map.ipynb)  |\n| LRU\u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u8a2d\u8a08 | [\u89e3\u7b54](solutions/object_oriented_design/lru_cache/lru_cache.ipynb)  |\n| \u30b3\u30fc\u30eb\u30bb\u30f3\u30bf\u30fc\u306e\u8a2d\u8a08 | [\u89e3\u7b54](solutions/object_oriented_design/call_center/call_center.ipynb)  |\n| \u30ab\u30fc\u30c9\u306e\u30c7\u30c3\u30ad\u306e\u8a2d\u8a08 | [\u89e3\u7b54](solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb)  |\n| \u99d0\u8eca\u5834\u306e\u8a2d\u8a08 | [\u89e3\u7b54](solutions/object_oriented_design/parking_lot/parking_lot.ipynb)  |\n| \u30c1\u30e3\u30c3\u30c8\u30b5\u30fc\u30d0\u30fc\u306e\u8a2d\u8a08 | [\u89e3\u7b54](solutions/object_oriented_design/online_chat/online_chat.ipynb)  |\n| \u5186\u5f62\u914d\u5217\u306e\u8a2d\u8a08 | [Contribute](#contributing)  |\n| \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u554f\u984c\u3092\u8ffd\u52a0\u3059\u308b | [Contribute](#contributing) |\n\n## \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30c8\u30d4\u30c3\u30af\u30b9: \u307e\u305a\u306f\u3053\u3053\u304b\u3089\n\n\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u306e\u52c9\u5f37\u306f\u521d\u3081\u3066\uff1f\n\n\u307e\u305a\u521d\u3081\u306b\u3001\u3088\u304f\u4f7f\u308f\u308c\u308b\u8a2d\u8a08\u539f\u7406\u306b\u3064\u3044\u3066\u3001\u305d\u308c\u3089\u304c\u4f55\u3067\u3042\u308b\u304b\u3001\u3069\u306e\u3088\u3046\u306b\u7528\u3044\u3089\u308c\u308b\u304b\u3001\u9577\u6240\u77ed\u6240\u306b\u3064\u3044\u3066\u57fa\u672c\u7684\u306a\u77e5\u8b58\u3092\u5f97\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n\n### \u30b9\u30c6\u30c3\u30d7 1: \u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306b\u95a2\u3059\u308b\u52d5\u753b\u3092\u89b3\u3066\u5fa9\u7fd2\u3059\u308b\n\n[Harvard\u3067\u306e\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306e\u8b1b\u7fa9](https://www.youtube.com/watch?v=-W9F__D3oY4)\n\n* \u3053\u3053\u3067\u89e6\u308c\u3089\u308c\u3066\u3044\u308b\u30c8\u30d4\u30c3\u30af\u30b9:\n    * \u5782\u76f4\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\n    * \u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\n    * \u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n    * \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\n    * \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n    * \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30f3\n\n### \u30b9\u30c6\u30c3\u30d7 2: \u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306b\u95a2\u3059\u308b\u8cc7\u6599\u3092\u8aad\u3093\u3067\u5fa9\u7fd2\u3059\u308b\n\n[\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3](http://www.lecloud.net/tagged/scalability/chrono)\n\n* \u3053\u3053\u3067\u89e6\u308c\u3089\u308c\u3066\u3044\u308b\u30c8\u30d4\u30c3\u30af\u30b9:\n    * [\u30af\u30ed\u30fc\u30f3](http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones)\n    * [\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database)\n    * [\u30ad\u30e3\u30c3\u30b7\u30e5](http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache)\n    * [\u975e\u540c\u671f](http://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism)\n\n### \u6b21\u306e\u30b9\u30c6\u30c3\u30d7\n\n\u6b21\u306b\u3001\u30cf\u30a4\u30ec\u30d9\u30eb\u3067\u306e\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306b\u3064\u3044\u3066\u307f\u3066\u3044\u304f:\n\n* **\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9** vs **\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3**\n* **\u30ec\u30a4\u30c6\u30f3\u30b7** vs **\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8**\n* **\u53ef\u7528\u6027** vs **\u4e00\u8cab\u6027**\n\n**\u5168\u3066\u306f\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306e\u95a2\u4fc2\u306b\u3042\u308b**\u3068\u3044\u3046\u306e\u3092\u809d\u306b\u547d\u3058\u3066\u304a\u304d\u307e\u3057\u3087\u3046\u3002\n\n\u305d\u308c\u304b\u3089\u3001\u3088\u308a\u6df1\u3044\u5185\u5bb9\u3001DNS\u3084CDN\u305d\u3057\u3066\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306a\u3069\u306b\u3064\u3044\u3066\u5b66\u7fd2\u3092\u9032\u3081\u3066\u3044\u304d\u307e\u3057\u3087\u3046\u3002\n\n## \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9 vs \u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\n\n\u30ea\u30bd\u30fc\u30b9\u304c\u8ffd\u52a0\u3055\u308c\u308b\u306e\u306b\u3064\u308c\u3066 **\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9** \u304c\u5411\u4e0a\u3059\u308b\u5834\u5408\u305d\u306e\u30b5\u30fc\u30d3\u30b9\u306f **\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb** \u3067\u3042\u308b\u3068\u8a00\u3048\u308b\u3067\u3057\u3087\u3046\u3002\u4e00\u822c\u7684\u306b\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a\u3055\u305b\u308b\u3068\u3044\u3046\u306e\u306f\u3059\u306a\u308f\u3061\u8a08\u7b97\u51e6\u7406\u3092\u5897\u3084\u3059\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u304c\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u5897\u3048\u305f\u6642\u306a\u3069\u3088\u308a\u5927\u304d\u306a\u51e6\u7406\u3092\u634c\u3051\u308b\u3088\u3046\u306b\u306a\u308b\u3053\u3068\u3067\u3082\u3042\u308a\u307e\u3059\u3002<sup><a href=http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html>1</a></sup>\n\n\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9vs\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3092\u3068\u3089\u3048\u308b\u4ed6\u306e\u8003\u3048\u65b9:\n\n* **\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9** \u3067\u306e\u554f\u984c\u3092\u62b1\u3048\u3066\u3044\u308b\u6642\u3001\u3042\u306a\u305f\u306e\u30b7\u30b9\u30c6\u30e0\u306f\u4e00\u4eba\u306e\u30e6\u30fc\u30b6\u30fc\u306b\u3068\u3063\u3066\u9045\u3044\u3068\u8a00\u3048\u308b\u3067\u3057\u3087\u3046\u3002\n* **\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3** \u3067\u306e\u554f\u984c\u3092\u62b1\u3048\u3066\u3044\u308b\u3068\u304d\u3001\u4e00\u4eba\u306e\u30e6\u30fc\u30b6\u30fc\u306b\u3068\u3063\u3066\u306f\u901f\u3044\u3067\u3059\u304c\u3001\u591a\u304f\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u304c\u3042\u308b\u6642\u306b\u306f\u9045\u304f\u306a\u3063\u3066\u3057\u307e\u3046\u3067\u3057\u3087\u3046\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u306b\u3064\u3044\u3066](http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html)\n* [\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3001\u53ef\u7528\u6027\u3001\u5b89\u5b9a\u6027\u3001\u30d1\u30bf\u30fc\u30f3](http://www.slideshare.net/jboner/scalability-availability-stability-patterns/)\n\n## \u30ec\u30a4\u30c6\u30f3\u30b7\u30fc vs \u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\n\n**\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc** \u3068\u306f\u306a\u306b\u304c\u3057\u304b\u306e\u52d5\u4f5c\u3092\u884c\u3046\u3001\u3082\u3057\u304f\u306f\u7d50\u679c\u3092\u7b97\u51fa\u3059\u308b\u306e\u306b\u8981\u3059\u308b\u6642\u9593\n\n**\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8** \u3068\u306f\u305d\u306e\u3088\u3046\u306a\u52d5\u4f5c\u3084\u7d50\u679c\u7b97\u51fa\u304c\u5358\u4f4d\u6642\u9593\u306b\u884c\u308f\u308c\u308b\u56de\u6570\n\n\u4e00\u822c\u7684\u306b\u3001 **\u6700\u5927\u9650\u306e\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8** \u3092 **\u8a31\u5bb9\u7bc4\u56f2\u5185\u306e\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc** \u3067\u5b9f\u73fe\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3059\u306e\u304c\u666e\u901a\u3060\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc vs \u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\u3092\u7406\u89e3\u3059\u308b](https://community.cadence.com/cadence_blogs_8/b/sd/archive/2010/09/13/understanding-latency-vs-throughput)\n\n## \u53ef\u7528\u6027 vs \u4e00\u8cab\u6027\n\n### CAP \u7406\u8ad6\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/bgLMI2u.png\"/>\n  <br/>\n  <i><a href=http://robertgreiner.com/2014/08/cap-theorem-revisited>Source: CAP theorem revisited</a></i>\n</p>\n\n\u5206\u6563\u578b\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30b7\u30b9\u30c6\u30e0\u306b\u304a\u3044\u3066\u306f\u4e0b\u306e\u4e09\u3064\u306e\u3046\u3061\u4e8c\u3064\u307e\u3067\u3057\u304b\u540c\u6642\u306b\u4fdd\u8a3c\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u3002:\n\n* **\u4e00\u8cab\u6027** - \u5168\u3066\u306e\u8aad\u307f\u8fbc\u307f\u306f\u6700\u65b0\u306e\u66f8\u304d\u8fbc\u307f\u3082\u3057\u304f\u306f\u30a8\u30e9\u30fc\u3092\u53d7\u3051\u53d6\u308b\n* **\u53ef\u7528\u6027** - \u53d7\u3051\u53d6\u308b\u60c5\u5831\u304c\u6700\u65b0\u306e\u3082\u306e\u3060\u3068\u3044\u3046\u4fdd\u8a3c\u306f\u306a\u3044\u304c\u3001\u5168\u3066\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u306f\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u5fc5\u305a\u53d7\u3051\u53d6\u308b\n* **\u5206\u65ad\u8010\u6027** - \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u554f\u984c\u306b\u3088\u3063\u3066\u9806\u4e0d\u540c\u306e\u5206\u65ad\u304c\u8d77\u304d\u3066\u3082\u30b7\u30b9\u30c6\u30e0\u304c\u52d5\u4f5c\u3092\u7d9a\u3051\u308b\n\n*\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\u4fe1\u983c\u3067\u304d\u306a\u3044\u306e\u3067\u3001\u5206\u65ad\u8010\u6027\u306f\u5fc5\u305a\u4fdd\u8a3c\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\u3064\u307e\u308a\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u30b7\u30b9\u30c6\u30e0\u3068\u3057\u3066\u306e\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306f\u3001\u4e00\u8cab\u6027\u3092\u53d6\u308b\u304b\u3001\u53ef\u7528\u6027\u3092\u53d6\u308b\u304b\u3092\u8003\u3048\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002*\n\n#### CP - \u4e00\u8cab\u6027\u3068\u5206\u65ad\u8010\u6027(consistency and partition tolerance)\n\n\u5206\u65ad\u3055\u308c\u305f\u30ce\u30fc\u30c9\u304b\u3089\u306e\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u5f85\u3061\u7d9a\u3051\u3066\u3044\u308b\u3068\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u30a8\u30e9\u30fc\u306b\u9665\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002CP\u306f\u3042\u306a\u305f\u306e\u30b5\u30fc\u30d3\u30b9\u304c\u30a2\u30c8\u30df\u30c3\u30af\u306a\u8aad\u307f\u66f8\u304d\uff08\u4e0d\u53ef\u5206\u64cd\u4f5c\uff09\u3092\u5fc5\u8981\u3068\u3059\u308b\u969b\u306b\u306f\u3044\u3044\u9078\u629e\u80a2\u3067\u3057\u3087\u3046\u3002\n\n#### AP - \u53ef\u7528\u6027\u3068\u5206\u65ad\u8010\u6027(availability and partition tolerance)\n\n\u30ec\u30b9\u30dd\u30f3\u30b9\u306f\u30ce\u30fc\u30c9\u4e0a\u306b\u3042\u308b\u30c7\u30fc\u30bf\u3067\u6700\u65b0\u306e\u3082\u306e\u3092\u8fd4\u3057\u307e\u3059\u3002\u3064\u307e\u308a\u3001\u6700\u65b0\u7248\u306e\u30c7\u30fc\u30bf\u304c\u8fd4\u3055\u308c\u308b\u3068\u306f\u9650\u308a\u307e\u305b\u3093\u3002\u5206\u65ad\u304c\u89e3\u6d88\u3055\u308c\u305f\u5f8c\u3082\u3001\u66f8\u304d\u8fbc\u307f\u304c\u53cd\u6620\u3055\u308c\u308b\u306e\u306b\u306f\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3002\n\n[\u7d50\u679c\u6574\u5408\u6027](#\u7d50\u679c\u6574\u5408\u6027)\u3000\u3092\u6c42\u3081\u308b\u30b5\u30fc\u30d3\u30b9\u306e\u969b\u306b\u306fAP\u3092\u63a1\u7528\u3059\u308b\u306e\u304c\u3044\u3044\u3067\u3057\u3087\u3046\u3002\u3082\u3057\u304f\u306f\u3001\u5916\u90e8\u30a8\u30e9\u30fc\u306b\u95a2\u308f\u3089\u305a\u30b7\u30b9\u30c6\u30e0\u304c\u7a3c\u50cd\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u969b\u306b\u3082\u540c\u69d8\u3067\u3059\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [CAP \u7406\u8ad6\u3092\u632f\u308a\u8fd4\u308b](http://robertgreiner.com/2014/08/cap-theorem-revisited/)\n* [\u5e73\u6613\u306a\u82f1\u8a9e\u3067\u306eCAP \u7406\u8ad6\u306e\u30a4\u30f3\u30c8\u30ed](http://ksat.me/a-plain-english-introduction-to-cap-theorem/)\n* [CAP FAQ](https://github.com/henryr/cap-faq)\n\n## \u4e00\u8cab\u6027\u30d1\u30bf\u30fc\u30f3\n\n\u540c\u3058\u30c7\u30fc\u30bf\u306e\u8907\u88fd\u304c\u8907\u6570\u3042\u308b\u72b6\u614b\u3067\u306f\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304c\u4e00\u8cab\u3057\u305f\u30c7\u30fc\u30bf\u8868\u793a\u3092\u53d7\u3051\u53d6\u308b\u305f\u3081\u306b\u3001\u3069\u306e\u3088\u3046\u306b\u305d\u308c\u3089\u3092\u540c\u671f\u3059\u308c\u3070\u3044\u3044\u306e\u304b\u3068\u3044\u3046\u8ab2\u984c\u304c\u3042\u308a\u307e\u3059\u3002 [CAP \u7406\u8ad6](#cap-\u7406\u8ad6) \u306b\u304a\u3051\u308b\u4e00\u8cab\u6027\u306e\u5b9a\u7fa9\u3092\u601d\u3044\u51fa\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u5168\u3066\u306e\u8aad\u307f\u53d6\u308a\u306f\u6700\u65b0\u306e\u66f8\u304d\u8fbc\u307f\u30c7\u30fc\u30bf\u3082\u3057\u304f\u306f\u30a8\u30e9\u30fc\u3092\u53d7\u3051\u53d6\u308b\u306f\u305a\u3067\u3059\u3002\n\n### \u5f31\u3044\u4e00\u8cab\u6027\n\n\u66f8\u304d\u8fbc\u307f\u5f8c\u306e\u8aad\u307f\u53d6\u308a\u3067\u306f\u3001\u305d\u306e\u6700\u65b0\u306e\u66f8\u304d\u8fbc\u307f\u3092\u8aad\u3081\u305f\u308a\u8aad\u3081\u306a\u304b\u3063\u305f\u308a\u3059\u308b\u3002\u30d9\u30b9\u30c8\u30a8\u30d5\u30a9\u30fc\u30c8\u578b\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306b\u57fa\u3065\u304f\u3002\n\n\u3053\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306fmemcached\u306a\u3069\u306e\u30b7\u30b9\u30c6\u30e0\u306b\u898b\u3089\u308c\u307e\u3059\u3002\u5f31\u3044\u4e00\u8cab\u6027\u306f\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u6027\u304c\u5fc5\u8981\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3001\u4f8b\u3048\u3070VoIP\u3001\u30d3\u30c7\u30aa\u30c1\u30e3\u30c3\u30c8\u3001\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30de\u30eb\u30c1\u30d7\u30ec\u30a4\u30e4\u30fc\u30b2\u30fc\u30e0\u306a\u3069\u3068\u76f8\u6027\u304c\u3044\u3044\u3067\u3057\u3087\u3046\u3002\u4f8b\u3048\u3070\u3001\u96fb\u8a71\u306b\u51fa\u3066\u3044\u308b\u3068\u304d\u306b\u6570\u79d2\u9593\u97f3\u58f0\u304c\u53d7\u3051\u53d6\u308c\u306a\u304f\u306a\u3063\u305f\u3068\u3057\u305f\u3089\u3001\u305d\u306e\u5f8c\u306b\u63a5\u7d9a\u304c\u56de\u5fa9\u3057\u3066\u3082\u305d\u306e\u63a5\u7d9a\u304c\u5207\u65ad\u3055\u308c\u3066\u3044\u305f\u9593\u306b\u8a71\u3055\u308c\u3066\u3044\u305f\u3053\u3068\u306f\u805e\u304d\u53d6\u308c\u306a\u3044\u3068\u3044\u3046\u3088\u3046\u306a\u611f\u3058\u3067\u3059\u3002\n\n### \u7d50\u679c\u6574\u5408\u6027\n\n\u66f8\u304d\u8fbc\u307f\u306e\u5f8c\u3001\u8aad\u307f\u53d6\u308a\u306f\u6700\u7d42\u7684\u306b\u306f\u305d\u306e\u7d50\u679c\u3092\u8aad\u307f\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u308b(\u30df\u30ea\u79d2\u307b\u3069\u9045\u308c\u3066\u3068\u3044\u3046\u306e\u304c\u4e00\u822c\u7684\u3067\u3059)\u3002\u30c7\u30fc\u30bf\u306f\u975e\u540c\u671f\u7684\u306b\u8907\u88fd\u3055\u308c\u307e\u3059\u3002\n\n\u3053\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306fDNS\u3084\u30e1\u30fc\u30eb\u30b7\u30b9\u30c6\u30e0\u306a\u3069\u306b\u63a1\u7528\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u7d50\u679c\u6574\u5408\u6027\u306f\u591a\u304f\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u634c\u304f\u30b5\u30fc\u30d3\u30b9\u3068\u76f8\u6027\u304c\u3044\u3044\u3067\u3057\u3087\u3046\u3002\n\n### \u5f37\u3044\u4e00\u8cab\u6027\n\n\u66f8\u304d\u8fbc\u307f\u306e\u5f8c\u3001\u8aad\u307f\u53d6\u308a\u306f\u305d\u308c\u3092\u5fc5\u305a\u8aad\u3080\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30c7\u30fc\u30bf\u306f\u540c\u671f\u7684\u306b\u8907\u88fd\u3055\u308c\u307e\u3059\u3002\n\n\u3053\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306f\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0\u3084RDBMS\u306a\u3069\u3067\u63a1\u7528\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\u3092\u6271\u3046\u30b5\u30fc\u30d3\u30b9\u3067\u306f\u5f37\u3044\u4e00\u8cab\u6027\u304c\u5fc5\u8981\u3067\u3057\u3087\u3046\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u9593\u3067\u306e\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3](http://snarfed.org/transactions_across_datacenters_io.html)\n\n## \u53ef\u7528\u6027\u30d1\u30bf\u30fc\u30f3\n\n\u9ad8\u3044\u53ef\u7528\u6027\u3092\u62c5\u4fdd\u3059\u308b\u306b\u306f\u4e3b\u306b\u6b21\u306e\u4e8c\u3064\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u3042\u308a\u307e\u3059: **\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc** \u3068 **\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3** \u3067\u3059\u3002\n\n### \u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\n\n#### \u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30d1\u30c3\u30b7\u30d6\n\n\u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30d1\u30c3\u30b7\u30d6\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\u306b\u304a\u3044\u3066\u306f\u3001\u5468\u671f\u4fe1\u53f7\u306f\u30a2\u30af\u30c6\u30a3\u30d6\u3082\u3057\u304f\u306f\u30b9\u30bf\u30f3\u30d0\u30a4\u4e2d\u306e\u30d1\u30c3\u30b7\u30d6\u306a\u30b5\u30fc\u30d0\u30fc\u306b\u9001\u3089\u308c\u307e\u3059\u3002\u5468\u671f\u4fe1\u53f7\u304c\u4e2d\u65ad\u3055\u308c\u305f\u6642\u306b\u306f\u3001\u30d1\u30c3\u30b7\u30d6\u3060\u3063\u305f\u30b5\u30fc\u30d0\u30fc\u304c\u30a2\u30af\u30c6\u30a3\u30d6\u30b5\u30fc\u30d0\u30fc\u306eIP\u30a2\u30c9\u30ec\u30b9\u3092\u5f15\u304d\u7d99\u3044\u3067\u30b5\u30fc\u30d3\u30b9\u3092\u518d\u958b\u3057\u307e\u3059\u3002\n\n\u8d77\u52d5\u307e\u3067\u306e\u30c0\u30a6\u30f3\u30bf\u30a4\u30e0\u306f\u30d1\u30c3\u30b7\u30d6\u30b5\u30fc\u30d0\u30fc\u304c\u300c\u30db\u30c3\u30c8\u300d\u306a\u30b9\u30bf\u30f3\u30d0\u30a4\u72b6\u614b\u306b\u3042\u308b\u304b\u3001\u300c\u30b3\u30fc\u30eb\u30c9\u300d\u306a\u30b9\u30bf\u30f3\u30d0\u30a4\u72b6\u614b\u306b\u3042\u308b\u304b\u3067\u5909\u308f\u308a\u307e\u3059\u3002\u30a2\u30af\u30c6\u30a3\u30d6\u306a\u30b5\u30fc\u30d0\u30fc\u306e\u307f\u304c\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u634c\u304d\u307e\u3059\u3002\n\n\u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30d1\u30c3\u30b7\u30d6\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\u306f\u30de\u30b9\u30bf\u30fc\u30fb\u30b9\u30ec\u30fc\u30d6\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\u3068\u547c\u3070\u308c\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\n\n#### \u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30a2\u30af\u30c6\u30a3\u30d6\n\n\u30a2\u30af\u30c6\u30a3\u30d6\u30a2\u30af\u30c6\u30a3\u30d6\u69cb\u6210\u3067\u306f\u4e21\u65b9\u306e\u30b5\u30fc\u30d0\u30fc\u304c\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u634c\u304f\u3053\u3068\u3067\u8ca0\u8377\u3092\u5206\u6563\u3057\u307e\u3059\u3002\n\n\u3053\u308c\u3089\u306e\u30b5\u30fc\u30d0\u30fc\u304c\u30d1\u30d6\u30ea\u30c3\u30af\u306a\u3082\u306e\u306e\u5834\u5408\u3001DNS\u306f\u4e21\u65b9\u306e\u30b5\u30fc\u30d0\u30fc\u306e\u30d1\u30d6\u30ea\u30c3\u30afIP\u3092\u77e5\u3063\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u3082\u3057\u3001\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u306a\u3082\u306e\u306a\u5834\u5408\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ed\u30b8\u30c3\u30af\u304c\u4e21\u65b9\u306e\u30b5\u30fc\u30d0\u30fc\u306e\u60c5\u5831\u306b\u3064\u3044\u3066\u77e5\u3063\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30a2\u30af\u30c6\u30a3\u30d6\u306a\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\u306f\u30de\u30b9\u30bf\u30fc\u30fb\u30de\u30b9\u30bf\u30fc\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\u3068\u547c\u3070\u308c\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\n\n### \u77ed\u6240: \u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\n\n* \u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc\u3067\u306f\u3088\u308a\u591a\u304f\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u3092\u8981\u3057\u3001\u8907\u96d1\u3055\u304c\u5897\u3057\u307e\u3059\u3002\n* \u6700\u65b0\u306e\u66f8\u304d\u8fbc\u307f\u304c\u30d1\u30c3\u30b7\u30d6\u30b5\u30fc\u30d0\u30fc\u306b\u8907\u88fd\u3055\u308c\u308b\u524d\u306b\u30a2\u30af\u30c6\u30a3\u30d6\u304c\u843d\u3061\u308b\u3068\u3001\u30c7\u30fc\u30bf\u6b20\u640d\u304c\u8d77\u304d\u308b\u6f5c\u5728\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n\n### \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n#### \u30de\u30b9\u30bf\u30fc\u30fb\u30b9\u30ec\u30fc\u30d6\u3000\u3068\u3000\u30de\u30b9\u30bf\u30fc\u30fb\u30de\u30b9\u30bf\u30fc\n\n\u3053\u306e\u30c8\u30d4\u30c3\u30af\u306f [\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](#\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9) \u30bb\u30af\u30b7\u30e7\u30f3\u306b\u304a\u3044\u3066\u3088\u308a\u8a73\u7d30\u306b\u89e3\u8aac\u3055\u308c\u3066\u3044\u307e\u3059:\n\n* [\u30de\u30b9\u30bf\u30fc\u30fb\u30b9\u30ec\u30fc\u30d6 \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](#\u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6-\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3)\n* [\u30de\u30b9\u30bf\u30fc\u30fb\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](#\u30de\u30b9\u30bf\u30fc\u30de\u30b9\u30bf\u30fc-\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3)\n\n## \u30c9\u30e1\u30a4\u30f3\u30cd\u30fc\u30e0\u30b7\u30b9\u30c6\u30e0\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/IOyLj4i.jpg\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/srikrupa5/dns-security-presentation-issa>Source: DNS security presentation</a></i>\n</p>\n\n\u30c9\u30e1\u30a4\u30f3\u30cd\u30fc\u30e0\u30b7\u30b9\u30c6\u30e0 (DNS) \u306f www.example.com \u306a\u3069\u306e\u30c9\u30e1\u30a4\u30f3\u30cd\u30fc\u30e0\u3092IP\u30a2\u30c9\u30ec\u30b9\u3078\u3068\u7ffb\u8a33\u3057\u307e\u3059\u3002\n\nDNS\u306f\u5c11\u6570\u306e\u30aa\u30fc\u30bd\u30e9\u30a4\u30ba\u3055\u308c\u305f\u30b5\u30fc\u30d0\u30fc\u304c\u4e0a\u4f4d\u306b\u4f4d\u7f6e\u3059\u308b\u968e\u5c64\u7684\u69cb\u9020\u3067\u3059\u3002\u3042\u306a\u305f\u306e\u30eb\u30fc\u30bf\u30fc\u3082\u3057\u304f\u306fISP\u306f\u691c\u7d22\u3092\u3059\u308b\u969b\u306b\u3069\u306eDNS\u30b5\u30fc\u30d0\u30fc\u306b\u63a5\u7d9a\u3059\u308b\u304b\u3068\u3044\u3046\u60c5\u5831\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u4f4e\u3044\u968e\u5c64\u306eDNS\u30b5\u30fc\u30d0\u30fc\u306f\u305d\u306e\u7d4c\u8def\u30de\u30c3\u30d7\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u3057\u307e\u3059\u3002\u305f\u3060\u3001\u3053\u306e\u60c5\u5831\u306f\u4f1d\u642c\u9045\u5ef6\u306b\u3088\u3063\u3066\u9673\u8150\u5316\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002DNS\u306e\u7d50\u679c\u306f\u3042\u306a\u305f\u306e\u30d6\u30e9\u30a6\u30b6\u3082\u3057\u304f\u306fOS\u306b\u4e00\u5b9a\u671f\u9593\uff08[time to live (TTL)](https://en.wikipedia.org/wiki/Time_to_live)\u306b\u8a2d\u5b9a\u3055\u308c\u305f\u671f\u9593\uff09\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u307e\u3059\u3002\n\n* **NS record (name server)** - \u3042\u306a\u305f\u306e\u30c9\u30e1\u30a4\u30f3\u30fb\u30b5\u30d6\u30c9\u30e1\u30a4\u30f3\u3067\u306eDNS\u30b5\u30fc\u30d0\u30fc\u3092\u7279\u5b9a\u3057\u307e\u3059\u3002\n* **MX record (mail exchange)** - \u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d7\u3051\u53d6\u308b\u30e1\u30fc\u30eb\u30b5\u30fc\u30d0\u30fc\u3092\u7279\u5b9a\u3057\u307e\u3059\u3002\n* **A record (address)** - IP\u30a2\u30c9\u30ec\u30b9\u306b\u540d\u524d\u3092\u3064\u3051\u307e\u3059\u3002\n* **CNAME (canonical)** - \u4ed6\u306e\u540d\u524d\u3082\u3057\u304f\u306f\u3000`CNAME` (example.com \u3092 www.example.com) \u3082\u3057\u304f\u306f `A` record\u3078\u3068\u540d\u524d\u3092\u6307\u3057\u793a\u3059\u3002\n\n[CloudFlare](https://www.cloudflare.com/dns/) \u3084 [Route 53](https://aws.amazon.com/route53/) \u306a\u3069\u306e\u30b5\u30fc\u30d3\u30b9\u306f\u30de\u30cd\u30fc\u30b8\u30c9DNS\u30b5\u30fc\u30d3\u30b9\u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u3002\u3044\u304f\u3064\u304b\u306eDNS\u30b5\u30fc\u30d3\u30b9\u3067\u306f\u69d8\u3005\u306a\u624b\u6cd5\u3092\u4f7f\u3063\u3066\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u634c\u304f\u3053\u3068\u304c\u3067\u304d\u307e\u3059:\n\n* [\u52a0\u91cd\u30e9\u30a6\u30f3\u30c9\u30ed\u30d3\u30f3](http://g33kinfo.com/info/archives/2657)\n    * \u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u304c\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9\u4e2d\u306e\u30b5\u30fc\u30d0\u30fc\u306b\u884c\u304f\u306e\u3092\u9632\u304e\u307e\u3059\n    * \u69d8\u3005\u306a\u30af\u30e9\u30b9\u30bf\u30fc\u30b5\u30a4\u30ba\u306b\u5fdc\u3058\u3066\u8abf\u6574\u3057\u307e\u3059\n    * A/B \u30c6\u30b9\u30c8\n* \u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u30d9\u30fc\u30b9\n* \u5730\u7406\u30d9\u30fc\u30b9\n\n### \u6b20\u70b9: DNS\n\n* \u4e0a\u8a18\u3067\u793a\u3055\u308c\u3066\u3044\u308b\u3088\u3046\u306a\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u306b\u3088\u3063\u3066\u7de9\u548c\u3055\u308c\u3066\u3044\u308b\u3068\u306f\u3044\u3048\u3001DNS\u30b5\u30fc\u30d0\u30fc\u3078\u306e\u63a5\u7d9a\u306b\u306f\u5c11\u3057\u9045\u5ef6\u304c\u751f\u3058\u308b\u3002\n* DNS\u30b5\u30fc\u30d0\u30fc\u306f\u3001[\u653f\u5e9c\u3001ISP\u4f01\u696d,\u305d\u3057\u3066\u5927\u4f01\u696d](http://superuser.com/questions/472695/who-controls-the-dns-servers/472729)\u306b\u7ba1\u7406\u3055\u308c\u3066\u3044\u308b\u304c\u3001\u305d\u308c\u3089\u306e\u7ba1\u7406\u306f\u8907\u96d1\u3067\u3042\u308b\u3002\n* DNS\u30b5\u30fc\u30d3\u30b9\u306f[DDoS attack](http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/)\u306e\u4f8b\u3067\u3001IP\u30a2\u30c9\u30ec\u30b9\u306a\u3057\u306b\u30e6\u30fc\u30b6\u30fc\u304cTwitter\u306a\u3069\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u306a\u304f\u306a\u3063\u305f\u3088\u3046\u306b\u3001\u653b\u6483\u3092\u53d7\u3051\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [DNS \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx)\n* [Wikipedia](https://en.wikipedia.org/wiki/Domain_Name_System)\n* [DNS \u8a18\u4e8b](https://support.dnsimple.com/categories/dns/)\n\n## \u30b3\u30f3\u30c6\u30f3\u30c4\u30c7\u30ea\u30d0\u30ea\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(Content delivery network)\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/h9TAuGI.jpg\"/>\n  <br/>\n  <i><a href=https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/>Source: Why use a CDN</a></i>\n</p>\n\n\u30b3\u30f3\u30c6\u30f3\u30c4\u30c7\u30ea\u30d0\u30ea\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(CDN)\u306f\u4e16\u754c\u4e2d\u306b\u914d\u7f6e\u3055\u308c\u305f\u30d7\u30ed\u30ad\u30b7\u30b5\u30fc\u30d0\u30fc\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u30e6\u30fc\u30b6\u30fc\u306b\u4e00\u756a\u5730\u7406\u7684\u306b\u8fd1\u3044\u30b5\u30fc\u30d0\u30fc\u304b\u3089\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u914d\u4fe1\u3059\u308b\u30b7\u30b9\u30c6\u30e0\u306e\u3053\u3068\u3067\u3059\u3002Amazon\u306eCloudFront\u306a\u3069\u306f\u4f8b\u5916\u7684\u306b\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u30b3\u30f3\u30c6\u30f3\u30c4\u3082\u914d\u4fe1\u3057\u307e\u3059\u304c\u3001\u4e00\u822c\u7684\u306b\u3001HTML/CSS/JS\u3001\u5199\u771f\u3001\u305d\u3057\u3066\u52d5\u753b\u306a\u3069\u306e\u9759\u7684\u30d5\u30a1\u30a4\u30eb\u304cCDN\u3092\u901a\u3058\u3066\u914d\u4fe1\u3055\u308c\u307e\u3059\u3002\u305d\u306e\u30b5\u30a4\u30c8\u306eDNS\u304c\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306b\u3069\u306e\u30b5\u30fc\u30d0\u30fc\u3068\u4ea4\u4fe1\u3059\u308b\u304b\u3068\u3044\u3046\u60c5\u5831\u3092\u4f1d\u3048\u307e\u3059\u3002\n\nCDN\u3092\u7528\u3044\u3066\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u914d\u4fe1\u3059\u308b\u3053\u3068\u3067\u4ee5\u4e0b\u306e\u4e8c\u3064\u306e\u7406\u7531\u3067\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u5287\u7684\u306b\u5411\u4e0a\u3057\u307e\u3059:\n\n* \u30e6\u30fc\u30b6\u30fc\u306f\u8fd1\u304f\u306b\u3042\u308b\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u304b\u3089\u53d7\u4fe1\u3067\u304d\u308b\n* \u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u30b5\u30fc\u30d0\u30fc\u306fCDN\u304c\u51e6\u7406\u3057\u3066\u304f\u308c\u308b\u30ea\u30af\u30a8\u30b9\u30c8\u306b\u95a2\u3057\u3066\u306f\u51e6\u7406\u3059\u308b\u5fc5\u8981\u304c\u306a\u304f\u306a\u308a\u307e\u3059\n\n### \u30d7\u30c3\u30b7\u30e5CDN\n\n\u30d7\u30c3\u30b7\u30e5CDN\u3067\u306f\u30b5\u30fc\u30d0\u30fc\u30c7\u30fc\u30bf\u306b\u66f4\u65b0\u304c\u3042\u3063\u305f\u6642\u306b\u306f\u5fc5\u305a\u3001\u65b0\u3057\u3044\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u53d7\u3051\u53d6\u308b\u65b9\u5f0f\u3067\u3059\u3002\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u7528\u610f\u3057\u3001CDN\u306b\u76f4\u63a5\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3001URL\u3092CDN\u3092\u6307\u3059\u3088\u3046\u306b\u6307\u5b9a\u3059\u308b\u3068\u3053\u308d\u307e\u3067\u3001\u5168\u3066\u81ea\u5206\u3067\u8cac\u4efb\u3092\u8ca0\u3046\u5f62\u3067\u3059\u3002\u30b3\u30f3\u30c6\u30f3\u30c4\u304c\u3044\u3064\u671f\u9650\u5207\u308c\u306b\u306a\u308b\u306e\u304b\u66f4\u65b0\u3055\u308c\u308b\u306e\u304b\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30b3\u30f3\u30c6\u30f3\u30c4\u306f\u65b0\u898f\u4f5c\u6210\u6642\u3001\u66f4\u65b0\u6642\u306e\u307f\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3055\u308c\u308b\u3053\u3068\u3067\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306f\u6700\u5c0f\u5316\u3055\u308c\u308b\u4e00\u65b9\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u306f\u6700\u5927\u9650\u6d88\u8cbb\u3055\u308c\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\n\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306e\u5c11\u306a\u3044\u3001\u3082\u3057\u304f\u306f\u983b\u7e41\u306b\u306f\u30b3\u30f3\u30c6\u30f3\u30c4\u304c\u66f4\u65b0\u3055\u308c\u306a\u3044\u30b5\u30a4\u30c8\u306e\u5834\u5408\u306b\u306f\u30d7\u30c3\u30b7\u30e5CDN\u3068\u76f8\u6027\u304c\u3044\u3044\u3067\u3057\u3087\u3046\u3002\u30b3\u30f3\u30c6\u30f3\u30c4\u306f\u5b9a\u671f\u7684\u306b\u518d\u3073\u30d7\u30eb\u3055\u308c\u308b\u306e\u3067\u306f\u306a\u304f\u3001CDN\u306b\u4e00\u5ea6\u306e\u307f\u914d\u7f6e\u3055\u308c\u307e\u3059\u3002\n\n### \u30d7\u30ebCDN\n\n\u30d7\u30ebCDN\u3067\u306f\u4e00\u4eba\u76ee\u306e\u30e6\u30fc\u30b6\u30fc\u304c\u30ea\u30af\u30a8\u30b9\u30c8\u3057\u305f\u6642\u306b\u3001\u65b0\u3057\u3044\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u30b5\u30fc\u30d3\u30b9\u306e\u30b5\u30fc\u30d0\u30fc\u304b\u3089\u53d6\u5f97\u3057\u307e\u3059\u3002\u30b3\u30f3\u30c6\u30f3\u30c4\u306f\u81ea\u5206\u306e\u30b5\u30fc\u30d0\u30fc\u306b\u4fdd\u5b58\u3057\u3066\u3001CDN\u3092\u6307\u3059URL\u3092\u66f8\u304d\u63db\u3048\u307e\u3059\u3002\u7d50\u679c\u3068\u3057\u3066\u3001CDN\u306b\u30b3\u30f3\u30c6\u30f3\u30c4\u304c\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u308b\u307e\u3067\u306f\u30ea\u30af\u30a8\u30b9\u30c8\u51e6\u7406\u304c\u9045\u304f\u306a\u308a\u307e\u3059\u3002\n\n[time-to-live (TTL)](https://en.wikipedia.org/wiki/Time_to_live) \u306f\u30b3\u30f3\u30c6\u30f3\u30c4\u304c\u3069\u308c\u3060\u3051\u306e\u671f\u9593\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u308b\u304b\u3092\u898f\u5b9a\u3057\u307e\u3059\u3002\u30d7\u30ebCDN\u306fCDN \u4e0a\u3067\u306e\u30b9\u30c8\u30ec\u30fc\u30b8\u30b9\u30da\u30fc\u30b9\u3092\u6700\u5c0f\u5316\u3057\u307e\u3059\u304c\u3001\u6709\u52b9\u671f\u9650\u304c\u5207\u308c\u305f\u30d5\u30a1\u30a4\u30eb\u304c\u66f4\u65b0\u524d\u306b\u30d7\u30eb\u3055\u308c\u3066\u3057\u307e\u3046\u3053\u3068\u3067\u5197\u9577\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306b\u7e4b\u304c\u3063\u3066\u3057\u307e\u3046\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u5927\u898f\u6a21\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306e\u3042\u308b\u30b5\u30a4\u30c8\u3067\u306f\u30d7\u30ebCDN\u304c\u76f8\u6027\u304c\u3044\u3044\u3067\u3057\u3087\u3046\u3002\u3068\u3044\u3046\u306e\u3082\u3001\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306e\u5927\u90e8\u5206\u306f\u6700\u8fd1\u30ea\u30af\u30a8\u30b9\u30c8\u3055\u308c\u3001CDN\u306b\u6b8b\u3063\u3066\u3044\u308b\u30b3\u30f3\u30c6\u30f3\u30c4\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b\u3082\u306e\u3067\u3042\u308b\u3053\u3068\u304c\u591a\u3044\u304b\u3089\u3067\u3059\u3002\n\n### \u6b20\u70b9: CDN\n\n* CDN\u306e\u30b3\u30b9\u30c8\u306f\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u91cf\u306b\u3088\u3063\u3066\u5909\u308f\u308a\u307e\u3059\u3002\u3082\u3061\u308d\u3093\u3001CDN\u3092\u4f7f\u308f\u306a\u3044\u5834\u5408\u306e\u30b3\u30b9\u30c8\u3068\u6bd4\u8f03\u3059\u308b\u3079\u304d\u3067\u3057\u3087\u3046\u3002\n* TTL\u304c\u5207\u308c\u308b\u524d\u306b\u30b3\u30f3\u30c6\u30f3\u30c4\u304c\u66f4\u65b0\u3055\u308c\u308b\u3068\u9673\u8150\u5316\u3059\u308b\u6050\u308c\u304c\u3042\u308a\u307e\u3059\u3002\n* CDN\u3067\u306f\u9759\u7684\u30b3\u30f3\u30c6\u30f3\u30c4\u304cCDN\u3092\u6307\u3059\u3088\u3046\u306bURL\u3092\u66f4\u65b0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [\u30b0\u30ed\u30fc\u30d0\u30eb\u306b\u5206\u6563\u3055\u308c\u305f\u30b3\u30f3\u30c6\u30f3\u30c4\u30c7\u30ea\u30d0\u30ea\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af](http://repository.cmu.edu/cgi/viewcontent.cgi?article=2112&context=compsci)\n* [\u30d7\u30c3\u30b7\u30e5CDN\u3068\u30d7\u30ebCDN\u306e\u9055\u3044](http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/)\n* [Wikipedia](https://en.wikipedia.org/wiki/Content_delivery_network)\n\n## \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/h81n9iK.png\"/>\n  <br/>\n  <i><a href=http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html>Source: Scalable system design patterns</a></i>\n</p>\n\n\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u5165\u529b\u3055\u308c\u308b\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b5\u30fc\u30d0\u30fc\u3084\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3078\u3068\u5206\u6563\u3055\u305b\u308b\u3002\u3069\u306e\u30b1\u30fc\u30b9\u3067\u3082\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u30b5\u30fc\u30d0\u30fc\u7b49\u8a08\u7b97\u30ea\u30bd\u30fc\u30b9\u304b\u3089\u306e\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u9069\u5207\u306a\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306b\u8fd4\u3059\u3002\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u4ee5\u4e0b\u306e\u3053\u3068\u306b\u52b9\u679c\u7684\u3067\u3059:\n\n* \u30ea\u30af\u30a8\u30b9\u30c8\u304c\u72b6\u614b\u306e\u826f\u304f\u306a\u3044\u30b5\u30fc\u30d0\u30fc\u306b\u884c\u304f\u306e\u3092\u9632\u3050\n* \u30ea\u30af\u30a8\u30b9\u30c8\u3092\u904e\u5270\u306b\u9001\u308b\u306e\u3092\u9632\u3050\n* \u7279\u5b9a\u7b87\u6240\u306e\u6b20\u9665\u3067\u30b5\u30fc\u30d3\u30b9\u304c\u843d\u3061\u308b\u3053\u3068\u3092\u9632\u3050\n\n\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f (\u8cbb\u7528\u306e\u9ad8\u3044) \u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u3082\u3057\u304f\u306fHAProxy\u306a\u3069\u306e\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u3067\u5b9f\u73fe\u3067\u304d\u308b\u3002\n\n\u4ed6\u306e\u5229\u70b9\u3068\u3057\u3066\u306f:\n\n* **SSL termination** - \u5165\u529b\u3055\u308c\u308b\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u89e3\u8aad\u3059\u308b\u3001\u307e\u305f\u3001\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u6697\u53f7\u5316\u3059\u308b\u3053\u3068\u3067\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u306e\u30b5\u30fc\u30d0\u30fc\u304c\u3053\u306e\u30b3\u30b9\u30c8\u304c\u9ad8\u304f\u3064\u304d\u304c\u3061\u306a\u51e6\u7406\u3092\u8acb\u3051\u8ca0\u308f\u306a\u304f\u3066\u3044\u3044\u3088\u3046\u306b\u80a9\u4ee3\u308f\u308a\u3057\u307e\u3059\u3002\n    * [X.509 certificates](https://en.wikipedia.org/wiki/X.509) \u3092\u305d\u308c\u305e\u308c\u306e\u30b5\u30fc\u30d0\u30fc\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5fc5\u8981\u3092\u306a\u304f\u3057\u307e\u3059\n* **\u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406** - \u30af\u30c3\u30ad\u30fc\u3092\u53d6\u308a\u6271\u3046\u30a6\u30a7\u30d6\u30a2\u30d7\u30ea\u304c\u30bb\u30c3\u30b7\u30e7\u30f3\u60c5\u5831\u3092\u4fdd\u6301\u3057\u3066\u3044\u306a\u3044\u6642\u306a\u3069\u306b\u3001\u7279\u5b9a\u306e\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u540c\u3058\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3078\u3068\u6d41\u3057\u307e\u3059\u3002\n\n\u969c\u5bb3\u306b\u5bfe\u5fdc\u3059\u308b\u305f\u3081\u306b\u3001[\u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30d1\u30c3\u30b7\u30d6](#\u30a2\u30af\u30c6\u30a3\u30d6\u30d1\u30c3\u30b7\u30d6) \u3082\u3057\u304f\u306f [\u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30a2\u30af\u30c6\u30a3\u30d6](#\u30a2\u30af\u30c6\u30a3\u30d6\u30a2\u30af\u30c6\u30a3\u30d6) \u30e2\u30fc\u30c9\u306e\u3069\u3061\u3089\u306b\u304a\u3044\u3066\u3082\u3001\u8907\u6570\u306e\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3092\u914d\u7f6e\u3059\u308b\u306e\u304c\u4e00\u822c\u7684\u3067\u3059\u3002\n\n\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7a2e\u3005\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u7528\u3044\u3066\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059:\n\n* \u30e9\u30f3\u30c0\u30e0\n* Least loaded\n* \u30bb\u30c3\u30b7\u30e7\u30f3/\u30af\u30c3\u30ad\u30fc\n* [\u30e9\u30a6\u30f3\u30c9\u30ed\u30d3\u30f3\u3082\u3057\u304f\u306f\u52a0\u91cd\u30e9\u30a6\u30f3\u30c9\u30ed\u30d3\u30f3](http://g33kinfo.com/info/archives/2657)\n* [Layer 4](#layer-4-\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0)\n* [Layer 7](#layer-7-\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0)\n\n### Layer 4 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\n\nLayer 4 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f [\u30c8\u30e9\u30f3\u30b9\u30dd\u30fc\u30c8\u30ec\u30a4\u30e4\u30fc](#\u901a\u4fe1) \u3092\u53c2\u7167\u3057\u3066\u3069\u306e\u3088\u3046\u306b\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u914d\u5206\u3059\u308b\u304b\u5224\u65ad\u3057\u307e\u3059\u3002\u4e00\u822c\u7684\u306b\u3001\u30c8\u30e9\u30f3\u30b9\u30dd\u30fc\u30c8\u30ec\u30a4\u30e4\u30fc\u3068\u3057\u3066\u306f\u3001\u30bd\u30fc\u30b9\u3001\u9001\u4fe1\u5148IP\u30a2\u30c9\u30ec\u30b9\u3001\u30d8\u30c3\u30c0\u30fc\u306b\u8a18\u8ff0\u3055\u308c\u305f\u30dd\u30fc\u30c8\u756a\u53f7\u304c\u542b\u307e\u308c\u307e\u3059\u304c\u3001\u30d1\u30b1\u30c3\u30c8\u306e\u4e2d\u8eab\u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u306f\u542b\u307f\u307e\u305b\u3093\u3002 Layer 4 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30d1\u30b1\u30c3\u30c8\u3092\u4e0a\u6d41\u30b5\u30fc\u30d0\u30fc\u3078\u5c4a\u3051\u3001\u4e0a\u6d41\u30b5\u30fc\u30d0\u30fc\u304b\u3089\u914d\u4fe1\u3059\u308b\u3053\u3068\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a2\u30c9\u30ec\u30b9\u5909\u63db [Network Address Translation (NAT)](https://www.nginx.com/resources/glossary/layer-4-load-balancing/) \u3092\u5b9f\u73fe\u3057\u307e\u3059\u3002\n\n### Layer 7 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\n\nLayer 7 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f [\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ec\u30a4\u30e4\u30fc](#\u901a\u4fe1) \u3092\u53c2\u7167\u3057\u3066\u3069\u306e\u3088\u3046\u306b\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u914d\u5206\u3059\u308b\u304b\u5224\u65ad\u3057\u307e\u3059\u3002\u30d8\u30c3\u30c0\u30fc\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u3001\u30af\u30c3\u30ad\u30fc\u306a\u3069\u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u306e\u3053\u3068\u3067\u3059\u3002Layer 7 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306e\u7d42\u7aef\u3092\u53d7\u3051\u6301\u3061 \u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8aad\u307f\u8fbc\u307f\u3001\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u306e\u5224\u65ad\u3092\u3057\u3001\u9078\u629e\u3057\u305f\u30b5\u30fc\u30d0\u30fc\u3068\u306e\u63a5\u7d9a\u3092\u7e4b\u304e\u307e\u3059\u3002\u4f8b\u3048\u3070 layer 7 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u52d5\u753b\u306e\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u76f4\u63a5\u3001\u305d\u306e\u30c7\u30fc\u30bf\u3092\u30db\u30b9\u30c8\u3057\u3066\u3044\u308b\u30b5\u30fc\u30d0\u30fc\u306b\u3064\u306a\u3050\u3068\u540c\u6642\u306b\u3001\u6c7a\u6e08\u51e6\u7406\u306a\u3069\u306e\u3088\u308a\u7e4a\u7d30\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5f37\u5316\u3055\u308c\u305f\u30b5\u30fc\u30d0\u30fc\u306b\u6d41\u3059\u3068\u3044\u3046\u3053\u3068\u3082\u3067\u304d\u308b\u3002\n\n\u67d4\u8edf\u6027\u3068\u306e\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306b\u306a\u308a\u307e\u3059\u304c\u3001 layer 4 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3067\u306fLayer 7\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3088\u308a\u3082\u6240\u8981\u6642\u9593\u3001\u8a08\u7b97\u30ea\u30bd\u30fc\u30b9\u3092\u5c11\u306a\u304f\u6e08\u307e\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u305f\u3060\u3057\u3001\u6628\u4eca\u306e\u6c4e\u7528\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u3067\u306f\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306f\u6700\u5c0f\u9650\u306e\u307f\u3057\u304b\u767a\u63ee\u3067\u304d\u306a\u3044\u3067\u3057\u3087\u3046\u3002\n\n### \u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\n\n\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3067\u306f\u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u306b\u3088\u3063\u3066\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u53ef\u7528\u6027\u3092\u5411\u4e0a\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u624b\u9803\u306a\u6c4e\u7528\u30de\u30b7\u30f3\u3092\u8ffd\u52a0\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u3055\u305b\u308b\u65b9\u304c\u3001\u4e00\u3064\u306e\u30b5\u30fc\u30d0\u30fc\u3092\u3088\u308a\u9ad8\u4fa1\u306a\u30de\u30b7\u30f3\u306b\u30b9\u30b1\u30fc\u30eb\u30a2\u30c3\u30d7\u3059\u308b\uff08**\u5782\u76f4\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0**\uff09\u3088\u308a\u8cbb\u7528\u5bfe\u52b9\u679c\u3082\u9ad8\u304f\u306a\u308a\u3001\u7d50\u679c\u7684\u306b\u53ef\u7528\u6027\u3082\u9ad8\u304f\u306a\u308a\u307e\u3059\u3002\u307e\u305f\u3001\u6c4e\u7528\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u3092\u6271\u3048\u308b\u4eba\u6750\u3092\u96c7\u3046\u65b9\u304c\u3001\u7279\u5316\u578b\u306e\u5546\u7528\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u3092\u6271\u3048\u308b\u4eba\u6750\u3092\u96c7\u3046\u3088\u308a\u3082\u7c21\u5358\u3067\u3057\u3087\u3046\u3002\n\n#### \u6b20\u70b9: \u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\n\n* \u6c34\u5e73\u7684\u306b\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3057\u3066\u3044\u304f\u3068\u3001\u8907\u96d1\u3055\u304c\u5897\u3059\u4e0a\u306b\u3001\u30b5\u30fc\u30d0\u30fc\u306e\u30af\u30ed\u30fc\u30cb\u30f3\u30b0\u304c\u5fc5\u8981\u306b\u306a\u308b\u3002\n    * \u30b5\u30fc\u30d0\u30fc\u306f\u30b9\u30c6\u30fc\u30c8\u30ec\u30b9\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308b: \u30e6\u30fc\u30b6\u30fc\u306b\u95a2\u9023\u3059\u308b\u30bb\u30c3\u30b7\u30e7\u30f3\u3084\u3001\u30d7\u30ed\u30d5\u30a3\u30fc\u30eb\u5199\u771f\u306a\u3069\u306e\u30c7\u30fc\u30bf\u3092\u6301\u3063\u3066\u306f\u3044\u3051\u306a\u3044\n    * \u30bb\u30c3\u30b7\u30e7\u30f3\u306f\u4e00\u5143\u7684\u306a[\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](#\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9) (SQL\u3001 NoSQL)\u306a\u3069\u306e\u30c7\u30fc\u30bf\u30b9\u30c8\u30a2\u306b\u30b9\u30c8\u30a2\u3055\u308c\u308b\u304b [\u30ad\u30e3\u30c3\u30b7\u30e5](#\u30ad\u30e3\u30c3\u30b7\u30e5) (Redis\u3001 Memcached)\u306b\u6b8b\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n* \u30ad\u30e3\u30c3\u30b7\u30e5\u3084\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306a\u3069\u306e\u4e0b\u6d41\u30b5\u30fc\u30d0\u30fc\u306f\u4e0a\u6d41\u30b5\u30fc\u30d0\u30fc\u304c\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u3059\u308b\u306b\u3064\u308c\u3066\u3088\u308a\u591a\u304f\u306e\u540c\u6642\u63a5\u7d9a\u3092\u4fdd\u305f\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\n\n### \u6b20\u70b9: \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\n\n* \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u30ea\u30bd\u30fc\u30b9\u304c\u4e0d\u8db3\u3057\u3066\u3044\u305f\u308a\u3001\u8a2d\u5b9a\u304c\u9069\u5207\u3067\u306a\u3044\u5834\u5408\u3001\u30b7\u30b9\u30c6\u30e0\u5168\u4f53\u306e\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u306b\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n* \u5358\u4e00\u969c\u5bb3\u70b9\u3092\u9664\u3053\u3046\u3068\u3057\u3066\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3092\u5c0e\u5165\u3057\u305f\u7d50\u679c\u3001\u8907\u96d1\u3055\u304c\u5897\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n* \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u304c\u4e00\u3064\u3060\u3051\u3060\u3068\u305d\u3053\u304c\u5358\u4e00\u969c\u5bb3\u70b9\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002\u4e00\u65b9\u3067\u3001\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3092\u8907\u6570\u306b\u3059\u308b\u3068\u3001\u3055\u3089\u306b\u8907\u96d1\u3055\u304c\u5897\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [NGINX \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/)\n* [HAProxy \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30ac\u30a4\u30c9](http://www.haproxy.org/download/1.2/doc/architecture.txt)\n* [\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3](http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones)\n* [Wikipedia](https://en.wikipedia.org/wiki/Load_balancing_(computing))\n* [Layer 4 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0](https://www.nginx.com/resources/glossary/layer-4-load-balancing/)\n* [Layer 7 \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0](https://www.nginx.com/resources/glossary/layer-7-load-balancing/)\n* [ELB listener config](http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html)\n\n## \u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7(web\u30b5\u30fc\u30d0\u30fc)\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/n41Azff.png\"/>\n  <br/>\n  <i><a href=https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg>Source: Wikipedia</a></i>\n  <br/>\n</p>\n\n\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u30b5\u30fc\u30d0\u30fc\u306f\u5185\u90e8\u30b5\u30fc\u30d3\u30b9\u3092\u307e\u3068\u3081\u3066\u5916\u90e8\u306b\u7d71\u4e00\u3055\u308c\u305f\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u63d0\u4f9b\u3059\u308b\u30a6\u30a7\u30d6\u30b5\u30fc\u30d0\u30fc\u3067\u3059\u3002\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u306f\u305d\u308c\u306b\u5bfe\u5fdc\u3059\u308b\u30b5\u30fc\u30d0\u30fc\u306b\u9001\u3089\u308c\u3066\u3001\u305d\u306e\u5f8c\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u304c\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306b\u8fd4\u3057\u307e\u3059\u3002\n\n\u4ed6\u306b\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u5229\u70b9\u304c\u3042\u308a\u307e\u3059:\n\n* **\u3088\u308a\u5805\u7262\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3** - \u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u30b5\u30fc\u30d0\u30fc\u306e\u60c5\u5831\u3092\u96a0\u3057\u305f\u308a\u3001IP\u30a2\u30c9\u30ec\u30b9\u3092\u30d6\u30e9\u30c3\u30af\u30ea\u30b9\u30c8\u5316\u3057\u305f\u308a\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3054\u3068\u306e\u63a5\u7d9a\u6570\u3092\u5236\u9650\u3057\u305f\u308a\u3067\u304d\u307e\u3059\u3002\n* **\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3084\u67d4\u8edf\u6027\u304c\u5897\u3057\u307e\u3059** - \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306f\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u306eIP\u3057\u304b\u898b\u306a\u3044\u306e\u3067\u3001\u88cf\u3067\u30b5\u30fc\u30d0\u30fc\u3092\u30b9\u30b1\u30fc\u30eb\u3057\u305f\u308a\u3001\u8a2d\u5b9a\u3092\u5909\u3048\u3084\u3059\u304f\u306a\u308a\u307e\u3059\u3002\n* **SSL termination** - \u5165\u529b\u3055\u308c\u308b\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u89e3\u8aad\u3057\u3001\u30b5\u30fc\u30d0\u30fc\u306e\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u6697\u53f7\u5316\u3059\u308b\u3053\u3068\u3067\u30b5\u30fc\u30d0\u30fc\u304c\u3053\u306e\u30b3\u30b9\u30c8\u306e\u304b\u304b\u308a\u3046\u308b\u51e6\u7406\u3092\u3057\u306a\u304f\u3066\u6e08\u3080\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n    * [X.509 \u8a3c\u660e\u66f8](https://en.wikipedia.org/wiki/X.509) \u3092\u5404\u30b5\u30fc\u30d0\u30fc\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5fc5\u8981\u304c\u306a\u304f\u306a\u308a\u307e\u3059\u3002\n* **\u5727\u7e2e** - \u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u5727\u7e2e\u3067\u304d\u307e\u3059\n* **\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0** - \u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u305f\u30ea\u30af\u30a8\u30b9\u30c8\u306b\u5bfe\u3057\u3066\u3001\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u8fd4\u3057\u307e\u3059\n* **\u9759\u7684\u30b3\u30f3\u30c6\u30f3\u30c4** - \u9759\u7684\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u76f4\u63a5\u9001\u4fe1\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n    * HTML/CSS/JS\n    * \u5199\u771f\n    * \u52d5\u753b\n    * \u306a\u3069\u306a\u3069\n\n### \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc vs \u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\n\n* \u8907\u6570\u306e\u30b5\u30fc\u30d0\u30fc\u304c\u3042\u308b\u6642\u306b\u306f\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u3068\u5f79\u306b\u7acb\u3064\u3067\u3057\u3087\u3046\u3002 \u3057\u3070\u3057\u3070\u3001\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306f\u540c\u3058\u6a5f\u80fd\u3092\u679c\u305f\u3059\u30b5\u30fc\u30d0\u30fc\u7fa4\u3078\u306e\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u634c\u304d\u307e\u3059\u3002\n* \u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u3067\u306f\u3001\u4e0a\u8a18\u306b\u8ff0\u3079\u305f\u3088\u3046\u306a\u5229\u70b9\u3092\u3001\u5358\u4e00\u306e\u30a6\u30a7\u30d6\u30b5\u30fc\u30d0\u30fc\u3084\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ec\u30a4\u30e4\u30fc\u306b\u5bfe\u3057\u3066\u3082\u793a\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n* NGINX \u3084 HAProxy \u306a\u3069\u306e\u6280\u8853\u306flayer 7 \u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u3068\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306e\u4e21\u65b9\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002\n\n### \u6b20\u70b9: \u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\n\n* \u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u3092\u5c0e\u5165\u3059\u308b\u3068\u30b7\u30b9\u30c6\u30e0\u306e\u8907\u96d1\u6027\u304c\u5897\u3057\u307e\u3059\u3002\n* \u5358\u4e00\u306e\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u306f\u5358\u4e00\u969c\u5bb3\u70b9\u306b\u306a\u308a\u3048\u307e\u3059\u3002\u4e00\u65b9\u3067\u3001\u8907\u6570\u306e\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7\u3092\u5c0e\u5165\u3059\u308b\u3068(\u4f8b: [\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc](https://en.wikipedia.org/wiki/Failover)) \u8907\u96d1\u6027\u306f\u3088\u308a\u5897\u3057\u307e\u3059\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7 vs \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc](https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/)\n* [NGINX \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/)\n* [HAProxy \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3 \u30ac\u30a4\u30c9](http://www.haproxy.org/download/1.2/doc/architecture.txt)\n* [Wikipedia](https://en.wikipedia.org/wiki/Reverse_proxy)\n\n## \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/yB5SYwm.png\"/>\n  <br/>\n  <i><a href=http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer>Source: Intro to architecting systems for scale</a></i>\n</p>\n\n\u30a6\u30a7\u30d6\u30ec\u30a4\u30e4\u30fc\u3092\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64 (\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u5c64\u3068\u3082\u8a00\u308f\u308c\u308b) \u3068\u5206\u96e2\u3059\u308b\u3053\u3068\u3067\u305d\u308c\u305e\u308c\u306e\u5c64\u3092\u72ec\u7acb\u306b\u30b9\u30b1\u30fc\u30eb\u3001\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\u65b0\u3057\u3044API\u3092\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u3001\u4e0d\u5fc5\u8981\u306b\u30a6\u30a7\u30d6\u30b5\u30fc\u30d0\u30fc\u3092\u8ffd\u52a0\u3059\u308b\u5fc5\u8981\u304c\u306a\u304f\u306a\u308a\u307e\u3059\u3002\n\n **\u5358\u4e00\u8cac\u4efb\u306e\u539f\u5247** \u3067\u306f\u3001\u5c0f\u3055\u3044\u81ea\u5f8b\u7684\u306a\u30b5\u30fc\u30d3\u30b9\u304c\u5354\u8abf\u3057\u3066\u52d5\u304f\u3088\u3046\u306b\u63d0\u5531\u3057\u3066\u3044\u307e\u3059\u3002\u5c0f\u3055\u3044\u30b5\u30fc\u30d3\u30b9\u306e\u5c0f\u3055\u3044\u30c1\u30fc\u30e0\u304c\u6025\u6210\u9577\u306e\u305f\u3081\u306b\u3088\u308a\u7a4d\u6975\u7684\u306a\u8a08\u753b\u3092\u7acb\u3066\u3089\u308c\u308b\u3088\u3046\u306b\u3059\u308b\u305f\u3081\u3067\u3059\u3002\n\n\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64\u306f[\u975e\u540c\u671f\u51e6\u7406](#\u975e\u540c\u671f\u51e6\u7406)\u3082\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002\n\n### \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\n\n\u72ec\u7acb\u3057\u3066\u30c7\u30d7\u30ed\u30a4\u3067\u304d\u308b\u3001\u5c0f\u898f\u6a21\u306a\u30e2\u30b8\u30e5\u30fc\u30eb\u69d8\u5f0f\u3067\u3042\u308b[\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9](https://en.wikipedia.org/wiki/Microservices)\u3082\u3053\u306e\u8b70\u8ad6\u306b\u95a2\u4fc2\u3057\u3066\u304f\u308b\u6280\u8853\u3067\u3057\u3087\u3046\u3002\u305d\u308c\u305e\u308c\u306e\u30b5\u30fc\u30d3\u30b9\u306f\u72ec\u81ea\u306e\u30d7\u30ed\u30bb\u30b9\u3092\u51e6\u7406\u3057\u3001\u660e\u78ba\u3067\u8efd\u91cf\u306a\u30e1\u30ab\u30cb\u30ba\u30e0\u3067\u901a\u4fe1\u3057\u3066\u3001\u305d\u306e\u76ee\u7684\u3068\u3059\u308b\u6a5f\u80fd\u3092\u5b9f\u73fe\u3057\u307e\u3059\u3002<sup><a href=https://smartbear.com/learn/api-design/what-are-microservices>1</a></sup>\n\n\u4f8b\u3048\u3070Pinterest\u3067\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u306b\u5206\u304b\u308c\u3066\u3044\u307e\u3059\u3002\u30e6\u30fc\u30b6\u30fc\u30d7\u30ed\u30d5\u30a3\u30fc\u30eb\u3001\u30d5\u30a9\u30ed\u30ef\u30fc\u3001\u30d5\u30a3\u30fc\u30c9\u3001\u691c\u7d22\u3001\u5199\u771f\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u306a\u3069\u3067\u3059\u3002\n\n### \u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\n\n[Consul](https://www.consul.io/docs/index.html)\u3001 [Etcd](https://coreos.com/etcd/docs/latest)\u3001 [Zookeeper](http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper) \u306a\u3069\u306e\u30b7\u30b9\u30c6\u30e0\u3067\u306f\u3001\u767b\u9332\u3055\u308c\u3066\u3044\u308b\u30b5\u30fc\u30d3\u30b9\u306e\u540d\u524d\u3001\u30a2\u30c9\u30ec\u30b9\u3001\u30dd\u30fc\u30c8\u306e\u60c5\u5831\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u3067\u3001\u30b5\u30fc\u30d3\u30b9\u540c\u58eb\u304c\u4e92\u3044\u3092\u898b\u3064\u3051\u3084\u3059\u304f\u3057\u3066\u3044\u307e\u3059\u3002\u30b5\u30fc\u30d3\u30b9\u306e\u5b8c\u5168\u6027\u306e\u78ba\u8a8d\u306b\u306f [Health checks](https://www.consul.io/intro/getting-started/checks.html) \u304c\u4fbf\u5229\u3067\u3001\u3053\u308c\u306b\u306f [HTTP](#hypertext-transfer-protocol-http) \u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u304c\u3088\u304f\u4f7f\u308f\u308c\u307e\u3059\u3002 Consul \u3068 Etcd \u306e\u3044\u305a\u308c\u3082\u7d44\u307f\u8fbc\u307f\u306e [key-value store](#\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2) \u3092\u6301\u3063\u3066\u304a\u308a\u3001\u8a2d\u5b9a\u30c7\u30fc\u30bf\u3084\u5171\u6709\u30c7\u30fc\u30bf\u306a\u3069\u306e\u30c7\u30fc\u30bf\u3092\u4fdd\u5b58\u3057\u3066\u304a\u304f\u3053\u3068\u306b\u4f7f\u308f\u308c\u307e\u3059\u3002\n\n### \u6b20\u70b9: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64\n\n* \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3001\u904b\u7528\u3001\u305d\u3057\u3066\u30d7\u30ed\u30bb\u30b9\u3092\u8003\u616e\u3059\u308b\u3068\u3001\u7de9\u304f\u7d50\u3073\u4ed8\u3051\u3089\u308c\u305f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64\u3092\u8ffd\u52a0\u3059\u308b\u306b\u306f\u3001\u30e2\u30ce\u30ea\u30b7\u30c3\u30af\u306a\u30b7\u30b9\u30c6\u30e0\u3068\u306f\u7570\u306a\u308b\u30a2\u30d7\u30ed\u30fc\u30c1\u304c\u5fc5\u8981\u3067\u3059\u3002\n* \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u306f\u30c7\u30d7\u30ed\u30a4\u3068\u904b\u7528\u306e\u70b9\u304b\u3089\u898b\u308b\u3068\u8907\u96d1\u6027\u304c\u5897\u3059\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [\u30b9\u30b1\u30fc\u30eb\u3059\u308b\u30b7\u30b9\u30c6\u30e0\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u8a2d\u8a08\u3059\u308b\u305f\u3081\u306e\u30a4\u30f3\u30c8\u30ed](http://lethain.com/introduction-to-architecting-systems-for-scale)\n* [\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u30a4\u30f3\u30bf\u30d3\u30e5\u30fc\u3092\u7d10\u89e3\u304f](http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview)\n* [\u30b5\u30fc\u30d3\u30b9\u6307\u5411\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://en.wikipedia.org/wiki/Service-oriented_architecture)\n* [Zookeeper\u306e\u30a4\u30f3\u30c8\u30ed\u30c0\u30af\u30b7\u30e7\u30f3](http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper)\n* [\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u3092\u4f5c\u308b\u305f\u3081\u306b\u77e5\u3063\u3066\u304a\u304d\u305f\u3044\u3053\u3068](https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/)\n\n## \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/Xkm5CXz.png\"/>\n  <br/>\n  <i><a href=https://www.youtube.com/watch?v=w95murBkYmU>Source: Scaling up to your first 10 million users</a></i>\n</p>\n\n### \u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30de\u30cd\u30b8\u30e1\u30f3\u30c8\u30b7\u30b9\u30c6\u30e0 (RDBMS)\n\nSQL\u306a\u3069\u306e\u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u30c6\u30fc\u30d6\u30eb\u306b\u6574\u7406\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306e\u96c6\u5408\u3067\u3042\u308b\u3002\n\n**ACID** \u306f\u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306b\u304a\u3051\u308b[\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3](https://en.wikipedia.org/wiki/Database_transaction)\u306e\u30d7\u30ed\u30d1\u30c6\u30a3\u306e\u96c6\u5408\u3067\u3042\u308b\n\n* **\u4e0d\u53ef\u5206\u6027** - \u305d\u308c\u305e\u308c\u306e\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\u306f\u3042\u308b\u304b\u306a\u3044\u304b\u306e\u3044\u305a\u308c\u304b\u3067\u3042\u308b\n* **\u4e00\u8cab\u6027** - \u3069\u3093\u306a\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\u3082\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u3042\u308b\u78ba\u304b\u306a\u72b6\u614b\u304b\u3089\u6b21\u306e\u72b6\u614b\u306b\u9077\u79fb\u3055\u305b\u308b\u3002\n* **\u72ec\u7acb\u6027** - \u540c\u6642\u306b\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\u3092\u51e6\u7406\u3059\u308b\u3053\u3068\u306f\u3001\u9023\u7d9a\u7684\u306b\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\u3092\u51e6\u7406\u3059\u308b\u306e\u3068\u540c\u3058\u7d50\u679c\u3092\u3082\u305f\u3089\u3059\u3002\n* **\u6c38\u7d9a\u6027** - \u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\u304c\u51e6\u7406\u3055\u308c\u305f\u3089\u3001\u305d\u306e\u3088\u3046\u306b\u4fdd\u5b58\u3055\u308c\u308b\n\n\u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u30b9\u30b1\u30fc\u30eb\u3055\u305b\u308b\u305f\u3081\u306b\u306f\u305f\u304f\u3055\u3093\u306e\u6280\u8853\u304c\u3042\u308b: **\u30de\u30b9\u30bf\u30fc\u30fb\u30b9\u30ec\u30fc\u30d6 \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3**\u3001 **\u30de\u30b9\u30bf\u30fc\u30fb\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3**\u3001 **federation**\u3001 **\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0**\u3001 **\u975e\u6b63\u898f\u5316**\u3001 \u305d\u3057\u3066 **SQL \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0**\n\n#### \u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6 \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n\u30de\u30b9\u30bf\u30fc\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u8aad\u307f\u53d6\u308a\u3068\u66f8\u304d\u8fbc\u307f\u3092\u51e6\u7406\u3057\u3001\u66f8\u304d\u8fbc\u307f\u3092\u4e00\u3064\u4ee5\u4e0a\u306e\u30b9\u30ec\u30fc\u30d6\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306b\u8907\u88fd\u3057\u307e\u3059\u3002\u30b9\u30ec\u30fc\u30d6\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u8aad\u307f\u53d6\u308a\u306e\u307f\u3092\u51e6\u7406\u3057\u307e\u3059\u3002\u30b9\u30ec\u30fc\u30d6\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u6728\u69cb\u9020\u306e\u3088\u3046\u306b\u8ffd\u52a0\u306e\u30b9\u30ec\u30fc\u30d6\u306b\u30c7\u30fc\u30bf\u3092\u8907\u88fd\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\u30de\u30b9\u30bf\u30fc\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u30aa\u30d5\u30e9\u30a4\u30f3\u306b\u306a\u3063\u305f\u5834\u5408\u306b\u306f\u3001\u3044\u305a\u308c\u304b\u306e\u30b9\u30ec\u30fc\u30d6\u304c\u30de\u30b9\u30bf\u30fc\u306b\u6607\u683c\u3059\u308b\u304b\u3001\u65b0\u3057\u3044\u30de\u30b9\u30bf\u30fc\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u8ffd\u52a0\u3055\u308c\u308b\u307e\u3067\u306f\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30e2\u30fc\u30c9\u3067\u7a3c\u50cd\u3057\u307e\u3059\u3002\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/C9ioGtn.png\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/jboner/scalability-availability-stability-patterns/>Source: Scalability, availability, stability, patterns</a></i>\n</p>\n\n##### \u6b20\u70b9: \u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6 \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n* \u30b9\u30ec\u30fc\u30d6\u3092\u30de\u30b9\u30bf\u30fc\u306b\u6607\u683c\u3055\u305b\u308b\u306b\u306f\u8ffd\u52a0\u306e\u30ed\u30b8\u30c3\u30af\u304c\u5fc5\u8981\u306b\u306a\u308b\u3002\n* \u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6 \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3001\u30de\u30b9\u30bf\u30fc\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e **\u4e21\u65b9** \u306e\u6b20\u70b9\u306f[\u6b20\u70b9: \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](#\u6b20\u70b9-\u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6-\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3)\u3092\u53c2\u7167\n\n#### \u30de\u30b9\u30bf\u30fc\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n\u3044\u305a\u308c\u306e\u30de\u30b9\u30bf\u30fc\u3082\u8aad\u307f\u53d6\u308a\u66f8\u304d\u8fbc\u307f\u306e\u4e21\u65b9\u306b\u5bfe\u5fdc\u3059\u308b\u3002\u66f8\u304d\u8fbc\u307f\u306b\u95a2\u3057\u3066\u306f\u305d\u308c\u305e\u308c\u5354\u8abf\u3059\u308b\u3002\u3044\u305a\u308c\u304b\u306e\u30de\u30b9\u30bf\u30fc\u304c\u843d\u3061\u3066\u3082\u3001\u30b7\u30b9\u30c6\u30e0\u5168\u4f53\u3068\u3057\u3066\u306f\u8aad\u307f\u66f8\u304d\u4e21\u65b9\u306b\u5bfe\u5fdc\u3057\u305f\u307e\u307e\u904b\u7528\u3067\u304d\u308b\u3002\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/krAHLGg.png\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/jboner/scalability-availability-stability-patterns/>Source: Scalability, availability, stability, patterns</a></i>\n</p>\n\n##### \u6b20\u70b9: \u30de\u30b9\u30bf\u30fc\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n* \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3092\u5c0e\u5165\u3059\u308b\u304b\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ed\u30b8\u30c3\u30af\u3092\u5909\u66f4\u3059\u308b\u3053\u3068\u3067\u3069\u3053\u306b\u66f8\u304d\u8fbc\u3080\u304b\u3092\u6307\u5b9a\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\n* \u5927\u4f53\u306e\u30de\u30b9\u30bf\u30fc\u30de\u30b9\u30bf\u30fc\u30b7\u30b9\u30c6\u30e0\u306f\u3001\u4e00\u8cab\u6027\u304c\u7de9\u3044\uff08ACID\u539f\u7406\u3092\u5b88\u3063\u3066\u3044\u306a\u3044\uff09\u3082\u3057\u304f\u306f\u3001\u540c\u671f\u3059\u308b\u6642\u9593\u304c\u304b\u304b\u308b\u305f\u3081\u306b\u66f8\u304d\u8fbc\u307f\u306e\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u304c\u5897\u52a0\u3057\u3066\u3057\u307e\u3063\u3066\u3044\u308b\u3002\n* \u66f8\u304d\u8fbc\u307f\u30ce\u30fc\u30c9\u304c\u8ffd\u52a0\u3055\u308c\u3001\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u304c\u5897\u52a0\u3059\u308b\u306b\u3064\u308c\u66f8\u304d\u8fbc\u307f\u306e\u885d\u7a81\u306e\u53ef\u80fd\u6027\u304c\u5897\u3048\u308b\u3002\n* \u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6 \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3001\u30de\u30b9\u30bf\u30fc\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e **\u4e21\u65b9** \u306e\u6b20\u70b9\u306f[\u6b20\u70b9: \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](#\u6b20\u70b9-\u30de\u30b9\u30bf\u30fc\u30b9\u30ec\u30fc\u30d6-\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3) \u3092\u53c2\u7167\n\n##### \u6b20\u70b9: \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n* \u65b0\u3057\u3044\u30c7\u30fc\u30bf\u66f8\u304d\u8fbc\u307f\u3092\u8907\u88fd\u3059\u308b\u524d\u306b\u30de\u30b9\u30bf\u30fc\u304c\u843d\u3061\u305f\u5834\u5408\u306b\u306f\u305d\u306e\u30c7\u30fc\u30bf\u304c\u5931\u308f\u308c\u3066\u3057\u307e\u3046\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002\n* \u66f8\u304d\u8fbc\u307f\u306f\u8aad\u307f\u53d6\u308a\u30ec\u30d7\u30ea\u30ab\u306b\u304a\u3044\u3066\u30ea\u30d7\u30ec\u30a4\u3055\u308c\u308b\u3002\u66f8\u304d\u8fbc\u307f\u304c\u591a\u3044\u5834\u5408\u3001\u8907\u88fd\u30ce\u30fc\u30c9\u304c\u66f8\u304d\u8fbc\u307f\u306e\u51e6\u7406\u306e\u307f\u3067\u884c\u304d\u8a70\u307e\u3063\u3066\u3001\u8aad\u307f\u53d6\u308a\u306e\u51e6\u7406\u3092\u6e80\u8db3\u306b\u884c\u3048\u306a\u3044\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002\n* \u8aad\u307f\u53d6\u308a\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u306e\u6570\u304c\u591a\u3051\u308c\u3070\u591a\u3044\u307b\u3069\u3001\u8907\u88fd\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u6570\u3082\u5897\u3048\u3001\u8907\u88fd\u6642\u9593\u304c\u4f38\u3073\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n* \u30b7\u30b9\u30c6\u30e0\u306b\u3088\u3063\u3066\u306f\u3001\u30de\u30b9\u30bf\u30fc\u3078\u306e\u66f8\u304d\u8fbc\u307f\u306f\u30de\u30eb\u30c1\u30b9\u30ec\u30c3\u30c9\u3067\u4e26\u5217\u51e6\u7406\u3067\u304d\u308b\u4e00\u65b9\u3001\u30b9\u30ec\u30fc\u30d6\u3078\u306e\u8907\u88fd\u306f\u5358\u4e00\u30b9\u30ec\u30c3\u30c9\u3067\u9023\u7d9a\u7684\u306b\u51e6\u7406\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\n* \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3067\u306f\u8ffd\u52a0\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u304c\u5fc5\u8981\u306b\u306a\u308a\u3001\u8907\u96d1\u6027\u3082\u5897\u3057\u307e\u3059\u3002\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n* [\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3001 \u53ef\u7528\u6027\u3001 \u30b9\u30bf\u30d3\u30ea\u30c6\u30a3 \u30d1\u30bf\u30fc\u30f3](http://www.slideshare.net/jboner/scalability-availability-stability-patterns/)\n* [\u30de\u30eb\u30c1\u30de\u30b9\u30bf\u30fc \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3](https://en.wikipedia.org/wiki/Multi-master_replication)\n\n#### Federation\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/U3qV33e.png\"/>\n  <br/>\n  <i><a href=https://www.youtube.com/watch?v=w95murBkYmU>Source: Scaling up to your first 10 million users</a></i>\n</p>\n\n\u30d5\u30a7\u30c7\u30ec\u30fc\u30b7\u30e7\u30f3 (\u3082\u3057\u304f\u306f\u6a5f\u80fd\u5206\u5272\u5316\u3068\u3082\u8a00\u3046) \u306f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u6a5f\u80fd\u3054\u3068\u306b\u5206\u5272\u3059\u308b\u3002\u4f8b\u3048\u3070\u3001\u30e2\u30ce\u30ea\u30b7\u30c3\u30af\u306a\u5358\u4e00\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u4ee3\u308f\u308a\u306b\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092 **\u30d5\u30a9\u30fc\u30e9\u30e0**\u3001 **\u30e6\u30fc\u30b6\u30fc**\u3001 **\u30d7\u30ed\u30c0\u30af\u30c8** \u306e\u3088\u3046\u306b\u4e09\u3064\u306b\u3059\u308b\u3053\u3068\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u4e00\u3064\u3042\u305f\u308a\u306e\u66f8\u304d\u8fbc\u307f\u30fb\u8aad\u307f\u53d6\u308a\u306e\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u304c\u6e1b\u308a\u3001\u305d\u306e\u7d50\u679c\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30e9\u30b0\u3082\u77ed\u304f\u306a\u308a\u307e\u3059\u3002\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u5c0f\u3055\u304f\u306a\u308b\u3053\u3068\u3067\u3001\u30e1\u30e2\u30ea\u30fc\u306b\u53ce\u307e\u308b\u30c7\u30fc\u30bf\u304c\u5897\u3048\u307e\u3059\u3002\u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u5c40\u6240\u6027\u304c\u9ad8\u307e\u308b\u305f\u3081\u3001\u30ad\u30e3\u30c3\u30b7\u30e5\u30d2\u30c3\u30c8\u7387\u3082\u4e0a\u304c\u308a\u307e\u3059\u3002\u5358\u4e00\u306e\u4e2d\u592e\u30de\u30b9\u30bf\u30fc\u3067\u66f8\u304d\u8fbc\u307f\u3092\u76f4\u5217\u5316\u3057\u305f\u308a\u3057\u306a\u3044\u305f\u3081\u3001\u4e26\u5217\u3067\u66f8\u304d\u8fbc\u307f\u3092\u51e6\u7406\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3001\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\u306e\u5411\u4e0a\u304c\u671f\u5f85\u3067\u304d\u307e\u3059\u3002\n\n##### \u6b20\u70b9: federation\n\n* \u5927\u898f\u6a21\u306a\u51e6\u7406\u3084\u30c6\u30fc\u30d6\u30eb\u3092\u8981\u3059\u308b\u30b9\u30ad\u30fc\u30de\u306e\u5834\u5408\u3001\u30d5\u30a7\u30c7\u30ec\u30fc\u30b7\u30e7\u30f3\u306f\u52b9\u679c\u7684\u3068\u306f\u8a00\u3048\u306a\u3044\u3067\u3057\u3087\u3046\u3002\n* \u3069\u306e\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306b\u8aad\u307f\u66f8\u304d\u3092\u3059\u308b\u306e\u304b\u3092\u6307\u5b9a\u3059\u308b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ed\u30b8\u30c3\u30af\u3092\u66f4\u65b0\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\n* [server link](http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers)\u3067\u4e8c\u3064\u306e\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304b\u3089\u306e\u30c7\u30fc\u30bf\u3092\u9023\u7d50\u3059\u308b\u306e\u306f\u3088\u308a\u8907\u96d1\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002\n* \u30d5\u30a7\u30c7\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u306f\u8ffd\u52a0\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u304c\u5fc5\u8981\u306b\u306a\u308a\u3001\u8907\u96d1\u6027\u3082\u5897\u3057\u307e\u3059\u3002\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: federation\n\n* [Scaling up to your first 10 million users](https://www.youtube.com/watch?v=w95murBkYmU)\n\n#### \u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/wU8x5Id.png\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/jboner/scalability-availability-stability-patterns/>Source: Scalability, availability, stability, patterns</a></i>\n</p>\n\n\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\u3067\u306f\u7570\u306a\u308b\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306b\u305d\u308c\u305e\u308c\u304c\u30c7\u30fc\u30bf\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u65ad\u7247\u306e\u307f\u3092\u6301\u3064\u3088\u3046\u306b\u30c7\u30fc\u30bf\u3092\u5206\u5272\u3057\u307e\u3059\u3002\u30e6\u30fc\u30b6\u30fc\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u4f8b\u306b\u3068\u308b\u3068\u3001\u30e6\u30fc\u30b6\u30fc\u6570\u304c\u5897\u3048\u308b\u306b\u3064\u308c\u3066\u30af\u30e9\u30b9\u30bf\u30fc\u306b\u306f\u3088\u308a\u591a\u304f\u306e\u65ad\u7247\u304c\u52a0\u3048\u3089\u308c\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n[federation](#federation)\u306e\u5229\u70b9\u306b\u4f3c\u3066\u3044\u3066\u3001\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\u3067\u306f\u8aad\u307f\u66f8\u304d\u306e\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u6e1b\u3089\u3057\u3001\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u6e1b\u3089\u3057\u3001\u30ad\u30e3\u30c3\u30b7\u30e5\u30d2\u30c3\u30c8\u3092\u5897\u3084\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u30b5\u30a4\u30ba\u3082\u6e1b\u3089\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u4e00\u822c\u7684\u306b\u306f\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u30b5\u30a4\u30ba\u3092\u6e1b\u3089\u3059\u3068\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u5411\u4e0a\u3057\u30af\u30a8\u30ea\u901f\u5ea6\u304c\u901f\u304f\u306a\u308a\u307e\u3059\u3002\u306a\u306b\u304c\u3057\u304b\u306e\u30c7\u30fc\u30bf\u3092\u8907\u88fd\u3059\u308b\u6a5f\u80fd\u304c\u306a\u3051\u308c\u3070\u30c7\u30fc\u30bf\u30ed\u30b9\u306b\u3064\u306a\u304c\u308a\u307e\u3059\u304c\u3001\u3082\u3057\u3001\u4e00\u3064\u306e\u30b7\u30e3\u30fc\u30c9\u304c\u843d\u3061\u3066\u3082\u3001\u4ed6\u306e\u30b7\u30e3\u30fc\u30c9\u304c\u52d5\u3044\u3066\u3044\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\u30d5\u30a7\u30c7\u30ec\u30fc\u30b7\u30e7\u30f3\u3068\u540c\u3058\u304f\u3001\u5358\u4e00\u306e\u4e2d\u592e\u30de\u30b9\u30bf\u30fc\u304c\u66f8\u304d\u8fbc\u307f\u306e\u51e6\u7406\u3092\u3057\u306a\u304f\u3066\u3082\u3001\u4e26\u5217\u3067\u66f8\u304d\u8fbc\u307f\u3092\u51e6\u7406\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3001\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\u306e\u5411\u4e0a\u304c\u671f\u5f85\u3067\u304d\u307e\u3059\u3002\n\n\u30e6\u30fc\u30b6\u30fc\u30c6\u30fc\u30d6\u30eb\u3092\u30b7\u30e3\u30fc\u30c9\u3059\u308b\u4e00\u822c\u7684\u306a\u65b9\u6cd5\u306f\u3001\u30e6\u30fc\u30b6\u30fc\u306e\u30e9\u30b9\u30c8\u30cd\u30fc\u30e0\u30a4\u30cb\u30b7\u30e3\u30eb\u3067\u30b7\u30e3\u30fc\u30c9\u3059\u308b\u304b\u3001\u30e6\u30fc\u30b6\u30fc\u306e\u5730\u7406\u7684\u914d\u7f6e\u3067\u30b7\u30e3\u30fc\u30c9\u3059\u308b\u306a\u3069\u3067\u3059\u3002\n\n##### \u6b20\u70b9: \u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\n\n* \u30b7\u30e3\u30fc\u30c9\u306b\u5bfe\u5fdc\u3059\u308b\u3088\u3046\u306b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ed\u30b8\u30c3\u30af\u3092\u5909\u66f4\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\u7d50\u679c\u3068\u3057\u3066SQL\u30af\u30a8\u30ea\u304c\u8907\u96d1\u306b\u306a\u308a\u307e\u3059\u3002\n* \u30b7\u30e3\u30fc\u30c9\u3067\u306f\u30c7\u30fc\u30bf\u914d\u5206\u304c\u3044\u3073\u3064\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001\u6a19\u6e96\u30e6\u30fc\u30b6\u30fc\u306e\u96c6\u5408\u3092\u6301\u3064\u30b7\u30e3\u30fc\u30c9\u304c\u3042\u308b\u5834\u5408\u3001\u305d\u306e\u30b7\u30e3\u30fc\u30c9\u304c\u4ed6\u306e\u30b7\u30e3\u30fc\u30c9\u3088\u308a\u3082\u91cd\u3044\u8ca0\u8377\u3092\u8ca0\u3046\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n    * \u30ea\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u3092\u3059\u308b\u3068\u8907\u96d1\u6027\u304c\u3088\u308a\u5897\u3057\u307e\u3059\u3002[consistent hashing](http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html) \u306b\u57fa\u3065\u3044\u305f\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\u3067\u306f\u3001\u901a\u4fe1\u30c7\u30fc\u30bf\u3092\u524a\u6e1b\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\n* \u8907\u6570\u306e\u30b7\u30e3\u30fc\u30c9\u304b\u3089\u306e\u30c7\u30fc\u30bf\u3092\u9023\u7d50\u3059\u308b\u306e\u306f\u3088\u308a\u8907\u96d1\u3067\u3059\u3002\n* \u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\u3067\u306f\u8ffd\u52a0\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u304c\u5fc5\u8981\u306b\u306a\u308a\u3001\u8907\u96d1\u6027\u3082\u5897\u3057\u307e\u3059\u3002\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: \u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0\n\n* [\u30b7\u30e3\u30fc\u30c9\u306e\u767b\u5834](http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html)\n* [\u30b7\u30e3\u30fc\u30c9\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://en.wikipedia.org/wiki/Shard_(database_architecture))\n* [Consistent hashing](http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html)\n\n#### \u975e\u6b63\u898f\u5316\n\n\u975e\u6b63\u898f\u5316\u3067\u306f\u3001\u66f8\u304d\u8fbc\u307f\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u3044\u304f\u3089\u304b\u72a0\u7272\u306b\u3057\u3066\u8aad\u307f\u8fbc\u307f\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a\u3055\u305b\u3088\u3046\u3068\u3057\u307e\u3059\u3002\u8a08\u7b97\u7684\u306b\u91cd\u3044\u30c6\u30fc\u30d6\u30eb\u306e\u7d50\u5408\u306a\u3069\u3092\u305b\u305a\u306b\u3001\u8907\u6570\u306e\u30c6\u30fc\u30d6\u30eb\u306b\u5197\u9577\u306a\u30c7\u30fc\u30bf\u306e\u30b3\u30d4\u30fc\u304c\u66f8\u304d\u8fbc\u307e\u308c\u308b\u306e\u3092\u8a31\u5bb9\u3057\u307e\u3059\u3002\u3044\u304f\u3064\u304b\u306eRDBMS\u4f8b\u3048\u3070\u3001[PostgreSQL](https://en.wikipedia.org/wiki/PostgreSQL) \u3084Oracle\u306f\u3053\u306e\u5197\u9577\u306a\u60c5\u5831\u3092\u53d6\u308a\u6271\u3044\u3001\u4e00\u8cab\u6027\u3092\u4fdd\u3064\u305f\u3081\u306e[materialized views](https://en.wikipedia.org/wiki/Materialized_view) \u3068\u3044\u3046\u6a5f\u80fd\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002\n\n[\u30d5\u30a7\u30c7\u30ec\u30fc\u30b7\u30e7\u30f3](#federation) \u3084 [\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0](#\u30b7\u30e3\u30fc\u30c7\u30a3\u30f3\u30b0)\u306a\u3069\u306e\u30c6\u30af\u30cb\u30c3\u30af\u306b\u3088\u3063\u3066\u305d\u308c\u305e\u308c\u306e\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u306b\u5206\u914d\u3055\u308c\u305f\u30c7\u30fc\u30bf\u3092\u5408\u4e00\u3055\u305b\u308b\u3053\u3068\u306f\u3068\u3066\u3082\u8907\u96d1\u306a\u4f5c\u696d\u3067\u3059\u3002\u975e\u6b63\u898f\u5316\u306b\u3088\u3063\u3066\u305d\u306e\u3088\u3046\u306a\u8907\u96d1\u306a\u51e6\u7406\u3092\u3057\u306a\u304f\u3066\u6e08\u3080\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u591a\u304f\u306e\u30b7\u30b9\u30c6\u30e0\u3067\u3001100\u5bfe1\u3042\u308b\u3044\u306f1000\u5bfe1\u304f\u3089\u3044\u306b\u306a\u308b\u304f\u3089\u3044\u8aad\u307f\u53d6\u308a\u306e\u65b9\u304c\u3001\u66f8\u304d\u8fbc\u307f\u306e\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3088\u308a\u3082\u591a\u3044\u3053\u3068\u3067\u3057\u3087\u3046\u3002\u8aad\u307f\u8fbc\u307f\u3092\u884c\u3046\u305f\u3081\u306b\u3001\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u30b8\u30e7\u30a4\u30f3\u51e6\u7406\u304c\u542b\u307e\u308c\u308b\u3082\u306e\u306f\u8a08\u7b97\u7684\u306b\u9ad8\u4fa1\u306b\u3064\u304d\u307e\u3059\u3057\u3001\u30c7\u30a3\u30b9\u30af\u306e\u51e6\u7406\u6642\u9593\u3067\u81a8\u5927\u306a\u6642\u9593\u3092\u8cbb\u6d88\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n##### \u6b20\u70b9: \u975e\u6b63\u898f\u5316\n\n* \u30c7\u30fc\u30bf\u304c\u8907\u88fd\u3055\u308c\u308b\u3002\n* \u5197\u9577\u306a\u30c7\u30fc\u30bf\u306e\u8907\u88fd\u304c\u540c\u671f\u3055\u308c\u308b\u3088\u3046\u306b\u5236\u7d04\u304c\u5b58\u5728\u3057\u3001\u305d\u306e\u3053\u3068\u3067\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u5168\u4f53\u306e\u8a2d\u8a08\u304c\u8907\u96d1\u5316\u3059\u308b\u3002\n* \u975e\u6b63\u898f\u5316\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u904e\u5927\u306a\u66f8\u304d\u8fbc\u307f\u3092\u51e6\u7406\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u5834\u5408\u3001\u6b63\u898f\u5316\u3055\u308c\u3066\u3044\u308b\u305d\u308c\u3088\u308a\u3082\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u304a\u3044\u3066\u52a3\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002\n\n###### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: \u975e\u6b63\u898f\u5316\n\n* [Denormalization](https://en.wikipedia.org/wiki/Denormalization)\n\n#### SQL\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\n\nSQL\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306f\u5e83\u7bc4\u306a\u77e5\u8b58\u3092\u5fc5\u8981\u3068\u3059\u308b\u5206\u91ce\u3067\u591a\u304f\u306e [\u672c](https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&field-keywords=sql+tuning) \u304c\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\n\n\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u3092\u660e\u3089\u304b\u306b\u3057\u3001\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3059\u308b\u4e0a\u3067\u3001 **\u30d9\u30f3\u30c1\u30de\u30fc\u30af** \u3092\u5b9a\u3081\u3001 **\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb** \u3059\u308b\u3053\u3068\u306f\u3068\u3066\u3082\u91cd\u8981\u3067\u3059\u3002\n\n* **\u30d9\u30f3\u30c1\u30de\u30fc\u30af** - [ab](http://httpd.apache.org/docs/2.2/programs/ab.html)\u306a\u3069\u306e\u30c4\u30fc\u30eb\u3092\u7528\u3044\u3066\u3001\u9ad8\u8ca0\u8377\u306e\u72b6\u6cc1\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n* **\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb** - [slow query log](http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html) \u306a\u3069\u306e\u30c4\u30fc\u30eb\u3092\u7528\u3044\u3066\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u72b6\u6cc1\u306e\u78ba\u8a8d\u3092\u3057\u307e\u3057\u3087\u3046\u3002\n\n\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3068\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u3068\u308b\u3053\u3068\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u52b9\u7387\u5316\u306e\u9078\u629e\u80a2\u3092\u3068\u308b\u3053\u3068\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002\n\n##### \u30b9\u30ad\u30fc\u30de\u3092\u7d5e\u308b\n\n* MySQL\u306f\u30a2\u30af\u30bb\u30b9\u901f\u5ea6\u5411\u4e0a\u306e\u305f\u3081\u3001\u30c7\u30a3\u30b9\u30af\u4e0a\u306e\u9023\u7d9a\u3057\u305f\u30d6\u30ed\u30c3\u30af\u3078\u30c7\u30fc\u30bf\u3092\u683c\u7d0d\u3057\u3066\u3044\u307e\u3059\u3002\n* \u9577\u3055\u306e\u6c7a\u307e\u3063\u305f\u30d5\u30a3\u30fc\u30eb\u30c9\u306b\u5bfe\u3057\u3066\u306f `VARCHAR` \u3088\u308a\u3082 `CHAR` \u3092\u4f7f\u3046\u3088\u3046\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n    * `CHAR` \u306e\u65b9\u304c\u52b9\u7387\u7684\u306b\u901f\u304f\u30e9\u30f3\u30c0\u30e0\u306b\u30c7\u30fc\u30bf\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u307e\u3059\u3002 \u4e00\u65b9\u3001 `VARCHAR` \u3067\u306f\u6b21\u306e\u30c7\u30fc\u30bf\u306b\u79fb\u308b\u524d\u306b\u30c7\u30fc\u30bf\u306e\u672b\u5c3e\u3092\u691c\u77e5\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u305f\u3081\u306b\u901f\u5ea6\u304c\u72a0\u7272\u306b\u306a\u308a\u307e\u3059\u3002\n* \u30d6\u30ed\u30b0\u306e\u6295\u7a3f\u306a\u3069\u3001\u5927\u304d\u306a\u30c6\u30ad\u30b9\u30c8\u306b\u306f TEXT \u3092\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002 TEXT \u3067\u306f\u30d6\u30fc\u30ea\u30a2\u30f3\u578b\u306e\u691c\u7d22\u3082\u53ef\u80fd\u3067\u3059\u3002 TEXT \u30d5\u30a3\u30fc\u30eb\u30c9\u306b\u306f\u3001\u30c6\u30ad\u30b9\u30c8\u30d6\u30ed\u30c3\u30af\u304c\u914d\u7f6e\u3055\u308c\u3066\u3044\u308b\u3001\u30c7\u30a3\u30b9\u30af\u4e0a\u306e\u5834\u6240\u3078\u306e\u30dd\u30a4\u30f3\u30bf\u30fc\u304c\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002\n* 2\u306e32\u4e57\u308440\u5104\u4ee5\u4e0b\u3092\u8d85\u3048\u306a\u3044\u7a0b\u5ea6\u306e\u5927\u304d\u306a\u6570\u306b\u306f INT \u3092\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002\n* \u901a\u8ca8\u306b\u95a2\u3057\u3066\u306f\u5c0f\u6570\u70b9\u8868\u793a\u4e0a\u306e\u30a8\u30e9\u30fc\u3092\u907f\u3051\u308b\u305f\u3081\u306b `DECIMAL` \u3092\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002\n* \u5927\u304d\u306a `BLOBS` \u3092\u4fdd\u5b58\u3059\u308b\u306e\u306f\u907f\u3051\u307e\u3057\u3087\u3046\u3002\u3069\u3053\u304b\u3089\u305d\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u53d6\u3063\u3066\u304f\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u304b\u306e\u60c5\u5831\u3092\u4fdd\u5b58\u3057\u307e\u3057\u3087\u3046\u3002\n* `VARCHAR(255)` \u306f8\u30d3\u30c3\u30c8\u3067\u6570\u3048\u3089\u308c\u308b\u6700\u5927\u306e\u6587\u5b57\u6570\u3067\u3059\u3002\u4e00\u90e8\u306eDBMS\u3067\u306f\u30011\u30d0\u30a4\u30c8\u306e\u5229\u7528\u52b9\u7387\u3092\u6700\u5927\u5316\u3059\u308b\u305f\u3081\u306b\u3053\u306e\u6587\u5b57\u6570\u304c\u3088\u304f\u4f7f\u308f\u308c\u307e\u3059\u3002\n* [\u691c\u7d22\u6027\u80fd\u5411\u4e0a\u306e\u305f\u3081](http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search) \u3001\u53ef\u80fd\u3067\u3042\u308c\u3070 `NOT NULL` \u5236\u7d04\u3092\u8a2d\u5b9a\u3057\u307e\u3057\u3087\u3046\u3002\n\n##### \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u52b9\u679c\u7684\u306b\u7528\u3044\u308b\n\n* \u30af\u30a8\u30ea(`SELECT`\u3001 `GROUP BY`\u3001 `ORDER BY`\u3001 `JOIN`) \u306e\u5bfe\u8c61\u3068\u306a\u308b\u5217\u306b\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u4f7f\u3046\u3053\u3068\u3067\u901f\u5ea6\u3092\u5411\u4e0a\u3067\u304d\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n* \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306f\u901a\u5e38\u3001\u5e73\u8861\u63a2\u7d22\u6728\u3067\u3042\u308b[B\u6728](https://en.wikipedia.org/wiki/B-tree)\u306e\u5f62\u3067\u8868\u3055\u308c\u307e\u3059\u3002B\u6728\u306b\u3088\u308a\u30c7\u30fc\u30bf\u306f\u5e38\u306b\u30bd\u30fc\u30c8\u3055\u308c\u305f\u72b6\u614b\u306b\u306a\u308a\u307e\u3059\u3002\u307e\u305f\u691c\u7d22\u3001\u9806\u6b21\u30a2\u30af\u30bb\u30b9\u3001\u633f\u5165\u3001\u524a\u9664\u3092\u5bfe\u6570\u6642\u9593\u3067\u884c\u3048\u307e\u3059\u3002\n* \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u914d\u7f6e\u3059\u308b\u3053\u3068\u306f\u30c7\u30fc\u30bf\u3092\u30e1\u30e2\u30ea\u30fc\u306b\u6b8b\u3059\u3053\u3068\u306b\u3064\u306a\u304c\u308a\u3088\u308a\u5bb9\u91cf\u3092\u5fc5\u8981\u3068\u3057\u307e\u3059\u3002\n* \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u66f4\u65b0\u3082\u5fc5\u8981\u306b\u306a\u308b\u305f\u3081\u66f8\u304d\u8fbc\u307f\u3082\u9045\u304f\u306a\u308a\u307e\u3059\u3002\n* \u5927\u91cf\u306e\u30c7\u30fc\u30bf\u3092\u30ed\u30fc\u30c9\u3059\u308b\u969b\u306b\u306f\u3001\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u5207\u3063\u3066\u304b\u3089\u30c7\u30fc\u30bf\u3092\u30ed\u30fc\u30c9\u3057\u3066\u518d\u3073\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u30d3\u30eb\u30c9\u3057\u305f\u65b9\u304c\u901f\u3044\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\n\n##### \u9ad8\u8ca0\u8377\u306a\u30b8\u30e7\u30a4\u30f3\u3092\u907f\u3051\u308b\n\n* \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u4e0a\u5fc5\u8981\u306a\u3068\u3053\u308d\u306b\u306f[\u975e\u6b63\u898f\u5316](#\u975e\u6b63\u898f\u5316)\u3092\u9069\u7528\u3059\u308b\n\n##### \u30c6\u30fc\u30d6\u30eb\u306e\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30f3\n\n* \u30c6\u30fc\u30d6\u30eb\u3092\u5206\u5272\u3057\u3001\u30db\u30c3\u30c8\u30b9\u30dd\u30c3\u30c8\u3092\u72ec\u7acb\u3057\u305f\u30c6\u30fc\u30d6\u30eb\u306b\u5206\u96e2\u3057\u3066\u30e1\u30e2\u30ea\u30fc\u306b\u4e57\u305b\u3089\u308c\u308b\u3088\u3046\u306b\u3059\u308b\u3002\n\n##### \u30af\u30a8\u30ea\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u8abf\u6574\u3059\u308b\n\n* \u5834\u5408\u306b\u3088\u3063\u3066\u306f[\u30af\u30a8\u30ea\u30ad\u30e3\u30c3\u30b7\u30e5](http://dev.mysql.com/doc/refman/5.7/en/query-cache) \u304c[\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u554f\u984c](https://www.percona.com/blog/2014/01/28/10-mysql-performance-tuning-settings-after-installation/) \u3092\u5f15\u304d\u8d77\u3053\u3059\u53ef\u80fd\u6027\u304c\u3042\u308b\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: SQL\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\n\n* [MySQL\u30af\u30a8\u30ea\u3092\u6700\u9069\u5316\u3059\u308b\u305f\u3081\u306eTips](http://20bits.com/article/10-tips-for-optimizing-mysql-queries-that-dont-suck)\n* [VARCHAR(255)\u3092\u3084\u305f\u3089\u3088\u304f\u898b\u304b\u3051\u308b\u306e\u306f\u306a\u3093\u3067\uff1f](http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l)\n* [null\u5024\u306f\u3069\u306e\u3088\u3046\u306b\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u5f71\u97ff\u3059\u308b\u306e\u304b\uff1f](http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search)\n* [Slow query log](http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html)\n\n### NoSQL\n\nNoSQL \u306f **key-value store**\u3001 **document-store**\u3001 **wide column store**\u3001 \u3082\u3057\u304f\u306f **graph database**\u306b\u3088\u3063\u3066\u8868\u73fe\u3055\u308c\u308b\u30c7\u30fc\u30bf\u30a2\u30a4\u30c6\u30e0\u306e\u96c6\u5408\u3067\u3059\u3002\u30c7\u30fc\u30bf\u306f\u4e00\u822c\u7684\u306b\u6b63\u898f\u5316\u3055\u308c\u3066\u304a\u3089\u305a\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5074\u3067\u30b8\u30e7\u30a4\u30f3\u304c\u884c\u308f\u308c\u307e\u3059\u3002\u5927\u90e8\u5206\u306eNoSQL\u306f\u771f\u306eACID\u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\u3092\u6301\u305f\u305a\u3001 [\u7d50\u679c\u6574\u5408\u6027](#\u7d50\u679c\u6574\u5408\u6027) \u7684\u306a\u632f\u308b\u821e\u3044\u306e\u65b9\u3092\u597d\u307f\u307e\u3059\u3002\n\n**BASE** \u306f\u3057\u3070\u3057\u3070NoSQL\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u30d7\u30ed\u30d1\u30c6\u30a3\u3092\u8aac\u660e\u3059\u308b\u305f\u3081\u306b\u7528\u3044\u3089\u308c\u307e\u3059\u3002[CAP Theorem](#cap-\u7406\u8ad6) \u3068\u5bfe\u7167\u7684\u306b\u3001BASE\u306f\u4e00\u8cab\u6027\u3088\u308a\u3082\u53ef\u7528\u6027\u3092\u512a\u5148\u3057\u307e\u3059\u3002\n\n* **Basically available** - \u30b7\u30b9\u30c6\u30e0\u306f\u53ef\u7528\u6027\u3092\u4fdd\u8a3c\u3057\u307e\u3059\u3002\n* **Soft state** - \u30b7\u30b9\u30c6\u30e0\u306e\u72b6\u614b\u306f\u5165\u529b\u304c\u306a\u304f\u3066\u3082\u6642\u9593\u7d4c\u904e\u3068\u3068\u3082\u306b\u5909\u5316\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n* **\u7d50\u679c\u6574\u5408\u6027** - \u30b7\u30b9\u30c6\u30e0\u5168\u4f53\u306f\u6642\u9593\u7d4c\u904e\u3068\u3068\u3082\u306b\u305d\u306e\u9593\u306b\u5165\u529b\u304c\u306a\u3044\u3068\u3044\u3046\u524d\u63d0\u306e\u3082\u3068\u3001\u4e00\u8cab\u6027\u304c\u9054\u6210\u3055\u308c\u307e\u3059\u3002\n\n[SQL\u304b\uff1fNoSQL\u304b\uff1f](#sql\u304bnosql\u304b) \u3092\u9078\u629e\u3059\u308b\u306e\u306b\u52a0\u3048\u3066\u3001\u3069\u306e\u30bf\u30a4\u30d7\u306eNoSQL\u304c\u3069\u306e\u4f7f\u7528\u4f8b\u306b\u6700\u3082\u9069\u3059\u308b\u304b\u3092\u7406\u89e3\u3059\u308b\u306e\u306f\u3068\u3066\u3082\u6709\u76ca\u3067\u3059\u3002\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f **\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2**\u3001 **\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2**\u3001 **\u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2**\u3001 \u3068 **\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9** \u306b\u3064\u3044\u3066\u89e6\u308c\u3066\u3044\u304d\u307e\u3059\u3002\n\n#### \u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\n\n> \u6982\u8981: \u30cf\u30c3\u30b7\u30e5\u30c6\u30fc\u30d6\u30eb\n\n\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u3067\u306f\u4e00\u822c\u7684\u306bO(1)\u306e\u8aad\u307f\u66f8\u304d\u304c\u3067\u304d\u3001\u305d\u308c\u3089\u306f\u30e1\u30e2\u30ea\u306a\u3044\u3057SSD\u3067\u88cf\u4ed8\u3051\u3089\u308c\u3066\u3044\u307e\u3059\u3002\u30c7\u30fc\u30bf\u30b9\u30c8\u30a2\u306f\u30ad\u30fc\u3092 [\u8f9e\u66f8\u7684\u9806\u5e8f](https://en.wikipedia.org/wiki/Lexicographical_order) \u3067\u4fdd\u6301\u3059\u308b\u3053\u3068\u3067\u30ad\u30fc\u306e\u52b9\u7387\u7684\u306a\u53d6\u5f97\u3092\u53ef\u80fd\u306b\u3057\u3066\u3044\u307e\u3059\u3002\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u3067\u306f\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u5024\u3068\u3068\u3082\u306b\u4fdd\u6301\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\n\n\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u306f\u30cf\u30a4\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306a\u6319\u52d5\u304c\u53ef\u80fd\u3067\u3001\u5358\u7d14\u306a\u30c7\u30fc\u30bf\u30e2\u30c7\u30eb\u3084\u30a4\u30f3\u30e1\u30e2\u30ea\u30fc\u30ad\u30e3\u30c3\u30b7\u30e5\u30ec\u30a4\u30e4\u30fc\u306a\u3069\u306e\u30c7\u30fc\u30bf\u304c\u6025\u901f\u306b\u5909\u308f\u308b\u5834\u5408\u306a\u3069\u306b\u4f7f\u308f\u308c\u307e\u3059\u3002\u5358\u7d14\u306a\u51e6\u7406\u306e\u307f\u306b\u6a5f\u80fd\u304c\u5236\u9650\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u8ffd\u52a0\u306e\u51e6\u7406\u6a5f\u80fd\u304c\u5fc5\u8981\u306a\u5834\u5408\u306b\u306f\u305d\u306e\u8907\u96d1\u6027\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64\u306b\u8f09\u305b\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u306f\u3082\u3063\u3068\u8907\u96d1\u306a\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\u3084\u3001\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306a\u3069\u306e\u57fa\u672c\u3067\u3059\u3002\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: \u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\n\n* [\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](https://en.wikipedia.org/wiki/Key-value_database)\n* [\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u306e\u6b20\u70b9](http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or)\n* [Redis\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](http://qnimate.com/overview-of-redis-architecture/)\n* [\u30e1\u30e0\u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://www.adayinthelifeof.nl/2011/02/06/memcache-internals/)\n\n#### \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\n\n> \u6982\u8981: \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u30d0\u30ea\u30e5\u30fc\u3068\u3057\u3066\u4fdd\u5b58\u3055\u308c\u305f\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\n\n\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\u306f\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u95a2\u3059\u308b\u5168\u3066\u306e\u60c5\u5831\u3092\u6301\u3064\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8(XML\u3001 JSON\u3001 binary\u306a\u3069)\u3092\u4e2d\u5fc3\u306b\u636e\u3048\u305f\u30b7\u30b9\u30c6\u30e0\u3067\u3059\u3002\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\u3067\u306f\u3001\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u81ea\u8eab\u306e\u5185\u90e8\u69cb\u9020\u306b\u57fa\u3065\u3044\u305f\u3001API\u3082\u3057\u304f\u306f\u30af\u30a8\u30ea\u8a00\u8a9e\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002 *\u30e1\u30e2\uff1a\u591a\u304f\u306e\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u3067\u306f\u3001\u5024\u306e\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u6271\u3046\u6a5f\u80fd\u3092\u542b\u3093\u3067\u3044\u307e\u3059\u304c\u3001\u305d\u306e\u3053\u3068\u306b\u3088\u3063\u3066\u4e8c\u3064\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\u3068\u306e\u5883\u754c\u7dda\u304c\u66d6\u6627\u306b\u306a\u3063\u3066\u3057\u307e\u3063\u3066\u3044\u307e\u3059\u3002*\n\n\u4ee5\u4e0a\u306e\u3053\u3068\u3092\u5b9f\u73fe\u3059\u308b\u305f\u3081\u306b\u3001\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306f\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u3001\u30bf\u30b0\u3001\u30e1\u30bf\u30c7\u30fc\u30bf\u3084\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306a\u3069\u3068\u3057\u3066\u6574\u7406\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u540c\u58eb\u306f\u307e\u3068\u3081\u3066\u30b0\u30eb\u30fc\u30d7\u306b\u3067\u304d\u308b\u3082\u306e\u306e\u3001\u305d\u308c\u305e\u308c\u3067\u5168\u304f\u7570\u306a\u308b\u30d5\u30a3\u30fc\u30eb\u30c9\u3092\u6301\u3064\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n\n[MongoDB](https://www.mongodb.com/mongodb-architecture) \u3084 [CouchDB](https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/) \u306a\u3069\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\u3082\u3001\u8907\u96d1\u306a\u30af\u30a8\u30ea\u3092\u51e6\u7406\u3059\u308b\u305f\u3081\u306eSQL\u306e\u3088\u3046\u306a\u8a00\u8a9e\u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u3002[DynamoDB](http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf) \u306f\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u3068\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u4e21\u65b9\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\u306f\u9ad8\u3044\u67d4\u8edf\u6027\u3092\u62c5\u4fdd\u3059\u308b\u306e\u3067\u3001\u983b\u7e41\u306b\u5909\u5316\u3059\u308b\u30c7\u30fc\u30bf\u3092\u6271\u3046\u6642\u306b\u7528\u3044\u3089\u308c\u307e\u3059\u3002\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:  \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b9\u30c8\u30a2\n\n* [\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u6307\u5411 \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](https://en.wikipedia.org/wiki/Document-oriented_database)\n* [MongoDB \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://www.mongodb.com/mongodb-architecture)\n* [CouchDB \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/)\n* [Elasticsearch \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up)\n\n#### \u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/n16iOGk.png\"/>\n  <br/>\n  <i><a href=http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html>Source: SQL & NoSQL, a brief history</a></i>\n</p>\n\n> \u6982\u8981: \u30cd\u30b9\u30c8\u3055\u308c\u305f\u30de\u30c3\u30d7 `\u30ab\u30e9\u30e0\u30d5\u30a1\u30df\u30ea\u30fc<\u884c\u30ad\u30fc\u3001 \u30ab\u30e9\u30e0<ColKey\u3001 Value\u3001 Timestamp>>`\n\n\u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2\u306e\u30c7\u30fc\u30bf\u306e\u57fa\u672c\u5358\u4f4d\u306f\u30ab\u30e9\u30e0\uff08\u30cd\u30fc\u30e0\u30fb\u30d0\u30ea\u30e5\u30fc\u306e\u30da\u30a2\uff09\u3067\u3059\u3002\u305d\u308c\u305e\u308c\u306e\u30ab\u30e9\u30e0\u306f\u30ab\u30e9\u30e0\u30d5\u30a1\u30df\u30ea\u30fc\u3068\u3057\u3066\uff08SQL\u30c6\u30fc\u30d6\u30eb\u306e\u3088\u3046\u306b\uff09\u30b0\u30eb\u30fc\u30d7\u5316\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30b9\u30fc\u30d1\u30fc\u30ab\u30e9\u30e0\u30d5\u30a1\u30df\u30ea\u30fc\u306f\u30ab\u30e9\u30e0\u30d5\u30a1\u30df\u30ea\u30fc\u306e\u96c6\u5408\u3067\u3059\u3002\u305d\u308c\u305e\u308c\u306e\u30ab\u30e9\u30e0\u306b\u306f\u884c\u30ad\u30fc\u3067\u30a2\u30af\u30bb\u30b9\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u540c\u3058\u884c\u30ad\u30fc\u3092\u6301\u3064\u30ab\u30e9\u30e0\u306f\u540c\u3058\u884c\u3068\u3057\u3066\u8a8d\u8b58\u3055\u308c\u307e\u3059\u3002\u305d\u308c\u305e\u308c\u306e\u5024\u306f\u3001\u30d0\u30fc\u30b8\u30e7\u30f3\u7ba1\u7406\u3068\u30b3\u30f3\u30d5\u30ea\u30af\u30c8\u304c\u8d77\u304d\u305f\u6642\u306e\u305f\u3081\u306b\u3001\u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u3092\u542b\u307f\u307e\u3059\u3002\n\nGoogle\u306f[Bigtable](http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf)\u3092\u521d\u306e\u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2\u3068\u3057\u3066\u767a\u8868\u3057\u307e\u3057\u305f\u3002\u305d\u308c\u304c\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u3067Hadoop\u306a\u3069\u3067\u3088\u304f\u4f7f\u308f\u308c\u308b[HBase](https://www.mapr.com/blog/in-depth-look-hbase-architecture) \u3084Facebook\u306b\u3088\u308b[Cassandra](http://docs.datastax.com/en/archived/cassandra/2.0/cassandra/architecture/architectureIntro_c.html) \u306a\u3069\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u307e\u3057\u305f\u3002BigTable\u3001HBase\u3084Cassandra\u306a\u3069\u306e\u30b9\u30c8\u30a2\u306f\u30ad\u30fc\u3092\u8f9e\u66f8\u5f62\u5f0f\u3067\u4fdd\u6301\u3059\u308b\u3053\u3068\u3067\u9078\u629e\u3057\u305f\u30ad\u30fc\u30ec\u30f3\u30b8\u3067\u306e\u30c7\u30fc\u30bf\u53d6\u5f97\u3092\u52b9\u7387\u7684\u306b\u3057\u307e\u3059\u3002\n\n\u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2\u306f\u9ad8\u3044\u53ef\u7528\u6027\u3068\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3092\u62c5\u4fdd\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306f\u3068\u3066\u3082\u5927\u898f\u6a21\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u6271\u3046\u3053\u3068\u306b\u3088\u304f\u4f7f\u308f\u308c\u307e\u3059\u3002\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:  \u30ef\u30a4\u30c9\u30ab\u30e9\u30e0\u30b9\u30c8\u30a2\n\n* [SQL & NoSQL\u7c21\u5358\u306b\u6b74\u53f2\u3092\u3055\u3089\u3046](http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html)\n* [Bigtable \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf)\n* [HBase \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](https://www.mapr.com/blog/in-depth-look-hbase-architecture)\n* [Cassandra \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3](http://docs.datastax.com/en/archived/cassandra/2.0/cassandra/architecture/architectureIntro_c.html)\n\n#### \u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/fNcl65g.png\"/>\n  <br/>\n  <i><a href=https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png>Source: Graph database</a></i>\n</p>\n\n> \u6982\u8981: \u30b0\u30e9\u30d5\n\n\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3067\u306f\u3001\u305d\u308c\u305e\u308c\u306e\u30ce\u30fc\u30c9\u304c\u30ec\u30b3\u30fc\u30c9\u3067\u3001\u305d\u308c\u305e\u308c\u306e\u30a2\u30fc\u30af\u306f\u4e8c\u3064\u306e\u30ce\u30fc\u30c9\u3092\u7e4b\u3050\u95a2\u4fc2\u6027\u3068\u3057\u3066\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u591a\u6570\u306e\u5916\u90e8\u30ad\u30fc\u3084\u591a\u5bfe\u591a\u306a\u3069\u306e\u8907\u96d1\u306a\u95a2\u4fc2\u6027\u3092\u8868\u3059\u306e\u306b\u6700\u9069\u3067\u3059\u3002\n\n\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306fSNS\u306a\u3069\u306e\u30b5\u30fc\u30d3\u30b9\u306e\u8907\u96d1\u306a\u95a2\u4fc2\u6027\u30e2\u30c7\u30eb\u306a\u3069\u306b\u3064\u3044\u3066\u9ad8\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u767a\u63ee\u3057\u307e\u3059\u3002\u6bd4\u8f03\u7684\u65b0\u3057\u304f\u3001\u307e\u3060\u4e00\u822c\u7684\u306b\u306f\u7528\u3044\u3089\u308c\u3066\u3044\u306a\u3044\u306e\u3067\u3001\u958b\u767a\u30c4\u30fc\u30eb\u3084\u30ea\u30bd\u30fc\u30b9\u3092\u63a2\u3059\u306e\u304c\u4ed6\u306e\u65b9\u6cd5\u306b\u6bd4\u3079\u3066\u96e3\u3057\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u591a\u304f\u306e\u30b0\u30e9\u30d5\u306f[REST APIs](#representational-state-transfer-rest)\u3092\u901a\u3058\u3066\u306e\u307f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u307e\u3059\u3002\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:  \u30b0\u30e9\u30d5\n\n* [Graph\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9](https://en.wikipedia.org/wiki/Graph_database)\n* [Neo4j](https://neo4j.com/)\n* [FlockDB](https://blog.twitter.com/2010/introducing-flockdb)\n\n#### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:  NoSQL\n\n* [\u57fa\u672c\u7528\u8a9e\u306e\u8aac\u660e](http://stackoverflow.com/questions/3342497/explanation-of-base-terminology)\n* [NoSQL\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306b\u3064\u3044\u3066\u8abf\u67fb\u3068\u9078\u629e\u30ac\u30a4\u30c9](https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq)\n* [\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3](http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database)\n* [NoSQL\u306e\u30a4\u30f3\u30c8\u30ed\u30c0\u30af\u30b7\u30e7\u30f3](https://www.youtube.com/watch?v=qI_g07C_Q5I)\n* [NoSQL\u30d1\u30bf\u30fc\u30f3](http://horicky.blogspot.com/2009/11/nosql-patterns.html)\n\n### SQL\u304b\uff1fNoSQL\u304b\uff1f\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/wXGqG5f.png\"/>\n  <br/>\n  <i><a href=https://www.infoq.com/articles/Transition-RDBMS-NoSQL/>Source: Transitioning from RDBMS to NoSQL</a></i>\n</p>\n\n**SQL** \u3092\u9078\u3076\u7406\u7531:\n\n* \u69cb\u9020\u5316\u3055\u308c\u305f\u30c7\u30fc\u30bf\n* \u53b3\u683c\u306a\u30b9\u30ad\u30fc\u30de\n* \u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\n* \u8907\u96d1\u306a\u30b8\u30e7\u30a4\u30f3\u3092\u3059\u308b\u5fc5\u8981\u6027\n* \u30c8\u30e9\u30f3\u30b6\u30af\u30b7\u30e7\u30f3\n* \u30b9\u30b1\u30fc\u30eb\u3059\u308b\u969b\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u660e\u78ba\u306a\u3068\u304d\n* \u958b\u767a\u8005\u306e\u6570\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3001\u30b3\u30fc\u30c9\u7b49\u304c\u3088\u308a\u5145\u5b9f\u3057\u3066\u3044\u308b\n* \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306b\u3088\u308b\u30c7\u30fc\u30bf\u63a2\u7d22\u306f\u3068\u3066\u3082\u901f\u3044\n\n**NoSQL** \u3092\u9078\u3076\u7406\u7531:\n\n* \u6e96\u69cb\u9020\u5316\u3055\u308c\u305f\u30c7\u30fc\u30bf\n* \u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u3044\u3057\u3001\u30d5\u30ec\u30ad\u30b7\u30d6\u30eb\u306a\u30b9\u30ad\u30fc\u30de\n* \u30ce\u30f3\u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u306a\u30c7\u30fc\u30bf\n* \u8907\u96d1\u306a\u30b8\u30e7\u30a4\u30f3\u3092\u3059\u308b\u5fc5\u8981\u304c\u306a\u3044\n* \u30c7\u30fc\u30bf\u306e\u591a\u304f\u306eTB (\u3082\u3057\u304f\u306f PB) \u3092\u4fdd\u5b58\u3059\u308b\n* \u96c6\u4e2d\u7684\u3001\u5927\u898f\u6a21\u306a\u30c7\u30fc\u30bf\u8ca0\u8377\u306b\u8010\u3048\u3089\u308c\u308b\n* IOPS\u306b\u3064\u3044\u3066\u306f\u6975\u3081\u3066\u9ad8\u3044\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\u3092\u793a\u3059\n\nNoSQL\u306b\u9069\u3059\u308b\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf:\n\n* \u6025\u6fc0\u306a\u30af\u30ea\u30c3\u30af\u30b9\u30c8\u30ea\u30fc\u30e0\u3084\u30ed\u30b0\u30c7\u30fc\u30bf\u306e\u53ce\u96c6\n* \u30ea\u30fc\u30c0\u30fc\u30dc\u30fc\u30c9\u3084\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\n* \u30b7\u30e7\u30c3\u30d4\u30f3\u30b0\u30ab\u30fc\u30c8\u306a\u3069\u306e\u4e00\u6642\u7684\u60c5\u5831\n* \u983b\u7e41\u306b\u30a2\u30af\u30bb\u30b9\u3055\u308c\u308b ('\u30db\u30c3\u30c8\u306a') \u30c6\u30fc\u30d6\u30eb\n* \u30e1\u30bf\u30c7\u30fc\u30bf\u3084\u30eb\u30c3\u30af\u30a2\u30c3\u30d7\u30c6\u30fc\u30d6\u30eb\n\n##### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:  \u3000SQL\u3082\u3057\u304f\u306fNoSQL\n\n* [\u6700\u521d\u306e1000\u4e07\u30e6\u30fc\u30b6\u30fc\u306b\u30b9\u30b1\u30fc\u30eb\u30a2\u30c3\u30d7\u3059\u308b\u305f\u3081\u306b](https://www.youtube.com/watch?v=w95murBkYmU)\n* [SQL\u3068NoSQL\u306e\u9055\u3044](https://www.sitepoint.com/sql-vs-nosql-differences/)\n\n## \u30ad\u30e3\u30c3\u30b7\u30e5\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/Q6z24La.png\"/>\n  <br/>\n  <i><a href=http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html>Source: Scalable system design patterns</a></i>\n</p>\n\n\u30ad\u30e3\u30c3\u30b7\u30e5\u306f\u30da\u30fc\u30b8\u306e\u8aad\u307f\u8fbc\u307f\u6642\u9593\u3092\u524a\u6e1b\u3057\u3001\u30b5\u30fc\u30d0\u30fc\u3084\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3078\u306e\u8ca0\u8377\u3092\u4f4e\u6e1b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u3053\u306e\u30e2\u30c7\u30eb\u3067\u306f\u3001\u5b9f\u969b\u306e\u51e6\u7406\u3092\u4fdd\u5b58\u3059\u308b\u305f\u3081\u306b\u3001\u30c7\u30a3\u30b9\u30d1\u30c3\u30c1\u30e3\u30fc\u304c\u307e\u305a\u4ee5\u524d\u306b\u30ea\u30af\u30a8\u30b9\u30c8\u304c\u9001\u4fe1\u3055\u308c\u305f\u304b\u3069\u3046\u304b\u3092\u78ba\u8a8d\u3057\u3001\u76f4\u524d\u306e\u7d50\u679c\u3092\u53d7\u3051\u53d6\u308a\u307e\u3059\u3002\n\n\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u305d\u306e\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30f3\u306b\u6e21\u3063\u3066\u7d71\u5408\u3055\u308c\u305f\u8aad\u307f\u53d6\u308a\u66f8\u304d\u8fbc\u307f\u306e\u5206\u914d\u3092\u8981\u6c42\u3057\u307e\u3059\u304c\u3001\u4eba\u6c17\u30a2\u30a4\u30c6\u30e0\u306f\u305d\u306e\u5206\u914d\u3092\u6b6a\u3081\u3066\u30b7\u30b9\u30c6\u30e0\u5168\u4f53\u306e\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u524d\u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u5dee\u3057\u8fbc\u3080\u3053\u3068\u3067\u3053\u306e\u3088\u3046\u306b\u3001\u5747\u4e00\u3067\u306a\u3044\u8ca0\u8377\u3084\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306e\u6025\u6fc0\u306a\u5897\u52a0\u3092\u5438\u53ce\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n### \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n\n\u30ad\u30e3\u30c3\u30b7\u30e5\u306fOS\u3084\u30d6\u30e9\u30a6\u30b6\u30fc\u306a\u3069\u306e\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30b5\u30a4\u30c9\u3001[\u30b5\u30fc\u30d0\u30fc\u30b5\u30a4\u30c9](#\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7web\u30b5\u30fc\u30d0\u30fc) \u3082\u3057\u304f\u306f\u72ec\u7acb\u306e\u30ad\u30e3\u30c3\u30b7\u30e5\u30ec\u30a4\u30e4\u30fc\u306b\u8a2d\u7f6e\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n### CDN\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n\n[CDN](#\u30b3\u30f3\u30c6\u30f3\u30c4\u30c7\u30ea\u30d0\u30ea\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30afcontent-delivery-network) \u3082\u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u4e00\u3064\u3068\u3057\u3066\u8003\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n### Web\u30b5\u30fc\u30d0\u30fc\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n\n[\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7](#\u30ea\u30d0\u30fc\u30b9\u30d7\u30ed\u30ad\u30b7web\u30b5\u30fc\u30d0\u30fc) \u3084 [Varnish](https://www.varnish-cache.org/) \u306a\u3069\u306e\u30ad\u30e3\u30c3\u30b7\u30e5\u306f\u9759\u7684\u305d\u3057\u3066\u52d5\u7684\u306a\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u76f4\u63a5\u914d\u4fe1\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 web\u30b5\u30fc\u30d0\u30fc\u3082\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u3057\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b5\u30fc\u30d0\u30fc\u306b\u63a5\u7d9a\u3059\u308b\u3053\u3068\u306a\u3057\u306b\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u8fd4\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n### \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n\n\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u666e\u901a\u3001\u4e00\u822c\u7684\u306a\u4f7f\u7528\u72b6\u6cc1\u306b\u9069\u3059\u308b\u3088\u3046\u306a\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u306e\u8a2d\u5b9a\u3092\u521d\u671f\u72b6\u614b\u3067\u6301\u3063\u3066\u3044\u307e\u3059\u3002\u3053\u306e\u8a2d\u5b9a\u3092\u7279\u5b9a\u306e\u4ed5\u69d8\u306b\u5408\u308f\u305b\u3066\u8abf\u6574\u3059\u308b\u3053\u3068\u3067\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n### \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n\n\u30e1\u30e0\u30ad\u30e3\u30c3\u30b7\u30e5\u306a\u3069\u306eIn-memory\u30ad\u30e3\u30c3\u30b7\u30e5\u3084Redis\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30c7\u30fc\u30bf\u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u9593\u306e\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u3067\u3059\u3002\u30c7\u30fc\u30bf\u306fRAM\u3067\u4fdd\u6301\u3055\u308c\u308b\u305f\u3081\u3001\u30c7\u30fc\u30bf\u304c\u30c7\u30a3\u30b9\u30af\u3067\u4fdd\u5b58\u3055\u308c\u308b\u4e00\u822c\u7684\u306a\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3088\u308a\u3082\u3060\u3044\u3076\u901f\u3044\u3067\u3059\u3002RAM\u5bb9\u91cf\u306f\u30c7\u30a3\u30b9\u30af\u3088\u308a\u3082\u9650\u3089\u308c\u3066\u3044\u308b\u306e\u3067\u3001[least recently used (LRU)](https://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used)\u306a\u3069\u306e[cache invalidation](https://en.wikipedia.org/wiki/Cache_algorithms) \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c '\u30b3\u30fc\u30eb\u30c9' \u306a\u30a8\u30f3\u30c8\u30ea\u3092\u5f3e\u304d\u3001'\u30db\u30c3\u30c8' \u306a\u30c7\u30fc\u30bf\u3092RAM\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002\n\nRedis\u306f\u3055\u3089\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u6a5f\u80fd\u3092\u5099\u3048\u3066\u3044\u307e\u3059:\n\n* \u30d1\u30fc\u30b8\u30b9\u30c6\u30f3\u30b9\u8a2d\u5b9a\n* \u30bd\u30fc\u30c8\u6e08\u307f\u30bb\u30c3\u30c8\u3001\u30ea\u30b9\u30c8\u306a\u3069\u306e\u7d44\u307f\u8fbc\u307f\u30c7\u30fc\u30bf\u69cb\u9020\n\n\u30ad\u30e3\u30c3\u30b7\u30e5\u306b\u306f\u69d8\u3005\u306a\u30ec\u30d9\u30eb\u306e\u3082\u306e\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u3044\u305a\u308c\u3082\u5927\u304d\u304f\u4e8c\u3064\u306e\u30ab\u30c6\u30b4\u30ea\u30fc\u306e\u3044\u305a\u308c\u304b\u306b\u5206\u985e\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059: **\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30af\u30a8\u30ea** \u3068 **\u30aa\u30d6\u30b8\u30a7\u30af\u30c8** \u3067\u3059:\n\n* \u884c\u30ec\u30d9\u30eb\n* \u30af\u30a8\u30ea\u30ec\u30d9\u30eb\n* Fully-formed serializable objects\n* Fully-rendered HTML\n\n\u4e00\u822c\u7684\u306b\u3001\u30d5\u30a1\u30a4\u30eb\u30d9\u30fc\u30b9\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u306f\u30af\u30ed\u30fc\u30f3\u3092\u4f5c\u308a\u51fa\u3057\u3066\u30aa\u30fc\u30c8\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3092\u96e3\u3057\u304f\u3057\u3066\u3057\u307e\u3046\u306e\u3067\u907f\u3051\u308b\u3079\u304d\u3067\u3059\u3002\n\n### \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30af\u30a8\u30ea\u30ec\u30d9\u30eb\u3067\u306e\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n\n\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u30af\u30a8\u30ea\u3059\u308b\u969b\u306b\u306f\u5fc5\u305a\u30af\u30a8\u30ea\u3092\u30ad\u30fc\u3068\u3057\u3066\u30cf\u30c3\u30b7\u30e5\u3057\u3066\u7d50\u679c\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u306b\u4fdd\u5b58\u3057\u307e\u3057\u3087\u3046\u3002\u3053\u306e\u624b\u6cd5\u306f\u30ad\u30e3\u30c3\u30b7\u30e5\u671f\u9650\u5207\u308c\u554f\u984c\u306b\u60a9\u3080\u3053\u3068\u306b\u306a\u308a\u307e\u3059:\n\n* \u8907\u96d1\u306a\u30af\u30a8\u30ea\u306b\u3088\u308a\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u305f\u7d50\u679c\u3092\u524a\u9664\u3059\u308b\u3053\u3068\u304c\u56f0\u96e3\n* \u30c6\u30fc\u30d6\u30eb\u30bb\u30eb\u306a\u3069\u306e\u30c7\u30fc\u30bf\u65ad\u7247\u304c\u5909\u5316\u3057\u305f\u6642\u306b\u3001\u305d\u306e\u5909\u5316\u3057\u305f\u30bb\u30eb\u3092\u542b\u3080\u304b\u3082\u3057\u308c\u306a\u3044\u5168\u3066\u306e\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u305f\u30af\u30a8\u30ea\u3092\u524a\u9664\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n\n### \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30ec\u30d9\u30eb\u3067\u306e\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\n\n\u30c7\u30fc\u30bf\u3092\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30fc\u30c9\u3067\u305d\u3046\u3059\u308b\u3088\u3046\u306b\u3001\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3068\u3057\u3066\u6349\u3048\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306b\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304b\u3089\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30af\u30e9\u30b9\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3084\u30c7\u30fc\u30bf\u69cb\u9020\u3068\u3057\u3066\u7d44\u307f\u7acb\u3066\u3055\u305b\u307e\u3059\u3002:\n\n* \u305d\u306e\u30c7\u30fc\u30bf\u304c\u5909\u66f4\u3055\u308c\u305f\u3089\u3001\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u304b\u3089\u524a\u9664\u3059\u308b\u3053\u3068\n* \u975e\u540c\u671f\u51e6\u7406\u3092\u8a31\u5bb9\u3057\u307e\u3059: \u30ef\u30fc\u30ab\u30fc\u304c\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u305f\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u4e2d\u3067\u6700\u65b0\u306e\u3082\u306e\u3092\u96c6\u3081\u3066\u304d\u307e\u3059\n\n\u4f55\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u3059\u308b\u304b:\n\n* \u30e6\u30fc\u30b6\u30fc\u306e\u30bb\u30c3\u30b7\u30e7\u30f3\n* \u5b8c\u5168\u306b\u30ec\u30f3\u30c0\u30fc\u3055\u308c\u305f\u30a6\u30a7\u30d6\u30da\u30fc\u30b8\n* \u30a2\u30af\u30c6\u30d3\u30c6\u30a3\u30b9\u30c8\u30ea\u30fc\u30e0\n* \u30e6\u30fc\u30b6\u30fc\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\n\n### \u3044\u3064\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u66f4\u65b0\u3059\u308b\u304b\n\n\u30ad\u30e3\u30c3\u30b7\u30e5\u306b\u4fdd\u5b58\u3067\u304d\u308b\u5bb9\u91cf\u306f\u9650\u3089\u308c\u3066\u3044\u308b\u305f\u3081\u3001\u81ea\u5206\u306e\u30b1\u30fc\u30b9\u3067\u306f\u3069\u306e\u30ad\u30e3\u30c3\u30b7\u30e5\u624b\u6cd5\u304c\u4e00\u756a\u3044\u3044\u304b\u306f\u691c\u8a0e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n#### \u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30b5\u30a4\u30c9\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/ONjORqk.png\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast>Source: From cache to in-memory data grid</a></i>\n</p>\n\n\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u30b9\u30c8\u30ec\u30fc\u30b8\u3078\u306e\u8aad\u307f\u66f8\u304d\u306e\u51e6\u7406\u3092\u3057\u307e\u3059\u3002\u30ad\u30e3\u30c3\u30b7\u30e5\u306f\u30b9\u30c8\u30ec\u30fc\u30b8\u3068\u306f\u76f4\u63a5\u3084\u308a\u3068\u308a\u3092\u3057\u307e\u305b\u3093\u3002\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u4ee5\u4e0b\u306e\u3053\u3068\u3092\u3057\u307e\u3059:\n\n* \u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u4e2d\u306e\u30a8\u30f3\u30c8\u30ea\u3092\u53c2\u7167\u3057\u307e\u3059\u304c\u3001\u7d50\u679c\u3068\u3057\u3066\u30ad\u30e3\u30c3\u30b7\u30e5\u30df\u30b9\u306b\u306a\u308a\u307e\u3059\n* \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304b\u3089\u30a8\u30f3\u30c8\u30ea\u3092\u53d6\u5f97\u3057\u307e\u3059\n* \u30a8\u30f3\u30c8\u30ea\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u306b\u8ffd\u52a0\u3057\u307e\u3059\n* \u30a8\u30f3\u30c8\u30ea\u3092\u8fd4\u3057\u307e\u3059\n\n```python\ndef get_user(self, user_id):\n    user = cache.get(\"user.{0}\", user_id)\n    if user is None:\n        user = db.query(\"SELECT * FROM users WHERE user_id = {0}\", user_id)\n        if user is not None:\n            key = \"user.{0}\".format(user_id)\n            cache.set(key, json.dumps(user))\n    return user\n```\n\n[Memcached](https://memcached.org/) \u306f\u901a\u5e38\u3053\u306e\u3088\u3046\u306b\u4f7f\u308f\u308c\u308b\u3002\n\n\u305d\u306e\u5f8c\u306e\u30ad\u30e3\u30c3\u30b7\u30e5\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\u306f\u901f\u3044\u3067\u3059\u3002\u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30b5\u30a4\u30c9\u306f\u30ec\u30fc\u30b8\u30fc\u30ed\u30fc\u30c7\u30a3\u30f3\u30b0\u3067\u3042\u308b\u3068\u3082\u8a00\u308f\u308c\u307e\u3059\u3002\u30ea\u30af\u30a8\u30b9\u30c8\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306e\u307f\u304c\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u3001\u30ea\u30af\u30a8\u30b9\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u30c7\u30fc\u30bf\u3067\u30ad\u30e3\u30c3\u30b7\u30e5\u304c\u6ea2\u308c\u308b\u306e\u3092\u9632\u6b62\u3057\u307e\u3059\u3002\n\n##### \u6b20\u70b9: \u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30b5\u30a4\u30c9\n\n* \u5404\u30ad\u30e3\u30c3\u30b7\u30e5\u30df\u30b9\u306f\u4e09\u3064\u306e\u30c8\u30ea\u30c3\u30d7\u3092\u547c\u3073\u51fa\u3059\u3053\u3068\u306b\u306a\u308a\u3001\u4f53\u611f\u3067\u304d\u308b\u307b\u3069\u306e\u9045\u5ef6\u304c\u8d77\u304d\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n* \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u30c7\u30fc\u30bf\u304c\u66f4\u65b0\u3055\u308c\u308b\u3068\u30ad\u30e3\u30c3\u30b7\u30e5\u30c7\u30fc\u30bf\u306f\u53e4\u3044\u3082\u306e\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002time-to-live (TTL)\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u3067\u30ad\u30e3\u30c3\u30b7\u30e5\u30a8\u30f3\u30c8\u30ea\u306e\u66f4\u65b0\u3092\u5f37\u5236\u7684\u306b\u884c\u3046\u3001\u3082\u3057\u304f\u306f\u30e9\u30a4\u30c8\u30b9\u30eb\u30fc\u3092\u63a1\u7528\u3059\u308b\u3053\u3068\u3067\u3053\u306e\u554f\u984c\u306f\u7de9\u548c\u3067\u304d\u307e\u3059\u3002\n* \u30ce\u30fc\u30c9\u304c\u843d\u3061\u308b\u3068\u3001\u65b0\u898f\u306e\u7a7a\u306e\u30ce\u30fc\u30c9\u3067\u4ee3\u66ff\u3055\u308c\u308b\u3053\u3068\u3067\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u304c\u5897\u52a0\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n#### \u30e9\u30a4\u30c8\u30b9\u30eb\u30fc\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/0vBc0hN.png\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/jboner/scalability-availability-stability-patterns/>Source: Scalability, availability, stability, patterns</a></i>\n</p>\n\n\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u30e1\u30a4\u30f3\u306e\u30c7\u30fc\u30bf\u30b9\u30c8\u30a2\u3068\u3057\u3066\u4f7f\u3044\u3001\u305d\u3053\u306b\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u66f8\u304d\u3092\u884c\u3044\u307e\u3059\u3002\u4e00\u65b9\u3001\u30ad\u30e3\u30c3\u30b7\u30e5\u306f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3078\u306e\u8aad\u307f\u66f8\u304d\u3092\u62c5\u5f53\u3057\u307e\u3059\u3002\n\n* \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u30ad\u30e3\u30c3\u30b7\u30e5\u306b\u3042\u308b\u30a8\u30f3\u30c8\u30ea\u3092\u8ffd\u52a0\u30fb\u66f4\u65b0\u3057\u307e\u3059\n* \u30ad\u30e3\u30c3\u30b7\u30e5\u306f\u540c\u671f\u7684\u306b\u30c7\u30fc\u30bf\u30b9\u30c8\u30a2\u306b\u66f8\u304d\u8fbc\u307f\u3092\u884c\u3044\u307e\u3059\n* \u30a8\u30f3\u30c8\u30ea\u3092\u8fd4\u3057\u307e\u3059\n\n\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30fc\u30c9:\n\n```\nset_user(12345, {\"foo\":\"bar\"})\n```\n\n\u30ad\u30e3\u30c3\u30b7\u30e5\u30b3\u30fc\u30c9:\n\n```python\ndef set_user(user_id, values):\n    user = db.query(\"UPDATE Users WHERE id = {0}\", user_id, values)\n    cache.set(user_id, user)\n```\n\n\u30e9\u30a4\u30c8\u30b9\u30eb\u30fc\u306f\u66f8\u304d\u8fbc\u307f\u51e6\u7406\u306e\u305b\u3044\u3067\u5168\u4f53\u3068\u3057\u3066\u306f\u9045\u3044\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u3059\u304c\u3001\u66f8\u304d\u8fbc\u307e\u308c\u305f\u3070\u304b\u308a\u306e\u30c7\u30fc\u30bf\u306b\u95a2\u3059\u308b\u8aad\u307f\u8fbc\u307f\u306f\u901f\u3044\u3067\u3059\u3002\u30e6\u30fc\u30b6\u30fc\u5074\u306f\u4e00\u822c\u7684\u306b\u30c7\u30fc\u30bf\u66f4\u65b0\u6642\u306e\u65b9\u304c\u8aad\u307f\u8fbc\u307f\u6642\u3088\u308a\u3082\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u306b\u8a31\u5bb9\u7684\u3067\u3059\u3002\u30ad\u30e3\u30c3\u30b7\u30e5\u5185\u306e\u30c7\u30fc\u30bf\u306f\u6700\u65b0\u7248\u3067\u4fdd\u305f\u308c\u307e\u3059\u3002\n\n##### \u6b20\u70b9: \u30e9\u30a4\u30c8\u30b9\u30eb\u30fc\n\n* \u30ce\u30fc\u30c9\u304c\u843d\u3061\u305f\u3053\u3068\u3001\u3082\u3057\u304f\u306f\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u306b\u3088\u3063\u3066\u65b0\u3057\u3044\u30ce\u30fc\u30c9\u304c\u4f5c\u6210\u3055\u308c\u305f\u6642\u306b\u3001\u65b0\u3057\u3044\u30ce\u30fc\u30c9\u306f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u5185\u306e\u30a8\u30f3\u30c8\u30ea\u30fc\u304c\u66f4\u65b0\u3055\u308c\u308b\u307e\u3067\u306f\u30a8\u30f3\u30c8\u30ea\u30fc\u3092\u30ad\u30e3\u30c3\u30b7\u30e5\u3057\u307e\u305b\u3093\u3002\u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30b5\u30a4\u30c9\u3068\u30e9\u30a4\u30c8\u30b9\u30eb\u30fc\u3092\u4f75\u7528\u3059\u308b\u3053\u3068\u3067\u3053\u306e\u554f\u984c\u3092\u7de9\u548c\u3067\u304d\u307e\u3059\u3002\n* \u66f8\u304d\u8fbc\u307e\u308c\u305f\u30c7\u30fc\u30bf\u306e\u5927\u90e8\u5206\u306f\u4e00\u5ea6\u3082\u8aad\u307f\u8fbc\u307e\u308c\u308b\u3053\u3068\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u3053\u306e\u30c7\u30fc\u30bf\u306fTTL\u306b\u3088\u3063\u3066\u5727\u7e2e\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n#### \u30e9\u30a4\u30c8\u30d3\u30cf\u30a4\u30f3\u30c9 (\u30e9\u30a4\u30c8\u30d0\u30c3\u30af)\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/rgSrvjG.png\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/jboner/scalability-availability-stability-patterns/>Source: Scalability, availability, stability, patterns</a></i>\n</p>\n\n\u30e9\u30a4\u30c8\u30d3\u30cf\u30a4\u30f3\u30c9\u3067\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u4ee5\u4e0b\u306e\u3053\u3068\u3092\u3057\u307e\u3059:\n\n* \u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u30a8\u30f3\u30c8\u30ea\u30fc\u3092\u8ffd\u52a0\u30fb\u66f4\u65b0\u3057\u307e\u3059\n* \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2\u3078\u306e\u66f8\u304d\u8fbc\u307f\u3092\u975e\u540c\u671f\u7684\u306b\u884c\u3046\u3053\u3068\u3067\u3001\u66f8\u304d\u8fbc\u307f\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a\u3055\u305b\u307e\u3059\u3002\n\n##### \u6b20\u70b9: \u30e9\u30a4\u30c8\u30d3\u30cf\u30a4\u30f3\u30c9\n\n* \u30ad\u30e3\u30c3\u30b7\u30e5\u304c\u30c7\u30fc\u30bf\u30b9\u30c8\u30a2\u5185\u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u306b\u30d2\u30c3\u30c8\u3059\u308b\u524d\u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u304c\u843d\u3061\u308b\u3068\u30c7\u30fc\u30bf\u6b20\u640d\u304c\u8d77\u304d\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n* \u30ad\u30e3\u30c3\u30b7\u30e5\u30a2\u30b5\u30a4\u30c9\u3084\u30e9\u30a4\u30c8\u30b9\u30eb\u30fc\u3088\u308a\u3082\u5b9f\u88c5\u304c\u8907\u96d1\u306b\u306a\u308a\u307e\u3059\u3002\n\n#### \u30ea\u30d5\u30ec\u30c3\u30b7\u30e5\u30a2\u30d8\u30c3\u30c9\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/kxtjqgE.png\"/>\n  <br/>\n  <i><a href=http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast>Source: From cache to in-memory data grid</a></i>\n</p>\n\n\u671f\u9650\u5207\u308c\u3088\u308a\u3082\u524d\u306b\u3001\u76f4\u8fd1\u3067\u30a2\u30af\u30bb\u30b9\u3055\u308c\u305f\u5168\u3066\u306e\u30ad\u30e3\u30c3\u30b7\u30e5\u30a8\u30f3\u30c8\u30ea\u3092\u81ea\u52d5\u7684\u306b\u66f4\u65b0\u3059\u308b\u3088\u3046\u306b\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\u3082\u3057\u3069\u306e\u30a2\u30a4\u30c6\u30e0\u304c\u5c06\u6765\u5fc5\u8981\u306b\u306a\u308b\u306e\u304b\u3092\u6b63\u78ba\u306b\u4e88\u6e2c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u306e\u306a\u3089\u3070\u3001\u30ea\u30fc\u30c9\u30b9\u30eb\u30fc\u3088\u308a\u3082\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u3092\u524a\u6e1b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n##### \u6b20\u70b9: \u30ea\u30d5\u30ec\u30c3\u30b7\u30e5\u30a2\u30d8\u30c3\u30c9\n\n* \u3069\u306e\u30a2\u30a4\u30c6\u30e0\u304c\u5fc5\u8981\u306b\u306a\u308b\u304b\u306e\u4e88\u6e2c\u304c\u6b63\u78ba\u3067\u306a\u3044\u5834\u5408\u306b\u306f\u30ea\u30d5\u30ec\u30c3\u30b7\u30e5\u30a2\u30d8\u30c3\u30c9\u304c\u306a\u3044\u65b9\u304c\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u306f\u826f\u3044\u3068\u3044\u3046\u7d50\u679c\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\n### \u6b20\u70b9: \u30ad\u30e3\u30c3\u30b7\u30e5\n\n* [cache invalidation](https://en.wikipedia.org/wiki/Cache_algorithms)\u306a\u3069\u3092\u7528\u3044\u3066\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306a\u3069\u306e\u771f\u306e\u30c7\u30fc\u30bf\u3068\u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u9593\u306e\u4e00\u8cab\u6027\u3092\u4fdd\u3064\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n* Redis\u3084memcached\u3092\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3067\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u69cb\u6210\u3092\u5909\u66f4\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n* Cache invalidation\u3082\u96e3\u3057\u3044\u3067\u3059\u304c\u305d\u308c\u306b\u52a0\u3048\u3066\u3001\u3044\u3064\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u66f4\u65b0\u3059\u308b\u304b\u3068\u3044\u3046\u8907\u96d1\u306a\u554f\u984c\u306b\u3082\u60a9\u307e\u3055\u308c\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [From cache to in-memory data grid](http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast)\n* [\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u306a\u30b7\u30b9\u30c6\u30e0\u30c7\u30b6\u30a4\u30f3\u30d1\u30bf\u30fc\u30f3](http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html)\n* [\u30b9\u30b1\u30fc\u30eb\u3067\u304d\u308b\u30b7\u30b9\u30c6\u30e0\u3092\u8a2d\u8a08\u3059\u308b\u305f\u3081\u306e\u30a4\u30f3\u30c8\u30ed\u30c0\u30af\u30b7\u30e7\u30f3](http://lethain.com/introduction-to-architecting-systems-for-scale/)\n* [\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3001\u53ef\u7528\u6027\u3001\u5b89\u5b9a\u6027\u3001\u30d1\u30bf\u30fc\u30f3](http://www.slideshare.net/jboner/scalability-availability-stability-patterns/)\n* [\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3](http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache)\n* [AWS ElastiCache\u306e\u30b9\u30c8\u30e9\u30c6\u30b8\u30fc](http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html)\n* [Wikipedia](https://en.wikipedia.org/wiki/Cache_(computing))\n\n## \u975e\u540c\u671f\u51e6\u7406\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/54GYsSx.png\"/>\n  <br/>\n  <i><a href=http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer>Source: Intro to architecting systems for scale</a></i>\n</p>\n\n\u975e\u540c\u671f\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306f\u3082\u3057\u3001\u9023\u7d9a\u7684\u306b\u884c\u308f\u308c\u308b\u3068\u30ea\u30af\u30a8\u30b9\u30c8\u6642\u9593\u3092\u5727\u8feb\u3057\u3066\u3057\u307e\u3046\u3088\u3046\u306a\u91cd\u3044\u51e6\u7406\u3092\u5225\u3067\u51e6\u7406\u3059\u308b\u624b\u6cd5\u3067\u3059\u3002\u307e\u305f\u3001\u5b9a\u671f\u7684\u306b\u30c7\u30fc\u30bf\u3092\u96c6\u5408\u3055\u305b\u308b\u306a\u3069\u306e\u6642\u9593\u304c\u304b\u304b\u308b\u3088\u3046\u306a\u51e6\u7406\u3092\u524d\u3082\u3063\u3066\u51e6\u7406\u3057\u3066\u304a\u304f\u3053\u3068\u306b\u3082\u5f79\u7acb\u3061\u307e\u3059\u3002\n\n### \u30e1\u30c3\u30bb\u30fc\u30b8\u30ad\u30e5\u30fc\n\n\u30e1\u30c3\u30bb\u30fc\u30b8\u30ad\u30e5\u30fc\u306f\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d7\u3051\u53d6\u308a\u3001\u4fdd\u5b58\u3057\u3001\u914d\u4fe1\u3057\u307e\u3059\u3002\u3082\u3057\u3001\u51e6\u7406\u304c\u30a4\u30f3\u30e9\u30a4\u30f3\u3067\u884c\u3046\u306b\u306f\u9045\u3059\u304e\u308b\u5834\u5408\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3067\u30e1\u30c3\u30bb\u30fc\u30b8\u30ad\u30e5\u30fc\u3092\u7528\u3044\u308b\u3068\u3044\u3044\u3067\u3057\u3087\u3046:\n\n* \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u30b8\u30e7\u30d6\u3092\u30ad\u30e5\u30fc\u306b\u914d\u4fe1\u3057\u3001\u30e6\u30fc\u30b6\u30fc\u306b\u30b8\u30e7\u30d6\u30b9\u30c6\u30fc\u30bf\u30b9\u3092\u4f1d\u3048\u307e\u3059\u3002\n* \u30ef\u30fc\u30ab\u30fc\u304c\u30b8\u30e7\u30d6\u30ad\u30e5\u30fc\u304b\u3089\u53d7\u3051\u53d6\u3063\u3066\u3001\u51e6\u7406\u3092\u884c\u3044\u3001\u7d42\u4e86\u3057\u305f\u3089\u305d\u306e\u30b7\u30b0\u30ca\u30eb\u3092\u8fd4\u3057\u307e\u3059\u3002\n\n\u30e6\u30fc\u30b6\u30fc\u306e\u51e6\u7406\u304c\u6b62\u307e\u308b\u3053\u3068\u306f\u306a\u304f\u3001\u30b8\u30e7\u30d6\u306f\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u51e6\u7406\u3055\u308c\u307e\u3059\u3002\u3053\u306e\u9593\u306b\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306f\u30aa\u30d7\u30b7\u30e7\u30f3\u3068\u3057\u3066\u3001\u30bf\u30b9\u30af\u304c\u5b8c\u4e86\u3057\u305f\u304b\u306e\u3088\u3046\u306b\u898b\u305b\u308b\u305f\u3081\u306b\u5c0f\u898f\u6a21\u306e\u51e6\u7406\u3092\u884c\u3044\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001\u30c4\u30a4\u30fc\u30c8\u3092\u6295\u7a3f\u3059\u308b\u3068\u304d\u306b\u3001\u30c4\u30a4\u30fc\u30c8\u306f\u3059\u3050\u306b\u3042\u306a\u305f\u306e\u30bf\u30a4\u30e0\u30e9\u30a4\u30f3\u306b\u53cd\u6620\u3055\u308c\u305f\u3088\u3046\u306b\u898b\u3048\u307e\u3059\u304c\u3001\u305d\u306e\u30c4\u30a4\u30fc\u30c8\u304c\u5b9f\u969b\u306b\u5168\u3066\u306e\u30d5\u30a9\u30ed\u30ef\u30fc\u306b\u914d\u4fe1\u3055\u308c\u308b\u307e\u3067\u306b\u306f\u3082\u3046\u5c11\u3057\u6642\u9593\u304c\u304b\u304b\u3063\u3066\u3044\u308b\u3067\u3057\u3087\u3046\u3002\n\n**Redis** \u306f\u30b7\u30f3\u30d7\u30eb\u306a\u30e1\u30c3\u30bb\u30fc\u30b8\u4ef2\u4ecb\u3068\u3057\u3066\u306f\u3044\u3044\u3067\u3059\u304c\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u5931\u308f\u308c\u3066\u3057\u307e\u3046\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n\n**RabbitMQ** \u306f\u3088\u304f\u4f7f\u308f\u308c\u3066\u3044\u307e\u3059\u304c\u3001'AMQP'\u30d7\u30ed\u30c8\u30b3\u30eb\u306b\u5bfe\u5fdc\u3057\u3066\u3001\u81ea\u524d\u306e\u30ce\u30fc\u30c9\u3092\u7acb\u3066\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n**Amazon SQS** \u3068\u3044\u3046\u9078\u629e\u80a2\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u304c\u9ad8\u304f\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u91cd\u8907\u3057\u3066\u914d\u4fe1\u3055\u308c\u3066\u3057\u307e\u3046\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n\n### \u30bf\u30b9\u30af\u30ad\u30e5\u30fc\n\n\u30bf\u30b9\u30af\u30ad\u30e5\u30fc\u306f\u30bf\u30b9\u30af\u3068\u305d\u306e\u95a2\u9023\u3059\u308b\u30c7\u30fc\u30bf\u3092\u53d7\u3051\u53d6\u308a\u3001\u51e6\u7406\u3057\u305f\u4e0a\u3067\u305d\u306e\u7d50\u679c\u3092\u8fd4\u3057\u307e\u3059\u3002\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u7ba1\u7406\u3092\u3067\u304d\u308b\u307b\u304b\u3001\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u3068\u3066\u3082\u91cd\u3044\u30b8\u30e7\u30d6\u3092\u3053\u306a\u3059\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\n\n**Celery** \u306f\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u3068python\u306e\u30b5\u30dd\u30fc\u30c8\u304c\u3042\u308a\u307e\u3059\u3002\n\n### \u30d0\u30c3\u30af\u30d7\u30ec\u30c3\u30b7\u30e3\u30fc\n\n\u3082\u3057\u3001\u30ad\u30e5\u30fc\u304c\u62e1\u5927\u3057\u3059\u304e\u308b\u3068\u3001\u30e1\u30e2\u30ea\u30fc\u3088\u308a\u3082\u30ad\u30e5\u30fc\u306e\u65b9\u304c\u5927\u304d\u304f\u306a\u308a\u30ad\u30e3\u30c3\u30b7\u30e5\u30df\u30b9\u304c\u8d77\u3053\u308a\u3001\u30c7\u30a3\u30b9\u30af\u8aad\u307f\u51fa\u3057\u306b\u3064\u306a\u304c\u308a\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u4f4e\u4e0b\u3059\u308b\u3053\u3068\u306b\u3064\u306a\u304c\u308a\u307e\u3059\u3002[\u30d0\u30c3\u30af\u30d7\u30ec\u30c3\u30b7\u30e3\u30fc](http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html)\u306f\u30ad\u30e5\u30fc\u30b5\u30a4\u30ba\u3092\u5236\u9650\u3059\u308b\u3053\u3068\u3067\u56de\u907f\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3001\u9ad8\u3044\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\u3092\u78ba\u4fdd\u3057\u30ad\u30e5\u30fc\u306b\u3059\u3067\u306b\u3042\u308b\u30b8\u30e7\u30d6\u306b\u3064\u3044\u3066\u306e\u30ec\u30b9\u30dd\u30f3\u30b9\u6642\u9593\u3092\u77ed\u7e2e\u3067\u304d\u307e\u3059\u3002\u30ad\u30e5\u30fc\u304c\u3044\u3063\u3071\u3044\u306b\u306a\u308b\u3068\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306f\u30b5\u30fc\u30d0\u30fc\u30d3\u30b8\u30fc\u3082\u3057\u304f\u306fHTTP 503\u3092\u30ec\u30b9\u30dd\u30f3\u30b9\u3068\u3057\u3066\u53d7\u3051\u53d6\u308a\u307e\u305f\u5f8c\u3067\u6642\u9593\u3092\u304a\u3044\u3066\u30a2\u30af\u30bb\u30b9\u3059\u308b\u3088\u3046\u306b\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d7\u3051\u53d6\u308a\u307e\u3059\u3002\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306f[exponential backoff](https://en.wikipedia.org/wiki/Exponential_backoff)\u306a\u3069\u306b\u3088\u3063\u3066\u5f8c\u307b\u3069\u518d\u5ea6\u6642\u9593\u3092\u7f6e\u3044\u3066\u30ea\u30af\u30a8\u30b9\u30c8\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n### \u6b20\u70b9: \u975e\u540c\u671f\u51e6\u7406\n\n* \u30ad\u30e5\u30fc\u3092\u7528\u3044\u308b\u3053\u3068\u3067\u9045\u5ef6\u304c\u8d77\u3053\u308a\u3001\u8907\u96d1\u3055\u3082\u5897\u3059\u305f\u3081\u3001\u3042\u307e\u308a\u91cd\u304f\u306a\u3044\u8a08\u7b97\u51e6\u7406\u3084\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306b\u304a\u3044\u3066\u306f\u540c\u671f\u51e6\u7406\u306e\u65b9\u304c\u3044\u3044\u3067\u3057\u3087\u3046\u3002\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8\n\n* [It's all a numbers game](https://www.youtube.com/watch?v=1KRYH75wgy4)\n* [\u30aa\u30fc\u30d0\u30fc\u30ed\u30fc\u30c9\u3057\u305f\u6642\u306b\u30d0\u30c3\u30af\u30d7\u30ec\u30c3\u30b7\u30e3\u30fc\u3092\u9069\u7528\u3059\u308b](http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html)\n* [Little's law](https://en.wikipedia.org/wiki/Little%27s_law)\n* [\u30e1\u30c3\u30bb\u30fc\u30b8\u30ad\u30e5\u30fc\u3068\u30bf\u30b9\u30af\u30ad\u30e5\u30fc\u306e\u9055\u3044\u3068\u306f\uff1f](https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function)\n\n## \u901a\u4fe1\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/5KeocQs.jpg\"/>\n  <br/>\n  <i><a href=http://www.escotal.com/osilayer.html>Source: OSI 7 layer model</a></i>\n</p>\n\n### Hypertext transfer protocol (HTTP)\n\nHTTP \u306f\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3068\u30b5\u30fc\u30d0\u30fc\u9593\u3067\u306e\u30c7\u30fc\u30bf\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\u3057\u3066\u8ee2\u9001\u3059\u308b\u305f\u3081\u306e\u624b\u6cd5\u3067\u3059\u3002\u30ea\u30af\u30a8\u30b9\u30c8\u30fb\u30ec\u30b9\u30dd\u30f3\u30b9\u306b\u95a2\u308f\u308b\u30d7\u30ed\u30c8\u30b3\u30eb\u3067\u3059\u3002\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304c\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u30b5\u30fc\u30d0\u30fc\u306b\u6295\u3052\u3001\u30b5\u30fc\u30d0\u30fc\u304c\u30ea\u30af\u30a8\u30b9\u30c8\u306b\u95a2\u4fc2\u3059\u308b\u30b3\u30f3\u30c6\u30f3\u30c4\u3068\u5b8c\u4e86\u30b9\u30c6\u30fc\u30bf\u30b9\u60c5\u5831\u3092\u30ec\u30b9\u30dd\u30f3\u30b9\u3068\u3057\u3066\u8fd4\u3057\u307e\u3059\u3002HTTP\u306f\u81ea\u5df1\u5b8c\u7d50\u3059\u308b\u306e\u3067\u3001\u9593\u306b\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3001\u30ad\u30e3\u30c3\u30b7\u30e5\u3001\u30a8\u30f3\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\u3001\u5727\u7e2e\u306a\u3069\u306e\u3069\u3093\u306a\u4e2d\u9593\u30eb\u30fc\u30bf\u30fc\u304c\u5165\u3063\u3066\u3082\u52d5\u304f\u3088\u3046\u306b\u3067\u304d\u3066\u3044\u307e\u3059\u3002\n\n\u57fa\u672c\u7684\u306aHTTP\u30ea\u30af\u30a8\u30b9\u30c8\u306fHTTP\u52d5\u8a5e(\u30e1\u30bd\u30c3\u30c9)\u3068\u30ea\u30bd\u30fc\u30b9(\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8)\u3067\u6210\u308a\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u4ee5\u4e0b\u304c\u3088\u304f\u3042\u308bHTTP\u52d5\u8a5e\u3067\u3059\u3002:\n\n| \u52d5\u8a5e | \u8a73\u7d30 | \u51aa\u7b49\u6027* | \u30bb\u30fc\u30d5 | \u30ad\u30e3\u30c3\u30b7\u30e5\u3067\u304d\u308b\u304b |\n|---|---|---|---|---|\n| GET | \u30ea\u30bd\u30fc\u30b9\u3092\u8aad\u307f\u53d6\u308b | Yes | Yes | Yes |\n| POST | \u30ea\u30bd\u30fc\u30b9\u3092\u4f5c\u6210\u3059\u308b\u3082\u3057\u304f\u306f\u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3059\u308b\u30c8\u30ea\u30ac\u30fc | No | No | Yes \u30ec\u30b9\u30dd\u30f3\u30b9\u304c\u65b0\u3057\u3044\u60c5\u5831\u3092\u542b\u3080\u5834\u5408 |\n| PUT | \u30ea\u30bd\u30fc\u30b9\u3092\u4f5c\u6210\u3082\u3057\u304f\u306f\u5165\u308c\u66ff\u3048\u308b | Yes | No | No |\n| PATCH | \u30ea\u30bd\u30fc\u30b9\u3092\u90e8\u5206\u7684\u306b\u66f4\u65b0\u3059\u308b | No | No | Yes \u30ec\u30b9\u30dd\u30f3\u30b9\u304c\u65b0\u3057\u3044\u60c5\u5831\u3092\u542b\u3080\u5834\u5408 |\n| DELETE | \u30ea\u30bd\u30fc\u30b9\u3092\u524a\u9664\u3059\u308b | Yes | No | No |\n\n*\u4f55\u5ea6\u547c\u3093\u3067\u3082\u540c\u3058\u7d50\u679c\u304c\u8fd4\u3063\u3066\u304f\u308b\u3053\u3068*\n\nHTTP\u306f**TCP** \u3084 **UDP** \u306a\u3069\u306e\u4f4e\u7d1a\u30d7\u30ed\u30c8\u30b3\u30eb\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ec\u30a4\u30e4\u30fc\u306e\u30d7\u30ed\u30c8\u30b3\u30eb\u3067\u3042\u308b\u3002\n\n#### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: HTTP\n\n* [HTTP\u3063\u3066\u306a\u306b?](https://www.nginx.com/resources/glossary/http/)\n* [HTTP \u3068 TCP\u306e\u9055\u3044](https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol)\n* [PUT \u3068 PATCH\u306e\u9055\u3044](https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1)\n\n### \u4f1d\u9001\u5236\u5fa1\u30d7\u30ed\u30c8\u30b3\u30eb (TCP)\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/JdAsdvG.jpg\"/>\n  <br/>\n  <i><a href=http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/>Source: How to make a multiplayer game</a></i>\n</p>\n\nTCP\u306f[IP network](https://en.wikipedia.org/wiki/Internet_Protocol)\u306e\u4e0a\u3067\u6210\u308a\u7acb\u3064\u63a5\u7d9a\u30d7\u30ed\u30c8\u30b3\u30eb\u3067\u3059\u3002\u63a5\u7d9a\u306f[handshake](https://en.wikipedia.org/wiki/Handshaking)\u306b\u3088\u3063\u3066\u958b\u59cb\u3001\u89e3\u9664\u3055\u308c\u307e\u3059\u3002\u5168\u3066\u306e\u9001\u4fe1\u3055\u308c\u305f\u30d1\u30b1\u30c3\u30c8\u306f\u6b20\u640d\u306a\u3057\u3067\u9001\u4fe1\u5148\u306b\u9001\u4fe1\u3055\u308c\u305f\u9806\u756a\u3067\u5230\u9054\u3059\u308b\u3088\u3046\u306b\u4ee5\u4e0b\u306e\u65b9\u6cd5\u3067\u4fdd\u8a3c\u3055\u308c\u3066\u3044\u307e\u3059:\n\n* \u30b7\u30fc\u30b1\u30f3\u30b9\u756a\u53f7\u3068[checksum fields](https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation)\u304c\u5168\u3066\u306e\u30d1\u30b1\u30c3\u30c8\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\n* [Acknowledgement](https://en.wikipedia.org/wiki/Acknowledgement_(data_networks))\u30d1\u30b1\u30c3\u30c8\u3068\u81ea\u52d5\u518d\u9001\u4fe1\n\n\u3082\u3057\u9001\u4fe1\u8005\u304c\u6b63\u3057\u3044\u30ec\u30b9\u30dd\u30f3\u30b9\u3092\u53d7\u3051\u53d6\u3089\u306a\u304b\u3063\u305f\u3068\u304d\u3001\u30d1\u30b1\u30c3\u30c8\u3092\u518d\u9001\u4fe1\u3057\u307e\u3059\u3002\u8907\u6570\u306e\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u304c\u3042\u3063\u305f\u3068\u304d\u3001\u63a5\u7d9a\u306f\u89e3\u9664\u3055\u308c\u307e\u3059\u3002TCP \u306f[\u30d5\u30ed\u30fc\u5236\u5fa1](https://en.wikipedia.org/wiki/Flow_control_(data)) \u3068 [\u8f3b\u8f33\u5236\u5fa1](https://en.wikipedia.org/wiki/Network_congestion#Congestion_control)\u3082\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u6a5f\u80fd\u306b\u3088\u3063\u3066\u901f\u5ea6\u306f\u4f4e\u4e0b\u3057\u3001\u4e00\u822c\u7684\u306bUDP\u3088\u308a\u3082\u975e\u52b9\u7387\u306a\u8ee2\u9001\u624b\u6bb5\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u30cf\u30a4\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\u3092\u5b9f\u73fe\u3059\u308b\u305f\u3081\u306b\u3001\u30a6\u30a7\u30d6\u30b5\u30fc\u30d0\u30fc\u306f\u304b\u306a\u308a\u5927\u304d\u306a\u6570\u306eTCP\u63a5\u7d9a\u3092\u958b\u3044\u3066\u304a\u304f\u3053\u3068\u304c\u3042\u308a\u3001\u305d\u306e\u3053\u3068\u3067\u30e1\u30e2\u30ea\u30fc\u4f7f\u7528\u304c\u5727\u8feb\u3055\u308c\u307e\u3059\u3002\u30a6\u30a7\u30d6\u30b5\u30fc\u30d0\u30b9\u30ec\u30c3\u30c9\u3068\u4f8b\u3048\u3070[memcached](#memcached) \u30b5\u30fc\u30d0\u30fc\u306e\u9593\u3067\u591a\u6570\u306e\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u3092\u4fdd\u3063\u3066\u304a\u304f\u3053\u3068\u306f\u9ad8\u304f\u3064\u304f\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u53ef\u80fd\u306a\u3068\u3053\u308d\u3067\u306fUDP\u306b\u5207\u308a\u66ff\u3048\u308b\u3060\u3051\u3067\u306a\u304f[\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u30d7\u30fc\u30ea\u30f3\u30b0](https://en.wikipedia.org/wiki/Connection_pool)\u306a\u3069\u3082\u5f79\u7acb\u3064\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\nTCP\u306f\u9ad8\u3044\u4f9d\u5b58\u6027\u3092\u8981\u3057\u3001\u6642\u9593\u5236\u7d04\u304c\u53b3\u3057\u304f\u306a\u3044\u3082\u306e\u306b\u9069\u3057\u3066\u3044\u308b\u3067\u3057\u3087\u3046\u3002\u30a6\u30a7\u30d6\u30b5\u30fc\u30d0\u30fc\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u60c5\u5831\u3001SMTP\u3001FTP\u3084SSH\u306a\u3069\u306e\u4f8b\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002\n\n\u4ee5\u4e0b\u306e\u6642\u306bUDP\u3088\u308a\u3082TCP\u3092\u4f7f\u3046\u3068\u3044\u3044\u3067\u3057\u3087\u3046:\n\n* \u5168\u3066\u306e\u30c7\u30fc\u30bf\u304c\u6b20\u640d\u3059\u308b\u3053\u3068\u306a\u3057\u306b\u5c4a\u3044\u3066\u307b\u3057\u3044\n* \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8\u306e\u6700\u9069\u306a\u81ea\u52d5\u63a8\u6e2c\u3092\u3057\u3066\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u3057\u305f\u3044\n\n### \u30e6\u30fc\u30b6\u30c7\u30fc\u30bf\u30b0\u30e9\u30e0\u30d7\u30ed\u30c8\u30b3\u30eb (UDP)\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/yzDrJtA.jpg\"/>\n  <br/>\n  <i><a href=http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/>Source: How to make a multiplayer game</a></i>\n</p>\n\nUDP\u306f\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u30ec\u30b9\u3067\u3059\u3002\u30c7\u30fc\u30bf\u30b0\u30e9\u30e0\uff08\u30d1\u30b1\u30c3\u30c8\u306e\u3088\u3046\u306a\u3082\u306e\uff09\u306f\u30c7\u30fc\u30bf\u30b0\u30e9\u30e0\u30ec\u30d9\u30eb\u3067\u306e\u4fdd\u8a3c\u3057\u304b\u3055\u308c\u307e\u305b\u3093\u3002\u30c7\u30fc\u30bf\u30b0\u30e9\u30e0\u306f\u9806\u4e0d\u540c\u3067\u53d7\u3051\u53d6\u308a\u5148\u306b\u5230\u7740\u3057\u305f\u308a\u305d\u3082\u305d\u3082\u7740\u304b\u306a\u304b\u3063\u305f\u308a\u3057\u307e\u3059\u3002UDP\u306f\u8f3b\u8f33\u5236\u5fa1\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u305b\u3093\u3002TCP\u306b\u304a\u3044\u3066\u306f\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u308b\u3053\u308c\u3089\u306e\u4fdd\u8a3c\u304c\u306a\u3044\u305f\u3081\u3001UDP\u306f\u4e00\u822c\u7684\u306b\u3001TCP\u3088\u308a\u3082\u52b9\u7387\u7684\u3067\u3059\u3002\n\nUDP\u306f\u30b5\u30d6\u30cd\u30c3\u30c8\u4e0a\u306e\u3059\u3079\u3066\u306e\u6a5f\u5668\u306b\u30c7\u30fc\u30bf\u30b0\u30e9\u30e0\u3092\u9001\u4fe1\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u3053\u308c\u306f[DHCP](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol) \u306b\u304a\u3044\u3066\u5f79\u306b\u7acb\u3061\u307e\u3059\u3002\u3068\u3044\u3046\u306e\u3082\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306f\u307e\u3060IP\u30a2\u30c9\u30ec\u30b9\u3092\u53d6\u5f97\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u3001IP\u30a2\u30c9\u30ec\u30b9\u3092\u5fc5\u8981\u3068\u3059\u308bTCP\u306b\u3088\u308b\u30b9\u30c8\u30ea\u30fc\u30e0\u304c\u3067\u304d\u306a\u3044\u304b\u3089\u3067\u3059\u3002\n\nUDP\u306f\u4fe1\u983c\u6027\u306e\u9762\u3067\u306f\u52a3\u308a\u307e\u3059\u304c\u3001VoIP\u3001\u30d3\u30c7\u30aa\u30c1\u30e3\u30c3\u30c8\u3001\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u3084\u540c\u6642\u901a\u4fe1\u30de\u30eb\u30c1\u30d7\u30ec\u30a4\u30e4\u30fc\u30b2\u30fc\u30e0\u306a\u3069\u306e\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u6027\u304c\u91cd\u8996\u3055\u308c\u308b\u6642\u306b\u306f\u3068\u3066\u3082\u52b9\u679c\u7684\u3067\u3059\u3002\n\nTCP\u3088\u308a\u3082UDP\u3092\u4f7f\u3046\u306e\u306f:\n\n* \u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u3092\u6700\u4f4e\u9650\u306b\u6291\u3048\u305f\u3044\u6642\n* \u30c7\u30fc\u30bf\u6b20\u640d\u3088\u308a\u3082\u3001\u30c7\u30fc\u30bf\u9045\u5ef6\u3092\u91cd\u8996\u3059\u308b\u3068\u304d\n* \u30a8\u30e9\u30fc\u4fee\u6b63\u3092\u81ea\u524d\u3067\u5b9f\u88c5\u3057\u305f\u3044\u3068\u304d\n\n#### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: TCP \u3068 UDP\n\n* [\u30b2\u30fc\u30e0\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306e\u305f\u3081\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af](http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/)\n* [TCP \u3068 UDP \u30d7\u30ed\u30c8\u30b3\u30eb\u306e\u4e3b\u306a\u9055\u3044](http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/)\n* [TCP \u3068 UDP\u306e\u9055\u3044](http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp)\n* [Transmission control protocol](https://en.wikipedia.org/wiki/Transmission_Control_Protocol)\n* [User datagram protocol](https://en.wikipedia.org/wiki/User_Datagram_Protocol)\n* [Facebook\u306e\u30e1\u30e0\u30ad\u30e3\u30c3\u30b7\u30e5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0](http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf)\n\n### \u9060\u9694\u624b\u7d9a\u547c\u51fa (RPC)\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/iF4Mkb5.png\"/>\n  <br/>\n  <i><a href=http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview>Source: Crack the system design interview</a></i>\n</p>\n\nRPC\u3067\u306f\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304c\u30ea\u30e2\u30fc\u30c8\u30b5\u30fc\u30d0\u30fc\u306a\u3069\u306e\u7570\u306a\u308b\u30a2\u30c9\u30ec\u30b9\u7a7a\u9593\u3067\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc\u304c\u51e6\u7406\u3055\u308c\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc\u306f\u30ed\u30fc\u30ab\u30eb\u3067\u306e\u30b3\u30fc\u30eb\u306e\u3088\u3046\u306b\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u30b5\u30fc\u30d0\u30fc\u306b\u3069\u306e\u3088\u3046\u306b\u901a\u4fe1\u3059\u308b\u304b\u3068\u3044\u3046\u8a73\u7d30\u3092\u7701\u3044\u305f\u72b6\u614b\u3067\u30b3\u30fc\u30c9\u304c\u66f8\u304b\u308c\u307e\u3059\u3002\u30ea\u30e2\u30fc\u30c8\u306e\u30b3\u30fc\u30eb\u306f\u666e\u901a\u3001\u30ed\u30fc\u30ab\u30eb\u306e\u30b3\u30fc\u30eb\u3088\u308a\u3082\u9045\u304f\u3001\u4fe1\u983c\u6027\u306b\u6b20\u3051\u308b\u305f\u3081\u3001RPC\u30b3\u30fc\u30eb\u3092\u30ed\u30fc\u30ab\u30eb\u30b3\u30fc\u30eb\u3068\u533a\u5225\u3055\u305b\u3066\u304a\u304f\u3053\u3068\u304c\u597d\u307e\u3057\u3044\u3067\u3057\u3087\u3046\u3002\u4eba\u6c17\u306eRPC\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306f\u4ee5\u4e0b\u3067\u3059\u3002[Protobuf](https://developers.google.com/protocol-buffers/)\u3001 [Thrift](https://thrift.apache.org/)\u3001[Avro](https://avro.apache.org/docs/current/)\n\nRPC \u306f \u30ea\u30af\u30a8\u30b9\u30c8\u30ec\u30b9\u30dd\u30f3\u30b9\u30d7\u30ed\u30c8\u30b3\u30eb:\n\n* **\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30d7\u30ed\u30b0\u30e9\u30e0** - \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30b9\u30bf\u30d6\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc\u3092\u547c\u3073\u51fa\u3057\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u30ed\u30fc\u30ab\u30eb\u3067\u306e\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc\u30b3\u30fc\u30eb\u306e\u3088\u3046\u306b\u30b9\u30bf\u30c3\u30af\u3078\u3068\u30d7\u30c3\u30b7\u30e5\u3055\u308c\u3066\u3044\u304d\u307e\u3059\u3002\n* **\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30b9\u30bf\u30d6\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc** - \u30d7\u30ed\u30b7\u30fc\u30b8\u30e3ID\u3068\u30a2\u30fc\u30ae\u30e5\u30e1\u30f3\u30c8\u3092\u30d1\u30c3\u30af\u3057\u3066\u30ea\u30af\u30a8\u30b9\u30c8\u30e1\u30c3\u30bb\u30fc\u30b8\u306b\u3057\u307e\u3059\u3002\n* **\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u901a\u4fe1\u30e2\u30b8\u30e5\u30fc\u30eb** - OS\u304c\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u30b5\u30fc\u30d0\u30fc\u3078\u3068\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u9001\u308a\u307e\u3059\u3002\n* **\u30b5\u30fc\u30d0\u30fc\u901a\u4fe1\u30e2\u30b8\u30e5\u30fc\u30eb** - OS\u304c\u53d7\u3051\u53d6\u3063\u305f\u30d1\u30b1\u30c3\u30c8\u3092\u30b5\u30fc\u30d0\u30fc\u30b9\u30bf\u30d6\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc\u306b\u53d7\u3051\u6e21\u3057\u307e\u3059\u3002\n* **\u30b5\u30fc\u30d0\u30fc\u30b9\u30bf\u30d6\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc** -  \u7d50\u679c\u3092\u5c55\u958b\u3057\u3001\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fcID\u306b\u30de\u30c3\u30c1\u3059\u308b\u30b5\u30fc\u30d0\u30fc\u30d7\u30ed\u30b7\u30fc\u30b8\u30e3\u30fc\u3092\u547c\u3073\u51fa\u3057\u3001\u7d50\u679c\u3092\u8fd4\u3057\u307e\u3059\u3002\n* \u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u30dd\u30f3\u30b9\u306f\u4e0a\u8a18\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u9006\u9806\u3067\u7e70\u308a\u8fd4\u3057\u307e\u3059\u3002\n\nSample RPC calls:\n\n```\nGET /someoperation?data=anId\n\nPOST /anotheroperation\n{\n  \"data\":\"anId\";\n  \"anotherdata\": \"another value\"\n}\n```\n\nRPC\u306f\u632f\u308b\u821e\u3044\u3092\u516c\u958b\u3059\u308b\u3053\u3068\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\u3002RPC\u306f\u5185\u90e8\u901a\u4fe1\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u7406\u7531\u3068\u3057\u3066\u4f7f\u308f\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u3002\u3068\u3044\u3046\u306e\u3082\u3001\u4f7f\u7528\u3059\u308b\u72b6\u6cc1\u306b\u5408\u308f\u305b\u3066\u30cd\u30a4\u30c6\u30a3\u30d6\u30b3\u30fc\u30eb\u3092\u81ea\u4f5c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u304b\u3089\u3067\u3059\u3002\n\n\u30cd\u30a4\u30c6\u30a3\u30d6\u30e9\u30a4\u30d6\u30e9\u30ea\u30fc (aka SDK) \u3092\u547c\u3076\u306e\u306f\u4ee5\u4e0b\u306e\u6642:\n\n* \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u77e5\u3063\u3066\u3044\u308b\u6642\n* \u30ed\u30b8\u30c3\u30af\u304c\u3069\u306e\u3088\u3046\u306b\u30a2\u30af\u30bb\u30b9\u3055\u308c\u308b\u306e\u304b\u3092\u7ba1\u7406\u3057\u305f\u3044\u3068\u304d\n* \u30e9\u30a4\u30d6\u30e9\u30ea\u30fc\u5916\u3067\u30a8\u30e9\u30fc\u304c\u3069\u306e\u3088\u3046\u306b\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u3055\u308c\u308b\u304b\u3092\u7ba1\u7406\u3057\u305f\u3044\u6642\n* \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30a8\u30f3\u30c9\u30e6\u30fc\u30b6\u30fc\u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u304c\u6700\u512a\u5148\u306e\u6642\n\n**REST** \u30d7\u30ed\u30c8\u30b3\u30eb\u306b\u5f93\u3046HTTP API\u306f\u30d1\u30d6\u30ea\u30c3\u30afAPI\u306b\u304a\u3044\u3066\u3088\u304f\u7528\u3044\u3089\u308c\u307e\u3059\u3002\n\n#### \u6b20\u70b9: RPC\n\n* RPC\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3068\u306f\u30b5\u30fc\u30d3\u30b9\u5b9f\u88c5\u306b\u3088\u308a\u53b3\u5bc6\u306b\u5de6\u53f3\u3055\u308c\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n* \u65b0\u3057\u3044\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u3001\u4f7f\u7528\u4f8b\u304c\u3042\u308b\u305f\u3073\u306b\u65b0\u3057\u304fAPI\u304c\u5b9a\u7fa9\u3055\u308c\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\n* RPC\u3092\u30c7\u30d0\u30c3\u30b0\u3059\u308b\u306e\u306f\u96e3\u3057\u3044\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\n* \u65e2\u5b58\u306e\u30c6\u30af\u30ce\u30ed\u30b8\u30fc\u3092\u305d\u306e\u307e\u307e\u4f7f\u3063\u3066\u30b5\u30fc\u30d3\u30b9\u3092\u69cb\u7bc9\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u4f8b\u3048\u3070\u3001[Squid](http://www.squid-cache.org/)\u306a\u3069\u306e\u30b5\u30fc\u30d0\u30fc\u306b[RPC\u30b3\u30fc\u30eb\u304c\u6b63\u3057\u304f\u30ad\u30e3\u30c3\u30b7\u30e5](http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/) \u3055\u308c\u308b\u3088\u3046\u306b\u8ffd\u52a0\u3067\u9aa8\u3092\u6298\u308b\u5fc5\u8981\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n### Representational state transfer (REST)\n\nREST\u306f\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304c\u30b5\u30fc\u30d0\u30fc\u306b\u3088\u3063\u3066\u30de\u30cd\u30fc\u30b8\u3055\u308c\u308b\u30ea\u30bd\u30fc\u30b9\u306b\u5bfe\u3057\u3066\u51e6\u7406\u3092\u884c\u3046\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30fb\u30b5\u30fc\u30d0\u30fc\u30e2\u30c7\u30eb\u3092\u652f\u6301\u3059\u308b\u30a2\u30fc\u30ad\u30c6\u30ad\u30c1\u30e3\u30b9\u30bf\u30a4\u30eb\u3067\u3059\u3002\u30b5\u30fc\u30d0\u30fc\u306f\u64cd\u4f5c\u3067\u304d\u308b\u3082\u3057\u304f\u306f\u65b0\u3057\u3044\u30ea\u30bd\u30fc\u30b9\u30ec\u30d7\u30ec\u30bc\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306a\u30ea\u30bd\u30fc\u30b9\u3084\u30a2\u30af\u30b7\u30e7\u30f3\u306e\u30ec\u30d7\u30ec\u30bc\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u3059\u3079\u3066\u306e\u901a\u4fe1\u306f\u30b9\u30c6\u30fc\u30c8\u30ec\u30b9\u3067\u30ad\u30e3\u30c3\u30b7\u30e5\u53ef\u80fd\u3067\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\n\nRESTful \u306a\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306b\u306f\u6b21\u306e\u56db\u3064\u306e\u7279\u5fb4\u304c\u3042\u308a\u307e\u3059:\n\n* **\u7279\u5fb4\u7684\u306a\u30ea\u30bd\u30fc\u30b9 (URI in HTTP)** - \u3069\u306e\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u3042\u3063\u3066\u3082\u540c\u3058URI\u3092\u4f7f\u3046\u3002\n* **HTTP\u52d5\u8a5e\u306b\u3088\u3063\u3066\u5909\u308f\u308b (Verbs in HTTP)** - \u52d5\u8a5e\u3001\u30d8\u30c3\u30c0\u30fc\u3001\u30dc\u30c7\u30a3\u3092\u4f7f\u3046\n* **\u81ea\u5df1\u8aac\u660e\u7684\u306a\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8 (status response in HTTP)** - \u30b9\u30c6\u30fc\u30bf\u30b9\u30b3\u30fc\u30c9\u3092\u4f7f\u3044\u3001\u65b0\u3057\u304f\u4f5c\u3063\u305f\u308a\u3057\u306a\u3044\u3053\u3068\u3002\n* **[HATEOAS](http://restcookbook.com/Basics/hateoas/) (HTML interface for HTTP)** - \u81ea\u5206\u306eweb\u30b5\u30fc\u30d3\u30b9\u304c\u30d6\u30e9\u30a6\u30b6\u3067\u5b8c\u5168\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3053\u3068\u3002\n\n\u30b5\u30f3\u30d7\u30eb REST \u30b3\u30fc\u30eb:\n\n```\nGET /someresources/anId\n\nPUT /someresources/anId\n{\"anotherdata\": \"another value\"}\n```\n\nREST\u306f\u30c7\u30fc\u30bf\u3092\u516c\u958b\u3059\u308b\u3053\u3068\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\u3002\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3068\u30b5\u30fc\u30d0\u30fc\u306e\u30ab\u30c3\u30d7\u30ea\u30f3\u30b0\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3082\u306e\u3067\u3001\u30d1\u30d6\u30ea\u30c3\u30afAPI\u306a\u3069\u306b\u3088\u304f\u7528\u3044\u3089\u308c\u307e\u3059\u3002REST\u306fURI\u3001 [representation through headers](https://github.com/for-GET/know-your-http-well/blob/master/headers.md)\u3001\u305d\u3057\u3066\u3001GET\u3001POST\u3001PUT\u3001 DELETE\u3001PATCH\u306a\u3069\u306eHTTP\u52d5\u8a5e\u7b49\u306e\u3088\u308a\u30b8\u30a7\u30cd\u30ea\u30c3\u30af\u3067\u7d71\u4e00\u3055\u308c\u305f\u30e1\u30bd\u30c3\u30c9\u3092\u7528\u3044\u307e\u3059\u3002\u30b9\u30c6\u30fc\u30c8\u30ec\u30b9\u3067\u3042\u308b\u306e\u3067REST\u306f\u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3084\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30cb\u30f3\u30b0\u306b\u6700\u9069\u3067\u3059\u3002\n\n#### \u6b20\u70b9: REST\n\n* REST\u306f\u30c7\u30fc\u30bf\u516c\u958b\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u308b\u306e\u3067\u3001\u30ea\u30bd\u30fc\u30b9\u304c\u81ea\u7136\u306b\u6574\u7406\u3055\u308c\u3066\u3044\u306a\u304b\u3063\u305f\u308a\u3001\u30b7\u30f3\u30d7\u30eb\u306a\u30d2\u30a8\u30e9\u30eb\u30ad\u30fc\u3067\u8868\u305b\u3089\u308c\u306a\u3044\u6642\u306b\u306f\u3088\u3044\u9078\u629e\u80a2\u3068\u306f\u8a00\u3048\u306a\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u4f8b\u3048\u3070\u3001\u3068\u3042\u308b\u30a4\u30d9\u30f3\u30c8\u306e\u30bb\u30c3\u30c8\u306b\u30de\u30c3\u30c1\u3059\u308b\u3059\u3079\u3066\u306e\u66f4\u65b0\u60c5\u5831\u3092\u8fd4\u3059\u3068\u8a00\u3063\u305f\u51e6\u7406\u306f\u7c21\u5358\u306b\u306f\u30d1\u30b9\u3067\u8868\u73fe\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002REST\u3067\u306f\u3001URI\u30d1\u30b9\u3001\u30af\u30a8\u30ea\u30d1\u30e9\u30e1\u30fc\u30bf\u3001\u305d\u3057\u3066\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u30ea\u30af\u30a8\u30b9\u30c8\u30dc\u30c7\u30a3\u306a\u3069\u306b\u3088\u3063\u3066\u5b9f\u88c5\u3055\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3057\u3087\u3046\u3002\n* REST\u306f\u5c11\u6570\u306e\u52d5\u8a5e\u306b\u4f9d\u5b58\u3057\u3066\u3044\u307e\u3059(GET\u3001POST\u3001PUT\u3001DELETE\u3001\u305d\u3057\u3066 PATCH) \u304c\u6642\u306b\u306f\u4f7f\u3044\u305f\u3044\u4e8b\u4f8b\u306b\u5408\u308f\u306a\u3044\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001\u671f\u9650\u306e\u5207\u308c\u305f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u30a2\u30fc\u30ab\u30a4\u30d6\u306b\u79fb\u3057\u305f\u3044\u5834\u5408\u306a\u3069\u306f\u3053\u308c\u3089\u306e\u52d5\u8a5e\u306e\u4e2d\u306b\u306f\u7dba\u9e97\u306b\u306f\u30d5\u30a3\u30c3\u30c8\u3057\u307e\u305b\u3093\u3002\n* \u30cd\u30b9\u30c8\u3055\u308c\u305f\u30d2\u30a8\u30e9\u30eb\u30ad\u30fc\u306e\u4e2d\u306b\u3042\u308b\u30ea\u30bd\u30fc\u30b9\u3092\u3068\u3063\u3066\u304f\u308b\u306e\u306f\u30b7\u30f3\u30b0\u30eb\u30d3\u30e5\u30fc\u3092\u63cf\u753b\u3059\u308b\u306e\u306b\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3068\u30b5\u30fc\u30d0\u30fc\u9593\u3067\u6570\u56de\u3084\u308a\u3068\u308a\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\u4f8b\u3068\u3057\u3066\u3001\u30d6\u30ed\u30b0\u30a8\u30f3\u30c8\u30ea\u30fc\u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u3068\u305d\u308c\u306b\u5bfe\u3059\u308b\u30b3\u30e1\u30f3\u30c8\u3092\u8868\u793a\u3059\u308b\u5834\u5408\u306a\u3069\u3067\u3059\u3002\u69d8\u3005\u306a\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u74b0\u5883\u3067\u52d5\u4f5c\u3059\u308b\u53ef\u80fd\u6027\u304c\u8003\u3048\u3089\u308c\u308b\u30e2\u30d0\u30a4\u30eb\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306b\u304a\u3044\u3066\u306f\u3053\u306e\u3088\u3046\u306a\u8907\u6570\u306e\u3084\u308a\u53d6\u308a\u306f\u597d\u307e\u3057\u304f\u3042\u308a\u307e\u305b\u3093\u3002\n* \u6642\u304c\u7d4c\u3064\u306b\u3064\u308c\u3066\u3001API\u30ec\u30b9\u30dd\u30f3\u30b9\u306b\u3088\u308a\u591a\u304f\u306e\u30d5\u30a3\u30fc\u30eb\u30c9\u304c\u4e0e\u3048\u3089\u308c\u3066\u3001\u53e4\u3044\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306f\u3059\u3067\u306b\u3044\u3089\u306a\u3044\u3082\u306e\u3082\u542b\u3081\u3066\u3059\u3079\u3066\u306e\u30c7\u30fc\u30bf\u30d5\u30a3\u30fc\u30eb\u30c9\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\u305d\u306e\u3053\u3068\u3067\u3001\u30da\u30a4\u30ed\u30fc\u30c9\u304c\u5927\u304d\u304f\u306a\u308a\u3059\u304e\u3066\u3001\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u3082\u62e1\u5927\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n### RPC\u3068REST\u6bd4\u8f03\n\n| Operation | RPC | REST |\n|---|---|---|\n| \u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\t| **POST** /signup | **POST** /persons |\n| \u30ea\u30b6\u30a4\u30f3\t| **POST** /resign<br/>{<br/>\"personid\": \"1234\"<br/>} | **DELETE** /persons/1234 |\n| Person\u8aad\u307f\u8fbc\u307f | **GET** /readPerson?personid=1234 | **GET** /persons/1234 |\n| Person\u306e\u30a2\u30a4\u30c6\u30e0\u30ea\u30b9\u30c8\u8aad\u307f\u8fbc\u307f | **GET** /readUsersItemsList?personid=1234 | **GET** /persons/1234/items |\n| Person\u306e\u30a2\u30a4\u30c6\u30e0\u3078\u306e\u30a2\u30a4\u30c6\u30e0\u8ffd\u52a0 | **POST** /addItemToUsersItemsList<br/>{<br/>\"personid\": \"1234\";<br/>\"itemid\": \"456\"<br/>} | **POST** /persons/1234/items<br/>{<br/>\"itemid\": \"456\"<br/>} |\n| \u30a2\u30a4\u30c6\u30e0\u66f4\u65b0\t| **POST** /modifyItem<br/>{<br/>\"itemid\": \"456\";<br/>\"key\": \"value\"<br/>} | **PUT** /items/456<br/>{<br/>\"key\": \"value\"<br/>} |\n| \u30a2\u30a4\u30c6\u30e0\u524a\u9664 | **POST** /removeItem<br/>{<br/>\"itemid\": \"456\"<br/>} | **DELETE** /items/456 |\n\n<p align=\"center\">\n  <i><a href=https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/>Source: Do you really know why you prefer REST over RPC</a></i>\n</p>\n\n#### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8: REST \u3068 RPC\n\n* [Do you really know why you prefer REST over RPC](https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/)\n* [When are RPC-ish approaches more appropriate than REST?](http://programmers.stackexchange.com/a/181186)\n* [REST vs JSON-RPC](http://stackoverflow.com/questions/15056878/rest-vs-json-rpc)\n* [Debunking the myths of RPC and REST](http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/)\n* [What are the drawbacks of using REST](https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs)\n* [Crack the system design interview](http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview)\n* [Thrift](https://code.facebook.com/posts/1468950976659943/)\n* [Why REST for internal use and not RPC](http://arstechnica.com/civis/viewtopic.php?t=1190508)\n\n## \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\n\n\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306f\u66f4\u65b0\u304c\u5fc5\u8981\u3067\u3059\u3002[contributing](#contributing)\u3057\u3066\u304f\u3060\u3055\u3044\uff01\n\n\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306f\u5e45\u5e83\u3044\u30c8\u30d4\u30c3\u30af\u3067\u3059\u3002\u5341\u5206\u306a\u7d4c\u9a13\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5206\u91ce\u306e\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u304c\u306a\u304f\u3066\u3082\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306e\u77e5\u8b58\u3092\u8981\u3059\u308b\u8077\u306b\u5fdc\u52df\u3059\u308b\u306e\u3067\u306a\u3044\u9650\u308a\u3001\u57fa\u672c\u4ee5\u4e0a\u306e\u3053\u3068\u3092\u77e5\u308b\u5fc5\u8981\u306f\u306a\u3044\u3067\u3057\u3087\u3046\u3002\n\n* \u60c5\u5831\u4f1d\u9054\u3001\u4fdd\u5b58\u306b\u304a\u3051\u308b\u6697\u53f7\u5316\n* [XSS](https://en.wikipedia.org/wiki/Cross-site_scripting) \u3084 [SQL injection](https://en.wikipedia.org/wiki/SQL_injection)\u3092\u9632\u3050\u305f\u3081\u306b\u3001\u5168\u3066\u306e\u30e6\u30fc\u30b6\u30fc\u5165\u529b\u3082\u3057\u304f\u306f\u30e6\u30fc\u30b6\u30fc\u306b\u9732\u51fa\u3055\u308c\u308b\u5165\u529b\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u30b5\u30cb\u30bf\u30a4\u30ba\u3059\u308b\n* SQL injection\u3092\u9632\u3050\u305f\u3081\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u5316\u3055\u308c\u305f\u30af\u30a8\u30ea\u3092\u7528\u3044\u308b\u3002\n* [least privilege](https://en.wikipedia.org/wiki/Principle_of_least_privilege)\u306e\u539f\u7406\u3092\u7528\u3044\u308b\n\n### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:\n\n* [\u958b\u767a\u8005\u306e\u305f\u3081\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30ac\u30a4\u30c9](https://github.com/FallibleInc/security-guide-for-developers)\n* [OWASP top ten](https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet)\n\n## \u88dc\u907a\n\n\u6697\u7b97\u3067\u3001\u63a8\u8a08\u5024\u3092\u6c42\u3081\u308b\u5fc5\u8981\u304c\u3042\u308b\u3053\u3068\u3082\u6642\u306b\u306f\u3042\u308a\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001\u30c7\u30a3\u30b9\u30af\u304b\u3089100\u679a\u30a4\u30e1\u30fc\u30b8\u5206\u306e\u30b5\u30e0\u30cd\u30a4\u30eb\u3092\u4f5c\u308b\u6642\u9593\u3092\u6c42\u3081\u305f\u308a\u3001\u305d\u306e\u6642\u306b\u3069\u308c\u3060\u3051\u30c7\u30a3\u30b9\u30af\u30e1\u30e2\u30ea\u30fc\u304c\u6d88\u8cbb\u3055\u308c\u308b\u304b\u306a\u3069\u306e\u5024\u3067\u3059\u3002**2\u306e\u4e57\u6570\u8868** \u3068 **\u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u308b\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u5024** \u306f\u826f\u3044\u53c2\u8003\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002\n\n### 2\u306e\u4e57\u6570\u8868\n\n```\n\u4e57\u6570           \u53b3\u5bc6\u306a\u5024         \u7d04        Bytes\n---------------------------------------------------------------\n7                             128\n8                             256\n10                           1024   1 thousand           1 KB\n16                         65,536                       64 KB\n20                      1,048,576   1 million            1 MB\n30                  1,073,741,824   1 billion            1 GB\n32                  4,294,967,296                        4 GB\n40              1,099,511,627,776   1 trillion           1 TB\n```\n\n#### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:\n\n* [2\u306e\u4e57\u6570\u8868](https://en.wikipedia.org/wiki/Power_of_two)\n\n### \u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u308b\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u5024\n\n```\nLatency Comparison Numbers\n--------------------------\nL1 cache reference                           0.5 ns\nBranch mispredict                            5   ns\nL2 cache reference                           7   ns                      14x L1 cache\nMutex lock/unlock                           25   ns\nMain memory reference                      100   ns                      20x L2 cache, 200x L1 cache\nCompress 1K bytes with Zippy            10,000   ns       10 us\nSend 1 KB bytes over 1 Gbps network     10,000   ns       10 us\nRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD\nRead 1 MB sequentially from memory     250,000   ns      250 us\nRound trip within same datacenter      500,000   ns      500 us\nRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory\nDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip\nRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD\nRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD\nSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 ms\n\nNotes\n-----\n1 ns = 10^-9 seconds\n1 us = 10^-6 seconds = 1,000 ns\n1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns\n```\n\n\u4e0a\u8a18\u8868\u306b\u57fa\u3065\u3044\u305f\u5f79\u306b\u7acb\u3064\u6570\u5024:\n\n* \u30c7\u30a3\u30b9\u30af\u304b\u3089\u306e\u9023\u7d9a\u8aad\u307f\u53d6\u308a\u901f\u5ea6 30 MB/s\n* 1 Gbps Ethernet\u304b\u3089\u306e\u9023\u7d9a\u8aad\u307f\u53d6\u308a\u901f\u5ea6\u3000100 MB/s\n* SSD\u304b\u3089\u306e\u9023\u7d9a\u8aad\u307f\u53d6\u308a\u901f\u5ea6 1 GB/s\n* main memory\u304b\u3089\u306e\u9023\u7d9a\u8aad\u307f\u53d6\u308a\u901f\u5ea6 4 GB/s\n* 1\u79d2\u3067\u5730\u74036-7\u5468\u3067\u304d\u308b\n* 1\u79d2\u3067\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u30682000\u5468\u3084\u308a\u3068\u308a\u3067\u304d\u308b\n\n#### \u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u306e\u8996\u899a\u7684\u8868\n\n![](https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67)\n\n#### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:\n\n* [\u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u308b\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u5024 - 1](https://gist.github.com/jboner/2841832)\n* [\u5168\u3066\u306e\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u304c\u77e5\u308b\u3079\u304d\u30ec\u30a4\u30c6\u30f3\u30b7\u30fc\u5024 - 2](https://gist.github.com/hellerbarde/2843375)\n* [Designs, lessons, and advice from building large distributed systems](http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf)\n* [Software Engineering Advice from Building Large-Scale Distributed Systems](https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf)\n\n### \u4ed6\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u4f8b\u984c\n\n> \u983b\u51fa\u306e\u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u9762\u63a5\u8ab2\u984c\u3068\u305d\u306e\u89e3\u7b54\u3078\u306e\u30ea\u30f3\u30af\n\n| \u8cea\u554f | \u89e3\u7b54 |\n|---|---|\n| Dropbox\u306e\u3088\u3046\u306a\u30d5\u30a1\u30a4\u30eb\u540c\u671f\u30b5\u30fc\u30d3\u30b9\u3092\u8a2d\u8a08\u3059\u308b | [youtube.com](https://www.youtube.com/watch?v=PE4gwstWhmc) |\n| Google\u306e\u3088\u3046\u306a\u691c\u7d22\u30a8\u30f3\u30b8\u30f3\u306e\u8a2d\u8a08 | [queue.acm.org](http://queue.acm.org/detail.cfm?id=988407)<br/>[stackexchange.com](http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search)<br/>[ardendertat.com](http://www.ardendertat.com/2012/01/11/implementing-search-engines/)<br/>[stanford.edu](http://infolab.stanford.edu/~backrub/google.html) |\n| Google\u306e\u3088\u3046\u306a\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u306aweb\u30af\u30ed\u30fc\u30e9\u30fc\u306e\u8a2d\u8a08 | [quora.com](https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch) |\n| Google docs\u306e\u8a2d\u8a08 | [code.google.com](https://code.google.com/p/google-mobwrite/)<br/>[neil.fraser.name](https://neil.fraser.name/writing/sync/) |\n| Redis\u306e\u3088\u3046\u306a\u30ad\u30fc\u30d0\u30ea\u30e5\u30fc\u30b9\u30c8\u30a2\u306e\u8a2d\u8a08 | [slideshare.net](http://www.slideshare.net/dvirsky/introduction-to-redis) |\n| Memcached\u306e\u3088\u3046\u306a\u30ad\u30e3\u30c3\u30b7\u30e5\u30b7\u30b9\u30c6\u30e0\u306e\u8a2d\u8a08 | [slideshare.net](http://www.slideshare.net/oemebamo/introduction-to-memcached) |\n| Amazon\u306e\u3088\u3046\u306a\u30ec\u30b3\u30e1\u30f3\u30c7\u30fc\u30b7\u30e7\u30f3\u30b7\u30b9\u30c6\u30e0\u306e\u8a2d\u8a08 | [hulu.com](http://tech.hulu.com/blog/2011/09/19/recommendation-system.html)<br/>[ijcai13.org](http://ijcai13.org/files/tutorial_slides/td3.pdf) |\n| Bitly\u306e\u3088\u3046\u306aURL\u77ed\u7e2e\u30b5\u30fc\u30d3\u30b9\u306e\u8a2d\u8a08 | [n00tc0d3r.blogspot.com](http://n00tc0d3r.blogspot.com/) |\n| WhatsApp\u306e\u3088\u3046\u306a\u30c1\u30e3\u30c3\u30c8\u30a2\u30d7\u30ea\u306e\u8a2d\u8a08 | [highscalability.com](http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html)\n| Instagram\u306e\u3088\u3046\u306a\u5199\u771f\u5171\u6709\u30b5\u30fc\u30d3\u30b9\u306e\u8a2d\u8a08 | [highscalability.com](http://highscalability.com/flickr-architecture)<br/>[highscalability.com](http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html) |\n| Facebook\u30cb\u30e5\u30fc\u30b9\u30d5\u30a3\u30fc\u30c9\u306e\u8a2d\u8a08 | [quora.com](http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed)<br/>[quora.com](http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed)<br/>[slideshare.net](http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture) |\n| Facebook\u30bf\u30a4\u30e0\u30e9\u30a4\u30f3\u306e\u8a2d\u8a08 | [facebook.com](https://www.facebook.com/note.php?note_id=10150468255628920)<br/>[highscalability.com](http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html) |\n| Facebook\u30c1\u30e3\u30c3\u30c8\u306e\u8a2d\u8a08 | [erlang-factory.com](http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf)<br/>[facebook.com](https://www.facebook.com/note.php?note_id=14218138919&id=9445547199&index=0) |\n| Facebook\u306e\u3088\u3046\u306agraph\u691c\u7d22\u306e\u8a2d\u8a08 | [facebook.com](https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920)<br/>[facebook.com](https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920)<br/>[facebook.com](https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920) |\n| CloudFlare\u306e\u3088\u3046\u306aCDN\u306e\u8a2d\u8a08 | [cmu.edu](http://repository.cmu.edu/cgi/viewcontent.cgi?article=2112&context=compsci) |\n| Twitter\u306e\u30c8\u30ec\u30f3\u30c9\u6a5f\u80fd\u306e\u8a2d\u8a08 | [michael-noll.com](http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/)<br/>[snikolov .wordpress.com](http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/) |\n| \u30e9\u30f3\u30c0\u30e0ID\u767a\u884c\u30b7\u30b9\u30c6\u30e0\u306e\u8a2d\u8a08 | [blog.twitter.com](https://blog.twitter.com/2010/announcing-snowflake)<br/>[github.com](https://github.com/twitter/snowflake/) |\n| \u4e00\u5b9a\u306e\u30a4\u30f3\u30bf\u30fc\u30d0\u30eb\u6642\u9593\u3067\u306e\u4e0a\u4f4dk\u4ef6\u3092\u8fd4\u3059 | [ucsb.edu](https://icmi.cs.ucsb.edu/research/tech_reports/reports/2005-23.pdf)<br/>[wpi.edu](http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf) |\n| \u8907\u6570\u306e\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u304b\u3089\u30c7\u30fc\u30bf\u3092\u914d\u4fe1\u3059\u308b\u30b5\u30fc\u30d3\u30b9\u306e\u8a2d\u8a08 | [highscalability.com](http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html) |\n| \u30aa\u30f3\u30e9\u30a4\u30f3\u306e\u8907\u6570\u30d7\u30ec\u30a4\u30e4\u30fc\u30ab\u30fc\u30c9\u30b2\u30fc\u30e0\u306e\u8a2d\u8a08 | [indieflashblog.com](http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html)<br/>[buildnewgames.com](http://buildnewgames.com/real-time-multiplayer/) |\n| \u30ac\u30fc\u30d9\u30c3\u30b8\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u30b7\u30b9\u30c6\u30e0\u306e\u8a2d\u8a08 | [stuffwithstuff.com](http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/)<br/>[washington.edu](http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf) |\n| \u30b7\u30b9\u30c6\u30e0\u8a2d\u8a08\u4f8b\u984c\u3092\u8ffd\u52a0\u3059\u308b | [Contribute](#contributing) |\n\n### \u5b9f\u4e16\u754c\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\n\n> \u4e16\u306e\u4e2d\u306e\u30b7\u30b9\u30c6\u30e0\u304c\u3069\u306e\u3088\u3046\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u308b\u304b\u306b\u3064\u3044\u3066\u306e\u8a18\u4e8b\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/TcUo2fw.png\"/>\n  <br/>\n  <i><a href=https://www.infoq.com/presentations/Twitter-Timeline-Scalability>Source: Twitter timelines at scale</a></i>\n</p>\n\n**\u4ee5\u4e0b\u306e\u8a18\u4e8b\u306e\u91cd\u7bb1\u306e\u9685\u3092\u3064\u3064\u304f\u3088\u3046\u306a\u7d30\u304b\u3044\u8a73\u7d30\u306b\u3053\u3060\u308f\u3089\u306a\u3044\u3053\u3068\u3002\u3080\u3057\u308d**\n\n* \u5171\u901a\u306e\u539f\u7406\u3001\u6280\u8853\u3001\u30d1\u30bf\u30fc\u30f3\u3092\u63a2\u308b\u3053\u3068\n* \u305d\u308c\u305e\u308c\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3067\u3069\u3093\u306a\u554f\u984c\u304c\u89e3\u6c7a\u3055\u308c\u3001\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306f\u3069\u3053\u3067\u3046\u307e\u304f\u4f7f\u3048\u3082\u3057\u304f\u306f\u4f7f\u3048\u306a\u3044\u304b\u3092\u77e5\u308b\u3053\u3068\n* \u5b66\u3093\u3060\u3053\u3068\u3092\u5fa9\u7fd2\u3059\u308b\u3053\u3068\n\n|\u7a2e\u985e | \u30b7\u30b9\u30c6\u30e0 | \u53c2\u8003\u30da\u30fc\u30b8 |\n|---|---|---|\n| \u30c7\u30fc\u30bf\u51e6\u7406 | **MapReduce** - Google\u306e\u5206\u6563\u30c7\u30fc\u30bf\u51e6\u7406\u30b7\u30b9\u30c6\u30e0 | [research.google.com](http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf) |\n| \u30c7\u30fc\u30bf\u51e6\u7406 | **Spark** - Databricks\u306e\u5206\u6563\u30c7\u30fc\u30bf\u51e6\u7406\u30b7\u30b9\u30c6\u30e0 | [slideshare.net](http://www.slideshare.net/AGrishchenko/apache-spark-architecture) |\n| \u30c7\u30fc\u30bf\u51e6\u7406 | **Storm** - Twitter\u306e\u5206\u6563\u30c7\u30fc\u30bf\u51e6\u7406\u30b7\u30b9\u30c6\u30e0 | [slideshare.net](http://www.slideshare.net/previa/storm-16094009) |\n| | | |\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **Bigtable** - Google\u306e\u30ab\u30e9\u30e0\u6307\u5411\u5206\u6563\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9 | [harvard.edu](http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf) |\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **HBase** - Bigtable\u306e\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u5b9f\u88c5 | [slideshare.net](http://www.slideshare.net/alexbaranau/intro-to-hbase) |\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **Cassandra** - Facebook\u306e\u30ab\u30e9\u30e0\u6307\u5411\u5206\u6563\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9 | [slideshare.net](http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666)\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **DynamoDB** - Amazon\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u6307\u5411\u5206\u6563\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9 | [harvard.edu](http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf) |\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **MongoDB** - \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u6307\u5411\u5206\u6563\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9 | [slideshare.net](http://www.slideshare.net/mdirolf/introduction-to-mongodb) |\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **Spanner** - Google\u306e\u30b0\u30ed\u30fc\u30d0\u30eb\u5206\u6563\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9 | [research.google.com](http://research.google.com/archive/spanner-osdi2012.pdf) |\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **Memcached** - \u5206\u6563\u30e1\u30e2\u30ea\u30fc\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0 | [slideshare.net](http://www.slideshare.net/oemebamo/introduction-to-memcached) |\n| \u30c7\u30fc\u30bf\u30b9\u30c8\u30a2 | **Redis** - \u6c38\u7d9a\u6027\u3068\u30d0\u30ea\u30e5\u30fc\u30bf\u30a4\u30d7\u3092\u517c\u306d\u5099\u3048\u305f\u5206\u6563\u30e1\u30e2\u30ea\u30fc\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0 | [slideshare.net](http://www.slideshare.net/dvirsky/introduction-to-redis) |\n| | | |\n| \u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0 | **Google File System (GFS)** - \u5206\u6563\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0 | [research.google.com](http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf) |\n| \u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0 | **Hadoop File System (HDFS)** - GFS\u306e\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u5b9f\u88c5 | [apache.org](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html) |\n| | | |\n| Misc | **Chubby** - \u758e\u7d50\u5408\u306e\u5206\u6563\u30b7\u30b9\u30c6\u30e0\u3092\u30ed\u30c3\u30af\u3059\u308bGoogle\u306e\u30b5\u30fc\u30d3\u30b9 | [research.google.com](http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf) |\n| Misc | **Dapper** - \u5206\u6563\u30b7\u30b9\u30c6\u30e0\u3092\u8ffd\u8de1\u3059\u308b\u30a4\u30f3\u30d5\u30e9 | [research.google.com](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf)\n| Misc | **Kafka** - LinkedIn\u306b\u3088\u308bPub/sub\u30e1\u30c3\u30bb\u30fc\u30b8\u30ad\u30e5\u30fc | [slideshare.net](http://www.slideshare.net/mumrah/kafka-talk-tri-hug) |\n| Misc | **Zookeeper** - \u540c\u671f\u3092\u53ef\u80fd\u306b\u3059\u308b\u4e2d\u592e\u96c6\u6a29\u30a4\u30f3\u30d5\u30e9\u3068\u30b5\u30fc\u30d3\u30b9 | [slideshare.net](http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper) |\n| | \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u8ffd\u52a0\u3059\u308b | [Contribute](#contributing) |\n\n### \u5404\u4f01\u696d\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\n\n| \u4f01\u696d | \u53c2\u8003\u30da\u30fc\u30b8 |\n|---|---|\n| Amazon | [Amazon architecture](http://highscalability.com/amazon-architecture) |\n| Cinchcast | [Producing 1,500 hours of audio every day](http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html) |\n| DataSift | [Realtime datamining At 120,000 tweets per second](http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html) |\n| DropBox | [How we've scaled Dropbox](https://www.youtube.com/watch?v=PE4gwstWhmc) |\n| ESPN | [Operating At 100,000 duh nuh nuhs per second](http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html) |\n| Google | [Google architecture](http://highscalability.com/google-architecture) |\n| Instagram | [14 million users, terabytes of photos](http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html)<br/>[What powers Instagram](http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances) |\n| Justin.tv | [Justin.Tv's live video broadcasting architecture](http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html) |\n| Facebook | [Scaling memcached at Facebook](https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf)<br/>[TAO: Facebook\u2019s distributed data store for the social graph](https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf)<br/>[Facebook\u2019s photo storage](https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf) |\n| Flickr | [Flickr architecture](http://highscalability.com/flickr-architecture) |\n| Mailbox | [From 0 to one million users in 6 weeks](http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html) |\n| Pinterest | [From 0 To 10s of billions of page views a month](http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html)<br/>[18 million visitors, 10x growth, 12 employees](http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html) |\n| Playfish | [50 million monthly users and growing](http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html) |\n| PlentyOfFish | [PlentyOfFish architecture](http://highscalability.com/plentyoffish-architecture) |\n| Salesforce | [How they handle 1.3 billion transactions a day](http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html) |\n| Stack Overflow | [Stack Overflow architecture](http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html) |\n| TripAdvisor | [40M visitors, 200M dynamic page views, 30TB data](http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html) |\n| Tumblr | [15 billion page views a month](http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html) |\n| Twitter | [Making Twitter 10000 percent faster](http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster)<br/>[Storing 250 million tweets a day using MySQL](http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html)<br/>[150M active users, 300K QPS, a 22 MB/S firehose](http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html)<br/>[Timelines at scale](https://www.infoq.com/presentations/Twitter-Timeline-Scalability)<br/>[Big and small data at Twitter](https://www.youtube.com/watch?v=5cKTP36HVgI)<br/>[Operations at Twitter: scaling beyond 100 million users](https://www.youtube.com/watch?v=z8LU0Cj6BOU) |\n| Uber | [How Uber scales their real-time market platform](http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html) |\n| WhatsApp | [The WhatsApp architecture Facebook bought for $19 billion](http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html) |\n| YouTube | [YouTube scalability](https://www.youtube.com/watch?v=w5WVu624fY8)<br/>[YouTube architecture](http://highscalability.com/youtube-architecture) |\n\n### \u4f01\u696d\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u30d6\u30ed\u30b0\n\n> \u9762\u63a5\u3092\u53d7\u3051\u308b\u4f01\u696d\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\n>\n> \u6295\u3052\u3089\u308c\u308b\u8cea\u554f\u306f\u540c\u3058\u5206\u91ce\u304b\u3089\u6765\u308b\u3053\u3068\u3082\u3042\u308b\u3067\u3057\u3087\u3046\n\n* [Airbnb Engineering](http://nerds.airbnb.com/)\n* [Atlassian Developers](https://developer.atlassian.com/blog/)\n* [Autodesk Engineering](http://cloudengineering.autodesk.com/blog/)\n* [AWS Blog](https://aws.amazon.com/blogs/aws/)\n* [Bitly Engineering Blog](http://word.bitly.com/)\n* [Box Blogs](https://www.box.com/blog/engineering/)\n* [Cloudera Developer Blog](http://blog.cloudera.com/blog/)\n* [Dropbox Tech Blog](https://tech.dropbox.com/)\n* [Engineering at Quora](http://engineering.quora.com/)\n* [Ebay Tech Blog](http://www.ebaytechblog.com/)\n* [Evernote Tech Blog](https://blog.evernote.com/tech/)\n* [Etsy Code as Craft](http://codeascraft.com/)\n* [Facebook Engineering](https://www.facebook.com/Engineering)\n* [Flickr Code](http://code.flickr.net/)\n* [Foursquare Engineering Blog](http://engineering.foursquare.com/)\n* [GitHub Engineering Blog](http://githubengineering.com/)\n* [Google Research Blog](http://googleresearch.blogspot.com/)\n* [Groupon Engineering Blog](https://engineering.groupon.com/)\n* [Heroku Engineering Blog](https://engineering.heroku.com/)\n* [Hubspot Engineering Blog](http://product.hubspot.com/blog/topic/engineering)\n* [High Scalability](http://highscalability.com/)\n* [Instagram Engineering](http://instagram-engineering.tumblr.com/)\n* [Intel Software Blog](https://software.intel.com/en-us/blogs/)\n* [Jane Street Tech Blog](https://blogs.janestreet.com/category/ocaml/)\n* [LinkedIn Engineering](http://engineering.linkedin.com/blog)\n* [Microsoft Engineering](https://engineering.microsoft.com/)\n* [Microsoft Python Engineering](https://blogs.msdn.microsoft.com/pythonengineering/)\n* [Netflix Tech Blog](http://techblog.netflix.com/)\n* [Paypal Developer Blog](https://devblog.paypal.com/category/engineering/)\n* [Pinterest Engineering Blog](http://engineering.pinterest.com/)\n* [Quora Engineering](https://engineering.quora.com/)\n* [Reddit Blog](http://www.redditblog.com/)\n* [Salesforce Engineering Blog](https://developer.salesforce.com/blogs/engineering/)\n* [Slack Engineering Blog](https://slack.engineering/)\n* [Spotify Labs](https://labs.spotify.com/)\n* [Twilio Engineering Blog](http://www.twilio.com/engineering)\n* [Twitter Engineering](https://engineering.twitter.com/)\n* [Uber Engineering Blog](http://eng.uber.com/)\n* [Yahoo Engineering Blog](http://yahooeng.tumblr.com/)\n* [Yelp Engineering Blog](http://engineeringblog.yelp.com/)\n* [Zynga Engineering Blog](https://www.zynga.com/blogs/engineering)\n\n#### \u305d\u306e\u4ed6\u306e\u53c2\u8003\u8cc7\u6599\u3001\u30da\u30fc\u30b8:\n\n* [kilimchoi/engineering-blogs](https://github.com/kilimchoi/engineering-blogs)\n\n\u3053\u3053\u306b\u3042\u308b\u30ea\u30b9\u30c8\u306f\u6bd4\u8f03\u7684\u5c0f\u898f\u6a21\u306a\u3082\u306e\u306b\u3068\u3069\u3081\u3001[kilimchoi/engineering-blogs](https://github.com/kilimchoi/engineering-blogs)\u306b\u3088\u308a\u8a73\u7d30\u306b\u8a18\u3059\u3053\u3068\u3067\u91cd\u8907\u3057\u306a\u3044\u3088\u3046\u306b\u3057\u3066\u304a\u304f\u3053\u3068\u306b\u3059\u308b\u3002\u30a8\u30f3\u30b8\u30cb\u30a2\u30d6\u30ed\u30b0\u3078\u306e\u30ea\u30f3\u30af\u3092\u8ffd\u52a0\u3059\u308b\u5834\u5408\u306f\u3053\u3053\u3067\u306f\u306a\u304f\u3001engineering-blogs\u30ec\u30dc\u30b8\u30c8\u30ea\u306b\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3092\u691c\u8a0e\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n## \u9032\u884c\u4e2d\u306e\u4f5c\u696d\n\n\u30bb\u30af\u30b7\u30e7\u30f3\u306e\u8ffd\u52a0\u3084\u3001\u9032\u884c\u4e2d\u306e\u4f5c\u696d\u3092\u624b\u4f1d\u3063\u3066\u3044\u305f\u3060\u3051\u308b\u5834\u5408\u306f[\u3053\u3061\u3089](#contributing)!\n\n* MapReduce\u306b\u3088\u308b\u5206\u6563\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\n* Consistent hashing\n* Scatter gather\n* [Contribute](#contributing)\n\n## \u30af\u30ec\u30b8\u30c3\u30c8\n\n\u30af\u30ec\u30b8\u30c3\u30c8\u53ca\u3073\u3001\u53c2\u7167\u30da\u30fc\u30b8\u306f\u9069\u6642\u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u5185\u306b\u8a18\u8f09\u3057\u3066\u3042\u308a\u307e\u3059\n\nSpecial thanks to:\n\n* [Hired in tech](http://www.hiredintech.com/system-design/the-system-design-process/)\n* [Cracking the coding interview](https://www.amazon.com/dp/0984782850/)\n* [High scalability](http://highscalability.com/)\n* [checkcheckzz/system-design-interview](https://github.com/checkcheckzz/system-design-interview)\n* [shashank88/system_design](https://github.com/shashank88/system_design)\n* [mmcgrana/services-engineering](https://github.com/mmcgrana/services-engineering)\n* [System design cheat sheet](https://gist.github.com/vasanthk/485d1c25737e8e72759f)\n* [A distributed systems reading list](http://dancres.github.io/Pages/)\n* [Cracking the system design interview](http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview)\n\n## Contact info\n\nFeel free to contact me to discuss any issues, questions, or comments.\n\nMy contact info can be found on my [GitHub page](https://github.com/donnemartin).\n\n## License\n\n*I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).*\n\n    Copyright 2017 Donne Martin\n\n    Creative Commons Attribution 4.0 International License (CC BY 4.0)\n\n    http://creativecommons.org/licenses/by/4.0/\n"}, {"repo": "vinta/awesome-python", "language": "Python", "readme_contents": "# Awesome Python [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated list of awesome Python frameworks, libraries, software and resources.\n\nInspired by [awesome-php](https://github.com/ziadoz/awesome-php).\n\n- [Awesome Python](#awesome-python)\n    - [Admin Panels](#admin-panels)\n    - [Algorithms and Design Patterns](#algorithms-and-design-patterns)\n    - [Asynchronous Programming](#asynchronous-programming)\n    - [Audio](#audio)\n    - [Authentication](#authentication)\n    - [Build Tools](#build-tools)\n    - [Built-in Classes Enhancement](#built-in-classes-enhancement)\n    - [Caching](#caching)\n    - [ChatOps Tools](#chatops-tools)\n    - [CMS](#cms)\n    - [Code Analysis](#code-analysis)\n    - [Command-line Interface Development](#command-line-interface-development)\n    - [Command-line Tools](#command-line-tools)\n    - [Compatibility](#compatibility)\n    - [Computer Vision](#computer-vision)\n    - [Concurrency and Parallelism](#concurrency-and-parallelism)\n    - [Configuration](#configuration)\n    - [Cryptography](#cryptography)\n    - [Data Analysis](#data-analysis)\n    - [Data Validation](#data-validation)\n    - [Data Visualization](#data-visualization)\n    - [Database Drivers](#database-drivers)\n    - [Database](#database)\n    - [Date and Time](#date-and-time)\n    - [Debugging Tools](#debugging-tools)\n    - [Deep Learning](#deep-learning)\n    - [DevOps Tools](#devops-tools)\n    - [Distributed Computing](#distributed-computing)\n    - [Distribution](#distribution)\n    - [Documentation](#documentation)\n    - [Downloader](#downloader)\n    - [E-commerce](#e-commerce)\n    - [Editor Plugins and IDEs](#editor-plugins-and-ides)\n    - [Email](#email)\n    - [Environment Management](#environment-management)\n    - [Files](#files)\n    - [Foreign Function Interface](#foreign-function-interface)\n    - [Forms](#forms)\n    - [Functional Programming](#functional-programming)\n    - [Game Development](#game-development)\n    - [Geolocation](#geolocation)\n    - [GUI Development](#gui-development)\n    - [Hardware](#hardware)\n    - [HTML Manipulation](#html-manipulation)\n    - [HTTP Clients](#http-clients)\n    - [Image Processing](#image-processing)\n    - [Implementations](#implementations)\n    - [Interactive Interpreter](#interactive-interpreter)\n    - [Internationalization](#internationalization)\n    - [Job Scheduler](#job-scheduler)\n    - [Logging](#logging)\n    - [Machine Learning](#machine-learning)\n    - [Miscellaneous](#miscellaneous)\n    - [Natural Language Processing](#natural-language-processing)\n    - [Network Virtualization](#network-virtualization)\n    - [News Feed](#news-feed)\n    - [ORM](#orm)\n    - [Package Management](#package-management)\n    - [Package Repositories](#package-repositories)\n    - [Permissions](#permissions)\n    - [Processes](#processes)\n    - [Recommender Systems](#recommender-systems)\n    - [RESTful API](#restful-api)\n    - [Robotics](#robotics)\n    - [RPC Servers](#rpc-servers)\n    - [Science](#science)\n    - [Search](#search)\n    - [Serialization](#serialization)\n    - [Serverless Frameworks](#serverless-frameworks)\n    - [Specific Formats Processing](#specific-formats-processing)\n    - [Static Site Generator](#static-site-generator)\n    - [Tagging](#tagging)\n    - [Task Queues](#task-queues)\n    - [Template Engine](#template-engine)\n    - [Testing](#testing)\n    - [Text Processing](#text-processing)\n    - [Third-party APIs](#third-party-apis)\n    - [URL Manipulation](#url-manipulation)\n    - [Video](#video)\n    - [Web Asset Management](#web-asset-management)\n    - [Web Content Extracting](#web-content-extracting)\n    - [Web Crawling](#web-crawling)\n    - [Web Frameworks](#web-frameworks)\n    - [WebSocket](#websocket)\n    - [WSGI Servers](#wsgi-servers)\n- [Resources](#resources)\n    - [Podcasts](#podcasts)\n    - [Twitter](#twitter)\n    - [Websites](#websites)\n    - [Weekly](#weekly)\n- [Contributing](#contributing)\n\n---\n\n## Admin Panels\n\n*Libraries for administrative interfaces.*\n\n* [ajenti](https://github.com/ajenti/ajenti) - The admin panel your servers deserve.\n* [django-grappelli](https://grappelliproject.com/) - A jazzy skin for the Django Admin-Interface.\n* [django-jet](https://github.com/geex-arts/django-jet) - Modern responsive template for the Django admin interface with improved functionality.\n* [django-suit](https://djangosuit.com/) - Alternative Django Admin-Interface (free only for Non-commercial use).\n* [django-xadmin](https://github.com/sshwsfc/xadmin) - Drop-in replacement of Django admin comes with lots of goodies.\n* [jet-bridge](https://github.com/jet-admin/jet-bridge) - Admin panel framework for any application with nice UI (ex Jet Django)\n* [flask-admin](https://github.com/flask-admin/flask-admin) - Simple and extensible administrative interface framework for Flask.\n* [flower](https://github.com/mher/flower) - Real-time monitor and web admin for Celery.\n* [wooey](https://github.com/wooey/wooey) - A Django app which creates automatic web UIs for Python scripts.\n\n## Algorithms and Design Patterns\n\n*Python implementation of algorithms and design patterns.*\n\n* [algorithms](https://github.com/keon/algorithms) - Minimal examples of data structures and algorithms in Python.\n* [PyPattyrn](https://github.com/tylerlaberge/PyPattyrn) - A simple yet effective library for implementing common design patterns.\n* [python-patterns](https://github.com/faif/python-patterns) - A collection of design patterns in Python.\n* [sortedcontainers](https://github.com/grantjenks/python-sortedcontainers) - Fast, pure-Python implementation of SortedList, SortedDict, and SortedSet types.\n\n## Asynchronous Programming\n\n* [asyncio](https://docs.python.org/3/library/asyncio.html) - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks.\n    - [awesome-asyncio](https://github.com/timofurrer/awesome-asyncio)\n* [uvloop](https://github.com/MagicStack/uvloop) - Ultra fast asyncio event loop.\n* [Twisted](https://twistedmatrix.com/trac/) - An event-driven networking engine.\n\n## Audio\n\n*Libraries for manipulating audio and its metadata.*\n\n* Audio\n    * [audioread](https://github.com/beetbox/audioread) - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.\n    * [dejavu](https://github.com/worldveil/dejavu) - Audio fingerprinting and recognition.\n    * [mingus](http://bspaans.github.io/python-mingus/) - An advanced music theory and notation package with MIDI file and playback support.\n    * [pyAudioAnalysis](https://github.com/tyiannak/pyAudioAnalysis) - Audio feature extraction, classification, segmentation and applications.\n    * [pydub](https://github.com/jiaaro/pydub) - Manipulate audio with a simple and easy high level interface.\n    * [TimeSide](https://github.com/Parisson/TimeSide) - Open web audio processing framework.\n* Metadata\n    * [beets](https://github.com/beetbox/beets) - A music library manager and [MusicBrainz](https://musicbrainz.org/) tagger.\n    * [eyeD3](https://github.com/nicfit/eyeD3) - A tool for working with audio files, specifically MP3 files containing ID3 metadata.\n    * [mutagen](https://github.com/quodlibet/mutagen) - A Python module to handle audio metadata.\n    * [tinytag](https://github.com/devsnd/tinytag) - A library for reading music meta data of MP3, OGG, FLAC and Wave files.\n\n## Authentication\n\n*Libraries for implementing authentications schemes.*\n\n* OAuth\n    * [authlib](https://github.com/lepture/authlib) - JavaScript Object Signing and Encryption draft implementation.\n    * [django-allauth](https://github.com/pennersr/django-allauth) - Authentication app for Django that \"just works.\"\n    * [django-oauth-toolkit](https://github.com/evonove/django-oauth-toolkit) - OAuth 2 goodies for Django.\n    * [oauthlib](https://github.com/idan/oauthlib) - A generic and thorough implementation of the OAuth request-signing logic.\n    * [python-oauth2](https://github.com/joestump/python-oauth2) - A fully tested, abstract interface to creating OAuth clients and servers.\n    * [python-social-auth](https://github.com/omab/python-social-auth) - An easy-to-setup social authentication mechanism.\n* JWT\n    * [pyjwt](https://github.com/jpadilla/pyjwt) - JSON Web Token implementation in Python.\n    * [python-jose](https://github.com/mpdavis/python-jose/) - A JOSE implementation in Python.\n    * [python-jwt](https://github.com/davedoesdev/python-jwt) - A module for generating and verifying JSON Web Tokens.\n\n## Build Tools\n\n*Compile software from source code.*\n\n* [BitBake](http://www.yoctoproject.org/docs/1.6/bitbake-user-manual/bitbake-user-manual.html) - A make-like build tool for embedded Linux.\n* [buildout](http://www.buildout.org/en/latest/) - A build system for creating, assembling and deploying applications from multiple parts.\n* [PlatformIO](https://github.com/platformio/platformio-core) - A console tool to build code with different development platforms.\n* [pybuilder](https://github.com/pybuilder/pybuilder) - A continuous build tool written in pure Python.\n* [SCons](http://www.scons.org/) - A software construction tool.\n\n## Built-in Classes Enhancement\n\n*Libraries for enhancing Python built-in classes.*\n\n* [dataclasses](https://docs.python.org/3/library/dataclasses.html) - (Python standard library) Data classes.\n* [attrs](https://github.com/python-attrs/attrs) - Replacement for `__init__`, `__eq__`, `__repr__`, etc. boilerplate in class definitions.\n* [bidict](https://github.com/jab/bidict) - Efficient, Pythonic bidirectional map data structures and related functionality..\n* [Box](https://github.com/cdgriffith/Box) - Python dictionaries with advanced dot notation access.\n* [DottedDict](https://github.com/carlosescri/DottedDict) - A library that provides a method of accessing lists and dicts with a dotted path notation.\n\n## CMS\n\n*Content Management Systems.*\n\n* [wagtail](https://wagtail.io/) - A Django content management system.\n* [django-cms](https://www.django-cms.org/en/) - An Open source enterprise CMS based on the Django.\n* [feincms](https://github.com/feincms/feincms) - One of the most advanced Content Management Systems built on Django.\n* [Kotti](https://github.com/Kotti/Kotti) - A high-level, Pythonic web application framework built on Pyramid.\n* [mezzanine](https://github.com/stephenmcd/mezzanine) - A powerful, consistent, and flexible content management platform.\n* [plone](https://plone.org/) - A CMS built on top of the open source application server Zope.\n* [quokka](https://github.com/rochacbruno/quokka) - Flexible, extensible, small CMS powered by Flask and MongoDB.\n\n## Caching\n\n*Libraries for caching data.*\n\n* [beaker](https://github.com/bbangert/beaker) - A WSGI middleware for sessions and caching.\n* [django-cache-machine](https://github.com/django-cache-machine/django-cache-machine) - Automatic caching and invalidation for Django models.\n* [django-cacheops](https://github.com/Suor/django-cacheops) - A slick ORM cache with automatic granular event-driven invalidation.\n* [dogpile.cache](http://dogpilecache.readthedocs.io/en/latest/) - dogpile.cache is next generation replacement for Beaker made by same authors.\n* [HermesCache](https://pypi.org/project/HermesCache/) - Python caching library with tag-based invalidation and dogpile effect prevention.\n* [pylibmc](https://github.com/lericson/pylibmc) - A Python wrapper around the [libmemcached](https://libmemcached.org/libMemcached.html) interface.\n* [python-diskcache](http://www.grantjenks.com/docs/diskcache/) - SQLite and file backed cache backend with faster lookups than memcached and redis.\n\n## ChatOps Tools\n\n*Libraries for chatbot development.*\n\n* [errbot](https://github.com/errbotio/errbot/) - The easiest and most popular chatbot to implement ChatOps.\n\n## Code Analysis\n\n*Tools of static analysis, linters and code quality checkers. Also see [awesome-static-analysis](https://github.com/mre/awesome-static-analysis).*\n\n* Code Analysis\n    * [coala](https://github.com/coala/coala/) - Language independent and easily extendable code analysis application.\n    * [code2flow](https://github.com/scottrogowski/code2flow) - Turn your Python and JavaScript code into DOT flowcharts.\n    * [prospector](https://github.com/PyCQA/prospector) - A tool to analyse Python code.\n    * [pycallgraph](https://github.com/gak/pycallgraph) - A library that visualises the flow (call graph) of your Python application.\n* Code Linters\n    * [flake8](https://pypi.org/project/flake8/) - A wrapper around `pycodestyle`, `pyflakes` and McCabe.\n        * [awesome-flake8-extensions](https://github.com/DmytroLitvinov/awesome-flake8-extensions)\n    * [pylint](https://www.pylint.org/) - A fully customizable source code analyzer.\n    * [pylama](https://github.com/klen/pylama) - A code audit tool for Python and JavaScript.\n    * [wemake-python-styleguide](https://github.com/wemake-services/wemake-python-styleguide) - The strictest and most opinionated python linter ever.\n* Code Formatters\n    * [black](https://github.com/python/black) - The uncompromising Python code formatter.\n    * [yapf](https://github.com/google/yapf) - Yet another Python code formatter from Google.\n* Static Type Checkers, also see [awesome-python-typing](https://github.com/typeddjango/awesome-python-typing)\n    * [mypy](http://mypy-lang.org/) - Check variable types during compile time.\n    * [pyre-check](https://github.com/facebook/pyre-check) - Performant type checking.\n* Static Type Annotations Generators\n    * [MonkeyType](https://github.com/Instagram/MonkeyType) - A system for Python that generates static type annotations by collecting runtime types\n\n## Command-line Interface Development\n\n*Libraries for building command-line applications.*\n\n* Command-line Application Development\n    * [cement](http://builtoncement.com/) - CLI Application Framework for Python.\n    * [click](http://click.pocoo.org/dev/) - A package for creating beautiful command line interfaces in a composable way.\n    * [cliff](https://docs.openstack.org/developer/cliff/) - A framework for creating command-line programs with multi-level commands.\n    * [clint](https://github.com/kennethreitz/clint) - Python Command-line Application Tools.\n    * [docopt](http://docopt.org/) - Pythonic command line arguments parser.\n    * [python-fire](https://github.com/google/python-fire) - A library for creating command line interfaces from absolutely any Python object.\n    * [python-prompt-toolkit](https://github.com/jonathanslenders/python-prompt-toolkit) - A library for building powerful interactive command lines.\n* Terminal Rendering\n    * [asciimatics](https://github.com/peterbrittain/asciimatics) - A package to create full-screen text UIs (from interactive forms to ASCII animations).\n    * [bashplotlib](https://github.com/glamp/bashplotlib) - Making basic plots in the terminal.\n    * [colorama](https://pypi.org/project/colorama/) - Cross-platform colored terminal text.\n    * [tqdm](https://github.com/tqdm/tqdm) - Fast, extensible progress bar for loops and CLI.\n\n## Command-line Tools\n\n*Useful CLI-based tools for productivity.*\n\n* Productivity Tools\n    * [cookiecutter](https://github.com/audreyr/cookiecutter) - A command-line utility that creates projects from cookiecutters (project templates).\n    * [doitlive](https://github.com/sloria/doitlive) - A tool for live presentations in the terminal.\n    * [howdoi](https://github.com/gleitz/howdoi) - Instant coding answers via the command line.\n    * [PathPicker](https://github.com/facebook/PathPicker) - Select files out of bash output.\n    * [percol](https://github.com/mooz/percol) - Adds flavor of interactive selection to the traditional pipe concept on UNIX.\n    * [thefuck](https://github.com/nvbn/thefuck) - Correcting your previous console command.\n    * [tmuxp](https://github.com/tony/tmuxp) - A [tmux](https://github.com/tmux/tmux) session manager.\n    * [try](https://github.com/timofurrer/try) - A dead simple CLI to try out python packages - it's never been easier.\n* CLI Enhancements\n    * [httpie](https://github.com/jakubroztocil/httpie) - A command line HTTP client, a user-friendly cURL replacement.\n    * [kube-shell](https://github.com/cloudnativelabs/kube-shell) - An integrated shell for working with the Kubernetes CLI.\n    * [mycli](https://github.com/dbcli/mycli) - A Terminal Client for MySQL with AutoCompletion and Syntax Highlighting.\n    * [pgcli](https://github.com/dbcli/pgcli) - Postgres CLI with autocompletion and syntax highlighting.\n    * [saws](https://github.com/donnemartin/saws) - A Supercharged [aws-cli](https://github.com/aws/aws-cli).\n\n## Compatibility\n\n*Libraries for migrating from Python 2 to 3.*\n\n* [python-future](http://python-future.org/index.html) - The missing compatibility layer between Python 2 and Python 3.\n* [python-modernize](https://github.com/mitsuhiko/python-modernize) - Modernizes Python code for eventual Python 3 migration.\n* [six](https://pypi.org/project/six/) - Python 2 and 3 compatibility utilities.\n\n## Computer Vision\n\n*Libraries for computer vision.*\n\n* [OpenCV](https://opencv.org/) - Open Source Computer Vision Library.\n* [pytesseract](https://github.com/madmaze/pytesseract) - Another wrapper for [Google Tesseract OCR](https://github.com/tesseract-ocr).\n* [SimpleCV](http://simplecv.org/) - An open source framework for building computer vision applications.\n\n## Concurrency and Parallelism\n\n*Libraries for concurrent and parallel execution. Also see [awesome-asyncio](https://github.com/timofurrer/awesome-asyncio).*\n\n* [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) - (Python standard library) A high-level interface for asynchronously executing callables.\n* [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) - (Python standard library) Process-based parallelism.\n* [eventlet](http://eventlet.net/) - Asynchronous framework with WSGI support.\n* [gevent](http://www.gevent.org/) - A coroutine-based Python networking library that uses [greenlet](https://github.com/python-greenlet/greenlet).\n* [uvloop](https://github.com/MagicStack/uvloop) - Ultra fast implementation of `asyncio` event loop on top of `libuv`.\n* [scoop](https://github.com/soravux/scoop) - Scalable Concurrent Operations in Python.\n\n## Configuration\n\n*Libraries for storing and parsing configuration options.*\n\n* [configobj](https://github.com/DiffSK/configobj) - INI file parser with validation.\n* [configparser](https://docs.python.org/3/library/configparser.html) - (Python standard library) INI file parser.\n* [profig](https://profig.readthedocs.io/en/default/) - Config from multiple formats with value conversion.\n* [python-decouple](https://github.com/henriquebastos/python-decouple) - Strict separation of settings from code.\n\n## Cryptography\n\n* [cryptography](https://cryptography.io/en/latest/) - A package designed to expose cryptographic primitives and recipes to Python developers.\n* [paramiko](https://github.com/paramiko/paramiko) - The leading native Python SSHv2 protocol library.\n* [passlib](https://passlib.readthedocs.io/en/stable/) - Secure password storage/hashing library, very high level.\n* [pynacl](https://github.com/pyca/pynacl) - Python binding to the Networking and Cryptography (NaCl) library.\n\n## Data Analysis\n\n*Libraries for data analyzing.*\n\n* [Blaze](https://github.com/blaze/blaze) - NumPy and Pandas interface to Big Data.\n* [Open Mining](https://github.com/mining/mining) - Business Intelligence (BI) in Pandas interface.\n* [Orange](https://orange.biolab.si/) - Data mining, data visualization, analysis and machine learning through visual programming or scripts.\n* [Pandas](http://pandas.pydata.org/) - A library providing high-performance, easy-to-use data structures and data analysis tools.\n* [Optimus](https://github.com/ironmussa/Optimus) - Agile Data Science Workflows made easy with PySpark.\n\n## Data Validation\n\n*Libraries for validating data. Used for forms in many cases.*\n\n* [Cerberus](https://github.com/pyeve/cerberus) - A lightweight and extensible data validation library.\n* [colander](https://docs.pylonsproject.org/projects/colander/en/latest/) - Validating and deserializing data obtained via XML, JSON, an HTML form post.\n* [jsonschema](https://github.com/Julian/jsonschema) - An implementation of [JSON Schema](http://json-schema.org/) for Python.\n* [schema](https://github.com/keleshev/schema) - A library for validating Python data structures.\n* [Schematics](https://github.com/schematics/schematics) - Data Structure Validation.\n* [valideer](https://github.com/podio/valideer) - Lightweight extensible data validation and adaptation library.\n* [voluptuous](https://github.com/alecthomas/voluptuous) - A Python data validation library.\n\n## Data Visualization\n\n*Libraries for visualizing data. Also see [awesome-javascript](https://github.com/sorrycc/awesome-javascript#data-visualization).*\n\n* [Altair](https://github.com/altair-viz/altair) - Declarative statistical visualization library for Python.\n* [Bokeh](https://github.com/bokeh/bokeh) - Interactive Web Plotting for Python.\n* [bqplot](https://github.com/bloomberg/bqplot) - Interactive Plotting Library for the Jupyter Notebook\n* [Dash](https://plot.ly/products/dash/) - Built on top of Flask, React and Plotly aimed at analytical web applications.\n    * [awesome-dash](https://github.com/Acrotrend/awesome-dash)\n* [plotnine](https://github.com/has2k1/plotnine) - A grammar of graphics for Python based on ggplot2.\n* [Matplotlib](http://matplotlib.org/) - A Python 2D plotting library.\n* [Pygal](http://www.pygal.org/en/latest/) - A Python SVG Charts Creator.\n* [PyGraphviz](https://pypi.org/project/pygraphviz/) - Python interface to [Graphviz](http://www.graphviz.org/).\n* [PyQtGraph](http://www.pyqtgraph.org/) - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets.\n* [Seaborn](https://github.com/mwaskom/seaborn) - Statistical data visualization using Matplotlib.\n* [VisPy](https://github.com/vispy/vispy) - High-performance scientific visualization based on OpenGL.\n\n## Database\n\n*Databases implemented in Python.*\n\n* [pickleDB](https://github.com/patx/pickledb) - A simple and lightweight key-value store for Python.\n* [tinydb](https://github.com/msiemens/tinydb) - A tiny, document-oriented database.\n* [ZODB](https://github.com/zopefoundation/ZODB) - A native object database for Python. A key-value and object graph database.\n\n## Database Drivers\n\n*Libraries for connecting and operating databases.*\n\n* MySQL - [awesome-mysql](http://shlomi-noach.github.io/awesome-mysql/)\n    * [mysqlclient](https://github.com/PyMySQL/mysqlclient-python) - MySQL connector with Python 3 support ([mysql-python](https://sourceforge.net/projects/mysql-python/) fork).\n    * [PyMySQL](https://github.com/PyMySQL/PyMySQL) - A pure Python MySQL driver compatible to mysql-python.\n* PostgreSQL - [awesome-postgres](https://github.com/dhamaniasad/awesome-postgres)\n    * [psycopg2](http://initd.org/psycopg/) - The most popular PostgreSQL adapter for Python.\n    * [queries](https://github.com/gmr/queries) - A wrapper of the psycopg2 library for interacting with PostgreSQL.\n* Other Relational Databases\n    * [pymssql](http://www.pymssql.org/en/latest/) - A simple database interface to Microsoft SQL Server.\n    * [SuperSQLite](https://github.com/plasticityai/supersqlite) - A supercharged SQLite library built on top of [apsw](https://github.com/rogerbinns/apsw).\n* NoSQL Databases\n    * [cassandra-driver](https://github.com/datastax/python-driver) - The Python Driver for Apache Cassandra.\n    * [happybase](https://github.com/wbolster/happybase) - A developer-friendly library for Apache HBase.\n    * [kafka-python](https://github.com/dpkp/kafka-python) - The Python client for Apache Kafka.\n    * [py2neo](https://py2neo.org/) - A client library and toolkit for working with Neo4j.\n    * [pymongo](https://github.com/mongodb/mongo-python-driver) - The official Python client for MongoDB.\n    * [redis-py](https://github.com/andymccurdy/redis-py) - The Python client for Redis.\n* Asynchronous Clients\n    * [motor](https://github.com/mongodb/motor) - The async Python driver for MongoDB.\n\n## Date and Time\n\n*Libraries for working with dates and times.*\n\n* [Chronyk](https://github.com/KoffeinFlummi/Chronyk) - A Python 3 library for parsing human-written times and dates.\n* [dateutil](https://github.com/dateutil/dateutil) - Extensions to the standard Python [datetime](https://docs.python.org/3/library/datetime.html) module.\n* [delorean](https://github.com/myusuf3/delorean/) - A library for clearing up the inconvenient truths that arise dealing with datetimes.\n* [moment](https://github.com/zachwill/moment) - A Python library for dealing with dates/times. Inspired by [Moment.js](http://momentjs.com/).\n* [Pendulum](https://github.com/sdispater/pendulum) - Python datetimes made easy.\n* [PyTime](https://github.com/shinux/PyTime) - An easy-to-use Python module which aims to operate date/time/datetime by string.\n* [pytz](https://launchpad.net/pytz) - World timezone definitions, modern and historical. Brings the [tz database](https://en.wikipedia.org/wiki/Tz_database) into Python.\n* [when.py](https://github.com/dirn/When.py) - Providing user-friendly functions to help perform common date and time actions.\n* [maya](https://github.com/kennethreitz/maya) - Datetimes for Humans.\n\n## Debugging Tools\n\n*Libraries for debugging code.*\n\n* pdb-like Debugger\n    * [ipdb](https://github.com/gotcha/ipdb) - IPython-enabled [pdb](https://docs.python.org/3/library/pdb.html).\n    * [pdb++](https://github.com/antocuni/pdb) - Another drop-in replacement for pdb.\n    * [pudb](https://github.com/inducer/pudb) - A full-screen, console-based Python debugger.\n    * [wdb](https://github.com/Kozea/wdb) - An improbable web debugger through WebSockets.\n* Tracing\n    * [lptrace](https://github.com/khamidou/lptrace) - [strace](http://man7.org/linux/man-pages/man1/strace.1.html) for Python programs.\n    * [manhole](https://github.com/ionelmc/python-manhole) - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt.\n    * [pyringe](https://github.com/google/pyringe) - Debugger capable of attaching to and injecting code into Python processes.\n    * [python-hunter](https://github.com/ionelmc/python-hunter) - A flexible code tracing toolkit.\n* Profiler\n    * [line_profiler](https://github.com/rkern/line_profiler) - Line-by-line profiling.\n    * [memory_profiler](https://github.com/fabianp/memory_profiler) - Monitor Memory usage of Python code.\n    * [profiling](https://github.com/what-studio/profiling) - An interactive Python profiler.\n    * [py-spy](https://github.com/benfred/py-spy) - A sampling profiler for Python programs. Written in Rust.\n    * [pyflame](https://github.com/uber/pyflame) - A ptracing profiler For Python.\n    * [vprof](https://github.com/nvdv/vprof) - Visual Python profiler.\n* Others\n    * [icecream](https://github.com/gruns/icecream) - Inspect variables, expressions, and program execution with a single, simple function call.\n    * [django-debug-toolbar](https://github.com/jazzband/django-debug-toolbar) - Display various debug information for Django.\n    * [django-devserver](https://github.com/dcramer/django-devserver) - A drop-in replacement for Django's runserver.\n    * [flask-debugtoolbar](https://github.com/mgood/flask-debugtoolbar) - A port of the django-debug-toolbar to flask.\n    * [pyelftools](https://github.com/eliben/pyelftools) - Parsing and analyzing ELF files and DWARF debugging information.\n\n## Deep Learning\n\n*Frameworks for Neural Networks and Deep Learning. Also see [awesome-deep-learning](https://github.com/ChristosChristofidis/awesome-deep-learning).*\n\n* [caffe](https://github.com/BVLC/caffe) - A fast open framework for deep learning..\n* [keras](https://github.com/keras-team/keras) - A high-level neural networks library and capable of running on top of either TensorFlow or Theano.\n* [mxnet](https://github.com/dmlc/mxnet) - A deep learning framework designed for both efficiency and flexibility.\n* [pytorch](https://github.com/pytorch/pytorch) - Tensors and Dynamic neural networks in Python with strong GPU acceleration.\n* [SerpentAI](https://github.com/SerpentAI/SerpentAI) - Game agent framework. Use any video game as a deep learning sandbox.\n* [tensorflow](https://github.com/tensorflow/tensorflow) - The most popular Deep Learning framework created by Google.\n* [Theano](https://github.com/Theano/Theano) - A library for fast numerical computation.\n\n## DevOps Tools\n\n*Software and libraries for DevOps.*\n\n* [ansible](https://github.com/ansible/ansible) - A radically simple IT automation platform.\n* [cloudinit](https://cloudinit.readthedocs.io/en/latest/) - A multi-distribution package that handles early initialization of a cloud instance.\n* [cuisine](https://github.com/sebastien/cuisine) - Chef-like functionality for Fabric.\n* [docker-compose](https://docs.docker.com/compose/) - Fast, isolated development environments using [Docker](https://www.docker.com/).\n* [fabric](https://github.com/fabric/fabric) - A simple, Pythonic tool for remote execution and deployment.\n* [fabtools](https://github.com/fabtools/fabtools) - Tools for writing awesome Fabric files.\n* [honcho](https://github.com/nickstenning/honcho) - A Python clone of [Foreman](https://github.com/ddollar/foreman), for managing Procfile-based applications.\n* [OpenStack](https://www.openstack.org/) - Open source software for building private and public clouds.\n* [pexpect](https://github.com/pexpect/pexpect) - Controlling interactive programs in a pseudo-terminal like GNU expect.\n* [psutil](https://github.com/giampaolo/psutil) - A cross-platform process and system utilities module.\n* [saltstack](https://github.com/saltstack/salt) - Infrastructure automation and management system.\n* [supervisor](https://github.com/Supervisor/supervisor) - Supervisor process control system for UNIX.\n\n## Distributed Computing\n\n*Frameworks and libraries for Distributed Computing.*\n\n* Batch Processing\n    * [PySpark](https://pypi.org/project/pyspark/) - [Apache Spark](https://spark.apache.org/) Python API.\n    * [dask](https://github.com/dask/dask) - A flexible parallel computing library for analytic computing.\n    * [luigi](https://github.com/spotify/luigi) - A module that helps you build complex pipelines of batch jobs.\n    * [mrjob](https://github.com/Yelp/mrjob) - Run MapReduce jobs on Hadoop or Amazon Web Services.\n    * [Ray](https://github.com/ray-project/ray/) - A system for parallel and distributed Python that unifies the machine learning ecosystem.\n* Stream Processing\n    * [faust](https://github.com/robinhood/faust) - A stream processing library, porting the ideas from [Kafka Streams](https://kafka.apache.org/documentation/streams/) to Python.\n    * [streamparse](https://github.com/Parsely/streamparse) - Run Python code against real-time streams of data via [Apache Storm](http://storm.apache.org/).\n\n## Distribution\n\n*Libraries to create packaged executables for release distribution.*\n\n* [dh-virtualenv](https://github.com/spotify/dh-virtualenv) - Build and distribute a virtualenv as a Debian package.\n* [Nuitka](http://nuitka.net/) - Compile scripts, modules, packages to an executable or extension module.\n* [py2app](http://pythonhosted.org/py2app/) - Freezes Python scripts (Mac OS X).\n* [py2exe](http://www.py2exe.org/) - Freezes Python scripts (Windows).\n* [PyInstaller](https://github.com/pyinstaller/pyinstaller) - Converts Python programs into stand-alone executables (cross-platform).\n* [pynsist](http://pynsist.readthedocs.io/en/latest/) - A tool to build Windows installers, installers bundle Python itself.\n\n## Documentation\n\n*Libraries for generating project documentation.*\n\n* [sphinx](https://github.com/sphinx-doc/sphinx/) - Python Documentation generator.\n    * [awesome-sphinxdoc](https://github.com/yoloseem/awesome-sphinxdoc)\n* [pdoc](https://github.com/mitmproxy/pdoc) - Epydoc replacement to auto generate API documentation for Python libraries.\n* [pycco](https://github.com/pycco-docs/pycco) - The literate-programming-style documentation generator.\n\n## Downloader\n\n*Libraries for downloading.*\n\n* [s3cmd](https://github.com/s3tools/s3cmd) - A command line tool for managing Amazon S3 and CloudFront.\n* [s4cmd](https://github.com/bloomreach/s4cmd) - Super S3 command line tool, good for higher performance.\n* [you-get](https://you-get.org/) - A YouTube/Youku/Niconico video downloader written in Python 3.\n* [youtube-dl](https://rg3.github.io/youtube-dl/) - A small command-line program to download videos from YouTube.\n\n## E-commerce\n\n*Frameworks and libraries for e-commerce and payments.*\n\n* [alipay](https://github.com/lxneng/alipay) - Unofficial Alipay API for Python.\n* [Cartridge](https://github.com/stephenmcd/cartridge) - A shopping cart app built using the Mezzanine.\n* [django-oscar](http://oscarcommerce.com/) - An open-source e-commerce framework for Django.\n* [django-shop](https://github.com/awesto/django-shop) - A Django based shop system.\n* [merchant](https://github.com/agiliq/merchant) - A Django app to accept payments from various payment processors.\n* [money](https://github.com/carlospalol/money) - `Money` class with optional CLDR-backed locale-aware formatting and an extensible currency exchange.\n* [python-currencies](https://github.com/Alir3z4/python-currencies) - Display money format and its filthy currencies.\n* [forex-python](https://github.com/MicroPyramid/forex-python) - Foreign exchange rates, Bitcoin price index and currency conversion.\n* [saleor](http://getsaleor.com/) - An e-commerce storefront for Django.\n* [shoop](https://www.shuup.com/en/) - An open source E-Commerce platform based on Django.\n\n## Editor Plugins and IDEs\n\n* Emacs\n    * [elpy](https://github.com/jorgenschaefer/elpy) - Emacs Python Development Environment.\n* Sublime Text\n    * [anaconda](https://github.com/DamnWidget/anaconda) - Anaconda turns your Sublime Text 3 in a full featured Python development IDE.\n    * [SublimeJEDI](https://github.com/srusskih/SublimeJEDI) - A Sublime Text plugin to the awesome auto-complete library Jedi.\n* Vim\n    * [jedi-vim](https://github.com/davidhalter/jedi-vim) - Vim bindings for the Jedi auto-completion library for Python.\n    * [python-mode](https://github.com/python-mode/python-mode) - An all in one plugin for turning Vim into a Python IDE.\n    * [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) - Includes [Jedi](https://github.com/davidhalter/jedi)-based completion engine for Python.\n* Visual Studio\n    * [PTVS](https://github.com/Microsoft/PTVS) - Python Tools for Visual Studio.\n* Visual Studio Code\n    * [Python](https://marketplace.visualstudio.com/items?itemName=ms-python.python) - The official VSCode extension with rich support for Python.\n* IDE\n    * [PyCharm](https://www.jetbrains.com/pycharm/) - Commercial Python IDE by JetBrains. Has free community edition available.\n    * [spyder](https://github.com/spyder-ide/spyder) - Open Source Python IDE.\n\n## Email\n\n*Libraries for sending and parsing email.*\n\n* [envelopes](http://tomekwojcik.github.io/envelopes/) - Mailing for human beings.\n* [flanker](https://github.com/mailgun/flanker) - An email address and Mime parsing library.\n* [imbox](https://github.com/martinrusev/imbox) - Python IMAP for Humans.\n* [inbox.py](https://github.com/kennethreitz/inbox.py) - Python SMTP Server for Humans.\n* [lamson](https://github.com/zedshaw/lamson) - Pythonic SMTP Application Server.\n* [Marrow Mailer](https://github.com/marrow/mailer) - High-performance extensible mail delivery framework.\n* [modoboa](https://github.com/modoboa/modoboa) - A mail hosting and management platform including a modern and simplified Web UI.\n* [Nylas Sync Engine](https://github.com/nylas/sync-engine) - Providing a RESTful API on top of a powerful email sync platform.\n* [yagmail](https://github.com/kootenpv/yagmail) - Yet another Gmail/SMTP client.\n\n## Environment Management\n\n*Libraries for Python version and virtual environment management.*\n\n* [pyenv](https://github.com/pyenv/pyenv) - Simple Python version management.\n* [pipenv](https://github.com/pypa/pipenv) - Python Development Workflow for Humans.\n* [poetry](https://github.com/sdispater/poetry) - Python dependency management and packaging made easy.\n* [virtualenv](https://github.com/pypa/virtualenv) - A tool to create isolated Python environments.\n\n## Files\n\n*Libraries for file manipulation and MIME type detection.*\n\n* [mimetypes](https://docs.python.org/3/library/mimetypes.html) - (Python standard library) Map filenames to MIME types.\n* [path.py](https://github.com/jaraco/path.py) - A module wrapper for [os.path](https://docs.python.org/3/library/os.path.html).\n* [pathlib](https://docs.python.org/3/library/pathlib.html) - (Python standard library) An cross-platform, object-oriented path library.\n* [PyFilesystem2](https://github.com/pyfilesystem/pyfilesystem2) - Python's filesystem abstraction layer.\n* [python-magic](https://github.com/ahupp/python-magic) - A Python interface to the libmagic file type identification library.\n* [Unipath](https://github.com/mikeorr/Unipath) - An object-oriented approach to file/directory operations.\n* [watchdog](https://github.com/gorakhargosh/watchdog) - API and shell utilities to monitor file system events.\n\n## Foreign Function Interface\n\n*Libraries for providing foreign function interface.*\n\n* [cffi](https://pypi.org/project/cffi/) - Foreign Function Interface for Python calling C code.\n* [ctypes](https://docs.python.org/3/library/ctypes.html) - (Python standard library) Foreign Function Interface for Python calling C code.\n* [PyCUDA](https://mathema.tician.de/software/pycuda/) - A Python wrapper for Nvidia's CUDA API.\n* [SWIG](http://www.swig.org/Doc1.3/Python.html) - Simplified Wrapper and Interface Generator.\n\n## Forms\n\n*Libraries for working with forms.*\n\n* [Deform](https://github.com/Pylons/deform) - Python HTML form generation library influenced by the formish form generation library.\n* [django-bootstrap3](https://github.com/dyve/django-bootstrap3) - Bootstrap 3 integration with Django.\n* [django-bootstrap4](https://github.com/zostera/django-bootstrap4) - Bootstrap 4 integration with Django.\n* [django-crispy-forms](https://github.com/django-crispy-forms/django-crispy-forms) - A Django app which lets you create beautiful forms in a very elegant and DRY way.\n* [django-remote-forms](https://github.com/WiserTogether/django-remote-forms) - A platform independent Django form serializer.\n* [WTForms](https://github.com/wtforms/wtforms) - A flexible forms validation and rendering library.\n\n## Functional Programming\n\n*Functional Programming with Python.*\n\n* [Coconut](http://coconut-lang.org/) - Coconut is a variant of Python built for simple, elegant, Pythonic functional programming.\n* [CyToolz](https://github.com/pytoolz/cytoolz/) - Cython implementation of Toolz: High performance functional utilities.\n* [fn.py](https://github.com/kachayev/fn.py) - Functional programming in Python: implementation of missing features to enjoy FP.\n* [funcy](https://github.com/Suor/funcy) - A fancy and practical functional tools.\n* [Toolz](https://github.com/pytoolz/toolz) - A collection of functional utilities for iterators, functions, and dictionaries.\n\n## GUI Development\n\n*Libraries for working with graphical user interface applications.*\n\n* [curses](https://docs.python.org/3/library/curses.html) - Built-in wrapper for [ncurses](http://www.gnu.org/software/ncurses/) used to create terminal GUI applications.\n* [Eel](https://github.com/ChrisKnott/Eel) - A library for making simple Electron-like offline HTML/JS GUI apps.\n* [enaml](https://github.com/nucleic/enaml) - Creating beautiful user-interfaces with Declarative Syntax like QML.\n* [Flexx](https://github.com/zoofIO/flexx) - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering.\n* [Gooey](https://github.com/chriskiehl/Gooey) - Turn command line programs into a full GUI application with one line.\n* [kivy](https://kivy.org/) - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS.\n* [pyglet](https://bitbucket.org/pyglet/pyglet/wiki/Home) - A cross-platform windowing and multimedia library for Python.\n* [PyGObject](https://wiki.gnome.org/Projects/PyGObject) - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3).\n* [PyQt](https://riverbankcomputing.com/software/pyqt/intro) - Python bindings for the [Qt](https://www.qt.io/) cross-platform application and UI framework.\n* [PySimpleGUI](https://github.com/PySimpleGUI/PySimpleGUI) - Wrapper for tkinter, Qt, WxPython and Remi.\n* [pywebview](https://github.com/r0x0r/pywebview/) - A lightweight cross-platform native wrapper around a webview component.\n* [Tkinter](https://wiki.python.org/moin/TkInter) - Tkinter is Python's de-facto standard GUI package.\n* [Toga](https://github.com/pybee/toga) - A Python native, OS native GUI toolkit.\n* [urwid](http://urwid.org/) - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc.\n* [wxPython](https://wxpython.org/) - A blending of the wxWidgets C++ class library with the Python.\n\n## Game Development\n\n*Awesome game development libraries.*\n\n* [Cocos2d](http://cocos2d.org/) - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications.\n* [Harfang3D](http://www.harfang3d.com) - Python framework for 3D, VR and game development.\n* [Panda3D](https://www.panda3d.org/) - 3D game engine developed by Disney.\n* [Pygame](http://www.pygame.org/news.html) - Pygame is a set of Python modules designed for writing games.\n* [PyOgre](http://www.ogre3d.org/tikiwiki/PyOgre) - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D.\n* [PyOpenGL](http://pyopengl.sourceforge.net/) - Python ctypes bindings for OpenGL and it's related APIs.\n* [PySDL2](https://pysdl2.readthedocs.io) - A ctypes based wrapper for the SDL2 library.\n* [RenPy](https://www.renpy.org/) - A Visual Novel engine.\n\n## Geolocation\n\n*Libraries for geocoding addresses and working with latitudes and longitudes.*\n\n* [django-countries](https://github.com/SmileyChris/django-countries) - A Django app that provides a country field for models and forms.\n* [GeoDjango](https://docs.djangoproject.com/en/dev/ref/contrib/gis/) - A world-class geographic web framework.\n* [GeoIP](https://github.com/maxmind/geoip-api-python) - Python API for MaxMind GeoIP Legacy Database.\n* [geojson](https://github.com/frewsxcv/python-geojson) - Python bindings and utilities for GeoJSON.\n* [geopy](https://github.com/geopy/geopy) - Python Geocoding Toolbox.\n* [pygeoip](https://github.com/appliedsec/pygeoip) - Pure Python GeoIP API.\n\n## HTML Manipulation\n\n*Libraries for working with HTML and XML.*\n\n* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML.\n* [bleach](https://github.com/mozilla/bleach) - A whitelist-based HTML sanitization and text linkification library.\n* [cssutils](https://pypi.org/project/cssutils/) - A CSS library for Python.\n* [html5lib](https://github.com/html5lib/html5lib-python) - A standards-compliant library for parsing and serializing HTML documents and fragments.\n* [lxml](http://lxml.de/) - A very fast, easy-to-use and versatile library for handling HTML and XML.\n* [MarkupSafe](https://github.com/pallets/markupsafe) - Implements a XML/HTML/XHTML Markup safe string for Python.\n* [pyquery](https://github.com/gawel/pyquery) - A jQuery-like library for parsing HTML.\n* [untangle](https://github.com/stchris/untangle) - Converts XML documents to Python objects for easy access.\n* [WeasyPrint](http://weasyprint.org) - A visual rendering engine for HTML and CSS that can export to PDF.\n* [xmldataset](https://xmldataset.readthedocs.io/en/latest/) - Simple XML Parsing.\n* [xmltodict](https://github.com/martinblech/xmltodict) - Working with XML feel like you are working with JSON.\n\n## HTTP Clients\n\n*Libraries for working with HTTP.*\n\n* [grequests](https://github.com/kennethreitz/grequests) - requests + gevent for asynchronous HTTP requests.\n* [httplib2](https://github.com/httplib2/httplib2) - Comprehensive HTTP client library.\n* [requests](https://requests.kennethreitz.org/en/master/) - HTTP Requests for Humans.\n* [treq](https://github.com/twisted/treq) - Python requests like API built on top of Twisted's HTTP client.\n* [urllib3](https://github.com/shazow/urllib3) - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.\n\n## Hardware\n\n*Libraries for programming with hardware.*\n\n* [ino](http://inotool.org/) - Command line toolkit for working with [Arduino](https://www.arduino.cc/).\n* [keyboard](https://github.com/boppreh/keyboard) - Hook and simulate global keyboard events on Windows and Linux.\n* [mouse](https://github.com/boppreh/mouse) - Hook and simulate global mouse events on Windows and Linux.\n* [Pingo](http://www.pingo.io/) - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc.\n* [PyUserInput](https://github.com/SavinaRoja/PyUserInput) - A module for cross-platform control of the mouse and keyboard.\n* [scapy](https://github.com/secdev/scapy) - A brilliant packet manipulation library.\n* [wifi](https://github.com/rockymeza/wifi) - A Python library and command line tool for working with WiFi on Linux.\n\n## Image Processing\n\n*Libraries for manipulating images.*\n\n* [hmap](https://github.com/rossgoodwin/hmap) - Image histogram remapping.\n* [imgSeek](https://sourceforge.net/projects/imgseek/) - A project for searching a collection of images using visual similarity.\n* [nude.py](https://github.com/hhatto/nude.py) - Nudity detection.\n* [pagan](https://github.com/daboth/pagan) - Retro identicon (Avatar) generation based on input string and hash.\n* [pillow](https://github.com/python-pillow/Pillow) - Pillow is the friendly [PIL](http://www.pythonware.com/products/pil/) fork.\n* [pyBarcode](https://pythonhosted.org/pyBarcode/) - Create barcodes in Python without needing PIL.\n* [pygram](https://github.com/ajkumar25/pygram) - Instagram-like image filters.\n* [python-qrcode](https://github.com/lincolnloop/python-qrcode) - A pure Python QR Code generator.\n* [Quads](https://github.com/fogleman/Quads) - Computer art based on quadtrees.\n* [scikit-image](http://scikit-image.org/) - A Python library for (scientific) image processing.\n* [thumbor](https://github.com/thumbor/thumbor) - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images.\n* [wand](https://github.com/dahlia/wand) - Python bindings for [MagickWand](http://www.imagemagick.org/script/magick-wand.php), C API for ImageMagick.\n\n## Implementations\n\n*Implementations of Python.*\n\n* [CPython](https://github.com/python/cpython) - **Default, most widely used implementation of the Python programming language written in C.**\n* [Cython](http://cython.org/) - Optimizing Static Compiler for Python.\n* [CLPython](https://github.com/metawilm/cl-python) - Implementation of the Python programming language written in Common Lisp.\n* [Grumpy](https://github.com/google/grumpy) - More compiler than interpreter as more powerful CPython2.7 replacement (alpha).\n* [IronPython](https://github.com/IronLanguages/ironpython3) - Implementation of the Python programming language written in C#.\n* [Jython](https://hg.python.org/jython) - Implementation of Python programming language written in Java for the JVM.\n* [MicroPython](https://github.com/micropython/micropython) - A lean and efficient Python programming language implementation.\n* [Numba](http://numba.pydata.org/) - Python JIT compiler to LLVM aimed at scientific Python.\n* [PeachPy](https://github.com/Maratyszcza/PeachPy) - x86-64 assembler embedded in Python.\n* [Pyjion](https://github.com/Microsoft/Pyjion) - A JIT for Python based upon CoreCLR.\n* [PyPy](https://bitbucket.org/pypy/pypy) - A very fast and compliant implementation of the Python language.\n* [Pyston](https://github.com/dropbox/pyston) - A Python implementation using JIT techniques.\n* [Stackless Python](https://github.com/stackless-dev/stackless) - An enhanced version of the Python programming language.\n\n## Interactive Interpreter\n\n*Interactive Python interpreters (REPL).*\n\n* [bpython](https://github.com/bpython/bpython) - A fancy interface to the Python interpreter.\n* [Jupyter Notebook (IPython)](https://jupyter.org) - A rich toolkit to help you make the most out of using Python interactively.\n    * [awesome-jupyter](https://github.com/markusschanta/awesome-jupyter)\n* [ptpython](https://github.com/jonathanslenders/ptpython) - Advanced Python REPL built on top of the [python-prompt-toolkit](https://github.com/jonathanslenders/python-prompt-toolkit).\n\n## Internationalization\n\n*Libraries for working with i18n.*\n\n* [Babel](http://babel.pocoo.org/en/latest/) - An internationalization library for Python.\n* [PyICU](https://github.com/ovalhub/pyicu) - A wrapper of International Components for Unicode C++ library ([ICU](http://site.icu-project.org/)).\n\n## Job Scheduler\n\n*Libraries for scheduling jobs.*\n\n* [APScheduler](http://apscheduler.readthedocs.io/en/latest/) - A light but powerful in-process task scheduler that lets you schedule functions.\n* [django-schedule](https://github.com/thauber/django-schedule) - A calendaring app for Django.\n* [doit](http://pydoit.org/) - A task runner and build tool.\n* [gunnery](https://github.com/gunnery/gunnery) - Multipurpose task execution tool for distributed systems with web-based interface.\n* [Joblib](https://joblib.readthedocs.io/) - A set of tools to provide lightweight pipelining in Python.\n* [Plan](https://github.com/fengsp/plan) - Writing crontab file in Python like a charm.\n* [schedule](https://github.com/dbader/schedule) - Python job scheduling for humans.\n* [Spiff](https://github.com/knipknap/SpiffWorkflow) - A powerful workflow engine implemented in pure Python.\n* [TaskFlow](https://docs.openstack.org/developer/taskflow/) - A Python library that helps to make task execution easy, consistent and reliable.\n* [Airflow](https://airflow.apache.org/) - Airflow is a platform to programmatically author, schedule and monitor workflows.\n\n## Logging\n\n*Libraries for generating and working with logs.*\n\n* [Eliot](https://github.com/ScatterHQ/eliot) - Logging for complex & distributed systems.\n* [logbook](http://logbook.readthedocs.io/en/stable/) - Logging replacement for Python.\n* [logging](https://docs.python.org/3/library/logging.html) - (Python standard library) Logging facility for Python.\n* [raven](https://github.com/getsentry/raven-python) - Python client for Sentry, a log/error tracking, crash reporting and aggregation platform for web applications.\n\n## Machine Learning\n\n*Libraries for Machine Learning. Also see [awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning#python).*\n\n* [H2O](https://github.com/h2oai/h2o-3) - Open Source Fast Scalable Machine Learning Platform.\n* [Metrics](https://github.com/benhamner/Metrics) - Machine learning evaluation metrics.\n* [NuPIC](https://github.com/numenta/nupic) - Numenta Platform for Intelligent Computing.\n* [scikit-learn](http://scikit-learn.org/) - The most popular Python library for Machine Learning.\n* [Spark ML](http://spark.apache.org/docs/latest/ml-guide.html) - [Apache Spark](http://spark.apache.org/)'s scalable Machine Learning library.\n* [vowpal_porpoise](https://github.com/josephreisinger/vowpal_porpoise) - A lightweight Python wrapper for [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/).\n* [xgboost](https://github.com/dmlc/xgboost) - A scalable, portable, and distributed gradient boosting library.\n\n## Microsoft Windows\n\n*Python programming on Microsoft Windows.*\n\n* [Python(x,y)](http://python-xy.github.io/) - Scientific-applications-oriented Python Distribution based on Qt and Spyder.\n* [pythonlibs](http://www.lfd.uci.edu/~gohlke/pythonlibs/) - Unofficial Windows binaries for Python extension packages.\n* [PythonNet](https://github.com/pythonnet/pythonnet) - Python Integration with the .NET Common Language Runtime (CLR).\n* [PyWin32](https://github.com/mhammond/pywin32) - Python Extensions for Windows.\n* [WinPython](https://winpython.github.io/) - Portable development environment for Windows 7/8.\n\n## Miscellaneous\n\n*Useful libraries or tools that don't fit in the categories above.*\n\n* [blinker](https://github.com/jek/blinker) - A fast Python in-process signal/event dispatching system.\n* [boltons](https://github.com/mahmoud/boltons) - A set of pure-Python utilities.\n* [itsdangerous](https://github.com/pallets/itsdangerous) - Various helpers to pass trusted data to untrusted environments.\n* [pluginbase](https://github.com/mitsuhiko/pluginbase) - A simple but flexible plugin system for Python.\n* [tryton](http://www.tryton.org/) - A general purpose business framework.\n\n## Natural Language Processing\n\n*Libraries for working with human languages.*\n\n- General\n    * [gensim](https://github.com/RaRe-Technologies/gensim) - Topic Modeling for Humans.\n    * [langid.py](https://github.com/saffsd/langid.py) - Stand-alone language identification system.\n    * [nltk](http://www.nltk.org/) - A leading platform for building Python programs to work with human language data.\n    * [pattern](https://github.com/clips/pattern) - A web mining module for the Python.\n    * [polyglot](https://github.com/aboSamoor/polyglot) - Natural language pipeline supporting hundreds of languages.\n    * [pytext](https://github.com/facebookresearch/pytext) - A natural language modeling framework based on PyTorch.\n    * [PyTorch-NLP](https://github.com/PetrochukM/PyTorch-NLP) - A toolkit enabling rapid deep learning NLP prototyping for research.\n    * [spacy](https://spacy.io/) - A library for industrial-strength natural language processing in Python and Cython.\n    * [stanfordnlp](https://github.com/stanfordnlp/stanfordnlp) - The Stanford NLP Group's official Python library, supporting 50+ languages.\n- Chinese\n    * [jieba](https://github.com/fxsjy/jieba) - The most popular Chinese text segmentation library.\n    * [pkuseg-python](https://github.com/lancopku/pkuseg-python) - A toolkit for Chinese word segmentation in various domains.\n    * [snownlp](https://github.com/isnowfy/snownlp) - A library for processing Chinese text.\n    * [funNLP](https://github.com/fighting41love/funNLP) - A collection of tools and datasets for Chinese NLP.\n\n## Network Virtualization\n\n*Tools and libraries for Virtual Networking and SDN (Software Defined Networking).*\n\n* [mininet](https://github.com/mininet/mininet) - A popular network emulator and API written in Python.\n* [napalm](https://github.com/napalm-automation/napalm) - Cross-vendor API to manipulate network devices.\n* [pox](https://github.com/noxrepo/pox) - A Python-based SDN control applications, such as OpenFlow SDN controllers.\n\n## News Feed\n\n*Libraries for building user's activities.*\n\n* [django-activity-stream](https://github.com/justquick/django-activity-stream) - Generating generic activity streams from the actions on your site.\n* [Stream Framework](https://github.com/tschellenbach/Stream-Framework) - Building news feed and notification systems using Cassandra and Redis.\n\n## ORM\n\n*Libraries that implement Object-Relational Mapping or data mapping techniques.*\n\n* Relational Databases\n    * [Django Models](https://docs.djangoproject.com/en/dev/topics/db/models/) - The Django ORM.\n    * [SQLAlchemy](https://www.sqlalchemy.org/) - The Python SQL Toolkit and Object Relational Mapper.\n        * [awesome-sqlalchemy](https://github.com/dahlia/awesome-sqlalchemy)\n    * [dataset](https://github.com/pudo/dataset) - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL.\n    * [orator](https://github.com/sdispater/orator) -  The Orator ORM provides a simple yet beautiful ActiveRecord implementation.\n    * [orm](https://github.com/encode/orm) - An async ORM.\n    * [peewee](https://github.com/coleifer/peewee) - A small, expressive ORM.\n    * [pony](https://github.com/ponyorm/pony/) - ORM that provides a generator-oriented interface to SQL.\n    * [pydal](https://github.com/web2py/pydal/) - A pure Python Database Abstraction Layer.\n* NoSQL Databases\n    * [hot-redis](https://github.com/stephenmcd/hot-redis) - Rich Python data types for Redis.\n    * [mongoengine](https://github.com/MongoEngine/mongoengine) - A Python Object-Document-Mapper for working with MongoDB.\n    * [PynamoDB](https://github.com/pynamodb/PynamoDB) - A Pythonic interface for [Amazon DynamoDB](https://aws.amazon.com/dynamodb/).\n    * [redisco](https://github.com/kiddouk/redisco) - A Python Library for Simple Models and Containers Persisted in Redis.\n\n## Package Management\n\n*Libraries for package and dependency management.*\n\n* [pip](https://pip.pypa.io/en/stable/) - The Python package and dependency manager.\n    * [PyPI](https://pypi.org/)\n    * [pip-tools](https://github.com/jazzband/pip-tools) - A set of tools to keep your pinned Python dependencies fresh.\n* [conda](https://github.com/conda/conda/) - Cross-platform, Python-agnostic binary package manager.\n\n## Package Repositories\n\n*Local PyPI repository server and proxies.*\n\n* [warehouse](https://github.com/pypa/warehouse) - Next generation Python Package Repository (PyPI).\n* [bandersnatch](https://github.com/pypa/bandersnatch/) - PyPI mirroring tool provided by Python Packaging Authority (PyPA).\n* [devpi](https://github.com/devpi/devpi) - PyPI server and packaging/testing/release tool.\n* [localshop](https://github.com/jazzband/localshop) - Local PyPI server (custom packages and auto-mirroring of pypi).\n\n## Permissions\n\n*Libraries that allow or deny users access to data or functionality.*\n\n* [django-guardian](https://github.com/django-guardian/django-guardian) - Implementation of per object permissions for Django 1.2+\n* [django-rules](https://github.com/dfunckt/django-rules) - A tiny but powerful app providing object-level permissions to Django, without requiring a database.\n\n## Processes\n\n*Libraries for starting and communicating with OS processes.*\n\n* [delegator.py](https://github.com/amitt001/delegator.py) - [Subprocesses](https://docs.python.org/3/library/subprocess.html) for Humans 2.0.\n* [sarge](https://sarge.readthedocs.io/en/latest/) - Yet another wrapper for subprocess.\n* [sh](https://github.com/amoffat/sh) - A full-fledged subprocess replacement for Python.\n\n## Recommender Systems\n\n*Libraries for building recommender systems.*\n\n* [annoy](https://github.com/spotify/annoy) - Approximate Nearest Neighbors in C++/Python optimized for memory usage.\n* [fastFM](https://github.com/ibayer/fastFM) - A library for Factorization Machines.\n* [implicit](https://github.com/benfred/implicit) - A fast Python implementation of collaborative filtering for implicit datasets.\n* [libffm](https://github.com/guestwalk/libffm) - A library for Field-aware Factorization Machine (FFM).\n* [lightfm](https://github.com/lyst/lightfm) - A Python implementation of a number of popular recommendation algorithms.\n* [spotlight](https://github.com/maciejkula/spotlight) - Deep recommender models using PyTorch.\n* [Surprise](https://github.com/NicolasHug/Surprise) - A scikit for building and analyzing recommender systems.\n* [tensorrec](https://github.com/jfkirk/tensorrec) - A Recommendation Engine Framework in TensorFlow.\n\n## RESTful API\n\n*Libraries for building RESTful APIs.*\n\n* Django\n    * [django-rest-framework](http://www.django-rest-framework.org/) - A powerful and flexible toolkit to build web APIs.\n    * [django-tastypie](http://tastypieapi.org/) - Creating delicious APIs for Django apps.\n* Flask\n    * [eve](https://github.com/pyeve/eve) - REST API framework powered by Flask, MongoDB and good intentions.\n    * [flask-api](https://github.com/flask-api/flask-api) - Browsable Web APIs for Flask.\n    * [flask-restful](https://github.com/flask-restful/flask-restful) - Quickly building REST APIs for Flask.\n* Pyramid\n    * [cornice](https://github.com/Cornices/cornice) - A RESTful framework for Pyramid.\n* Framework agnostic\n    * [apistar](https://github.com/encode/apistar) - A smart Web API framework, designed for Python 3.\n    * [falcon](https://github.com/falconry/falcon) - A high-performance framework for building cloud APIs and web app backends.\n    * [fastapi](https://github.com/tiangolo/fastapi) - A modern, fast, web framework for building APIs with Python 3.6+ based on standard Python type hints.\n    * [hug](https://github.com/hugapi/hug) - A Python 3 framework for cleanly exposing APIs.\n    * [sandman2](https://github.com/jeffknupp/sandman2) - Automated REST APIs for existing database-driven systems.\n    * [sanic](https://github.com/huge-success/sanic) - A Python 3.6+ web server and web framework that's written to go fast.\n    * [vibora](https://vibora.io/) - Fast, efficient and asynchronous Web framework inspired by Flask.\n\n## Robotics\n\n*Libraries for robotics.*\n\n* [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics) - This is a compilation of various robotics algorithms with visualizations.\n* [rospy](http://wiki.ros.org/rospy) - This is a library for ROS (Robot Operating System).\n\n## RPC Servers\n\n*RPC-compatible servers.*\n\n* [zeroRPC](https://github.com/0rpc/zerorpc-python) - zerorpc is a flexible RPC implementation based on [ZeroMQ](http://zeromq.org/) and [MessagePack](http://msgpack.org/).\n\n## Science\n\n*Libraries for scientific computing. Also see [Python-for-Scientists](https://github.com/TomNicholas/Python-for-Scientists)*\n\n* [astropy](http://www.astropy.org/) - A community Python library for Astronomy.\n* [bcbio-nextgen](https://github.com/chapmanb/bcbio-nextgen) - Providing best-practice pipelines for fully automated high throughput sequencing analysis.\n* [bccb](https://github.com/chapmanb/bcbb) - Collection of useful code related to biological analysis.\n* [Biopython](http://biopython.org/wiki/Main_Page) - Biopython is a set of freely available tools for biological computation.\n* [cclib](http://cclib.github.io/) - A library for parsing and interpreting the results of computational chemistry packages.\n* [Colour](http://colour-science.org/) - Implementing a comprehensive number of colour theory transformations and algorithms.\n* [NetworkX](https://networkx.github.io/) - A high-productivity software for complex networks.\n* [NIPY](http://nipy.org) - A collection of neuroimaging toolkits.\n* [NumPy](http://www.numpy.org/) - A fundamental package for scientific computing with Python.\n* [Open Babel](http://openbabel.org/wiki/Main_Page) - A chemical toolbox designed to speak the many languages of chemical data.\n* [ObsPy](https://github.com/obspy/obspy/wiki/) - A Python toolbox for seismology.\n* [PyDy](http://www.pydy.org/) - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion.\n* [PyMC](https://github.com/pymc-devs/pymc3) - Markov Chain Monte Carlo sampling toolkit.\n* [QuTiP](http://qutip.org/) - Quantum Toolbox in Python.\n* [RDKit](http://www.rdkit.org/) - Cheminformatics and Machine Learning Software.\n* [SciPy](https://www.scipy.org/) - A Python-based ecosystem of open-source software for mathematics, science, and engineering.\n* [statsmodels](https://github.com/statsmodels/statsmodels) - Statistical modeling and econometrics in Python.\n* [SymPy](https://github.com/sympy/sympy) - A Python library for symbolic mathematics.\n* [Zipline](https://github.com/quantopian/zipline) - A Pythonic algorithmic trading library.\n* [SimPy](https://bitbucket.org/simpy/simpy) -  A process-based discrete-event simulation framework.\n\n## Search\n\n*Libraries and software for indexing and performing search queries on data.*\n\n* [elasticsearch-py](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html) - The official low-level Python client for [Elasticsearch](https://www.elastic.co/products/elasticsearch).\n* [elasticsearch-dsl-py](https://github.com/elastic/elasticsearch-dsl-py) - The official high-level Python client for Elasticsearch.\n* [django-haystack](https://github.com/django-haystack/django-haystack) - Modular search for Django.\n* [pysolr](https://github.com/django-haystack/pysolr) - A lightweight Python wrapper for [Apache Solr](https://lucene.apache.org/solr/).\n* [whoosh](http://whoosh.readthedocs.io/en/latest/) - A fast, pure Python search engine library.\n\n## Serialization\n\n*Libraries for serializing complex data types*\n\n* [marshmallow](https://github.com/marshmallow-code/marshmallow) - A lightweight library for converting complex objects to and from simple Python datatypes.\n* [pysimdjson](https://github.com/TkTech/pysimdjson) - A Python bindings for [simdjson](https://github.com/lemire/simdjson).\n* [python-rapidjson](https://github.com/python-rapidjson/python-rapidjson) - A Python wrapper around [RapidJSON](https://github.com/Tencent/rapidjson).\n* [ultrajson](https://github.com/esnme/ultrajson) - A fast JSON decoder and encoder written in C with Python bindings.\n\n## Serverless Frameworks\n\n*Frameworks for developing serverless Python code.*\n\n* [python-lambda](https://github.com/nficano/python-lambda) - A toolkit for developing and deploying Python code in AWS Lambda.\n* [Zappa](https://github.com/Miserlou/Zappa) - A tool for deploying WSGI applications on AWS Lambda and API Gateway.\n\n## Specific Formats Processing\n\n*Libraries for parsing and manipulating specific text formats.*\n\n* General\n    * [tablib](https://github.com/kennethreitz/tablib) - A module for Tabular Datasets in XLS, CSV, JSON, YAML.\n* Office\n    * [openpyxl](https://openpyxl.readthedocs.io/en/stable/) - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files.\n    * [pyexcel](https://github.com/pyexcel/pyexcel) - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files.\n    * [python-docx](https://github.com/python-openxml/python-docx) - Reads, queries and modifies Microsoft Word 2007/2008 docx files.\n    * [python-pptx](https://github.com/scanny/python-pptx) - Python library for creating and updating PowerPoint (.pptx) files.\n    * [unoconv](https://github.com/unoconv/unoconv) - Convert between any document format supported by LibreOffice/OpenOffice.\n    * [XlsxWriter](https://github.com/jmcnamara/XlsxWriter) - A Python module for creating Excel .xlsx files.\n    * [xlwings](https://github.com/ZoomerAnalytics/xlwings) - A BSD-licensed library that makes it easy to call Python from Excel and vice versa.\n    * [xlwt](https://github.com/python-excel/xlwt) / [xlrd](https://github.com/python-excel/xlrd) - Writing and reading data and formatting information from Excel files.\n* PDF\n    * [PDFMiner](https://github.com/euske/pdfminer) - A tool for extracting information from PDF documents.\n    * [PyPDF2](https://github.com/mstamy2/PyPDF2) - A library capable of splitting, merging and transforming PDF pages.\n    * [ReportLab](https://www.reportlab.com/opensource/) - Allowing Rapid creation of rich PDF documents.\n* Markdown\n    * [Mistune](https://github.com/lepture/mistune) - Fastest and full featured pure Python parsers of Markdown.\n    * [Python-Markdown](https://github.com/waylan/Python-Markdown) - A Python implementation of John Gruber\u2019s Markdown.\n* YAML\n    * [PyYAML](http://pyyaml.org/) - YAML implementations for Python.\n* CSV\n    * [csvkit](https://github.com/wireservice/csvkit) - Utilities for converting to and working with CSV.\n* Archive\n    * [unp](https://github.com/mitsuhiko/unp) - A command line tool that can unpack archives easily.\n\n## Static Site Generator\n\n*Static site generator is a software that takes some text + templates as input and produces HTML files on the output.*\n\n* [mkdocs](https://github.com/mkdocs/mkdocs/) - Markdown friendly documentation generator.\n* [pelican](https://github.com/getpelican/pelican) - Static site generator that supports Markdown and reST syntax.\n* [lektor](https://github.com/lektor/lektor) - An easy to use static CMS and blog engine.\n* [nikola](https://github.com/getnikola/nikola) - A static website and blog generator.\n\n## Tagging\n\n*Libraries for tagging items.*\n\n* [django-taggit](https://github.com/jazzband/django-taggit) - Simple tagging for Django.\n\n## Task Queues\n\n*Libraries for working with task queues.*\n\n* [celery](http://www.celeryproject.org/) - An asynchronous task queue/job queue based on distributed message passing.\n* [huey](https://github.com/coleifer/huey) - Little multi-threaded task queue.\n* [mrq](https://github.com/pricingassistant/mrq) - A distributed worker task queue in Python using Redis & gevent.\n* [rq](https://github.com/rq/rq) - Simple job queues for Python.\n\n## Template Engine\n\n*Libraries and tools for templating and lexing.*\n\n* [Jinja2](https://github.com/pallets/jinja) - A modern and designer friendly templating language.\n* [Genshi](https://genshi.edgewall.org/) - Python templating toolkit for generation of web-aware output.\n* [Mako](http://www.makotemplates.org/) - Hyperfast and lightweight templating for the Python platform.\n\n## Testing\n\n*Libraries for testing codebases and generating test data.*\n\n* Testing Frameworks\n    * [pytest](https://docs.pytest.org/en/latest/) - A mature full-featured Python testing tool.\n    * [hypothesis](https://github.com/HypothesisWorks/hypothesis) - Hypothesis is an advanced Quickcheck style property based testing library.\n    * [nose2](https://github.com/nose-devs/nose2) - The successor to `nose`, based on `unittest2.\n    * [Robot Framework](https://github.com/robotframework/robotframework) - A generic test automation framework.\n    * [unittest](https://docs.python.org/3/library/unittest.html) - (Python standard library) Unit testing framework.\n* Test Runners\n    * [green](https://github.com/CleanCut/green) - A clean, colorful test runner.\n    * [mamba](http://nestorsalceda.github.io/mamba/) - The definitive testing tool for Python. Born under the banner of BDD.\n    * [tox](https://tox.readthedocs.io/en/latest/) - Auto builds and tests distributions in multiple Python versions\n* GUI / Web Testing\n    * [locust](https://github.com/locustio/locust) - Scalable user load testing tool written in Python.\n    * [PyAutoGUI](https://github.com/asweigart/pyautogui) - PyAutoGUI is a cross-platform GUI automation Python module for human beings.\n    * [Selenium](https://pypi.org/project/selenium/) - Python bindings for [Selenium](http://www.seleniumhq.org/) WebDriver.\n    * [sixpack](https://github.com/seatgeek/sixpack) - A language-agnostic A/B Testing framework.\n    * [splinter](https://github.com/cobrateam/splinter) - Open source tool for testing web applications.\n* Mock\n    * [mock](https://docs.python.org/3/library/unittest.mock.html) - (Python standard library) A mocking and patching library.\n    * [doublex](https://pypi.org/project/doublex/) - Powerful test doubles framework for Python.\n    * [freezegun](https://github.com/spulec/freezegun) - Travel through time by mocking the datetime module.\n    * [httmock](https://github.com/patrys/httmock) - A mocking library for requests for Python 2.6+ and 3.2+.\n    * [httpretty](https://github.com/gabrielfalcao/HTTPretty) - HTTP request mock tool for Python.\n    * [mocket](https://github.com/mindflayer/python-mocket) - A socket mock framework with gevent/asyncio/SSL support.\n    * [responses](https://github.com/getsentry/responses) - A utility library for mocking out the requests Python library.\n    * [VCR.py](https://github.com/kevin1024/vcrpy) - Record and replay HTTP interactions on your tests.\n* Object Factories\n    * [factory_boy](https://github.com/FactoryBoy/factory_boy) - A test fixtures replacement for Python.\n    * [mixer](https://github.com/klen/mixer) - Another fixtures replacement. Supported Django, Flask, SQLAlchemy, Peewee and etc.\n    * [model_mommy](https://github.com/vandersonmota/model_mommy) - Creating random fixtures for testing in Django.\n* Code Coverage\n    * [coverage](https://pypi.org/project/coverage/) - Code coverage measurement.\n* Fake Data\n    * [mimesis](https://github.com/lk-geimfari/mimesis) - is a Python library that help you generate fake data.\n    * [fake2db](https://github.com/emirozer/fake2db) - Fake database generator.\n    * [faker](https://github.com/joke2k/faker) - A Python package that generates fake data.\n    * [radar](https://pypi.org/project/radar/) - Generate random datetime / time.\n\n## Text Processing\n\n*Libraries for parsing and manipulating plain texts.*\n\n* General\n    * [chardet](https://github.com/chardet/chardet) - Python 2/3 compatible character encoding detector.\n    * [difflib](https://docs.python.org/3/library/difflib.html) - (Python standard library) Helpers for computing deltas.\n    * [ftfy](https://github.com/LuminosoInsight/python-ftfy) - Makes Unicode text less broken and more consistent automagically.\n    * [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) - Fuzzy String Matching.\n    * [Levenshtein](https://github.com/ztane/python-Levenshtein/) - Fast computation of Levenshtein distance and string similarity.\n    * [pangu.py](https://github.com/vinta/pangu.py) - Paranoid text spacing.\n    * [pyfiglet](https://github.com/pwaller/pyfiglet) - An implementation of figlet written in Python.\n    * [pypinyin](https://github.com/mozillazg/python-pinyin) - Convert Chinese hanzi (\u6f22\u5b57) to pinyin (\u62fc\u97f3).\n    * [textdistance](https://github.com/orsinium/textdistance) - Compute distance between sequences with 30+ algorithms.\n    * [unidecode](https://pypi.org/project/Unidecode/) - ASCII transliterations of Unicode text.\n* Slugify\n    * [awesome-slugify](https://github.com/dimka665/awesome-slugify) - A Python slugify library that can preserve unicode.\n    * [python-slugify](https://github.com/un33k/python-slugify) - A Python slugify library that translates unicode to ASCII.\n    * [unicode-slugify](https://github.com/mozilla/unicode-slugify) - A slugifier that generates unicode slugs with Django as a dependency.\n* Unique identifiers\n    * [hashids](https://github.com/davidaurelio/hashids-python) - Implementation of [hashids](http://hashids.org) in Python.\n    * [shortuuid](https://github.com/skorokithakis/shortuuid) - A generator library for concise, unambiguous and URL-safe UUIDs.\n* Parser\n    * [ply](https://github.com/dabeaz/ply) - Implementation of lex and yacc parsing tools for Python.\n    * [pygments](http://pygments.org/) - A generic syntax highlighter.\n    * [pyparsing](https://github.com/pyparsing/pyparsing) - A general purpose framework for generating parsers.\n    * [python-nameparser](https://github.com/derek73/python-nameparser) - Parsing human names into their individual components.\n    * [python-phonenumbers](https://github.com/daviddrysdale/python-phonenumbers) - Parsing, formatting, storing and validating international phone numbers.\n    * [python-user-agents](https://github.com/selwin/python-user-agents) - Browser user agent parser.\n    * [sqlparse](https://github.com/andialbrecht/sqlparse) - A non-validating SQL parser.\n\n## Third-party APIs\n\n*Libraries for accessing third party services APIs. Also see [List of Python API Wrappers and Libraries](https://github.com/realpython/list-of-python-api-wrappers).*\n\n* [apache-libcloud](https://libcloud.apache.org/) - One Python library for all clouds.\n* [boto3](https://github.com/boto/boto3) - Python interface to Amazon Web Services.\n* [django-wordpress](https://github.com/istrategylabs/django-wordpress) - WordPress models and views for Django.\n* [facebook-sdk](https://github.com/mobolic/facebook-sdk) - Facebook Platform Python SDK.\n* [google-api-python-client](https://github.com/google/google-api-python-client) - Google APIs Client Library for Python.\n* [gspread](https://github.com/burnash/gspread) - Google Spreadsheets Python API.\n* [twython](https://github.com/ryanmcgrath/twython) - A Python wrapper for the Twitter API.\n\n## URL Manipulation\n\n*Libraries for parsing URLs.*\n\n* [furl](https://github.com/gruns/furl) - A small Python library that makes parsing and manipulating URLs easy.\n* [purl](https://github.com/codeinthehole/purl) - A simple, immutable URL class with a clean API for interrogation and manipulation.\n* [pyshorteners](https://github.com/ellisonleao/pyshorteners) - A pure Python URL shortening lib.\n* [webargs](https://github.com/marshmallow-code/webargs) - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks.\n\n## Video\n\n*Libraries for manipulating video and GIFs.*\n\n* [moviepy](https://zulko.github.io/moviepy/) - A module for script-based movie editing with many formats, including animated GIFs.\n* [scikit-video](https://github.com/aizvorski/scikit-video) - Video processing routines for SciPy.\n\n## Web Asset Management\n\n*Tools for managing, compressing and minifying website assets.*\n\n* [django-compressor](https://github.com/django-compressor/django-compressor) - Compresses linked and inline JavaScript or CSS into a single cached file.\n* [django-pipeline](https://github.com/jazzband/django-pipeline) - An asset packaging library for Django.\n* [django-storages](https://github.com/jschneier/django-storages) - A collection of custom storage back ends for Django.\n* [fanstatic](http://www.fanstatic.org/en/latest/) - Packages, optimizes, and serves static file dependencies as Python packages.\n* [fileconveyor](http://wimleers.com/fileconveyor) - A daemon to detect and sync files to CDNs, S3 and FTP.\n* [flask-assets](https://github.com/miracle2k/flask-assets) - Helps you integrate webassets into your Flask app.\n* [webassets](https://github.com/miracle2k/webassets) - Bundles, optimizes, and manages unique cache-busting URLs for static resources.\n\n## Web Content Extracting\n\n*Libraries for extracting web contents.*\n\n* [html2text](https://github.com/Alir3z4/html2text) - Convert HTML to Markdown-formatted text.\n* [lassie](https://github.com/michaelhelmick/lassie) - Web Content Retrieval for Humans.\n* [micawber](https://github.com/coleifer/micawber) - A small library for extracting rich content from URLs.\n* [newspaper](https://github.com/codelucas/newspaper) - News extraction, article extraction and content curation in Python.\n* [python-readability](https://github.com/buriy/python-readability) - Fast Python port of arc90's readability tool.\n* [requests-html](https://github.com/kennethreitz/requests-html) - Pythonic HTML Parsing for Humans.\n* [sumy](https://github.com/miso-belica/sumy) - A module for automatic summarization of text documents and HTML pages.\n* [textract](https://github.com/deanmalmgren/textract) - Extract text from any document, Word, PowerPoint, PDFs, etc.\n* [toapi](https://github.com/gaojiuli/toapi) - Every web site provides APIs.\n\n## Web Crawling\n\n*Libraries to automate web scraping.*\n\n* [cola](https://github.com/chineking/cola) - A distributed crawling framework.\n* [feedparser](https://pythonhosted.org/feedparser/) - Universal feed parser.\n* [grab](https://github.com/lorien/grab) - Site scraping framework.\n* [MechanicalSoup](https://github.com/MechanicalSoup/MechanicalSoup) - A Python library for automating interaction with websites.\n* [pyspider](https://github.com/binux/pyspider) - A powerful spider system.\n* [robobrowser](https://github.com/jmcarp/robobrowser) - A simple, Pythonic library for browsing the web without a standalone web browser.\n* [scrapy](https://scrapy.org/) - A fast high-level screen scraping and web crawling framework.\n* [portia](https://github.com/scrapinghub/portia) - Visual scraping for Scrapy.\n\n## Web Frameworks\n\n*Traditional full stack web frameworks. Also see [RESTful API](https://github.com/vinta/awesome-python#restful-api)*\n\n* Synchronous\n    * [Django](https://www.djangoproject.com/) - The most popular web framework in Python.\n        * [awesome-django](https://github.com/shahraizali/awesome-django)\n    * [Flask](http://flask.pocoo.org/) - A microframework for Python.\n        * [awesome-flask](https://github.com/humiaozuzu/awesome-flask)\n    * [Pyramid](https://pylonsproject.org/) - A small, fast, down-to-earth, open source Python web framework.\n        * [awesome-pyramid](https://github.com/uralbash/awesome-pyramid)\n    * [Masonite](https://github.com/MasoniteFramework/masonite) - The modern and developer centric Python web framework.\n* Asynchronous\n    * [Tornado](http://www.tornadoweb.org/en/latest/) - A web framework and asynchronous networking library.\n\n## WebSocket\n\n*Libraries for working with WebSocket.*\n\n* [autobahn-python](https://github.com/crossbario/autobahn-python) - WebSocket & WAMP for Python on Twisted and [asyncio](https://docs.python.org/3/library/asyncio.html).\n* [channels](https://github.com/django/channels) - Developer-friendly asynchrony for Django.\n* [websockets](https://github.com/aaugustin/websockets) - A library for building WebSocket servers and clients with a focus on correctness and simplicity.\n\n## WSGI Servers\n\n*WSGI-compatible web servers.*\n\n* [bjoern](https://github.com/jonashaag/bjoern) - Asynchronous, very fast and written in C.\n* [gunicorn](https://github.com/benoitc/gunicorn) - Pre-forked, partly written in C.\n* [uWSGI](https://uwsgi-docs.readthedocs.io/en/latest/) - A project aims at developing a full stack for building hosting services, written in C.\n* [waitress](https://github.com/Pylons/waitress) - Multi-threaded, powers Pyramid.\n* [werkzeug](https://github.com/pallets/werkzeug) - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.\n\n# Resources\n\nWhere to discover new Python libraries.\n\n## Podcasts\n\n* [From Python Import Podcast](http://frompythonimportpodcast.com/)\n* [Podcast.init](https://podcastinit.com/)\n* [Python Bytes](https://pythonbytes.fm)\n* [Python Testing](http://pythontesting.net)\n* [Radio Free Python](http://radiofreepython.com/)\n* [Talk Python To Me](https://talkpython.fm/)\n* [Test and Code](https://testandcode.com/)\n\n## Twitter\n\n* [@codetengu](https://twitter.com/codetengu)\n* [@getpy](https://twitter.com/getpy)\n* [@importpython](https://twitter.com/importpython)\n* [@planetpython](https://twitter.com/planetpython)\n* [@pycoders](https://twitter.com/pycoders)\n* [@pypi](https://twitter.com/pypi)\n* [@pythontrending](https://twitter.com/pythontrending)\n* [@PythonWeekly](https://twitter.com/PythonWeekly)\n* [@TalkPython](https://twitter.com/talkpython)\n* [@realpython](https://twitter.com/realpython)\n\n## Websites\n\n* [/r/CoolGithubProjects](https://www.reddit.com/r/coolgithubprojects/)\n* [/r/Python](https://www.reddit.com/r/python)\n* [Awesome Python @LibHunt](https://python.libhunt.com/)\n* [Django Packages](https://djangopackages.org/)\n* [Full Stack Python](https://www.fullstackpython.com/)\n* [Python Cheatsheet](https://www.pythoncheatsheet.org/)\n* [Python ZEEF](https://python.zeef.com/alan.richmond)\n* [Python \u5f00\u53d1\u793e\u533a](https://www.ctolib.com/python/)\n* [Real Python](https://realpython.com)\n* [Trending Python repositories on GitHub today](https://github.com/trending?l=python)\n* [\u0421\u043e\u043e\u0431\u0449\u0435\u0441\u0442\u0432\u043e Python \u041f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0441\u0442\u043e\u0432](https://python-scripts.com/)\n\n## Weekly\n\n* [CodeTengu Weekly \u78bc\u5929\u72d7\u9031\u520a](https://weekly.codetengu.com/)\n* [Import Python Newsletter](http://importpython.com/newsletter/)\n* [Pycoder's Weekly](http://pycoders.com/)\n* [Python Weekly](http://www.pythonweekly.com/)\n* [Python Tricks](https://realpython.com/python-tricks/)\n\n# Contributing\n\nYour contributions are always welcome! Please take a look at the [contribution guidelines](https://github.com/vinta/awesome-python/blob/master/CONTRIBUTING.md) first.\n\nI will keep some pull requests open if I'm not sure whether those libraries are awesome, you could [vote for them](https://github.com/vinta/awesome-python/pulls) by adding :+1: to them. Pull requests will be merged when their votes reach **20**.\n\n- - -\n\nIf you have any question about this opinionated list, do not hesitate to contact me [@vinta](https://twitter.com/vinta) on Twitter or open an issue on GitHub.\n"}, {"repo": "public-apis/public-apis", "language": "Python", "readme_contents": "# Public APIs [![Build Status](https://api.travis-ci.org/public-apis/public-apis.svg)](https://travis-ci.org/public-apis/public-apis)\n\nA collective list of free APIs for use in software and web development.\n\nSponsor:\n\n<a href=\"https://ultimatecourses.com?utm_source=github.com\"><img src=\"https://ultimatecourses.com/assets/img/banners/ultimate-angular-github.svg\" style=\"width:100%;max-width:100%\"></a>\n\nA public API for this project can be found [here](https://github.com/davemachado/public-api) - thanks to [DigitalOcean](https://www.digitalocean.com/) for helping us provide this service!\n\nFor information on contributing to this project, please see the [contributing guide](.github/CONTRIBUTING.md).\n\nPlease note a passing build status indicates all listed APIs are available since the last update. A failing build status indicates that 1 or more services may be unavailable at the moment.\n\n## Index\n\n* [Animals](#animals)\n* [Anime](#anime)\n* [Anti-Malware](#anti-malware)\n* [Art & Design](#art--design)\n* [Books](#books)\n* [Business](#business)\n* [Calendar](#calendar)\n* [Cloud Storage & File Sharing](#cloud-storage--file-sharing)\n* [Continuous Integration](#continuous-integration)\n* [Cryptocurrency](#cryptocurrency)\n* [Currency Exchange](#currency-exchange)\n* [Data Validation](#data-validation)\n* [Development](#development)\n* [Dictionaries](#dictionaries)\n* [Documents & Productivity](#documents--productivity)\n* [Environment](#environment)\n* [Events](#events)\n* [Finance](#finance)\n* [Food & Drink](#food--drink)\n* [Fraud Prevention](#fraud-prevention)\n* [Games & Comics](#games--comics)\n* [Geocoding](#geocoding)\n* [Government](#government)\n* [Health](#health)\n* [Jobs](#jobs)\n* [Machine Learning](#machine-learning)\n* [Music](#music)\n* [News](#news)\n* [Open Data](#open-data)\n* [Open Source Projects](#open-source-projects)\n* [Patent](#patent)\n* [Personality](#personality)\n* [Photography](#photography)\n* [Science & Math](#science--math)\n* [Security](#security)\n* [Shopping](#shopping)\n* [Social](#social)\n* [Sports & Fitness](#sports--fitness)\n* [Test Data](#test-data)\n* [Text Analysis](#text-analysis)\n* [Tracking](#tracking)\n* [Transportation](#transportation)\n* [URL Shorteners](#url-shorteners)\n* [Vehicle](#vehicle)\n* [Video](#video)\n* [Weather](#weather)\n\n### Animals\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Cat Facts](https://alexwohlbruck.github.io/cat-facts/) | Daily cat facts | No | Yes | No |\n| [Cats](https://docs.thecatapi.com/) | Pictures of cats from Tumblr | `apiKey` | Yes | Unknown |\n| [Dogs](https://dog.ceo/dog-api/) | Based on the Stanford Dogs Dataset | No | Yes | Yes |\n| [HTTPCat](https://http.cat/) | Cat for every HTTP Status | No | Yes | Unknown |\n| [IUCN](http://apiv3.iucnredlist.org/api/v3/docs) | IUCN Red List of Threatened Species | `apiKey` | No | Unknown |\n| [Movebank](https://github.com/movebank/movebank-api-doc) | Movement and Migration data of animals | No | Yes | Unknown |\n| [Petfinder](https://www.petfinder.com/developers/v2/docs/) | Adoption | `OAuth` | Yes | Yes |\n| [PlaceGOAT](https://placegoat.com/) | Placeholder goat images | No | Yes | Unknown |\n| [RandomCat](https://aws.random.cat/meow) | Random pictures of cats | No | Yes | Yes |\n| [RandomDog](https://random.dog/woof.json) | Random pictures of dogs | No | Yes | Yes |\n| [RandomFox](https://randomfox.ca/floof/) | Random pictures of foxes | No | Yes | No |\n| [RescueGroups](https://userguide.rescuegroups.org/display/APIDG/API+Developers+Guide+Home) | Adoption | No | Yes | Unknown |\n| [Shibe.Online](http://shibe.online/) | Random pictures of Shibu Inu, cats or birds | No | No | No |\n\n**[\u2b06 Back to Index](#index)**\n### Anime\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [AniList](https://github.com/AniList/ApiV2-GraphQL-Docs) | Anime discovery & tracking | `OAuth` | Yes | Unknown |\n| [AnimeNewsNetwork](https://www.animenewsnetwork.com/encyclopedia/api.php) | Anime industry news | No | Yes | Yes |\n| [Jikan](https://jikan.moe) | Unofficial MyAnimeList API | No | Yes | Yes |\n| [Kitsu](http://docs.kitsu.apiary.io/) | Anime discovery platform | `OAuth` | Yes | Unknown |\n| [Studio Ghibli](https://ghibliapi.herokuapp.com) | Resources from Studio Ghibli films | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Anti-Malware\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [AbuseIPDB](https://docs.abuseipdb.com/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |\n| [AlienVault Open Threat Exchange (OTX)](https://otx.alienvault.com/api/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |\n| [Google Safe Browsing](https://developers.google.com/safe-browsing/) | Google Link/Domain Flagging | `apiKey` | Yes | Unknown |\n| [Metacert](https://metacert.com/) | Metacert Link Flagging | `apiKey` | Yes | Unknown |\n| [VirusTotal](https://www.virustotal.com/en/documentation/public-api/) | VirusTotal File/URL Analysis | `apiKey` | Yes | Unknown |\n| [Web Of Trust (WOT)](https://www.mywot.com/en/API) | Website reputation | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Art & Design\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Behance](https://www.behance.net/dev) | Design | `apiKey` | Yes | Unknown |\n| [Cooper Hewitt](https://collection.cooperhewitt.org/api) | Smithsonian Design Museum | `apiKey` | Yes | Unknown |\n| [Dribbble](http://developer.dribbble.com/v1/) | Design | `OAuth` | No | Unknown |\n| [Harvard Art Museums](https://github.com/harvardartmuseums/api-docs) | Art | `apiKey` | No | Unknown |\n| [Iconfinder](https://developer.iconfinder.com) | Icons | `apiKey` | Yes | Unknown |\n| [Icons8](http://docs.icons8.apiary.io/#reference/0/meta) | Icons | `OAuth` | Yes | Unknown |\n| [Noun Project](http://api.thenounproject.com/index.html) | Icons | `OAuth` | No | Unknown |\n| [Rijksmuseum](https://www.rijksmuseum.nl/en/api) | Art | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Books\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Bhagavad Gita](https://bhagavadgita.io/api) | Bhagavad Gita text | `OAuth` | Yes | Yes |\n| [BookNomads](https://www.booknomads.com/dev) | Books published in the Netherlands and Flanders (about 2.5 million), book covers and related data | No | Yes | Unknown |\n| [British National Bibliography](http://bnb.data.bl.uk/) | Books | No | No | Unknown |\n| [Goodreads](https://www.goodreads.com/api) | Books | `apiKey` | Yes | Unknown |\n| [Google Books](https://developers.google.com/books/) | Books | `OAuth` | Yes | Unknown |\n| [LibGen](http://garbage.world/posts/libgen/) | Library Genesis search engine | No | No | Unknown |\n| [Open Library](https://openlibrary.org/developers/api) | Books, book covers and related data | No | Yes | Unknown |\n| [Penguin Publishing](http://www.penguinrandomhouse.biz/webservices/rest/) | Books, book covers and related data | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Business\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Charity Search](http://charityapi.orghunter.com/) | Non-profit charity data | `apiKey` | No | Unknown |\n| [Clearbit Logo](https://clearbit.com/docs#logo-api) | Search for company logos and embed them in your projects | `apiKey` | Yes | Unknown |\n| [Domainsdb.info](https://domainsdb.info/) | Registered Domain Names Search | No | Yes | Unknown |\n| [Freelancer](https://developers.freelancer.com) | Hire freelancers to get work done | `OAuth` | Yes | Unknown |\n| [Gmail](https://developers.google.com/gmail/api/) | Flexible, RESTful access to the user's inbox | `OAuth` | Yes | Unknown |\n| [Google Analytics](https://developers.google.com/analytics/) | Collect, configure and analyze your data to reach the right audience | `OAuth` | Yes | Unknown |\n| [MailboxValidator](https://www.mailboxvalidator.com/api-single-validation) | Validate email address to improve deliverability | `apiKey` | Yes | Unknown |\n| [mailgun](https://www.mailgun.com/) | Email Service | `apiKey` | Yes | Unknown |\n| [markerapi](http://www.markerapi.com/) | Trademark Search | No | No | Unknown |\n| [Ticksel](https://ticksel.com) | Friendly website analytics made for humans | No | Yes | Unknown |\n| [Trello](https://developers.trello.com/) | Boards, lists and cards to help you organize and prioritize your projects | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Calendar\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Calendar Index](https://www.calendarindex.com/) | Worldwide Holidays and Working Days | `apiKey` | Yes | Yes |\n| [Church Calendar](http://calapi.inadiutorium.cz/) | Catholic liturgical calendar | No | No | Unknown |\n| [Czech Namedays Calendar](http://svatky.adresa.info/) | Lookup for a name and returns nameday date | No | No | Unknown |\n| [Google Calendar](https://developers.google.com/google-apps/calendar/) | Display, create and modify Google calendar events | `OAuth` | Yes | Unknown |\n| [Hebrew Calendar](https://www.hebcal.com/home/developer-apis) | Convert between Gregorian and Hebrew, fetch Shabbat and Holiday times, etc | No | No | Unknown |\n| [Holidays](https://holidayapi.com/) | Historical data regarding holidays | `apiKey` | Yes | Unknown |\n| [LectServe](http://www.lectserve.com) | Protestant liturgical calendar | No | No | Unknown |\n| [Nager.Date](https://date.nager.at) | Public holidays for more than 90 countries | No | Yes | No |\n| [Namedays Calendar](https://api.abalin.net/) | Provides namedays for multiple countries | No | Yes | Yes |\n| [Non-Working Days](https://github.com/gadael/icsdb) | Database of ICS files for non working days | No | Yes | Unknown |\n| [Russian Calendar](https://github.com/egno/work-calendar) | Check if a date is a Russian holiday or not | No | Yes | No |\n\n**[\u2b06 Back to Index](#index)**\n### Cloud Storage & File Sharing\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Box](https://developer.box.com/) | File Sharing and Storage | `OAuth` | Yes | Unknown |\n| [Dropbox](https://www.dropbox.com/developers) | File Sharing and Storage | `OAuth` | Yes | Unknown |\n| [Google Drive](https://developers.google.com/drive/) | File Sharing and Storage | `OAuth` | Yes | Unknown |\n| [OneDrive](https://dev.onedrive.com/) | File Sharing and Storage | `OAuth` | Yes | Unknown |\n| [Pastebin](https://pastebin.com/api/) | Plain Text Storage | `apiKey` | Yes | Unknown |\n| [Temporal](https://gateway.temporal.cloud/ipns/docs.api.temporal.cloud) | IPFS based file storage and sharing with optional IPNS naming | `apiKey` | Yes | No |\n| [WeTransfer](https://developers.wetransfer.com) | File Sharing | `apiKey` | Yes | Yes |\n\n**[\u2b06 Back to Index](#index)**\n### Continuous Integration\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [CircleCI](https://circleci.com/docs/api/v1-reference/) | Automate the software development process using continuous integration and continuous delivery | `apiKey` | Yes | Unknown |\n| [Codeship](https://apidocs.codeship.com/) | Codeship is a Continuous Integration Platform in the cloud | `apiKey` | Yes | Unknown |\n| [Travis CI](https://docs.travis-ci.com/api/) | Sync your GitHub projects with Travis CI to test your code in minutes | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Cryptocurrency\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Binance](https://github.com/binance-exchange/binance-official-api-docs) | Exchange for Trading Cryptocurrencies based in China | `apiKey` | Yes | Unknown |\n| [BitcoinAverage](https://apiv2.bitcoinaverage.com/) | Digital Asset Price Data for the blockchain industry | `apiKey` | Yes | Unknown |\n| [BitcoinCharts](https://bitcoincharts.com/about/exchanges/) | Financial and Technical Data related to the Bitcoin Network | No | Yes | Unknown |\n| [Bitfinex](https://docs.bitfinex.com/docs/getting-started) | Cryptocurrency Trading Platform | `apiKey` | Yes | Unknown |\n| [Bitmex](https://www.bitmex.com/app/apiOverview) | Real-Time Cryptocurrency derivatives trading platform based in Hong Kong | `apiKey` | Yes | Unknown |\n| [Bittrex](https://bittrex.com/Home/Api) | Next Generation Crypto Trading Platform | `apiKey` | Yes | Unknown |\n| [Block](https://www.block.io/docs/basic) | Bitcoin Payment, Wallet & Transaction Data | `apiKey` | Yes | Unknown |\n| [Blockchain](https://www.blockchain.info/api) | Bitcoin Payment, Wallet & Transaction Data | No | Yes | Unknown |\n| [CoinAPI](https://docs.coinapi.io/) | All Currency Exchanges integrate under a single api | `apiKey` | Yes | No |\n| [Coinbase](https://developers.coinbase.com) | Bitcoin, Bitcoin Cash, Litecoin and Ethereum Prices | `apiKey` | Yes | Unknown |\n| [Coinbase Pro](https://docs.pro.coinbase.com/#api) | Cryptocurrency Trading Platform | `apiKey` | Yes | Unknown |\n| [CoinDesk](http://www.coindesk.com/api/) | Bitcoin Price Index | No | No | Unknown |\n| [CoinGecko](http://www.coingecko.com/api) | Cryptocurrency Price, Market, and Developer/Social Data | No | Yes | Yes |\n| [Coinigy](https://coinigy.docs.apiary.io) | Interacting with Coinigy Accounts and Exchange Directly | `apiKey` | Yes | Unknown |\n| [CoinLayer](https://coinlayer.com) | Real-time Crypto Currency Exchange Rates | `apiKey` | Yes | Unknown |\n| [Coinlib](https://coinlib.io/apidocs) | Crypto Currency Prices | `apiKey` | Yes | Unknown |\n| [Coinlore](https://www.coinlore.com/cryptocurrency-data-api) | Cryptocurrencies prices, volume and more | No | Yes | Unknown |\n| [CoinMarketCap](https://coinmarketcap.com/api/) | Cryptocurrencies Prices | `apiKey` | Yes | Unknown |\n| [Coinpaprika](https://api.coinpaprika.com) | Cryptocurrencies prices, volume and more | No | Yes | Yes |\n| [CoinRanking](https://docs.coinranking.com/) | Live Cryptocurrency data | No | Yes | Unknown |\n| [CryptoCompare](https://www.cryptocompare.com/api#) | Cryptocurrencies Comparison | No | Yes | Unknown |\n| [Cryptonator](https://www.cryptonator.com/api/) | Cryptocurrencies Exchange Rates | No | Yes | Unknown |\n| [Gemini](https://docs.gemini.com/rest-api/) | Cryptocurrencies Exchange | No | Yes | Unknown |\n| [ICObench](https://icobench.com/developers) | Various information on listing, ratings, stats, and more | `apiKey` | Yes | Unknown |\n| [Livecoin](https://www.livecoin.net/api) | Cryptocurrency Exchange | No | Yes | Unknown |\n| [MercadoBitcoin](https://www.mercadobitcoin.net/api-doc/) | Brazilian Cryptocurrency Information | No | Yes | Unknown |\n| [Nexchange](https://nexchange2.docs.apiary.io/) | Automated cryptocurrency exchange service | No | No | Yes |\n| [NiceHash](https://docs.nicehash.com/) | Largest Crypto Mining Marketplace | `apiKey` | Yes | Unknown |\n| [Poloniex](https://poloniex.com/support/api/) | US based digital asset exchange | `apiKey` | Yes | Unknown |\n| [WorldCoinIndex](https://www.worldcoinindex.com/apiservice) | Cryptocurrencies Prices | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Currency Exchange\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [1Forge](https://1forge.com/forex-data-api/api-documentation) | Forex currency market data | `apiKey` | Yes | Unknown |\n| [Currencylayer](https://currencylayer.com/documentation) | Exchange rates and currency conversion | `apiKey` | Yes | Unknown |\n| [Czech National Bank](https://www.cnb.cz/cs/financni_trhy/devizovy_trh/kurzy_devizoveho_trhu/denni_kurz.xml) | A collection of exchange rates | No | Yes | Unknown |\n| [ExchangeRate-API](https://www.exchangerate-api.com) | Free currency conversion | No | Yes | Yes |\n| [Exchangeratesapi.io](https://exchangeratesapi.io) | Exchange rates with currency conversion | No | Yes | Yes |\n| [Fixer.io](http://fixer.io) | Exchange rates and currency conversion | `apiKey` | Yes | Unknown |\n| [Frankfurter](https://www.frankfurter.app/docs) | Exchange rates, currency conversion and time series | No | Yes | Yes |\n| [ratesapi](https://ratesapi.io) | Free exchange rates and historical rates | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Data Validation\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Cloudmersive Validate](https://cloudmersive.com/validate-api) | Validate email addresses, phone numbers, VAT numbers and domain names | `apiKey` | Yes | Yes |\n| [languagelayer](https://languagelayer.com) | Language detection | No | Yes | Unknown |\n| [Lob.com](https://lob.com/) | US Address Verification | `apiKey` | Yes | Unknown |\n| [mailboxlayer](https://mailboxlayer.com) | Email address validation | No | Yes | Unknown |\n| [NumValidate](https://numvalidate.com) | Open Source phone number validation | No | Yes | Unknown |\n| [numverify](https://numverify.com) | Phone number validation | No | Yes | Unknown |\n| [PurgoMalum](http://www.purgomalum.com) | Content validator against profanity & obscenity | No | No | Unknown |\n| [US Autocomplete](https://smartystreets.com/docs/cloud/us-autocomplete-api) | Enter address data quickly with real-time address suggestions | `apiKey` | Yes | Yes |\n| [US Extract](https://smartystreets.com/products/apis/us-extract-api) | Extract postal addresses from any text including emails | `apiKey` | Yes | Yes |\n| [US Street Address](https://smartystreets.com/docs/cloud/us-street-api) | Validate and append data for any US postal address | `apiKey` | Yes | Yes |\n| [vatlayer](https://vatlayer.com) | VAT number validation | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Development\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [24 Pull Requests](https://24pullrequests.com/api) | Project to promote open source collaboration during December | No | Yes | Yes |\n| [Agify.io](https://agify.io) | Estimates the age from a first name | No | Yes | Yes |\n| [ApiFlash](https://apiflash.com/) | Chrome based screenshot API for developers | `apiKey` | Yes | Unknown |\n| [Apility.io](https://apility.io/apidocs/) | IP, Domains and Emails anti-abuse API blocklist | No | Yes | Yes |\n| [APIs.guru](https://apis.guru/api-doc/) | Wikipedia for Web APIs, OpenAPI/Swagger specs for public APIs | No | Yes | Unknown |\n| [BetterMeta](http://bettermeta.io) | Return a site's meta tags in JSON format | `X-Mashape-Key` | Yes | Unknown |\n| [Bitbucket](https://api.bitbucket.org/2.0/users/karllhughes) | Pull public information for a Bitbucket account | No | Yes | Unknown |\n| [Bored](https://www.boredapi.com/) | Find random activities to fight boredom | No | Yes | Unknown |\n| [Browshot](https://browshot.com/api/documentation) | Easily make screenshots of web pages in any screen size, as any device | `apiKey` | Yes | Unknown |\n| [CDNJS](https://api.cdnjs.com/libraries/jquery) | Library info on CDNJS | No | Yes | Unknown |\n| [Changelogs.md](https://changelogs.md) | Structured changelog metadata from open source projects | No | Yes | Unknown |\n| [CountAPI](https://countapi.xyz) | Free and simple counting service. You can use it to track page hits and specific events | No | Yes | Yes |\n| [DigitalOcean Status](https://status.digitalocean.com/api/v1) | Status of all DigitalOcean services | No | Yes | Unknown |\n| [DomainDb Info](https://domainsdb.info/apidomainsdb/index.php) | Domain name search to find all domains containing particular words/phrases/etc | No | Yes | Unknown |\n| [Faceplusplus](https://www.faceplusplus.com/) | A tool to detect face | `OAuth` | Yes | Unknown |\n| [Genderize.io](https://genderize.io) | Estimates a gender from a first name | No | Yes | Yes |\n| [GitHub](https://developer.github.com/v3/) | Make use of GitHub repositories, code and user info programmatically | `OAuth` | Yes | Yes |\n| [Gitlab](https://docs.gitlab.com/ee/api/) | Automate GitLab interaction programmatically | `OAuth` | Yes | Unknown |\n| [Gitter](https://github.com/gitterHQ/docs) | Chat for GitHub | `OAuth` | Yes | Unknown |\n| [HTTP2.Pro](https://http2.pro/doc/api) | Test endpoints for client and server HTTP/2 protocol support | No | Yes | Unknown |\n| [IBM Text to Speech](https://console.bluemix.net/docs/services/text-to-speech/getting-started.html) | Convert text to speech | `apiKey` | Yes | Yes |\n| [import.io](http://api.docs.import.io/) | Retrieve structured data from a website or RSS feed | `apiKey` | Yes | Unknown |\n| [IPify](https://www.ipify.org/) | A simple IP Address API | No | Yes | Unknown |\n| [IPinfo](https://ipinfo.io/developers) | Another simple IP Address API | No | Yes | Unknown |\n| [JSON 2 JSONP](https://json2jsonp.com/) | Convert JSON to JSONP (on-the-fly) for easy cross-domain data requests using client-side JavaScript | No | Yes | Unknown |\n| [JSONbin.io](https://jsonbin.io) | Free JSON storage service. Ideal for small scale Web apps, Websites and Mobile apps | `apiKey` | Yes | Yes |\n| [Judge0](https://api.judge0.com/) | Compile and run source code | No | Yes | Unknown |\n| [Let's Validate](https://github.com/letsvalidate/api) | Uncovers the technologies used on websites and URL to thumbnail | No | Yes | Unknown |\n| [License-API](https://github.com/cmccandless/license-api/blob/master/README.md) | Unofficial REST API for choosealicense.com | No | Yes | No |\n| [LiveEdu](https://www.liveedu.tv/developer/applications/) | Live Coding Streaming | `OAuth` | Yes | Unknown |\n| [MAC address vendor lookup](https://macaddress.io) | Retrieve vendor details and other information regarding a given MAC address or an OUI | `apiKey` | Yes | Yes |\n| [Myjson](http://myjson.com/api) | A simple JSON store for your web or mobile app | No | No | Unknown |\n| [Nationalize.io](https://nationalize.io) | Estimate the nationality of a first name | No | Yes | Yes |\n| [OOPSpam](https://oopspam.com/) | Multiple spam filtering service | No | Yes | Yes |\n| [Plino](https://plino.herokuapp.com/) | Spam filtering system | No | Yes | Unknown |\n| [Postman](https://docs.api.getpostman.com/) | Tool for testing APIs | `apiKey` | Yes | Unknown |\n| [ProxyCrawl](https://proxycrawl.com) | Scraping and crawling anticaptcha service | `apiKey` | Yes | Unknown |\n| [Public APIs](https://github.com/davemachado/public-api) | A collective list of free JSON APIs for use in web development | No | Yes | Unknown |\n| [Pusher Beams](https://pusher.com/beams) | Push notifications for Android & iOS | `apiKey` | Yes | Unknown |\n| [QR code](http://qrtag.net/api/) | Create an easy to read QR code and URL shortener | No | Yes | Yes |\n| [QR code](http://goqr.me/api/) | Generate and decode / read QR code graphics | No | Yes | Unknown |\n| [QuickChart](https://quickchart.io/) | Generate chart and graph images | No | Yes | Yes |\n| [ReqRes](https://reqres.in/ ) | A hosted REST-API ready to respond to your AJAX requests | No | Yes | Unknown |\n| [Scrape Website Email](https://market.mashape.com/tommytcchan/scrape-website-email) | Grabs email addresses from a URL | `X-Mashape-Key` | Yes | Unknown |\n| [ScraperApi](https://www.scraperapi.com) | Easily build scalable web scrapers | `apiKey` | Yes | Unknown |\n| [ScreenshotAPI.net](https://screenshotapi.net/) | Create pixel-perfect website screenshots | `apiKey` | Yes | Yes |\n| [SHOUTCLOUD](http://shoutcloud.io/) | ALL-CAPS AS A SERVICE | No | No | Unknown |\n| [StackExchange](https://api.stackexchange.com/) | Q&A forum for developers | `OAuth` | Yes | Unknown |\n| [Verse](https://verse.pawelad.xyz/) | Check what's the latest version of your favorite open-source project | No | Yes | Unknown |\n| [XML to JSON](https://developers.wso2apistore.com/) | Integration developer utility APIs | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Dictionaries\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Lingua Robot](https://www.linguarobot.io) | Word definitions, pronunciations, synonyms, antonyms and others | `apiKey` | Yes | Yes |\n| [Merriam-Webster](https://dictionaryapi.com/) | Dictionary and Thesaurus Data | `apiKey` | Yes | Unknown |\n| [OwlBot](https://owlbot.info/) | Definitions with example sentence and photo if available | `apiKey` | Yes | Yes |\n| [Oxford](https://developer.oxforddictionaries.com/) | Dictionary Data | `apiKey` | Yes | No |\n| [Wordnik](http://developer.wordnik.com) | Dictionary Data | `apiKey` | No | Unknown |\n| [Words](https://www.wordsapi.com/) | Definitions and synonyms for more than 150,000 words | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Documents & Productivity\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Cloudmersive Document and Data Conversion](https://cloudmersive.com/convert-api) | HTML/URL to PDF/PNG, Office documents to PDF, image conversion | `apiKey` | Yes | Yes |\n| [File.io](https://www.file.io) | File Sharing | No | Yes | Unknown |\n| [Mercury](https://mercury.postlight.com/web-parser/) | Web parser | `apiKey` | Yes | Unknown |\n| [pdflayer](https://pdflayer.com) | HTML/URL to PDF | `apiKey` | Yes | Unknown |\n| [Pocket](https://getpocket.com/developer/) | Bookmarking service | `OAuth` | Yes | Unknown |\n| [PrexView](https://prexview.com) | Data from XML or JSON to PDF, HTML or Image | `apiKey` | Yes | Unknown |\n| [Restpack](https://restpack.io/) | Provides screenshot, HTML to PDF and content extraction APIs | `apiKey` | Yes | Unknown |\n| [Todoist](https://developer.todoist.com) | Todo Lists | `OAuth` | Yes | Unknown |\n| [Vector Express](http://vector.express) | Free vector file converting API | No | No | Yes |\n| [WakaTime](https://wakatime.com/developers) | Automated time tracking leaderboards for programmers | No | Yes | Unknown |\n| [Wunderlist](https://developer.wunderlist.com/documentation) | Todo Lists | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Environment\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [AirVisual](https://airvisual.com/api) | Air quality and weather data | `apiKey` | Yes | Unknown |\n| [Gr\u00fcnstromIndex](https://www.corrently.de/hintergrund/gruenstromindex/index.html) | Green Power Index for Germany (Gr\u00fcnstromindex/GSI) | No | No | Yes |\n| [OpenAQ](https://docs.openaq.org/) | Open air quality data | `apiKey` | Yes | Unknown |\n| [PM25.in](http://www.pm25.in/api_doc) | Air quality of China | `apiKey` | No | Unknown |\n| [PVWatts](https://developer.nrel.gov/docs/solar/pvwatts/v6/) | Energy production photovoltaic (PV) energy systems | `apiKey` | Yes | Unknown |\n| [UK Carbon Intensity](https://carbon-intensity.github.io/api-definitions/#carbon-intensity-api-v1-0-0) | The Official Carbon Intensity API for Great Britain developed by National Grid | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Events\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Eventbrite](https://www.eventbrite.com/developer/v3/) | Find events | `OAuth` | Yes | Unknown |\n| [Picatic](http://developer.picatic.com/?utm_medium=web&utm_source=github&utm_campaign=public-apis%20repo&utm_content=toddmotto) | Sell tickets anywhere | `apiKey` | Yes | Unknown |\n| [Ticketmaster](http://developer.ticketmaster.com/products-and-docs/apis/getting-started/) | Search events, attractions, or venues | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Finance\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Alpha Vantage](https://www.alphavantage.co/) | Realtime and historical stock data | `apiKey` | Yes | Unknown |\n| [Barchart OnDemand](https://www.barchartondemand.com/free) | Stock, Futures and Forex Market Data | `apiKey` | Yes | Unknown |\n| [Consumer Financial Protection Bureau](https://data.consumerfinance.gov/resource/jhzv-w97w.json) | Financial services consumer complaint data | `apiKey` | Yes | Unknown |\n| [Financial Modeling Prep](https://financialmodelingprep.com/) | Stock information and data | No | Yes | Unknown |\n| [IEX](https://iextrading.com/developer/) | Realtime stock data | No | Yes | Yes |\n| [IEX Cloud](https://iexcloud.io/) | Realtime & Historical Stock and Market Data | `apiKey` | Yes | Yes |\n| [IG](https://labs.ig.com/gettingstarted) | Spreadbetting and CFD Market Data | `apiKey` | Yes | Unknown |\n| [Plaid](https://plaid.com/) | Connect with users\u2019 bank accounts and access transaction data | `apiKey` | Yes | Unknown |\n| [Razorpay IFSC](https://ifsc.razorpay.com/) | Indian Financial Systems Code (Bank Branch Codes) | No | Yes | Unknown |\n| [RoutingNumbers.info](https://www.routingnumbers.info/api/index.html) | ACH/NACHA Bank Routing Numbers | No | Yes | Unknown |\n| [Tradier](https://developer.tradier.com) | US equity/option market data (delayed, intraday, historical) | `OAuth` | Yes | Yes |\n| [VAT Rates](https://jsonvat.com/) | A collection of all VAT rates for EU countries | No | Yes | Unknown |\n| [YNAB](https://api.youneedabudget.com/) | Budgeting & Planning | `OAuth` | Yes | Yes |\n\n**[\u2b06 Back to Index](#index)**\n### Food & Drink\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Edamam](https://developer.edamam.com/) | Recipe Search | `apiKey` | Yes | Unknown |\n| [LCBO](https://lcboapi.com/) | Alcohol | `apiKey` | Yes | Unknown |\n| [Open Brewery DB](https://www.openbrewerydb.org) | Breweries, Cideries and Craft Beer Bottle Shops | No | Yes | Yes |\n| [Open Food Facts](https://world.openfoodfacts.org/data) | Food Products Database | No | Yes | Unknown |\n| [PunkAPI](https://punkapi.com/) | Brewdog Beer Recipes | No | Yes | Unknown |\n| [Recipe Puppy](http://www.recipepuppy.com/about/api/) | Food | No | No | Unknown |\n| [TacoFancy](https://github.com/evz/tacofancy-api) | Community-driven taco database | No | No | Unknown |\n| [The Report of the Week](https://github.com/andyklimczak/TheReportOfTheWeek-API) | Food & Drink Reviews | No | Yes | Unknown |\n| [TheCocktailDB](https://www.thecocktaildb.com/api.php) | Cocktail Recipes | `apiKey` | Yes | Yes |\n| [TheMealDB](https://www.themealdb.com/api.php) | Meal Recipes | `apiKey` | Yes | Yes |\n| [What's on the menu?](http://nypl.github.io/menus-api/) | NYPL human-transcribed historical menu collection | `apiKey` | No | Unknown |\n| [Zomato](https://developers.zomato.com/api) | Discover restaurants | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Fraud Prevention\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [FraudLabs Pro](https://www.fraudlabspro.com/developer/api/screen-order) | Screen order information using AI to detect frauds | `apiKey` | Yes | Unknown |\n| [Whitepages Pro](https://pro.whitepages.com/developer/documentation/identity-check-api/) | Global identity verification with phone, address, email and IP | `apiKey` | Yes | Unknown |\n| [Whitepages Pro](https://pro.whitepages.com/developer/documentation/phone-reputation-api/) | Phone reputation to detect spammy phones | `apiKey` | Yes | Unknown |\n| [Whitepages Pro](https://pro.whitepages.com/developer/documentation/reverse-phone-api/) | Get an owner\u2019s name, address, demographics based on the phone number | `apiKey` | Yes | Unknown |\n| [Whitepages Pro](https://pro.whitepages.com/developer/documentation/phone-intelligence-api/) | Phone number validation, line_type, carrier append | `apiKey` | Yes | Unknown |\n| [Whitepages Pro](https://pro.whitepages.com/developer/documentation/reverse-address-api/) | Get normalized physical address, residents, address type and validity | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Games & Comics\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Age of Empires II](https://age-of-empires-2-api.herokuapp.com) | Get information about Age of Empires II resources | No | Yes | Unknown |\n| [AmiiboAPI](http://www.amiiboapi.com/) | Amiibo Information | No | No | Yes |\n| [Battle.net](https://dev.battle.net/) | Blizzard Entertainment | `apiKey` | Yes | Unknown |\n| [Chuck Norris Database](http://www.icndb.com/api/) | Jokes | No | No | Unknown |\n| [Clash of Clans](https://developer.clashofclans.com) | Clash of Clans Game Information | `apiKey` | Yes | Unknown |\n| [Clash Royale](https://developer.clashroyale.com) | Clash Royale Game Information | `apiKey` | Yes | Unknown |\n| [Comic Vine](https://comicvine.gamespot.com/api/documentation) | Comics | No | Yes | Unknown |\n| [Deck of Cards](http://deckofcardsapi.com/) | Deck of Cards | No | No | Unknown |\n| [Destiny The Game](https://github.com/Bungie-net/api) | Bungie Platform API | `apiKey` | Yes | Unknown |\n| [Dota 2](https://docs.opendota.com/) | Provides information about Player stats , Match stats, Rankings for Dota 2 | No | Yes | Unknown |\n| [Dungeons and Dragons](http://www.dnd5eapi.co/) | Reference for 5th edition spells, classes, monsters, and more | No | No | No |\n| [Eve Online](https://esi.evetech.net/ui) | Third-Party Developer Documentation | `OAuth` | Yes | Unknown |\n| [Final Fantasy XIV](https://xivapi.com/) | Final Fantasy XIV Game data API | No | Yes | Yes |\n| [Fortnite](https://fortniteapi.com/) | Fortnite Stats & Cosmetics | `apiKey` | Yes | Yes |\n| [Fortnite](https://fortnitetracker.com/site-api) | Fortnite Stats | `apiKey` | Yes | Unknown |\n| [Giant Bomb](https://www.giantbomb.com/api/documentation) | Video Games | No | Yes | Unknown |\n| [Guild Wars 2](https://wiki.guildwars2.com/wiki/API:Main) | Guild Wars 2 Game Information | `apiKey` | Yes | Unknown |\n| [Halo](https://developer.haloapi.com/) | Halo 5 and Halo Wars 2 Information | `apiKey` | Yes | Unknown |\n| [Hearthstone](http://hearthstoneapi.com/) | Hearthstone Cards Information | `X-Mashape-Key` | Yes | Unknown |\n| [Hypixel](https://api.hypixel.net/) | Hypixel player stats | `apiKey` | Yes | Unknown |\n| [IGDB.com](https://api.igdb.com/) | Video Game Database | `apiKey` | Yes | Unknown |\n| [JokeAPI](https://sv443.net/jokeapi) | Programming, Miscellaneous and Dark Jokes | No | Yes | Yes |\n| [Jokes](https://github.com/15Dkatz/official_joke_api) | Programming and general jokes | No | Yes | Unknown |\n| [Jservice](http://jservice.io) | Jeopardy Question Database | No | No | Unknown |\n| [Magic The Gathering](http://magicthegathering.io/) | Magic The Gathering Game Information | No | No | Unknown |\n| [Marvel](http://developer.marvel.com) | Marvel Comics | `apiKey` | No | Unknown |\n| [mod.io](https://docs.mod.io) | Cross Platform Mod API | `apiKey` | Yes | Unknown |\n| [Open Trivia](https://opentdb.com/api_config.php) | Trivia Questions | No | Yes | Unknown |\n| [PandaScore](https://api.pandascore.co) | E-sports games and results | `apiKey` | Yes | Unknown |\n| [PlayerUnknown's Battlegrounds](https://pubgtracker.com/site-api) | PUBG Stats | `apiKey` | Yes | Unknown |\n| [Pok\u00e9api](https://pokeapi.co) | Pok\u00e9mon Information | No | Yes | Unknown |\n| [Pok\u00e9mon TCG](https://pokemontcg.io) | Pok\u00e9mon TCG Information | No | Yes | Unknown |\n| [Rick and Morty](https://rickandmortyapi.com) | All the Rick and Morty information, including images | No | Yes | Yes |\n| [Riot Games](https://developer.riotgames.com/) | League of Legends Game Information | `apiKey` | Yes | Unknown |\n| [Scryfall](https://scryfall.com/docs/api) | Magic: The Gathering database | No | Yes | Yes |\n| [Steam](https://developer.valvesoftware.com/wiki/Steam_Web_API) | Steam Client Interaction | `OAuth` | Yes | Unknown |\n| [SuperHeroes](https://superheroapi.com) | All SuperHeroes and Villains data from all universes under a single API | `apiKey` | Yes | Unknown |\n| [Tronald Dump](https://www.tronalddump.io/) | The dumbest things Donald Trump has ever said | No | Yes | Unknown |\n| [Vainglory](https://developer.vainglorygame.com/) | Vainglory Players, Matches and Telemetry | `apiKey` | Yes | Yes |\n| [Wargaming.net](https://developers.wargaming.net/) | Wargaming.net info and stats | `apiKey` | Yes | No |\n| [xkcd](https://xkcd.com/json.html) | Retrieve xkcd comics as JSON | No | Yes | No |\n\n**[\u2b06 Back to Index](#index)**\n### Geocoding\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [adresse.data.gouv.fr](https://adresse.data.gouv.fr) | Address database of France, geocoding and reverse | No | Yes | Unknown |\n| [Battuta](http://battuta.medunes.net) | A (country/region/city) in-cascade location API | `apiKey` | No | Unknown |\n| [Bing Maps](https://www.microsoft.com/maps/) | Create/customize digital maps based on Bing Maps data | `apiKey` | Yes | Unknown |\n| [bng2latlong](https://www.getthedata.com/bng2latlong) | Convert British OSGB36 easting and northing (British National Grid) to WGS84 latitude and longitude | No | Yes | Yes |\n| [CitySDK](http://www.citysdk.eu/citysdk-toolkit/) | Open APIs for select European cities | No | Yes | Unknown |\n| [Daum Maps](http://apis.map.daum.net/) | Daum Maps provide multiple APIs for Korean maps | `apiKey` | No | Unknown |\n| [FreeGeoIP](https://freegeoip.app/) | Free geo ip information, no registration required. 15k/hour rate limit | No | Yes | Yes |\n| [GeoApi](https://api.gouv.fr/api/geoapi.html) | French geographical data | No | Yes | Unknown |\n| [Geocod.io](https://www.geocod.io/) | Address geocoding / reverse geocoding in bulk | `apiKey` | Yes | Unknown |\n| [Geocode.xyz](https://geocode.xyz/) | Provides worldwide forward/reverse geocoding, batch geocoding and geoparsing | No | Yes | Unknown |\n| [GeoDataSource](https://www.geodatasource.com/web-service) | Geocoding of city name by using latitude and longitude coordinates | `apiKey` | Yes | Unknown |\n| [GeoJS](https://geojs.io/) | IP geolocation with ChatOps integration | No | Yes | Yes |\n| [GeoNames](http://www.geonames.org/export/web-services.html) | Place names and other geographical data | No | No | Unknown |\n| [geoPlugin](https://www.geoplugin.com) | IP geolocation and currency conversion | No | Yes | Yes |\n| [Google Earth Engine](https://developers.google.com/earth-engine/) | A cloud-based platform for planetary-scale environmental data analysis | `apiKey` | Yes | Unknown |\n| [Google Maps](https://developers.google.com/maps/) | Create/customize digital maps based on Google Maps data | `apiKey` | Yes | Unknown |\n| [HelloSalut](https://www.fourtonfish.com/hellosalut/hello/) | Get hello translation following user language | No | Yes | Unknown |\n| [HERE Maps](https://developer.here.com) | Create/customize digital maps based on HERE Maps data | `apiKey` | Yes | Unknown |\n| [Indian Cities](https://indian-cities-api-nocbegfhqg.now.sh/) | Get all Indian cities in a clean JSON Format | No | Yes | Yes |\n| [IP 2 Country](https://ip2country.info) | Map an IP to a country | No | Yes | Unknown |\n| [IP Address Details](https://ipinfo.io/) | Find geolocation with ip address | No | Yes | Unknown |\n| [IP Location](http://ip-api.com/) | Find location with ip address | No | No | Unknown |\n| [IP Location](https://ipapi.co/) | Find IP address location information | No | Yes | Unknown |\n| [IP Sidekick](https://ipsidekick.com) | Geolocation API that returns extra information about an IP address | `apiKey` | Yes | Unknown |\n| [IP Vigilante](https://www.ipvigilante.com/) | Free IP Geolocation API | No | Yes | Unknown |\n| [IP2Location](https://www.ip2location.com/web-service/ip2location) | IP geolocation web service to get more than 55 parameters | `apiKey` | Yes | Unknown |\n| [IP2Proxy](https://www.ip2location.com/web-service/ip2proxy) | Detect proxy and VPN using IP address | `apiKey` | Yes | Unknown |\n| [IPGeolocationAPI.com](https://ipgeolocationapi.com/) | Locate your visitors by IP with country details | No | Yes | Yes |\n| [IPInfoDB](https://ipinfodb.com/api) | Free Geolocation tools and APIs for country, region, city and time zone lookup by IP address | `apiKey` | Yes | Unknown |\n| [ipstack](https://ipstack.com/) | Locate and identify website visitors by IP address | `apiKey` | Yes | Unknown |\n| [Kwelo Network](https://www.kwelo.com/network/ip-address) | Locate and get detailed information on IP address | No | Yes | Yes |\n| [LocationIQ](https://locationiq.org/docs/) | Provides forward/reverse geocoding and batch geocoding | `apiKey` | Yes | Yes |\n| [Mapbox](https://www.mapbox.com/developers/) | Create/customize beautiful digital maps | `apiKey` | Yes | Unknown |\n| [Mexico](https://github.com/IcaliaLabs/sepomex) | Mexico RESTful zip codes API | No | Yes | Unknown |\n| [One Map, Singapore](https://docs.onemap.sg/) | Singapore Land Authority REST API services for Singapore addresses | `apiKey` | Yes | Unknown |\n| [OnWater](https://onwater.io/) | Determine if a lat/lon is on water or land | No | Yes | Unknown |\n| [OpenCage](https://opencagedata.com) | Forward and reverse geocoding using open data | `apiKey` | Yes | Yes |\n| [OpenStreetMap](http://wiki.openstreetmap.org/wiki/API) | Navigation, geolocation and geographical data | `OAuth` | No | Unknown |\n| [PostcodeData.nl](http://api.postcodedata.nl/v1/postcode/?postcode=1211EP&streetnumber=60&ref=domeinnaam.nl&type=json) | Provide geolocation data based on postcode for Dutch addresses | No | No | Unknown |\n| [Postcodes.io](https://postcodes.io) | Postcode lookup & Geolocation for the UK | No | Yes | Yes |\n| [REST Countries](https://restcountries.eu) | Get information about countries via a RESTful API | No | Yes | Unknown |\n| [SmartIP.io](https://smartip.io) | IP Geolocation and Threat Intelligence API | `apiKey` | Yes | Yes |\n| [Uebermaps](https://uebermaps.com/api/v2) | Discover and share maps with friends | `apiKey` | Yes | Unknown |\n| [US ZipCode](https://smartystreets.com/docs/cloud/us-zipcode-api) | Validate and append data for any US ZipCode | `apiKey` | Yes | Yes |\n| [Utah AGRC](https://api.mapserv.utah.gov) | Utah Web API for geocoding Utah addresses | `apiKey` | Yes | Unknown |\n| [ViaCep](https://viacep.com.br) | Brazil RESTful zip codes API | No | Yes | Unknown |\n| [ZipCodeAPI](https://www.zipcodeapi.com) | US zip code distance, radius and location API | `apiKey` | Yes | Unknown |\n| [Zippopotam](http://www.zippopotam.us) | Get information about place such as country, city, state, etc | No | No | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Government\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [BCLaws](http://www.bclaws.ca/civix/template/complete/api/index.html) | Access to the laws of British Columbia | No | No | Unknown |\n| [BusinessUSA](https://business.usa.gov/developer) | Authoritative information on U.S. programs, events, services and more | `apiKey` | Yes | Unknown |\n| [Census.gov](https://www.census.gov/data/developers/data-sets.html) | The US Census Bureau provides various APIs and data sets on demographics and businesses | No | Yes | Unknown |\n| [City, Lyon Opendata](https://data.beta.grandlyon.com/fr/accueil) | Lyon(FR) City Open Data | `apiKey` | Yes | Unknown |\n| [City, Nantes Opendata](https://data.nantesmetropole.fr/pages/home/) | Nantes(FR) City Open Data | `apiKey` | Yes | Unknown |\n| [City, Prague Opendata](http://opendata.praha.eu/en) | Prague(CZ) City Open Data | No | No | Unknown |\n| [Code.gov](https://code.gov) | The primary platform for Open Source and code sharing for the U.S. Federal Government | `apiKey` | Yes | Unknown |\n| [Colorado Data Engine](http://codataengine.org/) | Formatted and geolocated Colorado public data | No | Yes | Unknown |\n| [Colorado Information Marketplace](https://data.colorado.gov/) | Colorado State Government Open Data | No | Yes | Unknown |\n| [Data USA](https://datausa.io/about/api/) | US Public Data | No | Yes | Unknown |\n| [Data.gov](https://api.data.gov/) | US Government Data | `apiKey` | Yes | Unknown |\n| [Data.parliament.uk](http://www.data.parliament.uk/developers/) | Contains live datasets including information about petitions, bills, MP votes, attendance and more | No | No | Unknown |\n| [District of Columbia Open Data](http://opendata.dc.gov/pages/using-apis) | Contains D.C. government public datasets, including crime, GIS, financial data, and so on | No | Yes | Unknown |\n| [EPA](https://developer.epa.gov/category/apis/) | Web services and data sets from the US Environmental Protection Agency | No | Yes | Unknown |\n| [FEC](https://api.open.fec.gov/developers/) | Information on campaign donations in federal elections | `apiKey` | Yes | Unknown |\n| [Federal Register](https://www.federalregister.gov/reader-aids/developer-resources) | The Daily Journal of the United States Government | No | Yes | Unknown |\n| [Food Standards Agency](http://ratings.food.gov.uk/open-data/en-GB) | UK food hygiene rating data API | No | No | Unknown |\n| [Open Government, Australia](https://www.data.gov.au/) | Australian Government Open Data | No | Yes | Unknown |\n| [Open Government, Belgium](https://data.gov.be/) | Belgium Government Open Data | No | Yes | Unknown |\n| [Open Government, Canada](http://open.canada.ca/en) | Canadian Government Open Data | No | No | Unknown |\n| [Open Government, France](https://www.data.gouv.fr/) | French Government Open Data | `apiKey` | Yes | Unknown |\n| [Open Government, India](https://data.gov.in/) | Indian Government Open Data | `apiKey` | Yes | Unknown |\n| [Open Government, Italy](https://www.dati.gov.it/) | Italy Government Open Data | No | Yes | Unknown |\n| [Open Government, New Zealand](https://www.data.govt.nz/) | New Zealand Government Open Data | No | Yes | Unknown |\n| [Open Government, Romania](http://data.gov.ro/) | Romania Government Open Data | No | No | Unknown |\n| [Open Government, Taiwan](https://data.gov.tw/) | Taiwan Government Open Data | No | Yes | Unknown |\n| [Open Government, USA](https://www.data.gov/) | United States Government Open Data | No | Yes | Unknown |\n| [Regulations.gov](https://regulationsgov.github.io/developers/) | Federal regulatory materials to increase understanding of the Federal rule making process | `apiKey` | Yes | Unknown |\n| [Represent by Open North](https://represent.opennorth.ca/) | Find Canadian Government Representatives | No | Yes | Unknown |\n| [USAspending.gov](https://api.usaspending.gov/) | US federal spending data | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Health\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [BetterDoctor](https://developer.betterdoctor.com/) | Detailed information about doctors in your area | `apiKey` | Yes | Unknown |\n| [Diabetes](http://predictbgl.com/api/) | Logging and retrieving diabetes information | No | No | Unknown |\n| [Flutrack](http://www.flutrack.org/) | Influenza-like symptoms with geotracking | No | No | Unknown |\n| [Healthcare.gov](https://www.healthcare.gov/developers/) | Educational content about the US Health Insurance Marketplace | No | Yes | Unknown |\n| [Lexigram](https://docs.lexigram.io/v1/welcome) | NLP that extracts mentions of clinical concepts from text, gives access to clinical ontology | `apiKey` | Yes | Unknown |\n| [Makeup](http://makeup-api.herokuapp.com/) | Makeup Information | No | No | Unknown |\n| [Medicare](https://data.medicare.gov/developers) | Access to the data from the CMS - medicare.gov | No | Yes | Unknown |\n| [NPPES](https://npiregistry.cms.hhs.gov/registry/help-api) | National Plan & Provider Enumeration System, info on healthcare providers registered in US | No | Yes | Unknown |\n| [Nutritionix](https://developer.nutritionix.com/) | Worlds largest verified nutrition database | `apiKey` | Yes | Unknown |\n| [openFDA](https://open.fda.gov) | Public FDA data about drugs, devices and foods | No | Yes | Unknown |\n| [USDA Nutrients](https://ndb.nal.usda.gov/ndb/doc/index) | National Nutrient Database for Standard Reference | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Jobs\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Adzuna](https://developer.adzuna.com/overview) | Job board aggregator | `apiKey` | Yes | Unknown |\n| [Authentic Jobs](https://authenticjobs.com/api/docs) | Job board for designers, hackers and creative pros | `apiKey` | Yes | Unknown |\n| [Careerjet](https://www.careerjet.com/partners/api/) | Job search engine | `apiKey` | No | Unknown |\n| [Github Jobs](https://jobs.github.com/api) | Jobs for software developers | No | Yes | Yes |\n| [GraphQL Jobs](https://api.graphql.jobs) | Jobs with GraphQL | No | Yes | Yes |\n| [Indeed](https://www.indeed.com/publisher) | Job board aggregator | `apiKey` | Yes | Unknown |\n| [Jobs2Careers](http://api.jobs2careers.com/api/spec.pdf) | Job aggregator | `apiKey` | Yes | Unknown |\n| [Jooble](https://us.jooble.org/api/about) | Job search engine | `apiKey` | Yes | Unknown |\n| [Juju](http://www.juju.com/publisher/spec/) | Job search engine | `apiKey` | No | Unknown |\n| [Open Skills](https://github.com/workforce-data-initiative/skills-api/wiki/API-Overview) | Job titles, skills and related jobs data | No | No | Unknown |\n| [Reed](https://www.reed.co.uk/developers) | Job board aggregator | `apiKey` | Yes | Unknown |\n| [Search.gov Jobs](https://search.gov/developer/jobs.html) | Tap into a list of current jobs openings with the United States government | No | Yes | Unknown |\n| [The Muse](https://www.themuse.com/developers/api/v2) | Job board and company profiles | `apiKey` | Yes | Unknown |\n| [Upwork](https://developers.upwork.com/) | Freelance job board and management system | `OAuth` | Yes | Unknown |\n| [USAJOBS](https://developer.usajobs.gov/) | US government job board | `apiKey` | Yes | Unknown |\n| [ZipRecruiter](https://www.ziprecruiter.com/publishers) | Job search app and website | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Machine Learning\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Clarifai](https://developer.clarifai.com/) | Computer Vision | `OAuth` | Yes | Unknown |\n| [Cloudmersive](https://www.cloudmersive.com/image-recognition-and-processing-api) | Image captioning, face recognition, NSFW classification | `apiKey` | Yes | Yes |\n| [Deepcode](https://www.deepcode.ai/docs/Overview%252FOverview) | AI for code review | No | Yes | Unknown |\n| [Dialogflow](https://dialogflow.com) | Natural Language Processing | `apiKey` | Yes | Unknown |\n| [Keen IO](https://keen.io/) | Data Analytics | `apiKey` | Yes | Unknown |\n| [Time Door](https://timedoor.io) | A time series analysis API | `apiKey` | Yes | Yes |\n| [Unplugg](https://unplu.gg/test_api.html) | Forecasting API for timeseries data | `apiKey` | Yes | Unknown |\n| [Wit.ai](https://wit.ai/) | Natural Language Processing | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Music\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [AI Mastering](https://aimastering.com/api_docs/) | Automated Music Mastering | `apiKey` | Yes | Yes |\n| [Bandsintown](https://app.swaggerhub.com/apis/Bandsintown/PublicAPI/3.0.0) | Music Events | No | Yes | Unknown |\n| [Deezer](https://developers.deezer.com/api) | Music | `OAuth` | Yes | Unknown |\n| [Discogs](https://www.discogs.com/developers/) | Music | `OAuth` | Yes | Unknown |\n| [Genius](https://docs.genius.com/) | Crowdsourced lyrics and music knowledge | `OAuth` | Yes | Unknown |\n| [Genrenator](https://binaryjazz.us/genrenator-api/) | Music genre generator | No | Yes | Unknown |\n| [iTunes Search](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/) | Software products | No | Yes | Unknown |\n| [Jamendo](https://developer.jamendo.com/v3.0/docs) | Music | `OAuth` | Yes | Unknown |\n| [KKBOX](https://developer.kkbox.com) | Get music libraries, playlists, charts, and perform out of KKBOX's platform | `OAuth` | Yes | Unknown |\n| [LastFm](https://www.last.fm/api) | Music | `apiKey` | Yes | Unknown |\n| [Lyrics.ovh](http://docs.lyricsovh.apiary.io/) | Simple API to retrieve the lyrics of a song | No | Yes | Unknown |\n| [Mixcloud](https://www.mixcloud.com/developers/) | Music | `OAuth` | Yes | Yes |\n| [MusicBrainz](https://musicbrainz.org/doc/Development/XML_Web_Service/Version_2) | Music | No | Yes | Unknown |\n| [Musikki](https://music-api.musikki.com/reference) | Music | `apiKey` | Yes | Unknown |\n| [Musixmatch](https://developer.musixmatch.com/) | Music | `apiKey` | Yes | Unknown |\n| [Openwhyd](https://openwhyd.github.io/openwhyd/API) | Download curated playlists of streaming tracks (YouTube, SoundCloud, etc...) | `No` | Yes | No |\n| [Songkick](https://www.songkick.com/developer/) | Music Events | `OAuth` | Yes | Unknown |\n| [Songsterr](https://www.songsterr.com/a/wa/api/) | Provides guitar, bass and drums tabs and chords | No | Yes | Unknown |\n| [SoundCloud](https://developers.soundcloud.com/) | Allow users to upload and share sounds | `OAuth` | Yes | Unknown |\n| [Spotify](https://beta.developer.spotify.com/documentation/web-api/) | View Spotify music catalog, manage users' libraries, get recommendations and more | `OAuth` | Yes | Unknown |\n| [TasteDive](https://tastedive.com/read/api) | Similar artist API (also works for movies and TV shows) | `apiKey` | Yes | Unknown |\n| [TheAudioDB](https://www.theaudiodb.com/api_guide.php) | Music | `apiKey` | Yes | Unknown |\n| [Vagalume](https://api.vagalume.com.br/docs/) | Crowdsourced lyrics and music knowledge | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### News\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Associated Press](https://developer.ap.org/) | Search for news and metadata from Associated Press | `apiKey` | Yes | Unknown |\n| [Chronicling America](http://chroniclingamerica.loc.gov/about/api/) | Provides access to millions of pages of historic US newspapers from the Library of Congress | No | No | Unknown |\n| [Currents](https://currentsapi.services/) | Latest news published in various news sources, blogs and forums | `apiKey` | Yes | Yes |\n| [Feedbin](https://github.com/feedbin/feedbin-api) | RSS reader | `OAuth` | Yes | Unknown |\n| [Feedster](https://api.feedster.me/v1/docs/) | Searchable and categorized collections of RSS feeds | `apiKey` | Yes | Unknown |\n| [New York Times](https://developer.nytimes.com/) | Provides news | `apiKey` | Yes | Unknown |\n| [News](https://newsapi.org/) | Headlines currently published on a range of news sources and blogs | `apiKey` | Yes | Unknown |\n| [NPR One](http://dev.npr.org/api/) | Personalized news listening experience from NPR | `OAuth` | Yes | Unknown |\n| [The Guardian](http://open-platform.theguardian.com/) | Access all the content the Guardian creates, categorised by tags and section | `apiKey` | Yes | Unknown |\n| [The Old Reader](https://github.com/theoldreader/api) | RSS reader | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Open Data\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [18F](http://18f.github.io/API-All-the-X/) | Unofficial US Federal Government API Development | No | No | Unknown |\n| [Abbreviation](https://market.mashape.com/daxeel/abbreviations) | Get abbreviations and meanings | `X-Mashape-Key` | Yes | Unknown |\n| [Archive.org](https://archive.readme.io/docs) | The Internet Archive | No | Yes | Unknown |\n| [ARSAT](https://datos.arsat.com.ar/developers/) | ARSAT public data | `apiKey` | Yes | Unknown |\n| [Callook.info](https://callook.info) | United States ham radio callsigns | No | Yes | Unknown |\n| [CARTO](https://carto.com/) | Location Information Prediction | `apiKey` | Yes | Unknown |\n| [Celebinfo](https://market.mashape.com/daxeel/celebinfo/) | Celebrity information | `X-Mashape-Key` | Yes | Unknown |\n| [CivicFeed](https://developers.civicfeed.com/) | News articles and public datasets | `apiKey` | Yes | Unknown |\n| [Datakick](https://www.datakick.org/api) | The open product database | `apiKey` | Yes | Unknown |\n| [Enigma Public](http://docs.enigma.com/public/public_v20_api_about) | Broadest collection of public data | `apiKey` | Yes | Yes |\n| [fonoApi](https://fonoapi.freshpixl.com/) | Mobile Device Description | No | Yes | Unknown |\n| [French Address Search](https://geo.api.gouv.fr/adresse) | Address search via the French Government | No | Yes | Unknown |\n| [LinkPreview](https://www.linkpreview.net) | Get JSON formatted summary with title, description and preview image for any requested URL | `apiKey` | Yes | Yes |\n| [Marijuana Strains](http://strains.evanbusse.com/) | Marijuana strains, races, flavors and effects | `apiKey` | No | Unknown |\n| [Microlink.io](https://microlink.io) | Extract structured data from any website | No | Yes | Yes |\n| [OpenCorporates](http://api.opencorporates.com/documentation/API-Reference) | Data on corporate entities and directors in many countries | `apiKey` | Yes | Unknown |\n| [Qmeta](https://api.qmeta.net/) | Global Search Engine | `apiKey` | Yes | Unknown |\n| [Quandl](https://www.quandl.com/) | Stock Market Data | No | Yes | Unknown |\n| [Recreation Information Database](https://ridb.recreation.gov/) | Recreational areas, federal lands, historic sites, museums, and other attractions/resources(US) | `apiKey` | Yes | Unknown |\n| [Scoop.it](http://www.scoop.it/dev) | Content Curation Service | `apiKey` | No | Unknown |\n| [Teleport](https://developers.teleport.org/) | Quality of Life Data | No | Yes | Unknown |\n| [Universities List](https://github.com/Hipo/university-domains-list) | University names, countries and domains | No | Yes | Unknown |\n| [University of Oslo](https://data.uio.no/) | Courses, lecture videos, detailed information for courses etc. for the University of Oslo (Norway) | No | Yes | Unknown |\n| [UPC database](https://upcdatabase.org/api) | More than 1.5 million barcode numbers from all around the world | `apiKey` | Yes | Unknown |\n| [Wikidata](https://www.wikidata.org/w/api.php?action=help) | Collaboratively edited knowledge base operated by the Wikimedia Foundation | `OAuth` | Yes | Unknown |\n| [Wikipedia](https://www.mediawiki.org/wiki/API:Main_page) | Mediawiki Encyclopedia | No | Yes | Unknown |\n| [Yelp](https://www.yelp.com/developers/documentation/v3) | Find Local Business | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Open Source Projects\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Countly](http://resources.count.ly/docs) | Countly web analytics | No | No | Unknown |\n| [Drupal.org](https://www.drupal.org/drupalorg/docs/api) | Drupal.org | No | Yes | Unknown |\n| [Evil Insult Generator](https://evilinsult.com/api) | Evil Insults | No | Yes | Yes |\n| [Libraries.io](https://libraries.io/api) | Open source software libraries | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Patent\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [EPO](https://developers.epo.org/) | European patent search system api | `OAuth` | Yes | Unknown |\n| [TIPO](https://tiponet.tipo.gov.tw/Gazette/OpenData/OD/OD05.aspx?QryDS=API00) | Taiwan patent search system api | `apiKey` | Yes | Unknown |\n| [USPTO](https://www.uspto.gov/learning-and-resources/open-data-and-mobility) | USA patent api services | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Personality\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Advice Slip](http://api.adviceslip.com/) | Generate random advice slips | No | Yes | Unknown |\n| [chucknorris.io](https://api.chucknorris.io) | JSON API for hand curated Chuck Norris jokes | No | Yes | Unknown |\n| [FavQs.com](https://favqs.com/api) | FavQs allows you to collect, discover and share your favorite quotes | `apiKey` | Yes | Unknown |\n| [FOAAS](http://www.foaas.com/) | Fuck Off As A Service | No | No | Unknown |\n| [Forismatic](http://forismatic.com/en/api/) | Inspirational Quotes | No | No | Unknown |\n| [icanhazdadjoke](https://icanhazdadjoke.com/api) | The largest selection of dad jokes on the internet | No | Yes | Unknown |\n| [kanye.rest](https://kanye.rest) | REST API for random Kanye West quotes | No | Yes | Yes |\n| [Medium](https://github.com/Medium/medium-api-docs) | Community of readers and writers offering unique perspectives on ideas | `OAuth` | Yes | Unknown |\n| [NaMoMemes](https://github.com/theIYD/NaMoMemes) | Memes on Narendra Modi | No | Yes | Unknown |\n| [Programming Quotes](https://github.com/skolakoda/programming-quotes-api) | Programming Quotes API for open source projects | No | Yes | Unknown |\n| [Quote Garden](https://pprathameshmore.github.io/QuoteGarden/) | REST API for more than 5000 famous quotes | No | Yes | Unknown |\n| [Quotes on Design](https://quotesondesign.com/api/) | Inspirational Quotes | No | Yes | Unknown |\n| [Traitify](https://app.traitify.com/developer) | Assess, collect and analyze Personality | No | Yes | Unknown |\n| [tronalddump.io](https://www.tronalddump.io) | Api & web archive for the things Donald Trump has said | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Photography\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Flickr](https://www.flickr.com/services/api/) | Flickr Services | `OAuth` | Yes | Unknown |\n| [Getty Images](http://developers.gettyimages.com/en/) | Build applications using the world's most powerful imagery | `OAuth` | Yes | Unknown |\n| [Gfycat](https://developers.gfycat.com/api/) | Jiffier GIFs | `OAuth` | Yes | Unknown |\n| [Giphy](https://developers.giphy.com/docs/) | Get all your gifs | `apiKey` | Yes | Unknown |\n| [Gyazo](https://gyazo.com/api/docs) | Upload images | `apiKey` | Yes | Unknown |\n| [Imgur](https://apidocs.imgur.com/) | Images | `OAuth` | Yes | Unknown |\n| [Lorem Picsum](https://picsum.photos/) | Images from Unsplash | No | Yes | Unknown |\n| [Pexels](https://www.pexels.com/api/) | Free Stock Photos and Videos | `apiKey` | Yes | Yes |\n| [Pixabay](https://pixabay.com/sk/service/about/api/) | Photography | `apiKey` | Yes | Unknown |\n| [Pixhost](https://pixhost.org/api/index.html) | Upload images, photos, galleries | No | Yes | Unknown |\n| [PlaceKitten](https://placekitten.com/) | Resizable kitten placeholder images | No | Yes | Unknown |\n| [ScreenShotLayer](https://screenshotlayer.com) | URL 2 Image | No | Yes | Unknown |\n| [Unsplash](https://unsplash.com/developers) | Photography | `OAuth` | Yes | Unknown |\n| [Wallhaven](https://wallhaven.cc/help/api) | Wallpapers | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Science & Math\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [arcsecond.io](https://api.arcsecond.io/) | Multiple astronomy data sources | No | Yes | Unknown |\n| [CORE](https://core.ac.uk/services#api) | Access the world's Open Access research papers | `apiKey` | Yes | Unknown |\n| [GBIF](http://api.gbif.org/v1/) | Global Biodiversity Information Facility | No | Yes | Yes |\n| [iDigBio](https://github.com/idigbio/idigbio-search-api/wiki) | Access millions of museum specimens from organizations around the world | No | Yes | Unknown |\n| [inspirehep.net](https://inspirehep.net/info/hep/api?ln=en) | High Energy Physics info. system | No | Yes | Unknown |\n| [ITIS](https://www.itis.gov/ws_description.html) | Integrated Taxonomic Information System | No | Yes | Unknown |\n| [Launch Library](https://launchlibrary.net/docs/1.3/api.html) | Upcoming Space Launches | No | Yes | Unknown |\n| [Minor Planet Center](http://www.asterank.com/mpc) | Asterank.com Information | No | No | Unknown |\n| [NASA](https://api.nasa.gov) | NASA data, including imagery | No | Yes | Unknown |\n| [NASA APOD (unofficial API)](https://apodapi.herokuapp.com/) | API for getting APOD (Astronomy Image of the Day) images along with metadata | No | Yes | Yes |\n| [Newton](https://newton.now.sh/) | Symbolic and Arithmetic Math Calculator | No | Yes | Unknown |\n| [Numbers](http://numbersapi.com) | Facts about numbers | No | No | Unknown |\n| [Open Notify](http://open-notify.org/Open-Notify-API/) | ISS astronauts, current location, etc | No | No | Unknown |\n| [Open Science Framework](https://developer.osf.io) | Repository and archive for study designs, research materials, data, manuscripts, etc | No | Yes | Unknown |\n| [SHARE](https://share.osf.io/api/v2/) | A free, open, dataset about research and scholarly activities | No | Yes | Unknown |\n| [SpaceX](https://github.com/r-spacex/SpaceX-API) | Company, vehicle, launchpad and launch data | No | Yes | Unknown |\n| [Sunrise and Sunset](https://sunrise-sunset.org/api) | Sunset and sunrise times for a given latitude and longitude | No | Yes | Unknown |\n| [Trefle](https://trefle.io/) | Botanical data for plant species | `apiKey` | Yes | Unknown |\n| [USGS Earthquake Hazards Program](https://earthquake.usgs.gov/fdsnws/event/1/) | Earthquakes data real-time | No | Yes | Unknown |\n| [USGS Water Services](https://waterservices.usgs.gov/) | Water quality and level info for rivers and lakes | No | Yes | Unknown |\n| [World Bank](https://datahelpdesk.worldbank.org/knowledgebase/topics/125589) | World Data | No | No | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Security\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Censys.io](https://censys.io/api) | Search engine for Internet connected host and devices | `apiKey` | Yes | No |\n| [CRXcavator](https://crxcavator.io/apidocs) | Chrome extension risk scoring | `apiKey` | Yes | Unknown |\n| [FilterLists](https://filterlists.com/api) | Lists of filters for adblockers and firewalls | No | Yes | Unknown |\n| [HaveIBeenPwned](https://haveibeenpwned.com/API/v3) | Passwords which have previously been exposed in data breaches | `apiKey` | Yes | Unknown |\n| [National Vulnerability Database](https://nvd.nist.gov/vuln/Data-Feeds/JSON-feed-changelog) | U.S. National Vulnerability Database | No | Yes | Unknown |\n| [SecurityTrails](https://securitytrails.com/corp/apidocs) | Domain and IP related information such as current and historical WHOIS and DNS records | `apiKey` | Yes | Unknown |\n| [Shodan](https://developer.shodan.io/) | Search engine for Internet connected devices | `apiKey` | Yes | Unknown |\n| [UK Police](https://data.police.uk/docs/) | UK Police data | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Shopping\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Best Buy](https://bestbuyapis.github.io/api-documentation/#overview) | Products, Buying Options, Categories, Recommendations, Stores and Commerce | `apiKey` | Yes | Unknown |\n| [Bratabase](https://developers.bratabase.com/) | Database of different types of Bra Sizes | `OAuth` | Yes | Unknown |\n| [eBay](https://go.developer.ebay.com/) | Sell and Buy on eBay | `OAuth` | Yes | Unknown |\n| [Wal-Mart](https://developer.walmartlabs.com/docs) | Item price and availability | `apiKey` | Yes | Unknown |\n| [Wegmans](https://dev.wegmans.io) | Wegmans Food Markets | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Social\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Buffer](https://buffer.com/developers/api) | Access to pending and sent updates in Buffer | `OAuth` | Yes | Unknown |\n| [Cisco Spark](https://developer.ciscospark.com) | Team Collaboration Software | `OAuth` | Yes | Unknown |\n| [Discord](https://discordapp.com/developers/docs/intro) | Make bots for Discord, integrate Discord onto an external platform | `OAuth` | Yes | Unknown |\n| [Disqus](https://disqus.com/api/docs/auth/) | Communicate with Disqus data | `OAuth` | Yes | Unknown |\n| [Facebook](https://developers.facebook.com/) | Facebook Login, Share on FB, Social Plugins, Analytics and more | `OAuth` | Yes | Unknown |\n| [Foursquare](https://developer.foursquare.com/) | Interact with Foursquare users and places (geolocation-based checkins, photos, tips, events, etc) | `OAuth` | Yes | Unknown |\n| [Fuck Off as a Service](https://www.foaas.com) | Asks someone to fuck off | No | Yes | Unknown |\n| [Full Contact](https://www.fullcontact.com/developer/docs/) | Get Social Media profiles and contact Information | `OAuth` | Yes | Unknown |\n| [HackerNews](https://github.com/HackerNews/API) | Social news for CS and entrepreneurship | No | Yes | Unknown |\n| [Instagram](https://www.instagram.com/developer/) | Instagram Login, Share on Instagram, Social Plugins and more | `OAuth` | Yes | Unknown |\n| [LinkedIn](https://developer.linkedin.com/docs/rest-api) | The foundation of all digital integrations with LinkedIn | `OAuth` | Yes | Unknown |\n| [Meetup.com](https://www.meetup.com/meetup_api/) | Data about Meetups from Meetup.com | `apiKey` | Yes | Unknown |\n| [Mixer](https://dev.mixer.com/) | Game Streaming API | `OAuth` | Yes | Unknown |\n| [MySocialApp](https://mysocialapp.io) | Seamless Social Networking features, API, SDK to any app | `apiKey` | Yes | Unknown |\n| [Open Collective](https://docs.opencollective.com/help/developers/api) | Get Open Collective data | No | Yes | Unknown |\n| [Pinterest](https://developers.pinterest.com/) | The world's catalog of ideas | `OAuth` | Yes | Unknown |\n| [PWRTelegram bot](https://pwrtelegram.xyz) | Boosted version of the Telegram bot API | `OAuth` | Yes | Unknown |\n| [Reddit](https://www.reddit.com/dev/api) | Homepage of the internet | `OAuth` | Yes | Unknown |\n| [SharedCount](http://docs.sharedcount.com/) | Social media like and share data for any URL | `apiKey` | Yes | Unknown |\n| [Slack](https://api.slack.com/) | Team Instant Messaging | `OAuth` | Yes | Unknown |\n| [Telegram Bot](https://core.telegram.org/bots/api) | Simplified HTTP version of the MTProto API for bots | `OAuth` | Yes | Unknown |\n| [Telegram MTProto](https://core.telegram.org/api#getting-started) | Read and write Telegram data | `OAuth` | Yes | Unknown |\n| [Trash Nothing](https://trashnothing.com/developer) | A freecycling community with thousands of free items posted every day | `OAuth` | Yes | Yes |\n| [Tumblr](https://www.tumblr.com/docs/en/api/v2) | Read and write Tumblr Data | `OAuth` | Yes | Unknown |\n| [Twitch](https://dev.twitch.tv/docs) | Game Streaming API | `OAuth` | Yes | Unknown |\n| [Twitter](https://developer.twitter.com/en/docs) | Read and write Twitter data | `OAuth` | Yes | No |\n| [vk](https://vk.com/dev/sites) | Read and write vk data | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Sports & Fitness\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [balldontlie](https://balldontlie.io) | Ballldontlie provides access to stats data from the NBA | No | Yes | Yes |\n| [BikeWise](https://www.bikewise.org/documentation/api_v2) | Bikewise is a place to learn about and report bike crashes, hazards and thefts | No | Yes | Unknown |\n| [Canadian Football League (CFL)](http://api.cfl.ca/) | Official JSON API providing real-time league, team and player statistics about the CFL | `apiKey` | Yes | No |\n| [Cartola FC](https://github.com/wgenial/cartrolandofc) | The Cartola FC API serves to check the partial points of your team | No | Yes | Unknown |\n| [City Bikes](http://api.citybik.es/v2/) | City Bikes around the world | No | No | Unknown |\n| [Cricket Live Scores](https://market.mashape.com/dev132/cricket-live-scores) | Live cricket scores | `X-Mashape-Key` | Yes | Unknown |\n| [Ergast F1](http://ergast.com/mrd/) | F1 data from the beginning of the world championships in 1950 | No | Yes | Unknown |\n| [Fitbit](https://dev.fitbit.com/) | Fitbit Information | `OAuth` | Yes | Unknown |\n| [Football (Soccer) Videos](https://www.scorebat.com/video-api/) | Embed codes for goals and highlights from Premier League, Bundesliga, Serie A and many more | No | Yes | Yes |\n| [Football Prediction](https://boggio-analytics.com/fp-api/) | Predictions for upcoming football matches, odds, results and stats | `X-Mashape-Key` | Yes | Unknown |\n| [Football-Data.org](http://api.football-data.org/index) | Football Data | No | No | Unknown |\n| [JCDecaux Bike](https://developer.jcdecaux.com/) | JCDecaux's self-service bicycles | `apiKey` | Yes | Unknown |\n| [NBA Stats](https://any-api.com/nba_com/nba_com/docs/API_Description) | Current and historical NBA Statistics | No | Yes | Unknown |\n| [NFL Arrests](http://nflarrest.com/api/) | NFL Arrest Data | No | No | Unknown |\n| [NHL Records and Stats](https://gitlab.com/dword4/nhlapi) | NHL historical data and statistics | No | Yes | Unknown |\n| [Pro Motocross](http://promotocrossapi.com) | The RESTful AMA Pro Motocross lap times for every racer on the start gate | No | No | Unknown |\n| [Strava](https://strava.github.io/api/) | Connect with athletes, activities and more | `OAuth` | Yes | Unknown |\n| [SuredBits](https://suredbits.com/api/) | Query sports data, including teams, players, games, scores and statistics | No | No | No |\n| [TheSportsDB](https://www.thesportsdb.com/api.php) | Crowd-Sourced Sports Data and Artwork | `apiKey` | Yes | Yes |\n| [Wger](https://wger.de/en/software/api) | Workout manager data as exercises, muscles or equipment | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Test Data\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Adorable Avatars](http://avatars.adorable.io) | Generate random cartoon avatars | No | Yes | Unknown |\n| [Bacon Ipsum](https://baconipsum.com/json-api/) | A Meatier Lorem Ipsum Generator | No | Yes | Unknown |\n| [Dicebear Avatars](https://avatars.dicebear.com/) | Generate random pixel-art avatars | No | Yes | No |\n| [FakeJSON](https://fakejson.com) | Service to generate test and fake data | `apiKey` | Yes | Yes |\n| [FHIR](http://fhirtest.uhn.ca/home) | Fast Healthcare Interoperability Resources test data | No | Yes | Unknown |\n| [Hipster Ipsum](http://hipsterjesus.com/) | Generates Hipster Ipsum text | No | No | Unknown |\n| [Identicon](https://www.kwelo.com/media/identicon/) | Generates abstract avatar image | No | Yes | Yes |\n| [JSONPlaceholder](http://jsonplaceholder.typicode.com/) | Fake data for testing and prototyping | No | No | Unknown |\n| [Lorem Text](https://market.mashape.com/montanaflynn/lorem-text-generator) | Generates Lorem Ipsum text | `X-Mashape-Key` | Yes | Unknown |\n| [LoremPicsum](http://lorempicsum.com) | Generate placeholder pictures | No | No | Unknown |\n| [Loripsum](http://loripsum.net/) | The \"lorem ipsum\" generator that doesn't suck | No | No | Unknown |\n| [RandomUser](https://randomuser.me) | Generates random user data | No | Yes | Unknown |\n| [RoboHash](https://robohash.org/) | Generate random robot/alien avatars | No | Yes | Unknown |\n| [This Person Does not Exist](https://thispersondoesnotexist.com) | Generates real-life faces of people who do not exist | No | Yes | Unknown |\n| [UI Names](https://github.com/thm/uinames) | Generate random fake names | No | Yes | Unknown |\n| [Yes No](https://yesno.wtf/api) | Generate yes or no randomly | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Text Analysis\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Aylien Text Analysis](http://docs.aylien.com/) | A collection of information retrieval and natural language APIs | `apiKey` | Yes | Unknown |\n| [Cloudmersive Natural Language Processing](https://www.cloudmersive.com/nlp-api) | Natural language processing and text analysis | `apiKey` | Yes | Yes |\n| [Detect Language](https://detectlanguage.com/) | Detects text language | `apiKey` | Yes | Unknown |\n| [Google Cloud Natural](https://cloud.google.com/natural-language/docs/) | Natural language understanding technology, including sentiment, entity and syntax analysis | `apiKey` | Yes | Unknown |\n| [Language Identification](https://rapidapi.com/BigLobster/api/language-identification-prediction) | Automatic language detection for any texts, supports over 175 languages | `X-Mashape-Key` | Yes | Unknown |\n| [Semantira](https://semantria.readme.io/docs) | Text Analytics with sentiment analysis, categorization & named entity extraction | `OAuth` | Yes | Unknown |\n| [Watson Natural Language Understanding](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/) | Natural language processing for advanced text analysis | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Tracking\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Postmon](http://postmon.com.br) | An API to query Brazilian ZIP codes and orders easily, quickly and free | No | No | Unknown |\n| [Sweden](https://developer.postnord.com/docs2) | Provides information about parcels in transport | `apiKey` | No | Unknown |\n| [UPS](https://www.ups.com/upsdeveloperkit) | Shipment and Address information | `apiKey` | Yes | Unknown |\n| [WhatPulse](https://whatpulse.org/pages/webapi/) | Small application that measures your keyboard/mouse usage | No | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Transportation\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [ADS-B Exchange](https://www.adsbexchange.com/data/) | Access real-time and historical data of any and all airborne aircraft | No | Yes | Unknown |\n| [AIS Hub](http://www.aishub.net/api) | Real-time data of any marine and inland vessel equipped with AIS tracking system | `apiKey` | No | Unknown |\n| [AIS Web](http://www.aisweb.aer.mil.br/api/doc/index.cfm) | Aeronautical information in digital media produced by the Department of Airspace Control (DECEA) | `apiKey` | No | Unknown |\n| [Amadeus Travel Innovation Sandbox](https://sandbox.amadeus.com/) | Travel Search - Limited usage | `apiKey` | Yes | Unknown |\n| [Bay Area Rapid Transit](http://api.bart.gov) | Stations and predicted arrivals for BART | `apiKey` | No | Unknown |\n| [BlaBlaCar](https://dev.blablacar.com) | Search car sharing trips | `apiKey` | Yes | Unknown |\n| [Community Transit](https://github.com/transitland/transitland-datastore/blob/master/README.md#api-endpoints) | Transitland API | No | Yes | Unknown |\n| [Goibibo](https://developer.goibibo.com/docs) | API for travel search | `apiKey` | Yes | Unknown |\n| [GraphHopper](https://graphhopper.com/api/1/docs/) | A-to-B routing with turn-by-turn instructions | `apiKey` | Yes | Unknown |\n| [Icelandic APIs](http://docs.apis.is/) | Open APIs that deliver services in or regarding Iceland | No | Yes | Unknown |\n| [Indian Railways](http://api.erail.in/) | Indian Railways Information | `apiKey` | No | Unknown |\n| [Izi](http://api-docs.izi.travel/) | Audio guide for travellers | `apiKey` | Yes | Unknown |\n| [Metro Lisboa](http://app.metrolisboa.pt/status/getLinhas.php) | Delays in subway lines | No | No | No |\n| [Navitia](https://api.navitia.io/) | The open API for building cool stuff with transport data | `apiKey` | Yes | Unknown |\n| [REFUGE Restrooms](https://www.refugerestrooms.org/api/docs/#!/restrooms) | Provides safe restroom access for transgender, intersex and gender nonconforming individuals | No | Yes | Unknown |\n| [Schiphol Airport](https://developer.schiphol.nl/) | Schiphol | `apiKey` | Yes | Unknown |\n| [TransitLand](https://transit.land/documentation/datastore/api-endpoints.html) | Transit Aggregation | No | Yes | Unknown |\n| [Transport for Atlanta, US](http://www.itsmarta.com/app-developer-resources.aspx) | Marta | No | No | Unknown |\n| [Transport for Auckland, New Zealand](https://api.at.govt.nz/) | Auckland Transport | No | Yes | Unknown |\n| [Transport for Belgium](https://hello.irail.be/api/) | Belgian transport API | No | Yes | Unknown |\n| [Transport for Berlin, Germany](https://github.com/derhuerst/vbb-rest/blob/master/docs/index.md) | Third-party VBB API | No | Yes | Unknown |\n| [Transport for Bordeaux, France](https://opendata.bordeaux-metropole.fr/explore/) | Bordeaux M\u00e9tropole public transport and more (France) | `apiKey` | Yes | Unknown |\n| [Transport for Boston, US](https://mbta.com/developers/v3-api) | MBTA API | No | No | Unknown |\n| [Transport for Budapest, Hungary](https://bkkfutar.docs.apiary.io) | Budapest public transport API | No | Yes | Unknown |\n| [Transport for Chicago, US](http://www.transitchicago.com/developers/) | CTA | No | No | Unknown |\n| [Transport for Czech Republic](https://www.chaps.cz/eng/products/idos-internet) | Czech transport API | No | Yes | Unknown |\n| [Transport for Denver, US](http://www.rtd-denver.com/gtfs-developer-guide.shtml) | RTD | No | No | Unknown |\n| [Transport for Finland](https://digitransit.fi/en/developers/ ) | Finnish transport API | No | Yes | Unknown |\n| [Transport for Germany](http://data.deutschebahn.com/dataset/api-fahrplan) | Deutsche Bahn (DB) API | `apiKey` | No | Unknown |\n| [Transport for Grenoble, France](https://www.metromobilite.fr/pages/opendata/OpenDataApi.html) | Grenoble public transport | No | No | No |\n| [Transport for Honolulu, US](http://hea.thebus.org/api_info.asp) | Honolulu Transportation Information | `apiKey` | No | Unknown |\n| [Transport for India](https://data.gov.in/sector/transport) | India Public Transport API | `apiKey` | Yes | Unknown |\n| [Transport for Lisbon, Portugal](https://emel.city-platform.com/opendata/) | Data about buses routes, parking and traffic | `apiKey` | Yes | Unknown | \n| [Transport for London, England](https://api.tfl.gov.uk) | TfL API | No | Yes | Unknown |\n| [Transport for Madrid, Spain](http://opendata.emtmadrid.es/Servicios-web/BUS) | Madrid BUS transport API | `apiKey` | No | Unknown |\n| [Transport for Manchester, England](https://developer.tfgm.com/) | TfGM transport network data | `apiKey` | Yes | No |\n| [Transport for Minneapolis, US](http://svc.metrotransit.org/) | NexTrip API | `OAuth` | No | Unknown |\n| [Transport for New York City, US](http://datamine.mta.info/) | MTA | `apiKey` | No | Unknown |\n| [Transport for Norway](http://reisapi.ruter.no/help) | Norwegian transport API | No | No | Unknown |\n| [Transport for Ottawa, Canada](http://www.octranspo.com/index.php/developers) | OC Transpo next bus arrival API | No | No | Unknown |\n| [Transport for Paris, France](http://restratpws.azurewebsites.net/swagger/) | Live schedules made simple | No | No | Unknown |\n| [Transport for Paris, France](http://data.ratp.fr/api/v1/console/datasets/1.0/search/) | RATP Open Data API | No | No | Unknown |\n| [Transport for Philadelphia, US](http://www3.septa.org/hackathon/) | SEPTA APIs | No | No | Unknown |\n| [Transport for Sao Paulo, Brazil](http://www.sptrans.com.br/desenvolvedores/APIOlhoVivo/Documentacao.aspx) | SPTrans | `OAuth` | No | Unknown |\n| [Transport for Sweden](https://www.trafiklab.se/api) | Public Transport consumer | `OAuth` | Yes | Unknown |\n| [Transport for Switzerland](https://opentransportdata.swiss/en/) | Official Swiss Public Transport Open Data | `apiKey` | Yes | Unknown |\n| [Transport for Switzerland](https://transport.opendata.ch/) | Swiss public transport API | No | Yes | Unknown |\n| [Transport for The Netherlands](http://www.ns.nl/reisinformatie/ns-api) | NS, only trains | `apiKey` | No | Unknown |\n| [Transport for The Netherlands](https://github.com/skywave/KV78Turbo-OVAPI/wiki) | OVAPI, country-wide public transport | No | Yes | Unknown |\n| [Transport for Toronto, Canada](https://myttc.ca/developers) | TTC | No | Yes | Unknown |\n| [Transport for United States](http://www.nextbus.com/xmlFeedDocs/NextBusXMLFeed.pdf) | NextBus API | No | No | Unknown |\n| [Transport for Vancouver, Canada](https://developer.translink.ca/) | TransLink | `OAuth` | Yes | Unknown |\n| [Transport for Victoria, AU](https://www.ptv.vic.gov.au/about-ptv/ptv-data-and-reports/digital-products/ptv-timetable-api/) | PTV API | `apiKey` | Yes | Unknown |\n| [Transport for Washington, US](https://developer.wmata.com/) | Washington Metro transport API | `OAuth` | Yes | Unknown |\n| [Uber](https://developer.uber.com/products) | Uber ride requests and price estimation | `OAuth` | Yes | Yes |\n| [WhereIsMyTransport](https://developer.whereismytransport.com/) | Platform for public transport data in emerging cities | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### URL Shorteners\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Bitly](http://dev.bitly.com/get_started.html) | URL shortener and link management | `OAuth` | Yes | Unknown |\n| [CleanURI](https://cleanuri.com/docs) | URL shortener service | `No` | Yes | Yes |\n| [ClickMeter](https://support.clickmeter.com/hc/en-us/categories/201474986) | Monitor, compare and optimize your marketing links | `apiKey` | Yes | Unknown |\n| [Rebrandly](https://developers.rebrandly.com/v1/docs) | Custom URL shortener for sharing branded links | `apiKey` | Yes | Unknown |\n| [Relink](https://rel.ink) | Free and secure URL shortener | No | Yes | Yes |\n\n**[\u2b06 Back to Index](#index)**\n### Vehicle\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [Brazilian Vehicles and Prices](https://deividfortuna.github.io/fipe/) | Vehicles information from Funda\u00e7\u00e3o Instituto de Pesquisas Econ\u00f4micas - Fipe | No | Yes | Unknown |\n| [Kelley Blue Book](http://developer.kbb.com/#!/data/1-Default) | Vehicle info, pricing, configuration, plus much more | `apiKey` | Yes | No |\n| [Mercedes-Benz](https://developer.mercedes-benz.com/apis) | Telematics data, remotely access vehicle functions, car configurator, locate service dealers | `apiKey` | Yes | No |\n| [NHTSA](https://vpic.nhtsa.dot.gov/api/) | NHTSA Product Information Catalog and Vehicle Listing | No | Yes | Unknown |\n| [Smartcar](https://smartcar.com/docs/) | Lock and unlock vehicles and get data like odometer reading and location. Works on most new cars | `OAuth` | Yes | Yes |\n\n**[\u2b06 Back to Index](#index)**\n### Video\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [An API of Ice And Fire](https://anapioficeandfire.com/) | Game Of Thrones API | No | Yes | Unknown |\n| [Breaking Bad](https://breakingbadapi.com/documentation) | Breaking Bad API | No | Yes | Unknown |\n| [Breaking Bad Quotes](https://github.com/shevabam/breaking-bad-quotes) | Some Breaking Bad quotes | No | Yes | Unknown |\n| [Czech Television](http://www.ceskatelevize.cz/xml/tv-program/) | TV programme of Czech TV | No | No | Unknown |\n| [Dailymotion](https://developer.dailymotion.com/) | Dailymotion Developer API | `OAuth` | Yes | Unknown |\n| [Harry Potter](https://www.potterapi.com/) | Harry Potter API | `apiKey` | Yes | Yes |\n| [Open Movie Database](http://www.omdbapi.com/) | Movie information | `apiKey` | Yes | Unknown |\n| [Ron Swanson Quotes](https://github.com/jamesseanwright/ron-swanson-quotes#ron-swanson-quotes-api) | Television | No | Yes | Unknown |\n| [STAPI](http://stapi.co) | Information on all things Star Trek | No | No | No |\n| [SWAPI](https://swapi.co) | Star Wars Information | No | Yes | Unknown |\n| [The Lord of the Rings](https://the-one-api.herokuapp.com/) | The Lord of the Rings API | `apiKey` | Yes | Unknown |\n| [TMDb](https://www.themoviedb.org/documentation/api) | Community-based movie data | `apiKey` | Yes | Unknown |\n| [Trakt](https://trakt.tv/b/api-docs) | Movie and TV Data | `apiKey` | Yes | Yes |\n| [TVDB](https://api.thetvdb.com/swagger) | Television data | `apiKey` | Yes | Unknown |\n| [TVMaze](http://www.tvmaze.com/api) | TV Show Data | No | No | Unknown |\n| [Utelly](https://market.mashape.com/utelly/utelly) | Check where a tv show or movie is available | `X-Mashape-Key` | Yes | Unknown |\n| [Vimeo](https://developer.vimeo.com/) | Vimeo Developer API | `OAuth` | Yes | Unknown |\n| [YouTube](https://developers.google.com/youtube/) | Add YouTube functionality to your sites and apps | `OAuth` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n### Weather\nAPI | Description | Auth | HTTPS | CORS |\n|---|---|---|---|---|\n| [7Timer!](http://www.7timer.info/doc.php?lang=en) | Weather, especially for Astroweather | No | No | Unknown |\n| [APIXU](https://www.apixu.com/doc/request.aspx) | Weather | `apiKey` | Yes | Unknown |\n| [Dark Sky](https://darksky.net/dev/) | Weather | `apiKey` | Yes | No |\n| [MetaWeather](https://www.metaweather.com/api/) | Weather | No | Yes | No |\n| [Meteorologisk Institutt](https://api.met.no/weatherapi/documentation) | Weather and climate data | No | Yes | Unknown |\n| [NOAA Climate Data](https://www.ncdc.noaa.gov/cdo-web/) | Weather and climate data | `apiKey` | Yes | Unknown |\n| [ODWeather](http://api.oceandrivers.com/static/docs.html) | Weather and weather webcams | No | No | Unknown |\n| [OpenUV](https://www.openuv.io) | Real-time UV Index Forecast | `apiKey` | Yes | Unknown |\n| [OpenWeatherMap](http://openweathermap.org/api) | Weather | `apiKey` | No | Unknown |\n| [Storm Glass](https://stormglass.io/) | Global marine weather from multiple sources | `apiKey` | Yes | Yes |\n| [Weatherbit](https://www.weatherbit.io/api) | Weather | `apiKey` | Yes | Unknown |\n| [Yahoo! Weather](https://developer.yahoo.com/weather/) | Weather | `apiKey` | Yes | Unknown |\n\n**[\u2b06 Back to Index](#index)**\n"}, {"repo": "TheAlgorithms/Python", "language": "Python", "readme_contents": "# The Algorithms - Python\n\n[![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg?logo=paypal&style=flat-square)](https://www.paypal.me/TheAlgorithms/100)&nbsp;\n[![Build Status](https://img.shields.io/travis/TheAlgorithms/Python.svg?label=Travis%20CI&logo=travis&style=flat-square)](https://travis-ci.com/TheAlgorithms/Python)&nbsp;\n[![LGTM](https://img.shields.io/lgtm/alerts/github/TheAlgorithms/Python.svg?label=LGTM&logo=LGTM&style=flat-square)](https://lgtm.com/projects/g/TheAlgorithms/Python/alerts)&nbsp;\n[![Gitter chat](https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&logo=gitter&style=flat-square)](https://gitter.im/TheAlgorithms)&nbsp;\n[![contributions welcome](https://img.shields.io/static/v1.svg?label=Contributions&message=Welcome&color=0059b3&style=flat-square)](https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md)&nbsp;\n![](https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&style=flat-square)&nbsp;\n<!--[![Tested on Python 3.7](https://img.shields.io/badge/Tested%20-Python%203.7-blue.svg?logo=python&style=flat-square)]( https://www.python.org/downloads) &nbsp;-->\n\n### All algorithms implemented in Python (for education)\n\nThese implementations are for learning purposes. They may be less efficient than the implementations in the Python standard library.\n\n## Contribution Guidelines\n\nRead our [Contribution Guidelines](CONTRIBUTING.md) before you contribute.\n\n## Community Channel\n\nWe're on [Gitter](https://gitter.im/TheAlgorithms)! Please join us.\n\n## List of Algorithms\n\nSee our [directory](DIRECTORY.md).\n\n\n\n\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg?style=flat-square)](https://gitpod.io/#https://github.com/TheAlgorithms/Python)\n"}, {"repo": "tensorflow/models", "language": "Python", "readme_contents": "# TensorFlow Models\n\nThis repository contains a number of different models implemented in [TensorFlow](https://www.tensorflow.org):\n\nThe [official models](official) are a collection of example models that use TensorFlow's high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest stable TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read. We especially recommend newer TensorFlow users to start here.\n\nThe [research models](https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported or available in release branches; it is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.\n\nThe [samples folder](samples) contains code snippets and smaller models that demonstrate features of TensorFlow, including code presented in various blog posts.\n\nThe [tutorials folder](tutorials) is a collection of models described in the [TensorFlow tutorials](https://www.tensorflow.org/tutorials/).\n\n## Contribution guidelines\n\nIf you want to contribute to models, be sure to review the [contribution guidelines](CONTRIBUTING.md).\n\n## License\n\n[Apache License 2.0](LICENSE)\n"}, {"repo": "ytdl-org/youtube-dl", "language": "Python", "readme_contents": "[![Build Status](https://travis-ci.org/ytdl-org/youtube-dl.svg?branch=master)](https://travis-ci.org/ytdl-org/youtube-dl)\n\nyoutube-dl - download videos from youtube.com or other video platforms\n\n- [INSTALLATION](#installation)\n- [DESCRIPTION](#description)\n- [OPTIONS](#options)\n- [CONFIGURATION](#configuration)\n- [OUTPUT TEMPLATE](#output-template)\n- [FORMAT SELECTION](#format-selection)\n- [VIDEO SELECTION](#video-selection)\n- [FAQ](#faq)\n- [DEVELOPER INSTRUCTIONS](#developer-instructions)\n- [EMBEDDING YOUTUBE-DL](#embedding-youtube-dl)\n- [BUGS](#bugs)\n- [COPYRIGHT](#copyright)\n\n# INSTALLATION\n\nTo install it right away for all UNIX users (Linux, macOS, etc.), type:\n\n    sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl\n    sudo chmod a+rx /usr/local/bin/youtube-dl\n\nIf you do not have curl, you can alternatively use a recent wget:\n\n    sudo wget https://yt-dl.org/downloads/latest/youtube-dl -O /usr/local/bin/youtube-dl\n    sudo chmod a+rx /usr/local/bin/youtube-dl\n\nWindows users can [download an .exe file](https://yt-dl.org/latest/youtube-dl.exe) and place it in any location on their [PATH](https://en.wikipedia.org/wiki/PATH_%28variable%29) except for `%SYSTEMROOT%\\System32` (e.g. **do not** put in `C:\\Windows\\System32`).\n\nYou can also use pip:\n\n    sudo -H pip install --upgrade youtube-dl\n    \nThis command will update youtube-dl if you have already installed it. See the [pypi page](https://pypi.python.org/pypi/youtube_dl) for more information.\n\nmacOS users can install youtube-dl with [Homebrew](https://brew.sh/):\n\n    brew install youtube-dl\n\nOr with [MacPorts](https://www.macports.org/):\n\n    sudo port install youtube-dl\n\nAlternatively, refer to the [developer instructions](#developer-instructions) for how to check out and work with the git repository. For further options, including PGP signatures, see the [youtube-dl Download Page](https://ytdl-org.github.io/youtube-dl/download.html).\n\n# DESCRIPTION\n**youtube-dl** is a command-line program to download videos from YouTube.com and a few more sites. It requires the Python interpreter, version 2.6, 2.7, or 3.2+, and it is not platform specific. It should work on your Unix box, on Windows or on macOS. It is released to the public domain, which means you can modify it, redistribute it or use it however you like.\n\n    youtube-dl [OPTIONS] URL [URL...]\n\n# OPTIONS\n    -h, --help                       Print this help text and exit\n    --version                        Print program version and exit\n    -U, --update                     Update this program to latest version. Make\n                                     sure that you have sufficient permissions\n                                     (run with sudo if needed)\n    -i, --ignore-errors              Continue on download errors, for example to\n                                     skip unavailable videos in a playlist\n    --abort-on-error                 Abort downloading of further videos (in the\n                                     playlist or the command line) if an error\n                                     occurs\n    --dump-user-agent                Display the current browser identification\n    --list-extractors                List all supported extractors\n    --extractor-descriptions         Output descriptions of all supported\n                                     extractors\n    --force-generic-extractor        Force extraction to use the generic\n                                     extractor\n    --default-search PREFIX          Use this prefix for unqualified URLs. For\n                                     example \"gvsearch2:\" downloads two videos\n                                     from google videos for youtube-dl \"large\n                                     apple\". Use the value \"auto\" to let\n                                     youtube-dl guess (\"auto_warning\" to emit a\n                                     warning when guessing). \"error\" just throws\n                                     an error. The default value \"fixup_error\"\n                                     repairs broken URLs, but emits an error if\n                                     this is not possible instead of searching.\n    --ignore-config                  Do not read configuration files. When given\n                                     in the global configuration file\n                                     /etc/youtube-dl.conf: Do not read the user\n                                     configuration in ~/.config/youtube-\n                                     dl/config (%APPDATA%/youtube-dl/config.txt\n                                     on Windows)\n    --config-location PATH           Location of the configuration file; either\n                                     the path to the config or its containing\n                                     directory.\n    --flat-playlist                  Do not extract the videos of a playlist,\n                                     only list them.\n    --mark-watched                   Mark videos watched (YouTube only)\n    --no-mark-watched                Do not mark videos watched (YouTube only)\n    --no-color                       Do not emit color codes in output\n\n## Network Options:\n    --proxy URL                      Use the specified HTTP/HTTPS/SOCKS proxy.\n                                     To enable SOCKS proxy, specify a proper\n                                     scheme. For example\n                                     socks5://127.0.0.1:1080/. Pass in an empty\n                                     string (--proxy \"\") for direct connection\n    --socket-timeout SECONDS         Time to wait before giving up, in seconds\n    --source-address IP              Client-side IP address to bind to\n    -4, --force-ipv4                 Make all connections via IPv4\n    -6, --force-ipv6                 Make all connections via IPv6\n\n## Geo Restriction:\n    --geo-verification-proxy URL     Use this proxy to verify the IP address for\n                                     some geo-restricted sites. The default\n                                     proxy specified by --proxy (or none, if the\n                                     option is not present) is used for the\n                                     actual downloading.\n    --geo-bypass                     Bypass geographic restriction via faking\n                                     X-Forwarded-For HTTP header\n    --no-geo-bypass                  Do not bypass geographic restriction via\n                                     faking X-Forwarded-For HTTP header\n    --geo-bypass-country CODE        Force bypass geographic restriction with\n                                     explicitly provided two-letter ISO 3166-2\n                                     country code\n    --geo-bypass-ip-block IP_BLOCK   Force bypass geographic restriction with\n                                     explicitly provided IP block in CIDR\n                                     notation\n\n## Video Selection:\n    --playlist-start NUMBER          Playlist video to start at (default is 1)\n    --playlist-end NUMBER            Playlist video to end at (default is last)\n    --playlist-items ITEM_SPEC       Playlist video items to download. Specify\n                                     indices of the videos in the playlist\n                                     separated by commas like: \"--playlist-items\n                                     1,2,5,8\" if you want to download videos\n                                     indexed 1, 2, 5, 8 in the playlist. You can\n                                     specify range: \"--playlist-items\n                                     1-3,7,10-13\", it will download the videos\n                                     at index 1, 2, 3, 7, 10, 11, 12 and 13.\n    --match-title REGEX              Download only matching titles (regex or\n                                     caseless sub-string)\n    --reject-title REGEX             Skip download for matching titles (regex or\n                                     caseless sub-string)\n    --max-downloads NUMBER           Abort after downloading NUMBER files\n    --min-filesize SIZE              Do not download any videos smaller than\n                                     SIZE (e.g. 50k or 44.6m)\n    --max-filesize SIZE              Do not download any videos larger than SIZE\n                                     (e.g. 50k or 44.6m)\n    --date DATE                      Download only videos uploaded in this date\n    --datebefore DATE                Download only videos uploaded on or before\n                                     this date (i.e. inclusive)\n    --dateafter DATE                 Download only videos uploaded on or after\n                                     this date (i.e. inclusive)\n    --min-views COUNT                Do not download any videos with less than\n                                     COUNT views\n    --max-views COUNT                Do not download any videos with more than\n                                     COUNT views\n    --match-filter FILTER            Generic video filter. Specify any key (see\n                                     the \"OUTPUT TEMPLATE\" for a list of\n                                     available keys) to match if the key is\n                                     present, !key to check if the key is not\n                                     present, key > NUMBER (like \"comment_count\n                                     > 12\", also works with >=, <, <=, !=, =) to\n                                     compare against a number, key = 'LITERAL'\n                                     (like \"uploader = 'Mike Smith'\", also works\n                                     with !=) to match against a string literal\n                                     and & to require multiple matches. Values\n                                     which are not known are excluded unless you\n                                     put a question mark (?) after the operator.\n                                     For example, to only match videos that have\n                                     been liked more than 100 times and disliked\n                                     less than 50 times (or the dislike\n                                     functionality is not available at the given\n                                     service), but who also have a description,\n                                     use --match-filter \"like_count > 100 &\n                                     dislike_count <? 50 & description\" .\n    --no-playlist                    Download only the video, if the URL refers\n                                     to a video and a playlist.\n    --yes-playlist                   Download the playlist, if the URL refers to\n                                     a video and a playlist.\n    --age-limit YEARS                Download only videos suitable for the given\n                                     age\n    --download-archive FILE          Download only videos not listed in the\n                                     archive file. Record the IDs of all\n                                     downloaded videos in it.\n    --include-ads                    Download advertisements as well\n                                     (experimental)\n\n## Download Options:\n    -r, --limit-rate RATE            Maximum download rate in bytes per second\n                                     (e.g. 50K or 4.2M)\n    -R, --retries RETRIES            Number of retries (default is 10), or\n                                     \"infinite\".\n    --fragment-retries RETRIES       Number of retries for a fragment (default\n                                     is 10), or \"infinite\" (DASH, hlsnative and\n                                     ISM)\n    --skip-unavailable-fragments     Skip unavailable fragments (DASH, hlsnative\n                                     and ISM)\n    --abort-on-unavailable-fragment  Abort downloading when some fragment is not\n                                     available\n    --keep-fragments                 Keep downloaded fragments on disk after\n                                     downloading is finished; fragments are\n                                     erased by default\n    --buffer-size SIZE               Size of download buffer (e.g. 1024 or 16K)\n                                     (default is 1024)\n    --no-resize-buffer               Do not automatically adjust the buffer\n                                     size. By default, the buffer size is\n                                     automatically resized from an initial value\n                                     of SIZE.\n    --http-chunk-size SIZE           Size of a chunk for chunk-based HTTP\n                                     downloading (e.g. 10485760 or 10M) (default\n                                     is disabled). May be useful for bypassing\n                                     bandwidth throttling imposed by a webserver\n                                     (experimental)\n    --playlist-reverse               Download playlist videos in reverse order\n    --playlist-random                Download playlist videos in random order\n    --xattr-set-filesize             Set file xattribute ytdl.filesize with\n                                     expected file size\n    --hls-prefer-native              Use the native HLS downloader instead of\n                                     ffmpeg\n    --hls-prefer-ffmpeg              Use ffmpeg instead of the native HLS\n                                     downloader\n    --hls-use-mpegts                 Use the mpegts container for HLS videos,\n                                     allowing to play the video while\n                                     downloading (some players may not be able\n                                     to play it)\n    --external-downloader COMMAND    Use the specified external downloader.\n                                     Currently supports\n                                     aria2c,avconv,axel,curl,ffmpeg,httpie,wget\n    --external-downloader-args ARGS  Give these arguments to the external\n                                     downloader\n\n## Filesystem Options:\n    -a, --batch-file FILE            File containing URLs to download ('-' for\n                                     stdin), one URL per line. Lines starting\n                                     with '#', ';' or ']' are considered as\n                                     comments and ignored.\n    --id                             Use only video ID in file name\n    -o, --output TEMPLATE            Output filename template, see the \"OUTPUT\n                                     TEMPLATE\" for all the info\n    --autonumber-start NUMBER        Specify the start value for %(autonumber)s\n                                     (default is 1)\n    --restrict-filenames             Restrict filenames to only ASCII\n                                     characters, and avoid \"&\" and spaces in\n                                     filenames\n    -w, --no-overwrites              Do not overwrite files\n    -c, --continue                   Force resume of partially downloaded files.\n                                     By default, youtube-dl will resume\n                                     downloads if possible.\n    --no-continue                    Do not resume partially downloaded files\n                                     (restart from beginning)\n    --no-part                        Do not use .part files - write directly\n                                     into output file\n    --no-mtime                       Do not use the Last-modified header to set\n                                     the file modification time\n    --write-description              Write video description to a .description\n                                     file\n    --write-info-json                Write video metadata to a .info.json file\n    --write-annotations              Write video annotations to a\n                                     .annotations.xml file\n    --load-info-json FILE            JSON file containing the video information\n                                     (created with the \"--write-info-json\"\n                                     option)\n    --cookies FILE                   File to read cookies from and dump cookie\n                                     jar in\n    --cache-dir DIR                  Location in the filesystem where youtube-dl\n                                     can store some downloaded information\n                                     permanently. By default\n                                     $XDG_CACHE_HOME/youtube-dl or\n                                     ~/.cache/youtube-dl . At the moment, only\n                                     YouTube player files (for videos with\n                                     obfuscated signatures) are cached, but that\n                                     may change.\n    --no-cache-dir                   Disable filesystem caching\n    --rm-cache-dir                   Delete all filesystem cache files\n\n## Thumbnail images:\n    --write-thumbnail                Write thumbnail image to disk\n    --write-all-thumbnails           Write all thumbnail image formats to disk\n    --list-thumbnails                Simulate and list all available thumbnail\n                                     formats\n\n## Verbosity / Simulation Options:\n    -q, --quiet                      Activate quiet mode\n    --no-warnings                    Ignore warnings\n    -s, --simulate                   Do not download the video and do not write\n                                     anything to disk\n    --skip-download                  Do not download the video\n    -g, --get-url                    Simulate, quiet but print URL\n    -e, --get-title                  Simulate, quiet but print title\n    --get-id                         Simulate, quiet but print id\n    --get-thumbnail                  Simulate, quiet but print thumbnail URL\n    --get-description                Simulate, quiet but print video description\n    --get-duration                   Simulate, quiet but print video length\n    --get-filename                   Simulate, quiet but print output filename\n    --get-format                     Simulate, quiet but print output format\n    -j, --dump-json                  Simulate, quiet but print JSON information.\n                                     See the \"OUTPUT TEMPLATE\" for a description\n                                     of available keys.\n    -J, --dump-single-json           Simulate, quiet but print JSON information\n                                     for each command-line argument. If the URL\n                                     refers to a playlist, dump the whole\n                                     playlist information in a single line.\n    --print-json                     Be quiet and print the video information as\n                                     JSON (video is still being downloaded).\n    --newline                        Output progress bar as new lines\n    --no-progress                    Do not print progress bar\n    --console-title                  Display progress in console titlebar\n    -v, --verbose                    Print various debugging information\n    --dump-pages                     Print downloaded pages encoded using base64\n                                     to debug problems (very verbose)\n    --write-pages                    Write downloaded intermediary pages to\n                                     files in the current directory to debug\n                                     problems\n    --print-traffic                  Display sent and read HTTP traffic\n    -C, --call-home                  Contact the youtube-dl server for debugging\n    --no-call-home                   Do NOT contact the youtube-dl server for\n                                     debugging\n\n## Workarounds:\n    --encoding ENCODING              Force the specified encoding (experimental)\n    --no-check-certificate           Suppress HTTPS certificate validation\n    --prefer-insecure                Use an unencrypted connection to retrieve\n                                     information about the video. (Currently\n                                     supported only for YouTube)\n    --user-agent UA                  Specify a custom user agent\n    --referer URL                    Specify a custom referer, use if the video\n                                     access is restricted to one domain\n    --add-header FIELD:VALUE         Specify a custom HTTP header and its value,\n                                     separated by a colon ':'. You can use this\n                                     option multiple times\n    --bidi-workaround                Work around terminals that lack\n                                     bidirectional text support. Requires bidiv\n                                     or fribidi executable in PATH\n    --sleep-interval SECONDS         Number of seconds to sleep before each\n                                     download when used alone or a lower bound\n                                     of a range for randomized sleep before each\n                                     download (minimum possible number of\n                                     seconds to sleep) when used along with\n                                     --max-sleep-interval.\n    --max-sleep-interval SECONDS     Upper bound of a range for randomized sleep\n                                     before each download (maximum possible\n                                     number of seconds to sleep). Must only be\n                                     used along with --min-sleep-interval.\n\n## Video Format Options:\n    -f, --format FORMAT              Video format code, see the \"FORMAT\n                                     SELECTION\" for all the info\n    --all-formats                    Download all available video formats\n    --prefer-free-formats            Prefer free video formats unless a specific\n                                     one is requested\n    -F, --list-formats               List all available formats of requested\n                                     videos\n    --youtube-skip-dash-manifest     Do not download the DASH manifests and\n                                     related data on YouTube videos\n    --merge-output-format FORMAT     If a merge is required (e.g.\n                                     bestvideo+bestaudio), output to given\n                                     container format. One of mkv, mp4, ogg,\n                                     webm, flv. Ignored if no merge is required\n\n## Subtitle Options:\n    --write-sub                      Write subtitle file\n    --write-auto-sub                 Write automatically generated subtitle file\n                                     (YouTube only)\n    --all-subs                       Download all the available subtitles of the\n                                     video\n    --list-subs                      List all available subtitles for the video\n    --sub-format FORMAT              Subtitle format, accepts formats\n                                     preference, for example: \"srt\" or\n                                     \"ass/srt/best\"\n    --sub-lang LANGS                 Languages of the subtitles to download\n                                     (optional) separated by commas, use --list-\n                                     subs for available language tags\n\n## Authentication Options:\n    -u, --username USERNAME          Login with this account ID\n    -p, --password PASSWORD          Account password. If this option is left\n                                     out, youtube-dl will ask interactively.\n    -2, --twofactor TWOFACTOR        Two-factor authentication code\n    -n, --netrc                      Use .netrc authentication data\n    --video-password PASSWORD        Video password (vimeo, smotri, youku)\n\n## Adobe Pass Options:\n    --ap-mso MSO                     Adobe Pass multiple-system operator (TV\n                                     provider) identifier, use --ap-list-mso for\n                                     a list of available MSOs\n    --ap-username USERNAME           Multiple-system operator account login\n    --ap-password PASSWORD           Multiple-system operator account password.\n                                     If this option is left out, youtube-dl will\n                                     ask interactively.\n    --ap-list-mso                    List all supported multiple-system\n                                     operators\n\n## Post-processing Options:\n    -x, --extract-audio              Convert video files to audio-only files\n                                     (requires ffmpeg or avconv and ffprobe or\n                                     avprobe)\n    --audio-format FORMAT            Specify audio format: \"best\", \"aac\",\n                                     \"flac\", \"mp3\", \"m4a\", \"opus\", \"vorbis\", or\n                                     \"wav\"; \"best\" by default; No effect without\n                                     -x\n    --audio-quality QUALITY          Specify ffmpeg/avconv audio quality, insert\n                                     a value between 0 (better) and 9 (worse)\n                                     for VBR or a specific bitrate like 128K\n                                     (default 5)\n    --recode-video FORMAT            Encode the video to another format if\n                                     necessary (currently supported:\n                                     mp4|flv|ogg|webm|mkv|avi)\n    --postprocessor-args ARGS        Give these arguments to the postprocessor\n    -k, --keep-video                 Keep the video file on disk after the post-\n                                     processing; the video is erased by default\n    --no-post-overwrites             Do not overwrite post-processed files; the\n                                     post-processed files are overwritten by\n                                     default\n    --embed-subs                     Embed subtitles in the video (only for mp4,\n                                     webm and mkv videos)\n    --embed-thumbnail                Embed thumbnail in the audio as cover art\n    --add-metadata                   Write metadata to the video file\n    --metadata-from-title FORMAT     Parse additional metadata like song title /\n                                     artist from the video title. The format\n                                     syntax is the same as --output. Regular\n                                     expression with named capture groups may\n                                     also be used. The parsed parameters replace\n                                     existing values. Example: --metadata-from-\n                                     title \"%(artist)s - %(title)s\" matches a\n                                     title like \"Coldplay - Paradise\". Example\n                                     (regex): --metadata-from-title\n                                     \"(?P<artist>.+?) - (?P<title>.+)\"\n    --xattrs                         Write metadata to the video file's xattrs\n                                     (using dublin core and xdg standards)\n    --fixup POLICY                   Automatically correct known faults of the\n                                     file. One of never (do nothing), warn (only\n                                     emit a warning), detect_or_warn (the\n                                     default; fix file if we can, warn\n                                     otherwise)\n    --prefer-avconv                  Prefer avconv over ffmpeg for running the\n                                     postprocessors\n    --prefer-ffmpeg                  Prefer ffmpeg over avconv for running the\n                                     postprocessors (default)\n    --ffmpeg-location PATH           Location of the ffmpeg/avconv binary;\n                                     either the path to the binary or its\n                                     containing directory.\n    --exec CMD                       Execute a command on the file after\n                                     downloading, similar to find's -exec\n                                     syntax. Example: --exec 'adb push {}\n                                     /sdcard/Music/ && rm {}'\n    --convert-subs FORMAT            Convert the subtitles to other format\n                                     (currently supported: srt|ass|vtt|lrc)\n\n# CONFIGURATION\n\nYou can configure youtube-dl by placing any supported command line option to a configuration file. On Linux and macOS, the system wide configuration file is located at `/etc/youtube-dl.conf` and the user wide configuration file at `~/.config/youtube-dl/config`. On Windows, the user wide configuration file locations are `%APPDATA%\\youtube-dl\\config.txt` or `C:\\Users\\<user name>\\youtube-dl.conf`. Note that by default configuration file may not exist so you may need to create it yourself.\n\nFor example, with the following configuration file youtube-dl will always extract the audio, not copy the mtime, use a proxy and save all videos under `Movies` directory in your home directory:\n```\n# Lines starting with # are comments\n\n# Always extract audio\n-x\n\n# Do not copy the mtime\n--no-mtime\n\n# Use this proxy\n--proxy 127.0.0.1:3128\n\n# Save all videos under Movies directory in your home directory\n-o ~/Movies/%(title)s.%(ext)s\n```\n\nNote that options in configuration file are just the same options aka switches used in regular command line calls thus there **must be no whitespace** after `-` or `--`, e.g. `-o` or `--proxy` but not `- o` or `-- proxy`.\n\nYou can use `--ignore-config` if you want to disable the configuration file for a particular youtube-dl run.\n\nYou can also use `--config-location` if you want to use custom configuration file for a particular youtube-dl run.\n\n### Authentication with `.netrc` file\n\nYou may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with `--username` and `--password`) in order not to pass credentials as command line arguments on every youtube-dl execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a [`.netrc` file](https://stackoverflow.com/tags/.netrc/info) on a per extractor basis. For that you will need to create a `.netrc` file in your `$HOME` and restrict permissions to read/write by only you:\n```\ntouch $HOME/.netrc\nchmod a-rwx,u+rw $HOME/.netrc\n```\nAfter that you can add credentials for an extractor in the following format, where *extractor* is the name of the extractor in lowercase:\n```\nmachine <extractor> login <login> password <password>\n```\nFor example:\n```\nmachine youtube login myaccount@gmail.com password my_youtube_password\nmachine twitch login my_twitch_account_name password my_twitch_password\n```\nTo activate authentication with the `.netrc` file you should pass `--netrc` to youtube-dl or place it in the [configuration file](#configuration).\n\nOn Windows you may also need to setup the `%HOME%` environment variable manually. For example:\n```\nset HOME=%USERPROFILE%\n```\n\n# OUTPUT TEMPLATE\n\nThe `-o` option allows users to indicate a template for the output file names.\n\n**tl;dr:** [navigate me to examples](#output-template-examples).\n\nThe basic usage is not to set any template arguments when downloading a single file, like in `youtube-dl -o funny_video.flv \"https://some/video\"`. However, it may contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to [python string formatting operations](https://docs.python.org/2/library/stdtypes.html#string-formatting). For example, `%(NAME)s` or `%(NAME)05d`. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations. Allowed names along with sequence type are:\n\n - `id` (string): Video identifier\n - `title` (string): Video title\n - `url` (string): Video URL\n - `ext` (string): Video filename extension\n - `alt_title` (string): A secondary title of the video\n - `display_id` (string): An alternative identifier for the video\n - `uploader` (string): Full name of the video uploader\n - `license` (string): License name the video is licensed under\n - `creator` (string): The creator of the video\n - `release_date` (string): The date (YYYYMMDD) when the video was released\n - `timestamp` (numeric): UNIX timestamp of the moment the video became available\n - `upload_date` (string): Video upload date (YYYYMMDD)\n - `uploader_id` (string): Nickname or id of the video uploader\n - `channel` (string): Full name of the channel the video is uploaded on\n - `channel_id` (string): Id of the channel\n - `location` (string): Physical location where the video was filmed\n - `duration` (numeric): Length of the video in seconds\n - `view_count` (numeric): How many users have watched the video on the platform\n - `like_count` (numeric): Number of positive ratings of the video\n - `dislike_count` (numeric): Number of negative ratings of the video\n - `repost_count` (numeric): Number of reposts of the video\n - `average_rating` (numeric): Average rating give by users, the scale used depends on the webpage\n - `comment_count` (numeric): Number of comments on the video\n - `age_limit` (numeric): Age restriction for the video (years)\n - `is_live` (boolean): Whether this video is a live stream or a fixed-length video\n - `start_time` (numeric): Time in seconds where the reproduction should start, as specified in the URL\n - `end_time` (numeric): Time in seconds where the reproduction should end, as specified in the URL\n - `format` (string): A human-readable description of the format \n - `format_id` (string): Format code specified by `--format`\n - `format_note` (string): Additional info about the format\n - `width` (numeric): Width of the video\n - `height` (numeric): Height of the video\n - `resolution` (string): Textual description of width and height\n - `tbr` (numeric): Average bitrate of audio and video in KBit/s\n - `abr` (numeric): Average audio bitrate in KBit/s\n - `acodec` (string): Name of the audio codec in use\n - `asr` (numeric): Audio sampling rate in Hertz\n - `vbr` (numeric): Average video bitrate in KBit/s\n - `fps` (numeric): Frame rate\n - `vcodec` (string): Name of the video codec in use\n - `container` (string): Name of the container format\n - `filesize` (numeric): The number of bytes, if known in advance\n - `filesize_approx` (numeric): An estimate for the number of bytes\n - `protocol` (string): The protocol that will be used for the actual download\n - `extractor` (string): Name of the extractor\n - `extractor_key` (string): Key name of the extractor\n - `epoch` (numeric): Unix epoch when creating the file\n - `autonumber` (numeric): Five-digit number that will be increased with each download, starting at zero\n - `playlist` (string): Name or id of the playlist that contains the video\n - `playlist_index` (numeric): Index of the video in the playlist padded with leading zeros according to the total length of the playlist\n - `playlist_id` (string): Playlist identifier\n - `playlist_title` (string): Playlist title\n - `playlist_uploader` (string): Full name of the playlist uploader\n - `playlist_uploader_id` (string): Nickname or id of the playlist uploader\n\nAvailable for the video that belongs to some logical chapter or section:\n\n - `chapter` (string): Name or title of the chapter the video belongs to\n - `chapter_number` (numeric): Number of the chapter the video belongs to\n - `chapter_id` (string): Id of the chapter the video belongs to\n\nAvailable for the video that is an episode of some series or programme:\n\n - `series` (string): Title of the series or programme the video episode belongs to\n - `season` (string): Title of the season the video episode belongs to\n - `season_number` (numeric): Number of the season the video episode belongs to\n - `season_id` (string): Id of the season the video episode belongs to\n - `episode` (string): Title of the video episode\n - `episode_number` (numeric): Number of the video episode within a season\n - `episode_id` (string): Id of the video episode\n\nAvailable for the media that is a track or a part of a music album:\n\n - `track` (string): Title of the track\n - `track_number` (numeric): Number of the track within an album or a disc\n - `track_id` (string): Id of the track\n - `artist` (string): Artist(s) of the track\n - `genre` (string): Genre(s) of the track\n - `album` (string): Title of the album the track belongs to\n - `album_type` (string): Type of the album\n - `album_artist` (string): List of all artists appeared on the album\n - `disc_number` (numeric): Number of the disc or other physical medium the track belongs to\n - `release_year` (numeric): Year (YYYY) when the album was released\n\nEach aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. Note that some of the sequences are not guaranteed to be present since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with `NA`.\n\nFor example for `-o %(title)s-%(id)s.%(ext)s` and an mp4 video with title `youtube-dl test video` and id `BaW_jenozKcj`, this will result in a `youtube-dl test video-BaW_jenozKcj.mp4` file created in the current directory.\n\nFor numeric sequences you can use numeric related formatting, for example, `%(view_count)05d` will result in a string with view count padded with zeros up to 5 characters, like in `00042`.\n\nOutput templates can also contain arbitrary hierarchical path, e.g. `-o '%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s'` which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.\n\nTo use percent literals in an output template use `%%`. To output to stdout use `-o -`.\n\nThe current default template is `%(title)s-%(id)s.%(ext)s`.\n\nIn some cases, you don't want special characters such as \u4e2d, spaces, or &, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the `--restrict-filenames` flag to get a shorter title:\n\n#### Output template and Windows batch files\n\nIf you are using an output template inside a Windows batch file then you must escape plain percent characters (`%`) by doubling, so that `-o \"%(title)s-%(id)s.%(ext)s\"` should become `-o \"%%(title)s-%%(id)s.%%(ext)s\"`. However you should not touch `%`'s that are not plain characters, e.g. environment variables for expansion should stay intact: `-o \"C:\\%HOMEPATH%\\Desktop\\%%(title)s.%%(ext)s\"`.\n\n#### Output template examples\n\nNote that on Windows you may need to use double quotes instead of single.\n\n```bash\n$ youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc\nyoutube-dl test video ''_\u00e4\u21ad\ud835\udd50.mp4    # All kinds of weird characters\n\n$ youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc --restrict-filenames\nyoutube-dl_test_video_.mp4          # A simple file name\n\n# Download YouTube playlist videos in separate directory indexed by video order in a playlist\n$ youtube-dl -o '%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\n\n# Download all playlists of YouTube channel/user keeping each playlist in separate directory:\n$ youtube-dl -o '%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' https://www.youtube.com/user/TheLinuxFoundation/playlists\n\n# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home\n$ youtube-dl -u user -p password -o '~/MyVideos/%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s' https://www.udemy.com/java-tutorial/\n\n# Download entire series season keeping each series and each season in separate directory under C:/MyVideos\n$ youtube-dl -o \"C:/MyVideos/%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s\" https://videomore.ru/kino_v_detalayah/5_sezon/367617\n\n# Stream the video being downloaded to stdout\n$ youtube-dl -o - BaW_jenozKc\n```\n\n# FORMAT SELECTION\n\nBy default youtube-dl tries to download the best available quality, i.e. if you want the best quality you **don't need** to pass any special options, youtube-dl will guess it for you by **default**.\n\nBut sometimes you may want to download in a different format, for example when you are on a slow or intermittent connection. The key mechanism for achieving this is so-called *format selection* based on which you can explicitly specify desired format, select formats based on some criterion or criteria, setup precedence and much more.\n\nThe general syntax for format selection is `--format FORMAT` or shorter `-f FORMAT` where `FORMAT` is a *selector expression*, i.e. an expression that describes format or formats you would like to download.\n\n**tl;dr:** [navigate me to examples](#format-selection-examples).\n\nThe simplest case is requesting a specific format, for example with `-f 22` you can download the format with format code equal to 22. You can get the list of available format codes for particular video using `--list-formats` or `-F`. Note that these format codes are extractor specific. \n\nYou can also use a file extension (currently `3gp`, `aac`, `flv`, `m4a`, `mp3`, `mp4`, `ogg`, `wav`, `webm` are supported) to download the best quality format of a particular file extension served as a single file, e.g. `-f webm` will download the best quality format with the `webm` extension served as a single file.\n\nYou can also use special names to select particular edge case formats:\n\n - `best`: Select the best quality format represented by a single file with video and audio.\n - `worst`: Select the worst quality format represented by a single file with video and audio.\n - `bestvideo`: Select the best quality video-only format (e.g. DASH video). May not be available.\n - `worstvideo`: Select the worst quality video-only format. May not be available.\n - `bestaudio`: Select the best quality audio only-format. May not be available.\n - `worstaudio`: Select the worst quality audio only-format. May not be available.\n\nFor example, to download the worst quality video-only format you can use `-f worstvideo`.\n\nIf you want to download multiple videos and they don't have the same formats available, you can specify the order of preference using slashes. Note that slash is left-associative, i.e. formats on the left hand side are preferred, for example `-f 22/17/18` will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.\n\nIf you want to download several formats of the same video use a comma as a separator, e.g. `-f 22,17,18` will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: `-f 136/137/mp4/bestvideo,140/m4a/bestaudio`.\n\nYou can also filter the video formats by putting a condition in brackets, as in `-f \"best[height=720]\"` (or `-f \"[filesize>10M]\"`).\n\nThe following numeric meta fields can be used with comparisons `<`, `<=`, `>`, `>=`, `=` (equals), `!=` (not equals):\n\n - `filesize`: The number of bytes, if known in advance\n - `width`: Width of the video, if known\n - `height`: Height of the video, if known\n - `tbr`: Average bitrate of audio and video in KBit/s\n - `abr`: Average audio bitrate in KBit/s\n - `vbr`: Average video bitrate in KBit/s\n - `asr`: Audio sampling rate in Hertz\n - `fps`: Frame rate\n\nAlso filtering work for comparisons `=` (equals), `^=` (starts with), `$=` (ends with), `*=` (contains) and following string meta fields:\n\n - `ext`: File extension\n - `acodec`: Name of the audio codec in use\n - `vcodec`: Name of the video codec in use\n - `container`: Name of the container format\n - `protocol`: The protocol that will be used for the actual download, lower-case (`http`, `https`, `rtsp`, `rtmp`, `rtmpe`, `mms`, `f4m`, `ism`, `http_dash_segments`, `m3u8`, or `m3u8_native`)\n - `format_id`: A short description of the format\n\nAny string comparison may be prefixed with negation `!` in order to produce an opposite comparison, e.g. `!*=` (does not contain).\n\nNote that none of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by particular extractor, i.e. the metadata offered by the video hoster.\n\nFormats for which the value is not known are excluded unless you put a question mark (`?`) after the operator. You can combine format filters, so `-f \"[height <=? 720][tbr>500]\"` selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 KBit/s.\n\nYou can merge the video and audio of two formats into a single file using `-f <video-format>+<audio-format>` (requires ffmpeg or avconv installed), for example `-f bestvideo+bestaudio` will download the best video-only format, the best audio-only format and mux them together with ffmpeg/avconv.\n\nFormat selectors can also be grouped using parentheses, for example if you want to download the best mp4 and webm formats with a height lower than 480 you can use `-f '(mp4,webm)[height<480]'`.\n\nSince the end of April 2015 and version 2015.04.26, youtube-dl uses `-f bestvideo+bestaudio/best` as the default format selection (see [#5447](https://github.com/ytdl-org/youtube-dl/issues/5447), [#5456](https://github.com/ytdl-org/youtube-dl/issues/5456)). If ffmpeg or avconv are installed this results in downloading `bestvideo` and `bestaudio` separately and muxing them together into a single file giving the best overall quality available. Otherwise it falls back to `best` and results in downloading the best available quality served as a single file. `best` is also needed for videos that don't come from YouTube because they don't provide the audio and video in two different files. If you want to only download some DASH formats (for example if you are not interested in getting videos with a resolution higher than 1080p), you can add `-f bestvideo[height<=?1080]+bestaudio/best` to your configuration file. Note that if you use youtube-dl to stream to `stdout` (and most likely to pipe it to your media player then), i.e. you explicitly specify output template as `-o -`, youtube-dl still uses `-f best` format selection in order to start content delivery immediately to your player and not to wait until `bestvideo` and `bestaudio` are downloaded and muxed.\n\nIf you want to preserve the old format selection behavior (prior to youtube-dl 2015.04.26), i.e. you want to download the best available quality media served as a single file, you should explicitly specify your choice with `-f best`. You may want to add it to the [configuration file](#configuration) in order not to type it every time you run youtube-dl.\n\n#### Format selection examples\n\nNote that on Windows you may need to use double quotes instead of single.\n\n```bash\n# Download best mp4 format available or any other best if no mp4 available\n$ youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best'\n\n# Download best format available but no better than 480p\n$ youtube-dl -f 'bestvideo[height<=480]+bestaudio/best[height<=480]'\n\n# Download best video only format but no bigger than 50 MB\n$ youtube-dl -f 'best[filesize<50M]'\n\n# Download best format available via direct link over HTTP/HTTPS protocol\n$ youtube-dl -f '(bestvideo+bestaudio/best)[protocol^=http]'\n\n# Download the best video format and the best audio format without merging them\n$ youtube-dl -f 'bestvideo,bestaudio' -o '%(title)s.f%(format_id)s.%(ext)s'\n```\nNote that in the last example, an output template is recommended as bestvideo and bestaudio may have the same file name.\n\n\n# VIDEO SELECTION\n\nVideos can be filtered by their upload date using the options `--date`, `--datebefore` or `--dateafter`. They accept dates in two formats:\n\n - Absolute dates: Dates in the format `YYYYMMDD`.\n - Relative dates: Dates in the format `(now|today)[+-][0-9](day|week|month|year)(s)?`\n \nExamples:\n\n```bash\n# Download only the videos uploaded in the last 6 months\n$ youtube-dl --dateafter now-6months\n\n# Download only the videos uploaded on January 1, 1970\n$ youtube-dl --date 19700101\n\n$ # Download only the videos uploaded in the 200x decade\n$ youtube-dl --dateafter 20000101 --datebefore 20091231\n```\n\n# FAQ\n\n### How do I update youtube-dl?\n\nIf you've followed [our manual installation instructions](https://ytdl-org.github.io/youtube-dl/download.html), you can simply run `youtube-dl -U` (or, on Linux, `sudo youtube-dl -U`).\n\nIf you have used pip, a simple `sudo pip install -U youtube-dl` is sufficient to update.\n\nIf you have installed youtube-dl using a package manager like *apt-get* or *yum*, use the standard system update mechanism to update. Note that distribution packages are often outdated. As a rule of thumb, youtube-dl releases at least once a month, and often weekly or even daily. Simply go to https://yt-dl.org to find out the current version. Unfortunately, there is nothing we youtube-dl developers can do if your distribution serves a really outdated version. You can (and should) complain to your distribution in their bugtracker or support forum.\n\nAs a last resort, you can also uninstall the version installed by your package manager and follow our manual installation instructions. For that, remove the distribution's package, with a line like\n\n    sudo apt-get remove -y youtube-dl\n\nAfterwards, simply follow [our manual installation instructions](https://ytdl-org.github.io/youtube-dl/download.html):\n\n```\nsudo wget https://yt-dl.org/downloads/latest/youtube-dl -O /usr/local/bin/youtube-dl\nsudo chmod a+rx /usr/local/bin/youtube-dl\nhash -r\n```\n\nAgain, from then on you'll be able to update with `sudo youtube-dl -U`.\n\n### youtube-dl is extremely slow to start on Windows\n\nAdd a file exclusion for `youtube-dl.exe` in Windows Defender settings.\n\n### I'm getting an error `Unable to extract OpenGraph title` on YouTube playlists\n\nYouTube changed their playlist format in March 2014 and later on, so you'll need at least youtube-dl 2014.07.25 to download all YouTube videos.\n\nIf you have installed youtube-dl with a package manager, pip, setup.py or a tarball, please use that to update. Note that Ubuntu packages do not seem to get updated anymore. Since we are not affiliated with Ubuntu, there is little we can do. Feel free to [report bugs](https://bugs.launchpad.net/ubuntu/+source/youtube-dl/+filebug) to the [Ubuntu packaging people](mailto:ubuntu-motu@lists.ubuntu.com?subject=outdated%20version%20of%20youtube-dl) - all they have to do is update the package to a somewhat recent version. See above for a way to update.\n\n### I'm getting an error when trying to use output template: `error: using output template conflicts with using title, video ID or auto number`\n\nMake sure you are not using `-o` with any of these options `-t`, `--title`, `--id`, `-A` or `--auto-number` set in command line or in a configuration file. Remove the latter if any.\n\n### Do I always have to pass `-citw`?\n\nBy default, youtube-dl intends to have the best options (incidentally, if you have a convincing case that these should be different, [please file an issue where you explain that](https://yt-dl.org/bug)). Therefore, it is unnecessary and sometimes harmful to copy long option strings from webpages. In particular, the only option out of `-citw` that is regularly useful is `-i`.\n\n### Can you please put the `-b` option back?\n\nMost people asking this question are not aware that youtube-dl now defaults to downloading the highest available quality as reported by YouTube, which will be 1080p or 720p in some cases, so you no longer need the `-b` option. For some specific videos, maybe YouTube does not report them to be available in a specific high quality format you're interested in. In that case, simply request it with the `-f` option and youtube-dl will try to download it.\n\n### I get HTTP error 402 when trying to download a video. What's this?\n\nApparently YouTube requires you to pass a CAPTCHA test if you download too much. We're [considering to provide a way to let you solve the CAPTCHA](https://github.com/ytdl-org/youtube-dl/issues/154), but at the moment, your best course of action is pointing a web browser to the youtube URL, solving the CAPTCHA, and restart youtube-dl.\n\n### Do I need any other programs?\n\nyoutube-dl works fine on its own on most sites. However, if you want to convert video/audio, you'll need [avconv](https://libav.org/) or [ffmpeg](https://www.ffmpeg.org/). On some sites - most notably YouTube - videos can be retrieved in a higher quality format without sound. youtube-dl will detect whether avconv/ffmpeg is present and automatically pick the best option.\n\nVideos or video formats streamed via RTMP protocol can only be downloaded when [rtmpdump](https://rtmpdump.mplayerhq.hu/) is installed. Downloading MMS and RTSP videos requires either [mplayer](https://mplayerhq.hu/) or [mpv](https://mpv.io/) to be installed.\n\n### I have downloaded a video but how can I play it?\n\nOnce the video is fully downloaded, use any video player, such as [mpv](https://mpv.io/), [vlc](https://www.videolan.org/) or [mplayer](https://www.mplayerhq.hu/).\n\n### I extracted a video URL with `-g`, but it does not play on another machine / in my web browser.\n\nIt depends a lot on the service. In many cases, requests for the video (to download/play it) must come from the same IP address and with the same cookies and/or HTTP headers. Use the `--cookies` option to write the required cookies into a file, and advise your downloader to read cookies from that file. Some sites also require a common user agent to be used, use `--dump-user-agent` to see the one in use by youtube-dl. You can also get necessary cookies and HTTP headers from JSON output obtained with `--dump-json`.\n\nIt may be beneficial to use IPv6; in some cases, the restrictions are only applied to IPv4. Some services (sometimes only for a subset of videos) do not restrict the video URL by IP address, cookie, or user-agent, but these are the exception rather than the rule.\n\nPlease bear in mind that some URL protocols are **not** supported by browsers out of the box, including RTMP. If you are using `-g`, your own downloader must support these as well.\n\nIf you want to play the video on a machine that is not running youtube-dl, you can relay the video content from the machine that runs youtube-dl. You can use `-o -` to let youtube-dl stream a video to stdout, or simply allow the player to download the files written by youtube-dl in turn.\n\n### ERROR: no fmt_url_map or conn information found in video info\n\nYouTube has switched to a new video info format in July 2011 which is not supported by old versions of youtube-dl. See [above](#how-do-i-update-youtube-dl) for how to update youtube-dl.\n\n### ERROR: unable to download video\n\nYouTube requires an additional signature since September 2012 which is not supported by old versions of youtube-dl. See [above](#how-do-i-update-youtube-dl) for how to update youtube-dl.\n\n### Video URL contains an ampersand and I'm getting some strange output `[1] 2839` or `'v' is not recognized as an internal or external command`\n\nThat's actually the output from your shell. Since ampersand is one of the special shell characters it's interpreted by the shell preventing you from passing the whole URL to youtube-dl. To disable your shell from interpreting the ampersands (or any other special characters) you have to either put the whole URL in quotes or escape them with a backslash (which approach will work depends on your shell).\n\nFor example if your URL is https://www.youtube.com/watch?t=4&v=BaW_jenozKc you should end up with following command:\n\n```youtube-dl 'https://www.youtube.com/watch?t=4&v=BaW_jenozKc'```\n\nor\n\n```youtube-dl https://www.youtube.com/watch?t=4\\&v=BaW_jenozKc```\n\nFor Windows you have to use the double quotes:\n\n```youtube-dl \"https://www.youtube.com/watch?t=4&v=BaW_jenozKc\"```\n\n### ExtractorError: Could not find JS function u'OF'\n\nIn February 2015, the new YouTube player contained a character sequence in a string that was misinterpreted by old versions of youtube-dl. See [above](#how-do-i-update-youtube-dl) for how to update youtube-dl.\n\n### HTTP Error 429: Too Many Requests or 402: Payment Required\n\nThese two error codes indicate that the service is blocking your IP address because of overuse. Contact the service and ask them to unblock your IP address, or - if you have acquired a whitelisted IP address already - use the [`--proxy` or `--source-address` options](#network-options) to select another IP address.\n\n### SyntaxError: Non-ASCII character\n\nThe error\n\n    File \"youtube-dl\", line 2\n    SyntaxError: Non-ASCII character '\\x93' ...\n\nmeans you're using an outdated version of Python. Please update to Python 2.6 or 2.7.\n\n### What is this binary file? Where has the code gone?\n\nSince June 2012 ([#342](https://github.com/ytdl-org/youtube-dl/issues/342)) youtube-dl is packed as an executable zipfile, simply unzip it (might need renaming to `youtube-dl.zip` first on some systems) or clone the git repository, as laid out above. If you modify the code, you can run it by executing the `__main__.py` file. To recompile the executable, run `make youtube-dl`.\n\n### The exe throws an error due to missing `MSVCR100.dll`\n\nTo run the exe you need to install first the [Microsoft Visual C++ 2010 Redistributable Package (x86)](https://www.microsoft.com/en-US/download/details.aspx?id=5555).\n\n### On Windows, how should I set up ffmpeg and youtube-dl? Where should I put the exe files?\n\nIf you put youtube-dl and ffmpeg in the same directory that you're running the command from, it will work, but that's rather cumbersome.\n\nTo make a different directory work - either for ffmpeg, or for youtube-dl, or for both - simply create the directory (say, `C:\\bin`, or `C:\\Users\\<User name>\\bin`), put all the executables directly in there, and then [set your PATH environment variable](https://www.java.com/en/download/help/path.xml) to include that directory.\n\nFrom then on, after restarting your shell, you will be able to access both youtube-dl and ffmpeg (and youtube-dl will be able to find ffmpeg) by simply typing `youtube-dl` or `ffmpeg`, no matter what directory you're in.\n\n### How do I put downloads into a specific folder?\n\nUse the `-o` to specify an [output template](#output-template), for example `-o \"/home/user/videos/%(title)s-%(id)s.%(ext)s\"`. If you want this for all of your downloads, put the option into your [configuration file](#configuration).\n\n### How do I download a video starting with a `-`?\n\nEither prepend `https://www.youtube.com/watch?v=` or separate the ID from the options with `--`:\n\n    youtube-dl -- -wNyEUrxzFU\n    youtube-dl \"https://www.youtube.com/watch?v=-wNyEUrxzFU\"\n\n### How do I pass cookies to youtube-dl?\n\nUse the `--cookies` option, for example `--cookies /path/to/cookies/file.txt`.\n\nIn order to extract cookies from browser use any conforming browser extension for exporting cookies. For example, [cookies.txt](https://chrome.google.com/webstore/detail/cookiestxt/njabckikapfpffapmjgojcnbfjonfjfg) (for Chrome) or [cookies.txt](https://addons.mozilla.org/en-US/firefox/addon/cookies-txt/) (for Firefox).\n\nNote that the cookies file must be in Mozilla/Netscape format and the first line of the cookies file must be either `# HTTP Cookie File` or `# Netscape HTTP Cookie File`. Make sure you have correct [newline format](https://en.wikipedia.org/wiki/Newline) in the cookies file and convert newlines if necessary to correspond with your OS, namely `CRLF` (`\\r\\n`) for Windows and `LF` (`\\n`) for Unix and Unix-like systems (Linux, macOS, etc.). `HTTP Error 400: Bad Request` when using `--cookies` is a good sign of invalid newline format.\n\nPassing cookies to youtube-dl is a good way to workaround login when a particular extractor does not implement it explicitly. Another use case is working around [CAPTCHA](https://en.wikipedia.org/wiki/CAPTCHA) some websites require you to solve in particular cases in order to get access (e.g. YouTube, CloudFlare).\n\n### How do I stream directly to media player?\n\nYou will first need to tell youtube-dl to stream media to stdout with `-o -`, and also tell your media player to read from stdin (it must be capable of this for streaming) and then pipe former to latter. For example, streaming to [vlc](https://www.videolan.org/) can be achieved with:\n\n    youtube-dl -o - \"https://www.youtube.com/watch?v=BaW_jenozKcj\" | vlc -\n\n### How do I download only new videos from a playlist?\n\nUse download-archive feature. With this feature you should initially download the complete playlist with `--download-archive /path/to/download/archive/file.txt` that will record identifiers of all the videos in a special file. Each subsequent run with the same `--download-archive` will download only new videos and skip all videos that have been downloaded before. Note that only successful downloads are recorded in the file.\n\nFor example, at first,\n\n    youtube-dl --download-archive archive.txt \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\"\n\nwill download the complete `PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re` playlist and create a file `archive.txt`. Each subsequent run will only download new videos if any:\n\n    youtube-dl --download-archive archive.txt \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\"\n\n### Should I add `--hls-prefer-native` into my config?\n\nWhen youtube-dl detects an HLS video, it can download it either with the built-in downloader or ffmpeg. Since many HLS streams are slightly invalid and ffmpeg/youtube-dl each handle some invalid cases better than the other, there is an option to switch the downloader if needed.\n\nWhen youtube-dl knows that one particular downloader works better for a given website, that downloader will be picked. Otherwise, youtube-dl will pick the best downloader for general compatibility, which at the moment happens to be ffmpeg. This choice may change in future versions of youtube-dl, with improvements of the built-in downloader and/or ffmpeg.\n\nIn particular, the generic extractor (used when your website is not in the [list of supported sites by youtube-dl](https://ytdl-org.github.io/youtube-dl/supportedsites.html) cannot mandate one specific downloader.\n\nIf you put either `--hls-prefer-native` or `--hls-prefer-ffmpeg` into your configuration, a different subset of videos will fail to download correctly. Instead, it is much better to [file an issue](https://yt-dl.org/bug) or a pull request which details why the native or the ffmpeg HLS downloader is a better choice for your use case.\n\n### Can you add support for this anime video site, or site which shows current movies for free?\n\nAs a matter of policy (as well as legality), youtube-dl does not include support for services that specialize in infringing copyright. As a rule of thumb, if you cannot easily find a video that the service is quite obviously allowed to distribute (i.e. that has been uploaded by the creator, the creator's distributor, or is published under a free license), the service is probably unfit for inclusion to youtube-dl.\n\nA note on the service that they don't host the infringing content, but just link to those who do, is evidence that the service should **not** be included into youtube-dl. The same goes for any DMCA note when the whole front page of the service is filled with videos they are not allowed to distribute. A \"fair use\" note is equally unconvincing if the service shows copyright-protected videos in full without authorization.\n\nSupport requests for services that **do** purchase the rights to distribute their content are perfectly fine though. If in doubt, you can simply include a source that mentions the legitimate purchase of content.\n\n### How can I speed up work on my issue?\n\n(Also known as: Help, my important issue not being solved!) The youtube-dl core developer team is quite small. While we do our best to solve as many issues as possible, sometimes that can take quite a while. To speed up your issue, here's what you can do:\n\nFirst of all, please do report the issue [at our issue tracker](https://yt-dl.org/bugs). That allows us to coordinate all efforts by users and developers, and serves as a unified point. Unfortunately, the youtube-dl project has grown too large to use personal email as an effective communication channel.\n\nPlease read the [bug reporting instructions](#bugs) below. A lot of bugs lack all the necessary information. If you can, offer proxy, VPN, or shell access to the youtube-dl developers. If you are able to, test the issue from multiple computers in multiple countries to exclude local censorship or misconfiguration issues.\n\nIf nobody is interested in solving your issue, you are welcome to take matters into your own hands and submit a pull request (or coerce/pay somebody else to do so).\n\nFeel free to bump the issue from time to time by writing a small comment (\"Issue is still present in youtube-dl version ...from France, but fixed from Belgium\"), but please not more than once a month. Please do not declare your issue as `important` or `urgent`.\n\n### How can I detect whether a given URL is supported by youtube-dl?\n\nFor one, have a look at the [list of supported sites](docs/supportedsites.md). Note that it can sometimes happen that the site changes its URL scheme (say, from https://example.com/video/1234567 to https://example.com/v/1234567 ) and youtube-dl reports an URL of a service in that list as unsupported. In that case, simply report a bug.\n\nIt is *not* possible to detect whether a URL is supported or not. That's because youtube-dl contains a generic extractor which matches **all** URLs. You may be tempted to disable, exclude, or remove the generic extractor, but the generic extractor not only allows users to extract videos from lots of websites that embed a video from another service, but may also be used to extract video from a service that it's hosting itself. Therefore, we neither recommend nor support disabling, excluding, or removing the generic extractor.\n\nIf you want to find out whether a given URL is supported, simply call youtube-dl with it. If you get no videos back, chances are the URL is either not referring to a video or unsupported. You can find out which by examining the output (if you run youtube-dl on the console) or catching an `UnsupportedError` exception if you run it from a Python program.\n\n# Why do I need to go through that much red tape when filing bugs?\n\nBefore we had the issue template, despite our extensive [bug reporting instructions](#bugs), about 80% of the issue reports we got were useless, for instance because people used ancient versions hundreds of releases old, because of simple syntactic errors (not in youtube-dl but in general shell usage), because the problem was already reported multiple times before, because people did not actually read an error message, even if it said \"please install ffmpeg\", because people did not mention the URL they were trying to download and many more simple, easy-to-avoid problems, many of whom were totally unrelated to youtube-dl.\n\nyoutube-dl is an open-source project manned by too few volunteers, so we'd rather spend time fixing bugs where we are certain none of those simple problems apply, and where we can be reasonably confident to be able to reproduce the issue without asking the reporter repeatedly. As such, the output of `youtube-dl -v YOUR_URL_HERE` is really all that's required to file an issue. The issue template also guides you through some basic steps you can do, such as checking that your version of youtube-dl is current.\n\n# DEVELOPER INSTRUCTIONS\n\nMost users do not need to build youtube-dl and can [download the builds](https://ytdl-org.github.io/youtube-dl/download.html) or get them from their distribution.\n\nTo run youtube-dl as a developer, you don't need to build anything either. Simply execute\n\n    python -m youtube_dl\n\nTo run the test, simply invoke your favorite test runner, or execute a test file directly; any of the following work:\n\n    python -m unittest discover\n    python test/test_download.py\n    nosetests\n\nSee item 6 of [new extractor tutorial](#adding-support-for-a-new-site) for how to run extractor specific test cases.\n\nIf you want to create a build of youtube-dl yourself, you'll need\n\n* python\n* make (only GNU make is supported)\n* pandoc\n* zip\n* nosetests\n\n### Adding support for a new site\n\nIf you want to add support for a new site, first of all **make sure** this site is **not dedicated to [copyright infringement](README.md#can-you-add-support-for-this-anime-video-site-or-site-which-shows-current-movies-for-free)**. youtube-dl does **not support** such sites thus pull requests adding support for them **will be rejected**.\n\nAfter you have ensured this site is distributing its content legally, you can follow this quick list (assuming your service is called `yourextractor`):\n\n1. [Fork this repository](https://github.com/ytdl-org/youtube-dl/fork)\n2. Check out the source code with:\n\n        git clone git@github.com:YOUR_GITHUB_USERNAME/youtube-dl.git\n\n3. Start a new git branch with\n\n        cd youtube-dl\n        git checkout -b yourextractor\n\n4. Start with this simple template and save it to `youtube_dl/extractor/yourextractor.py`:\n\n    ```python\n    # coding: utf-8\n    from __future__ import unicode_literals\n\n    from .common import InfoExtractor\n\n\n    class YourExtractorIE(InfoExtractor):\n        _VALID_URL = r'https?://(?:www\\.)?yourextractor\\.com/watch/(?P<id>[0-9]+)'\n        _TEST = {\n            'url': 'https://yourextractor.com/watch/42',\n            'md5': 'TODO: md5 sum of the first 10241 bytes of the video file (use --test)',\n            'info_dict': {\n                'id': '42',\n                'ext': 'mp4',\n                'title': 'Video title goes here',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                # TODO more properties, either as:\n                # * A value\n                # * MD5 checksum; start the string with md5:\n                # * A regular expression; start the string with re:\n                # * Any Python type (for example int or float)\n            }\n        }\n\n        def _real_extract(self, url):\n            video_id = self._match_id(url)\n            webpage = self._download_webpage(url, video_id)\n\n            # TODO more code goes here, for example ...\n            title = self._html_search_regex(r'<h1>(.+?)</h1>', webpage, 'title')\n\n            return {\n                'id': video_id,\n                'title': title,\n                'description': self._og_search_description(webpage),\n                'uploader': self._search_regex(r'<div[^>]+id=\"uploader\"[^>]*>([^<]+)<', webpage, 'uploader', fatal=False),\n                # TODO more properties (see youtube_dl/extractor/common.py)\n            }\n    ```\n5. Add an import in [`youtube_dl/extractor/extractors.py`](https://github.com/ytdl-org/youtube-dl/blob/master/youtube_dl/extractor/extractors.py).\n6. Run `python test/test_download.py TestDownload.test_YourExtractor`. This *should fail* at first, but you can continually re-run it until you're done. If you decide to add more than one test, then rename ``_TEST`` to ``_TESTS`` and make it into a list of dictionaries. The tests will then be named `TestDownload.test_YourExtractor`, `TestDownload.test_YourExtractor_1`, `TestDownload.test_YourExtractor_2`, etc. Note that tests with `only_matching` key in test's dict are not counted in.\n7. Have a look at [`youtube_dl/extractor/common.py`](https://github.com/ytdl-org/youtube-dl/blob/master/youtube_dl/extractor/common.py) for possible helper methods and a [detailed description of what your extractor should and may return](https://github.com/ytdl-org/youtube-dl/blob/7f41a598b3fba1bcab2817de64a08941200aa3c8/youtube_dl/extractor/common.py#L94-L303). Add tests and code for as many as you want.\n8. Make sure your code follows [youtube-dl coding conventions](#youtube-dl-coding-conventions) and check the code with [flake8](http://flake8.pycqa.org/en/latest/index.html#quickstart):\n\n        $ flake8 youtube_dl/extractor/yourextractor.py\n\n9. Make sure your code works under all [Python](https://www.python.org/) versions claimed supported by youtube-dl, namely 2.6, 2.7, and 3.2+.\n10. When the tests pass, [add](https://git-scm.com/docs/git-add) the new files and [commit](https://git-scm.com/docs/git-commit) them and [push](https://git-scm.com/docs/git-push) the result, like this:\n\n        $ git add youtube_dl/extractor/extractors.py\n        $ git add youtube_dl/extractor/yourextractor.py\n        $ git commit -m '[yourextractor] Add new extractor'\n        $ git push origin yourextractor\n\n11. Finally, [create a pull request](https://help.github.com/articles/creating-a-pull-request). We'll then review and merge it.\n\nIn any case, thank you very much for your contributions!\n\n## youtube-dl coding conventions\n\nThis section introduces a guide lines for writing idiomatic, robust and future-proof extractor code.\n\nExtractors are very fragile by nature since they depend on the layout of the source data provided by 3rd party media hosters out of your control and this layout tends to change. As an extractor implementer your task is not only to write code that will extract media links and metadata correctly but also to minimize dependency on the source's layout and even to make the code foresee potential future changes and be ready for that. This is important because it will allow the extractor not to break on minor layout changes thus keeping old youtube-dl versions working. Even though this breakage issue is easily fixed by emitting a new version of youtube-dl with a fix incorporated, all the previous versions become broken in all repositories and distros' packages that may not be so prompt in fetching the update from us. Needless to say, some non rolling release distros may never receive an update at all.\n\n### Mandatory and optional metafields\n\nFor extraction to work youtube-dl relies on metadata your extractor extracts and provides to youtube-dl expressed by an [information dictionary](https://github.com/ytdl-org/youtube-dl/blob/7f41a598b3fba1bcab2817de64a08941200aa3c8/youtube_dl/extractor/common.py#L94-L303) or simply *info dict*. Only the following meta fields in the *info dict* are considered mandatory for a successful extraction process by youtube-dl:\n\n - `id` (media identifier)\n - `title` (media title)\n - `url` (media download URL) or `formats`\n\nIn fact only the last option is technically mandatory (i.e. if you can't figure out the download location of the media the extraction does not make any sense). But by convention youtube-dl also treats `id` and `title` as mandatory. Thus the aforementioned metafields are the critical data that the extraction does not make any sense without and if any of them fail to be extracted then the extractor is considered completely broken.\n\n[Any field](https://github.com/ytdl-org/youtube-dl/blob/7f41a598b3fba1bcab2817de64a08941200aa3c8/youtube_dl/extractor/common.py#L188-L303) apart from the aforementioned ones are considered **optional**. That means that extraction should be **tolerant** to situations when sources for these fields can potentially be unavailable (even if they are always available at the moment) and **future-proof** in order not to break the extraction of general purpose mandatory fields.\n\n#### Example\n\nSay you have some source dictionary `meta` that you've fetched as JSON with HTTP request and it has a key `summary`:\n\n```python\nmeta = self._download_json(url, video_id)\n```\n    \nAssume at this point `meta`'s layout is:\n\n```python\n{\n    ...\n    \"summary\": \"some fancy summary text\",\n    ...\n}\n```\n\nAssume you want to extract `summary` and put it into the resulting info dict as `description`. Since `description` is an optional meta field you should be ready that this key may be missing from the `meta` dict, so that you should extract it like:\n\n```python\ndescription = meta.get('summary')  # correct\n```\n\nand not like:\n\n```python\ndescription = meta['summary']  # incorrect\n```\n\nThe latter will break extraction process with `KeyError` if `summary` disappears from `meta` at some later time but with the former approach extraction will just go ahead with `description` set to `None` which is perfectly fine (remember `None` is equivalent to the absence of data).\n\nSimilarly, you should pass `fatal=False` when extracting optional data from a webpage with `_search_regex`, `_html_search_regex` or similar methods, for instance:\n\n```python\ndescription = self._search_regex(\n    r'<span[^>]+id=\"title\"[^>]*>([^<]+)<',\n    webpage, 'description', fatal=False)\n```\n\nWith `fatal` set to `False` if `_search_regex` fails to extract `description` it will emit a warning and continue extraction.\n\nYou can also pass `default=<some fallback value>`, for example:\n\n```python\ndescription = self._search_regex(\n    r'<span[^>]+id=\"title\"[^>]*>([^<]+)<',\n    webpage, 'description', default=None)\n```\n\nOn failure this code will silently continue the extraction with `description` set to `None`. That is useful for metafields that may or may not be present.\n \n### Provide fallbacks\n\nWhen extracting metadata try to do so from multiple sources. For example if `title` is present in several places, try extracting from at least some of them. This makes it more future-proof in case some of the sources become unavailable.\n\n#### Example\n\nSay `meta` from the previous example has a `title` and you are about to extract it. Since `title` is a mandatory meta field you should end up with something like:\n\n```python\ntitle = meta['title']\n```\n\nIf `title` disappears from `meta` in future due to some changes on the hoster's side the extraction would fail since `title` is mandatory. That's expected.\n\nAssume that you have some another source you can extract `title` from, for example `og:title` HTML meta of a `webpage`. In this case you can provide a fallback scenario:\n\n```python\ntitle = meta.get('title') or self._og_search_title(webpage)\n```\n\nThis code will try to extract from `meta` first and if it fails it will try extracting `og:title` from a `webpage`.\n\n### Regular expressions\n\n#### Don't capture groups you don't use\n\nCapturing group must be an indication that it's used somewhere in the code. Any group that is not used must be non capturing.\n\n##### Example\n\nDon't capture id attribute name here since you can't use it for anything anyway.\n\nCorrect:\n\n```python\nr'(?:id|ID)=(?P<id>\\d+)'\n```\n\nIncorrect:\n```python\nr'(id|ID)=(?P<id>\\d+)'\n```\n\n\n#### Make regular expressions relaxed and flexible\n\nWhen using regular expressions try to write them fuzzy, relaxed and flexible, skipping insignificant parts that are more likely to change, allowing both single and double quotes for quoted values and so on.\n \n##### Example\n\nSay you need to extract `title` from the following HTML code:\n\n```html\n<span style=\"position: absolute; left: 910px; width: 90px; float: right; z-index: 9999;\" class=\"title\">some fancy title</span>\n```\n\nThe code for that task should look similar to:\n\n```python\ntitle = self._search_regex(\n    r'<span[^>]+class=\"title\"[^>]*>([^<]+)', webpage, 'title')\n```\n\nOr even better:\n\n```python\ntitle = self._search_regex(\n    r'<span[^>]+class=([\"\\'])title\\1[^>]*>(?P<title>[^<]+)',\n    webpage, 'title', group='title')\n```\n\nNote how you tolerate potential changes in the `style` attribute's value or switch from using double quotes to single for `class` attribute: \n\nThe code definitely should not look like:\n\n```python\ntitle = self._search_regex(\n    r'<span style=\"position: absolute; left: 910px; width: 90px; float: right; z-index: 9999;\" class=\"title\">(.*?)</span>',\n    webpage, 'title', group='title')\n```\n\n### Long lines policy\n\nThere is a soft limit to keep lines of code under 80 characters long. This means it should be respected if possible and if it does not make readability and code maintenance worse.\n\nFor example, you should **never** split long string literals like URLs or some other often copied entities over multiple lines to fit this limit:\n\nCorrect:\n\n```python\n'https://www.youtube.com/watch?v=FqZTN594JQw&list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4'\n```\n\nIncorrect:\n\n```python\n'https://www.youtube.com/watch?v=FqZTN594JQw&list='\n'PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4'\n```\n\n### Inline values\n\nExtracting variables is acceptable for reducing code duplication and improving readability of complex expressions. However, you should avoid extracting variables used only once and moving them to opposite parts of the extractor file, which makes reading the linear flow difficult.\n\n#### Example\n\nCorrect:\n\n```python\ntitle = self._html_search_regex(r'<title>([^<]+)</title>', webpage, 'title')\n```\n\nIncorrect:\n\n```python\nTITLE_RE = r'<title>([^<]+)</title>'\n# ...some lines of code...\ntitle = self._html_search_regex(TITLE_RE, webpage, 'title')\n```\n\n### Collapse fallbacks\n\nMultiple fallback values can quickly become unwieldy. Collapse multiple fallback values into a single expression via a list of patterns.\n\n#### Example\n\nGood:\n\n```python\ndescription = self._html_search_meta(\n    ['og:description', 'description', 'twitter:description'],\n    webpage, 'description', default=None)\n```\n\nUnwieldy:\n\n```python\ndescription = (\n    self._og_search_description(webpage, default=None)\n    or self._html_search_meta('description', webpage, default=None)\n    or self._html_search_meta('twitter:description', webpage, default=None))\n```\n\nMethods supporting list of patterns are: `_search_regex`, `_html_search_regex`, `_og_search_property`, `_html_search_meta`.\n\n### Trailing parentheses\n\nAlways move trailing parentheses after the last argument.\n\n#### Example\n\nCorrect:\n\n```python\n    lambda x: x['ResultSet']['Result'][0]['VideoUrlSet']['VideoUrl'],\n    list)\n```\n\nIncorrect:\n\n```python\n    lambda x: x['ResultSet']['Result'][0]['VideoUrlSet']['VideoUrl'],\n    list,\n)\n```\n\n### Use convenience conversion and parsing functions\n\nWrap all extracted numeric data into safe functions from [`youtube_dl/utils.py`](https://github.com/ytdl-org/youtube-dl/blob/master/youtube_dl/utils.py): `int_or_none`, `float_or_none`. Use them for string to number conversions as well.\n\nUse `url_or_none` for safe URL processing.\n\nUse `try_get` for safe metadata extraction from parsed JSON.\n\nUse `unified_strdate` for uniform `upload_date` or any `YYYYMMDD` meta field extraction, `unified_timestamp` for uniform `timestamp` extraction, `parse_filesize` for `filesize` extraction, `parse_count` for count meta fields extraction, `parse_resolution`, `parse_duration` for `duration` extraction, `parse_age_limit` for `age_limit` extraction. \n\nExplore [`youtube_dl/utils.py`](https://github.com/ytdl-org/youtube-dl/blob/master/youtube_dl/utils.py) for more useful convenience functions.\n\n#### More examples\n\n##### Safely extract optional description from parsed JSON\n```python\ndescription = try_get(response, lambda x: x['result']['video'][0]['summary'], compat_str)\n```\n\n##### Safely extract more optional metadata\n```python\nvideo = try_get(response, lambda x: x['result']['video'][0], dict) or {}\ndescription = video.get('summary')\nduration = float_or_none(video.get('durationMs'), scale=1000)\nview_count = int_or_none(video.get('views'))\n```\n\n# EMBEDDING YOUTUBE-DL\n\nyoutube-dl makes the best effort to be a good command-line program, and thus should be callable from any programming language. If you encounter any problems parsing its output, feel free to [create a report](https://github.com/ytdl-org/youtube-dl/issues/new).\n\nFrom a Python program, you can embed youtube-dl in a more powerful fashion, like this:\n\n```python\nfrom __future__ import unicode_literals\nimport youtube_dl\n\nydl_opts = {}\nwith youtube_dl.YoutubeDL(ydl_opts) as ydl:\n    ydl.download(['https://www.youtube.com/watch?v=BaW_jenozKc'])\n```\n\nMost likely, you'll want to use various options. For a list of options available, have a look at [`youtube_dl/YoutubeDL.py`](https://github.com/ytdl-org/youtube-dl/blob/3e4cedf9e8cd3157df2457df7274d0c842421945/youtube_dl/YoutubeDL.py#L137-L312). For a start, if you want to intercept youtube-dl's output, set a `logger` object.\n\nHere's a more complete example of a program that outputs only errors (and a short message after the download is finished), and downloads/converts the video to an mp3 file:\n\n```python\nfrom __future__ import unicode_literals\nimport youtube_dl\n\n\nclass MyLogger(object):\n    def debug(self, msg):\n        pass\n\n    def warning(self, msg):\n        pass\n\n    def error(self, msg):\n        print(msg)\n\n\ndef my_hook(d):\n    if d['status'] == 'finished':\n        print('Done downloading, now converting ...')\n\n\nydl_opts = {\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192',\n    }],\n    'logger': MyLogger(),\n    'progress_hooks': [my_hook],\n}\nwith youtube_dl.YoutubeDL(ydl_opts) as ydl:\n    ydl.download(['https://www.youtube.com/watch?v=BaW_jenozKc'])\n```\n\n# BUGS\n\nBugs and suggestions should be reported at: <https://github.com/ytdl-org/youtube-dl/issues>. Unless you were prompted to or there is another pertinent reason (e.g. GitHub fails to accept the bug report), please do not send bug reports via personal email. For discussions, join us in the IRC channel [#youtube-dl](irc://chat.freenode.net/#youtube-dl) on freenode ([webchat](https://webchat.freenode.net/?randomnick=1&channels=youtube-dl)).\n\n**Please include the full output of youtube-dl when run with `-v`**, i.e. **add** `-v` flag to **your command line**, copy the **whole** output and post it in the issue body wrapped in \\`\\`\\` for better formatting. It should look similar to this:\n```\n$ youtube-dl -v <your command line>\n[debug] System config: []\n[debug] User config: []\n[debug] Command-line args: [u'-v', u'https://www.youtube.com/watch?v=BaW_jenozKcj']\n[debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251\n[debug] youtube-dl version 2015.12.06\n[debug] Git HEAD: 135392e\n[debug] Python version 2.6.6 - Windows-2003Server-5.2.3790-SP2\n[debug] exe versions: ffmpeg N-75573-g1d0487f, ffprobe N-75573-g1d0487f, rtmpdump 2.4\n[debug] Proxy map: {}\n...\n```\n**Do not post screenshots of verbose logs; only plain text is acceptable.**\n\nThe output (including the first lines) contains important debugging information. Issues without the full output are often not reproducible and therefore do not get solved in short order, if ever.\n\nPlease re-read your issue once again to avoid a couple of common mistakes (you can and should use this as a checklist):\n\n### Is the description of the issue itself sufficient?\n\nWe often get issue reports that we cannot really decipher. While in most cases we eventually get the required information after asking back multiple times, this poses an unnecessary drain on our resources. Many contributors, including myself, are also not native speakers, so we may misread some parts.\n\nSo please elaborate on what feature you are requesting, or what bug you want to be fixed. Make sure that it's obvious\n\n- What the problem is\n- How it could be fixed\n- How your proposed solution would look like\n\nIf your report is shorter than two lines, it is almost certainly missing some of these, which makes it hard for us to respond to it. We're often too polite to close the issue outright, but the missing info makes misinterpretation likely. As a committer myself, I often get frustrated by these issues, since the only possible way for me to move forward on them is to ask for clarification over and over.\n\nFor bug reports, this means that your report should contain the *complete* output of youtube-dl when called with the `-v` flag. The error message you get for (most) bugs even says so, but you would not believe how many of our bug reports do not contain this information.\n\nIf your server has multiple IPs or you suspect censorship, adding `--call-home` may be a good idea to get more diagnostics. If the error is `ERROR: Unable to extract ...` and you cannot reproduce it from multiple countries, add `--dump-pages` (warning: this will yield a rather large output, redirect it to the file `log.txt` by adding `>log.txt 2>&1` to your command-line) or upload the `.dump` files you get when you add `--write-pages` [somewhere](https://gist.github.com/).\n\n**Site support requests must contain an example URL**. An example URL is a URL you might want to download, like `https://www.youtube.com/watch?v=BaW_jenozKc`. There should be an obvious video present. Except under very special circumstances, the main page of a video service (e.g. `https://www.youtube.com/`) is *not* an example URL.\n\n###  Are you using the latest version?\n\nBefore reporting any issue, type `youtube-dl -U`. This should report that you're up-to-date. About 20% of the reports we receive are already fixed, but people are using outdated versions. This goes for feature requests as well.\n\n###  Is the issue already documented?\n\nMake sure that someone has not already opened the issue you're trying to open. Search at the top of the window or browse the [GitHub Issues](https://github.com/ytdl-org/youtube-dl/search?type=Issues) of this repository. If there is an issue, feel free to write something along the lines of \"This affects me as well, with version 2015.01.01. Here is some more information on the issue: ...\". While some issues may be old, a new post into them often spurs rapid activity.\n\n###  Why are existing options not enough?\n\nBefore requesting a new feature, please have a quick peek at [the list of supported options](https://github.com/ytdl-org/youtube-dl/blob/master/README.md#options). Many feature requests are for features that actually exist already! Please, absolutely do show off your work in the issue report and detail how the existing similar options do *not* solve your problem.\n\n###  Is there enough context in your bug report?\n\nPeople want to solve problems, and often think they do us a favor by breaking down their larger problems (e.g. wanting to skip already downloaded files) to a specific request (e.g. requesting us to look whether the file exists before downloading the info page). However, what often happens is that they break down the problem into two steps: One simple, and one impossible (or extremely complicated one).\n\nWe are then presented with a very complicated request when the original problem could be solved far easier, e.g. by recording the downloaded video IDs in a separate file. To avoid this, you must include the greater context where it is non-obvious. In particular, every feature request that does not consist of adding support for a new site should contain a use case scenario that explains in what situation the missing feature would be useful.\n\n###  Does the issue involve one problem, and one problem only?\n\nSome of our users seem to think there is a limit of issues they can or should open. There is no limit of issues they can or should open. While it may seem appealing to be able to dump all your issues into one ticket, that means that someone who solves one of your issues cannot mark the issue as closed. Typically, reporting a bunch of issues leads to the ticket lingering since nobody wants to attack that behemoth, until someone mercifully splits the issue into multiple ones.\n\nIn particular, every site support request issue should only pertain to services at one site (generally under a common domain, but always using the same backend technology). Do not request support for vimeo user videos, White house podcasts, and Google Plus pages in the same issue. Also, make sure that you don't post bug reports alongside feature requests. As a rule of thumb, a feature request does not include outputs of youtube-dl that are not immediately related to the feature at hand. Do not post reports of a network error alongside the request for a new video service.\n\n###  Is anyone going to need the feature?\n\nOnly post features that you (or an incapacitated friend you can personally talk to) require. Do not post features because they seem like a good idea. If they are really useful, they will be requested by someone who requires them.\n\n###  Is your question about youtube-dl?\n\nIt may sound strange, but some bug reports we receive are completely unrelated to youtube-dl and relate to a different, or even the reporter's own, application. Please make sure that you are actually using youtube-dl. If you are using a UI for youtube-dl, report the bug to the maintainer of the actual application providing the UI. On the other hand, if your UI for youtube-dl fails in some way you believe is related to youtube-dl, by all means, go ahead and report the bug.\n\n# COPYRIGHT\n\nyoutube-dl is released into the public domain by the copyright holders.\n\nThis README file was originally written by [Daniel Bolton](https://github.com/dbbolton) and is likewise released into the public domain.\n"}, {"repo": "nvbn/thefuck", "language": "Python", "readme_contents": "# The Fuck [![Version][version-badge]][version-link] [![Build Status][travis-badge]][travis-link] [![Windows Build Status][appveyor-badge]][appveyor-link] [![Coverage][coverage-badge]][coverage-link] [![MIT License][license-badge]](LICENSE.md)\n\n*The Fuck* is a magnificent app, inspired by a [@liamosaur](https://twitter.com/liamosaur/)\n[tweet](https://twitter.com/liamosaur/status/506975850596536320),\nthat corrects errors in previous console commands.\n\n\nIs *The Fuck* too slow? [Try the experimental instant mode!](#experimental-instant-mode)\n\n[![gif with examples][examples-link]][examples-link]\n\nMore examples:\n\n```bash\n\u279c apt-get install vim\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\n\u279c fuck\nsudo apt-get install vim [enter/\u2191/\u2193/ctrl+c]\n[sudo] password for nvbn:\nReading package lists... Done\n...\n```\n\n```bash\n\u279c git push\nfatal: The current branch master has no upstream branch.\nTo push the current branch and set the remote as upstream, use\n\n    git push --set-upstream origin master\n\n\n\u279c fuck\ngit push --set-upstream origin master [enter/\u2191/\u2193/ctrl+c]\nCounting objects: 9, done.\n...\n```\n\n```bash\n\u279c puthon\nNo command 'puthon' found, did you mean:\n Command 'python' from package 'python-minimal' (main)\n Command 'python' from package 'python3' (main)\nzsh: command not found: puthon\n\n\u279c fuck\npython [enter/\u2191/\u2193/ctrl+c]\nPython 3.4.2 (default, Oct  8 2014, 13:08:17)\n...\n```\n\n```bash\n\u279c git brnch\ngit: 'brnch' is not a git command. See 'git --help'.\n\nDid you mean this?\n    branch\n\n\u279c fuck\ngit branch [enter/\u2191/\u2193/ctrl+c]\n* master\n```\n\n```bash\n\u279c lein rpl\n'rpl' is not a task. See 'lein help'.\n\nDid you mean this?\n         repl\n\n\u279c fuck\nlein repl [enter/\u2191/\u2193/ctrl+c]\nnREPL server started on port 54848 on host 127.0.0.1 - nrepl://127.0.0.1:54848\nREPL-y 0.3.1\n...\n```\n\nIf you're not afraid of blindly running corrected commands, the\n`require_confirmation` [settings](#settings) option can be disabled:\n\n```bash\n\u279c apt-get install vim\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\n\u279c fuck\nsudo apt-get install vim\n[sudo] password for nvbn:\nReading package lists... Done\n...\n```\n\n## Requirements\n\n- python (3.4+)\n- pip\n- python-dev\n\n## Installation\n\nOn OS X, you can install *The Fuck* via [Homebrew][homebrew] (or via [Linuxbrew][linuxbrew] on Linux):\n\n```bash\nbrew install thefuck\n```\n\nOn Ubuntu / Mint, install *The Fuck* with the following commands:\n```bash\nsudo apt update\nsudo apt install python3-dev python3-pip python3-setuptools\nsudo pip3 install thefuck\n```\n\nOn FreeBSD, install *The Fuck* with the following commands:\n```bash\npkg install thefuck\n```\n\nOn ChromeOS, install *The Fuck* using [chromebrew](https://github.com/skycocker/chromebrew) with the following command:\n```bash\ncrew install thefuck\n```\n\nOn other systems, install *The Fuck*  by using `pip`:\n\n```bash\npip install thefuck\n```\n\n[Alternatively, you may use an OS package manager (OS X, Ubuntu, Arch).](https://github.com/nvbn/thefuck/wiki/Installation)\n\n<a href='#manual-installation' name='manual-installation'>#</a>\nIt is recommended that you place this command in your `.bash_profile`,\n`.bashrc`, `.zshrc` or other startup script:\n\n```bash\neval $(thefuck --alias)\n# You can use whatever you want as an alias, like for Mondays:\neval $(thefuck --alias FUCK)\n```\n\n[Or in your shell config (Bash, Zsh, Fish, Powershell, tcsh).](https://github.com/nvbn/thefuck/wiki/Shell-aliases)\n\nChanges are only available in a new shell session. To make changes immediately\navailable, run `source ~/.bashrc` (or your shell config file like `.zshrc`).\n\nTo run fixed commands without confirmation, use the `--yeah` option (or just `-y` for short, or `--hard` if you're especially frustrated):\n\n```bash\nfuck --yeah\n```\n\nTo fix commands recursively until succeeding, use the `-r` option:\n\n```bash\nfuck -r\n```\n\n## Updating\n\n```bash\npip3 install thefuck --upgrade\n```\n\n**Note: Alias functionality was changed in v1.34 of *The Fuck***\n\n## How it works\n\n*The Fuck* attempts to match the previous command with a rule. If a match is\nfound, a new command is created using the matched rule and executed. The\nfollowing rules are enabled by default:\n\n* `adb_unknown_command` &ndash; fixes misspelled commands like `adb logcta`;\n* `ag_literal` &ndash; adds `-Q` to `ag` when suggested;\n* `aws_cli` &ndash; fixes misspelled commands like `aws dynamdb scan`;\n* `az_cli` &ndash; fixes misspelled commands like `az providers`;\n* `cargo` &ndash; runs `cargo build` instead of `cargo`;\n* `cargo_no_command` &ndash; fixes wrongs commands like `cargo buid`;\n* `cat_dir` &ndash; replaces `cat` with `ls` when you try to `cat` a directory;\n* `cd_correction` &ndash; spellchecks and correct failed cd commands;\n* `cd_mkdir` &ndash; creates directories before cd'ing into them;\n* `cd_parent` &ndash; changes `cd..` to `cd ..`;\n* `chmod_x` &ndash; add execution bit;\n* `choco_install` &ndash; append common suffixes for chocolatey packages;\n* `composer_not_command` &ndash; fixes composer command name;\n* `cp_omitting_directory` &ndash; adds `-a` when you `cp` directory;\n* `cpp11` &ndash; adds missing `-std=c++11` to `g++` or `clang++`;\n* `dirty_untar` &ndash; fixes `tar x` command that untarred in the current directory;\n* `dirty_unzip` &ndash; fixes `unzip` command that unzipped in the current directory;\n* `django_south_ghost` &ndash; adds `--delete-ghost-migrations` to failed because ghosts django south migration;\n* `django_south_merge` &ndash; adds `--merge` to inconsistent django south migration;\n* `docker_login` &ndash; executes a `docker login` and repeats the previous command;\n* `docker_not_command` &ndash; fixes wrong docker commands like `docker tags`;\n* `docker_image_being_used_by_container` &dash; removes the container that is using the image before removing the image;\n* `dry` &ndash; fixes repetitions like `git git push`;\n* `fab_command_not_found` &ndash; fix misspelled fabric commands;\n* `fix_alt_space` &ndash; replaces Alt+Space with Space character;\n* `fix_file` &ndash; opens a file with an error in your `$EDITOR`;\n* `gem_unknown_command` &ndash; fixes wrong `gem` commands;\n* `git_add` &ndash; fixes *\"pathspec 'foo' did not match any file(s) known to git.\"*;\n* `git_add_force` &ndash; adds `--force` to `git add <pathspec>...` when paths are .gitignore'd;\n* `git_bisect_usage` &ndash; fixes `git bisect strt`, `git bisect goood`, `git bisect rset`, etc. when bisecting;\n* `git_branch_delete` &ndash; changes `git branch -d` to `git branch -D`;\n* `git_branch_delete_checked_out` &ndash; changes `git branch -d` to `git checkout master && git branch -D` when trying to delete a checked out branch;\n* `git_branch_exists` &ndash; offers `git branch -d foo`, `git branch -D foo` or `git checkout foo` when creating a branch that already exists;\n* `git_branch_list` &ndash; catches `git branch list` in place of `git branch` and removes created branch;\n* `git_checkout` &ndash; fixes branch name or creates new branch;\n* `git_commit_amend` &ndash; offers `git commit --amend` after previous commit;\n* `git_commit_reset` &ndash; offers `git reset HEAD~` after previous commit;\n* `git_diff_no_index` &ndash; adds `--no-index` to previous `git diff` on untracked files;\n* `git_diff_staged` &ndash; adds `--staged` to previous `git diff` with unexpected output;\n* `git_fix_stash` &ndash; fixes `git stash` commands (misspelled subcommand and missing `save`);\n* `git_flag_after_filename` &ndash; fixes `fatal: bad flag '...' after filename`\n* `git_help_aliased` &ndash; fixes `git help <alias>` commands replacing <alias> with the aliased command;\n* `git_merge` &ndash; adds remote to branch names;\n* `git_merge_unrelated` &ndash; adds `--allow-unrelated-histories` when required\n* `git_not_command` &ndash; fixes wrong git commands like `git brnch`;\n* `git_pull` &ndash; sets upstream before executing previous `git pull`;\n* `git_pull_clone` &ndash; clones instead of pulling when the repo does not exist;\n* `git_pull_uncommitted_changes` &ndash; stashes changes before pulling and pops them afterwards;\n* `git_push` &ndash; adds `--set-upstream origin $branch` to previous failed `git push`;\n* `git_push_different_branch_names` &ndash; fixes pushes when local brach name does not match remote branch name;\n* `git_push_pull` &ndash; runs `git pull` when `push` was rejected;\n* `git_push_without_commits` &ndash; Creates an initial commit if you forget and only `git add .`, when setting up a new project;\n* `git_rebase_no_changes` &ndash; runs `git rebase --skip` instead of `git rebase --continue` when there are no changes;\n* `git_remote_delete` &ndash; replaces `git remote delete remote_name` with `git remote remove remote_name`;\n* `git_rm_local_modifications` &ndash;  adds `-f` or `--cached` when you try to `rm` a locally modified file;\n* `git_rm_recursive` &ndash; adds `-r` when you try to `rm` a directory;\n* `git_rm_staged` &ndash;  adds `-f` or `--cached` when you try to `rm` a file with staged changes\n* `git_rebase_merge_dir` &ndash; offers `git rebase (--continue | --abort | --skip)` or removing the `.git/rebase-merge` dir when a rebase is in progress;\n* `git_remote_seturl_add` &ndash; runs `git remote add` when `git remote set_url` on nonexistent remote;\n* `git_stash` &ndash; stashes your local modifications before rebasing or switching branch;\n* `git_stash_pop` &ndash; adds your local modifications before popping stash, then resets;\n* `git_tag_force` &ndash; adds `--force` to `git tag <tagname>` when the tag already exists;\n* `git_two_dashes` &ndash; adds a missing dash to commands like `git commit -amend` or `git rebase -continue`;\n* `go_run` &ndash; appends `.go` extension when compiling/running Go programs;\n* `go_unknown_command` &ndash; fixes wrong `go` commands, for example `go bulid`;\n* `gradle_no_task` &ndash; fixes not found or ambiguous `gradle` task;\n* `gradle_wrapper` &ndash; replaces `gradle` with `./gradlew`;\n* `grep_arguments_order` &ndash; fixes `grep` arguments order for situations like `grep -lir . test`;\n* `grep_recursive` &ndash; adds `-r` when you try to `grep` directory;\n* `grunt_task_not_found` &ndash; fixes misspelled `grunt` commands;\n* `gulp_not_task` &ndash; fixes misspelled `gulp` tasks;\n* `has_exists_script` &ndash; prepends `./` when script/binary exists;\n* `heroku_multiple_apps` &ndash; add `--app <app>` to `heroku` commands like `heroku pg`;\n* `heroku_not_command` &ndash; fixes wrong `heroku` commands like `heroku log`;\n* `history` &ndash; tries to replace command with most similar command from history;\n* `hostscli` &ndash; tries to fix `hostscli` usage;\n* `ifconfig_device_not_found` &ndash; fixes wrong device names like `wlan0` to `wlp2s0`;\n* `java` &ndash; removes `.java` extension when running Java programs;\n* `javac` &ndash; appends missing `.java` when compiling Java files;\n* `lein_not_task` &ndash; fixes wrong `lein` tasks like `lein rpl`;\n* `long_form_help` &ndash; changes `-h` to `--help` when the short form version is not supported\n* `ln_no_hard_link` &ndash; catches hard link creation on directories, suggest symbolic link;\n* `ln_s_order` &ndash; fixes `ln -s` arguments order;\n* `ls_all` &ndash; adds `-A` to `ls` when output is empty;\n* `ls_lah` &ndash; adds `-lah` to `ls`;\n* `man` &ndash; changes manual section;\n* `man_no_space` &ndash; fixes man commands without spaces, for example `mandiff`;\n* `mercurial` &ndash; fixes wrong `hg` commands;\n* `missing_space_before_subcommand` &ndash; fixes command with missing space like `npminstall`;\n* `mkdir_p` &ndash; adds `-p` when you try to create a directory without parent;\n* `mvn_no_command` &ndash; adds `clean package` to `mvn`;\n* `mvn_unknown_lifecycle_phase` &ndash; fixes misspelled life cycle phases with `mvn`;\n* `npm_missing_script` &ndash; fixes `npm` custom script name in `npm run-script <script>`;\n* `npm_run_script` &ndash; adds missing `run-script` for custom `npm` scripts;\n* `npm_wrong_command` &ndash; fixes wrong npm commands like `npm urgrade`;\n* `no_command` &ndash; fixes wrong console commands, for example `vom/vim`;\n* `no_such_file` &ndash; creates missing directories with `mv` and `cp` commands;\n* `open` &ndash; either prepends `http://` to address passed to `open` or create a new file or directory and passes it to `open`;\n* `pip_install` &ndash; fixes permission issues with `pip install` commands by adding `--user` or prepending `sudo` if necessary;\n* `pip_unknown_command` &ndash; fixes wrong `pip` commands, for example `pip instatl/pip install`;\n* `php_s` &ndash; replaces `-s` by `-S` when trying to run a local php server;\n* `port_already_in_use` &ndash; kills process that bound port;\n* `prove_recursively` &ndash; adds `-r` when called with directory;\n* `pyenv_no_such_command` &ndash; fixes wrong pyenv commands like `pyenv isntall` or `pyenv list`;\n* `python_command` &ndash; prepends `python` when you try to run non-executable/without `./` python script;\n* `python_execute` &ndash; appends missing `.py` when executing Python files;\n* `quotation_marks` &ndash; fixes uneven usage of `'` and `\"` when containing args';\n* `path_from_history` &ndash; replaces not found path with similar absolute path from history;\n* `react_native_command_unrecognized` &ndash; fixes unrecognized `react-native` commands;\n* `remove_shell_prompt_literal` &ndash; remove leading shell prompt symbol `$`, common when copying commands from documentations;\n* `remove_trailing_cedilla` &ndash; remove trailing cedillas `\u00e7`, a common typo for european keyboard layouts;\n* `rm_dir` &ndash; adds `-rf` when you try to remove a directory;\n* `scm_correction` &ndash; corrects wrong scm like `hg log` to `git log`;\n* `sed_unterminated_s` &ndash; adds missing '/' to `sed`'s `s` commands;\n* `sl_ls` &ndash; changes `sl` to `ls`;\n* `ssh_known_hosts` &ndash; removes host from `known_hosts` on warning;\n* `sudo` &ndash; prepends `sudo` to previous command if it failed because of permissions;\n* `sudo_command_from_user_path` &ndash; runs commands from users `$PATH` with `sudo`;\n* `switch_lang` &ndash; switches command from your local layout to en;\n* `systemctl` &ndash; correctly orders parameters of confusing `systemctl`;\n* `terraform_init.py` &ndash; run `terraform init` before plan or apply;\n* `test.py` &ndash; runs `py.test` instead of `test.py`;\n* `touch` &ndash; creates missing directories before \"touching\";\n* `tsuru_login` &ndash; runs `tsuru login` if not authenticated or session expired;\n* `tsuru_not_command` &ndash; fixes wrong `tsuru` commands like `tsuru shell`;\n* `tmux` &ndash; fixes `tmux` commands;\n* `unknown_command` &ndash; fixes hadoop hdfs-style \"unknown command\", for example adds missing '-' to the command on `hdfs dfs ls`;\n* `unsudo` &ndash; removes `sudo` from previous command if a process refuses to run on super user privilege.\n* `vagrant_up` &ndash; starts up the vagrant instance;\n* `whois` &ndash; fixes `whois` command;\n* `workon_doesnt_exists` &ndash; fixes `virtualenvwrapper` env name os suggests to create new.\n* `yarn_alias` &ndash; fixes aliased `yarn` commands like `yarn ls`;\n* `yarn_command_not_found` &ndash; fixes misspelled `yarn` commands;\n* `yarn_command_replaced` &ndash; fixes replaced `yarn` commands;\n* `yarn_help` &ndash; makes it easier to open `yarn` documentation;\n\nThe following rules are enabled by default on specific platforms only:\n\n* `apt_get` &ndash; installs app from apt if it not installed (requires `python-commandnotfound` / `python3-commandnotfound`);\n* `apt_get_search` &ndash; changes trying to search using `apt-get` with searching using `apt-cache`;\n* `apt_invalid_operation` &ndash; fixes invalid `apt` and `apt-get` calls, like `apt-get isntall vim`;\n* `apt_list_upgradable` &ndash; helps you run `apt list --upgradable` after `apt update`;\n* `apt_upgrade` &ndash; helps you run `apt upgrade` after `apt list --upgradable`;\n* `brew_cask_dependency` &ndash; installs cask dependencies;\n* `brew_install` &ndash; fixes formula name for `brew install`;\n* `brew_reinstall` &ndash; turns `brew install <formula>` into `brew reinstall <formula>`;\n* `brew_link` &ndash; adds `--overwrite --dry-run` if linking fails;\n* `brew_uninstall` &ndash; adds `--force` to `brew uninstall` if multiple versions were installed;\n* `brew_unknown_command` &ndash; fixes wrong brew commands, for example `brew docto/brew doctor`;\n* `brew_update_formula` &ndash; turns `brew update <formula>` into `brew upgrade <formula>`;\n* `dnf_no_such_command` &ndash; fixes mistyped DNF commands;\n* `nixos_cmd_not_found` &ndash; installs apps on NixOS;\n* `pacman` &ndash; installs app with `pacman` if it is not installed (uses `yay` or `yaourt` if available);\n* `pacman_not_found` &ndash; fixes package name with `pacman`, `yay` or `yaourt`.\n* `yum_invalid_operation` &ndash; fixes invalid `yum` calls, like `yum isntall vim`;\n\nThe following commands are bundled with *The Fuck*, but are not enabled by\ndefault:\n\n* `git_push_force` &ndash; adds `--force-with-lease` to a `git push` (may conflict with `git_push_pull`);\n* `rm_root` &ndash; adds `--no-preserve-root` to `rm -rf /` command.\n\n## Creating your own rules\n\nTo add your own rule, create a file named `your-rule-name.py`\nin `~/.config/thefuck/rules`. The rule file must contain two functions:\n\n```python\nmatch(command: Command) -> bool\nget_new_command(command: Command) -> str | list[str]\n```\n\nAdditionally, rules can contain optional functions:\n\n```python\nside_effect(old_command: Command, fixed_command: str) -> None\n```\nRules can also contain the optional variables `enabled_by_default`, `requires_output` and `priority`.\n\n`Command` has three attributes: `script`, `output` and `script_parts`.\nYour rule should not change `Command`.\n\n\n**Rules api changed in 3.0:** To access a rule's settings, import it with\n `from thefuck.conf import settings`\n\n`settings` is a special object assembled from `~/.config/thefuck/settings.py`,\nand values from env ([see more below](#settings)).\n\nA simple example rule for running a script with `sudo`:\n\n```python\ndef match(command):\n    return ('permission denied' in command.output.lower()\n            or 'EACCES' in command.output)\n\n\ndef get_new_command(command):\n    return 'sudo {}'.format(command.script)\n\n# Optional:\nenabled_by_default = True\n\ndef side_effect(command, fixed_command):\n    subprocess.call('chmod 777 .', shell=True)\n\npriority = 1000  # Lower first, default is 1000\n\nrequires_output = True\n```\n\n[More examples of rules](https://github.com/nvbn/thefuck/tree/master/thefuck/rules),\n[utility functions for rules](https://github.com/nvbn/thefuck/tree/master/thefuck/utils.py),\n[app/os-specific helpers](https://github.com/nvbn/thefuck/tree/master/thefuck/specific/).\n\n## Settings\n\nSeveral *The Fuck* parameters can be changed in the file `$XDG_CONFIG_HOME/thefuck/settings.py`\n(`$XDG_CONFIG_HOME` defaults to `~/.config`):\n\n* `rules` &ndash; list of enabled rules, by default `thefuck.const.DEFAULT_RULES`;\n* `exclude_rules` &ndash; list of disabled rules, by default `[]`;\n* `require_confirmation` &ndash; requires confirmation before running new command, by default `True`;\n* `wait_command` &ndash; max amount of time in seconds for getting previous command output;\n* `no_colors` &ndash; disable colored output;\n* `priority` &ndash; dict with rules priorities, rule with lower `priority` will be matched first;\n* `debug` &ndash; enables debug output, by default `False`;\n* `history_limit` &ndash; numeric value of how many history commands will be scanned, like `2000`;\n* `alter_history` &ndash; push fixed command to history, by default `True`;\n* `wait_slow_command` &ndash; max amount of time in seconds for getting previous command output if it in `slow_commands` list;\n* `slow_commands` &ndash; list of slow commands;\n* `num_close_matches` &ndash; maximum number of close matches to suggest, by default `3`.\n\nAn example of `settings.py`:\n\n```python\nrules = ['sudo', 'no_command']\nexclude_rules = ['git_push']\nrequire_confirmation = True\nwait_command = 10\nno_colors = False\npriority = {'sudo': 100, 'no_command': 9999}\ndebug = False\nhistory_limit = 9999\nwait_slow_command = 20\nslow_commands = ['react-native', 'gradle']\nnum_close_matches = 5\n```\n\nOr via environment variables:\n\n* `THEFUCK_RULES` &ndash; list of enabled rules, like `DEFAULT_RULES:rm_root` or `sudo:no_command`;\n* `THEFUCK_EXCLUDE_RULES` &ndash; list of disabled rules, like `git_pull:git_push`;\n* `THEFUCK_REQUIRE_CONFIRMATION` &ndash; require confirmation before running new command, `true/false`;\n* `THEFUCK_WAIT_COMMAND` &ndash; max amount of time in seconds for getting previous command output;\n* `THEFUCK_NO_COLORS` &ndash; disable colored output, `true/false`;\n* `THEFUCK_PRIORITY` &ndash; priority of the rules, like `no_command=9999:apt_get=100`,\nrule with lower `priority` will be matched first;\n* `THEFUCK_DEBUG` &ndash; enables debug output, `true/false`;\n* `THEFUCK_HISTORY_LIMIT` &ndash; how many history commands will be scanned, like `2000`;\n* `THEFUCK_ALTER_HISTORY` &ndash; push fixed command to history `true/false`;\n* `THEFUCK_WAIT_SLOW_COMMAND` &ndash; max amount of time in seconds for getting previous command output if it in `slow_commands` list;\n* `THEFUCK_SLOW_COMMANDS` &ndash; list of slow commands, like `lein:gradle`;\n* `THEFUCK_NUM_CLOSE_MATCHES` &ndash; maximum number of close matches to suggest, like `5`.\n\nFor example:\n\n```bash\nexport THEFUCK_RULES='sudo:no_command'\nexport THEFUCK_EXCLUDE_RULES='git_pull:git_push'\nexport THEFUCK_REQUIRE_CONFIRMATION='true'\nexport THEFUCK_WAIT_COMMAND=10\nexport THEFUCK_NO_COLORS='false'\nexport THEFUCK_PRIORITY='no_command=9999:apt_get=100'\nexport THEFUCK_HISTORY_LIMIT='2000'\nexport THEFUCK_NUM_CLOSE_MATCHES='5'\n```\n\n## Third-party packages with rules\n\nIf you'd like to make a specific set of non-public rules, but would still like\nto share them with others, create a package named `thefuck_contrib_*` with\nthe following structure:\n\n```\nthefuck_contrib_foo\n  thefuck_contrib_foo\n    rules\n      __init__.py\n      *third-party rules*\n    __init__.py\n    *third-party-utils*\n  setup.py\n```\n\n*The Fuck* will find rules located in the `rules` module.\n\n## Experimental instant mode\n\nThe default behavior of *The Fuck* requires time to re-run previous commands.\nWhen in instant mode, *The Fuck* saves time by logging output with [script](https://en.wikipedia.org/wiki/Script_(Unix)),\nthen reading the log.\n\n[![gif with instant mode][instant-mode-gif-link]][instant-mode-gif-link]\n\nCurrently, instant mode only supports Python 3 with bash or zsh. zsh's autocorrect function also needs to be disabled in order for thefuck to work properly.\n\nTo enable instant mode, add `--enable-experimental-instant-mode`\nto the alias initialization in `.bashrc`, `.bash_profile` or `.zshrc`.\n\nFor example:\n\n```bash\neval $(thefuck --alias --enable-experimental-instant-mode)\n```\n\n## Developing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## License MIT\nProject License can be found [here](LICENSE.md).\n\n\n[version-badge]:   https://img.shields.io/pypi/v/thefuck.svg?label=version\n[version-link]:    https://pypi.python.org/pypi/thefuck/\n[travis-badge]:    https://travis-ci.org/nvbn/thefuck.svg?branch=master\n[travis-link]:     https://travis-ci.org/nvbn/thefuck\n[appveyor-badge]:  https://ci.appveyor.com/api/projects/status/1sskj4imj02um0gu/branch/master?svg=true\n[appveyor-link]:   https://ci.appveyor.com/project/nvbn/thefuck\n[coverage-badge]:  https://img.shields.io/coveralls/nvbn/thefuck.svg\n[coverage-link]:   https://coveralls.io/github/nvbn/thefuck\n[license-badge]:   https://img.shields.io/badge/license-MIT-007EC7.svg\n[examples-link]:   https://raw.githubusercontent.com/nvbn/thefuck/master/example.gif\n[instant-mode-gif-link]:   https://raw.githubusercontent.com/nvbn/thefuck/master/example_instant_mode.gif\n[homebrew]:        https://brew.sh/\n[linuxbrew]:       https://linuxbrew.sh/\n"}, {"repo": "pallets/flask", "language": "Python", "readme_contents": "Flask\n=====\n\nFlask is a lightweight `WSGI`_ web application framework. It is designed\nto make getting started quick and easy, with the ability to scale up to\ncomplex applications. It began as a simple wrapper around `Werkzeug`_\nand `Jinja`_ and has become one of the most popular Python web\napplication frameworks.\n\nFlask offers suggestions, but doesn't enforce any dependencies or\nproject layout. It is up to the developer to choose the tools and\nlibraries they want to use. There are many extensions provided by the\ncommunity that make adding new functionality easy.\n\n\nInstalling\n----------\n\nInstall and update using `pip`_:\n\n.. code-block:: text\n\n    pip install -U Flask\n\n\nA Simple Example\n----------------\n\n.. code-block:: python\n\n    from flask import Flask\n\n    app = Flask(__name__)\n\n    @app.route(\"/\")\n    def hello():\n        return \"Hello, World!\"\n\n.. code-block:: text\n\n    $ env FLASK_APP=hello.py flask run\n     * Serving Flask app \"hello\"\n     * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n\n\nContributing\n------------\n\nFor guidance on setting up a development environment and how to make a\ncontribution to Flask, see the `contributing guidelines`_.\n\n.. _contributing guidelines: https://github.com/pallets/flask/blob/master/CONTRIBUTING.rst\n\n\nDonate\n------\n\nThe Pallets organization develops and supports Flask and the libraries\nit uses. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, `please\ndonate today`_.\n\n.. _please donate today: https://psfmember.org/civicrm/contribute/transact?reset=1&id=20\n\n\nLinks\n-----\n\n* Website: https://palletsprojects.com/p/flask/\n* Documentation: https://flask.palletsprojects.com/\n* Releases: https://pypi.org/project/Flask/\n* Code: https://github.com/pallets/flask\n* Issue tracker: https://github.com/pallets/flask/issues\n* Test status: https://dev.azure.com/pallets/flask/_build\n* Official chat: https://discord.gg/t6rrQZH\n\n.. _WSGI: https://wsgi.readthedocs.io\n.. _Werkzeug: https://www.palletsprojects.com/p/werkzeug/\n.. _Jinja: https://www.palletsprojects.com/p/jinja/\n.. _pip: https://pip.pypa.io/en/stable/quickstart/\n"}, {"repo": "keras-team/keras", "language": "Python", "readme_contents": "\ufeff# Keras: Deep Learning for humans\n\n![Keras logo](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)\n\n[![Build Status](https://travis-ci.org/keras-team/keras.svg?branch=master)](https://travis-ci.org/keras-team/keras)\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://github.com/keras-team/keras/blob/master/LICENSE)\n\n## You have just found Keras.\n\nKeras is a high-level neural networks API, written in Python and capable of running on top of [TensorFlow](https://github.com/tensorflow/tensorflow), [CNTK](https://github.com/Microsoft/cntk), or [Theano](https://github.com/Theano/Theano). It was developed with a focus on enabling fast experimentation. *Being able to go from idea to result with the least possible delay is key to doing good research.*\n\nUse Keras if you need a deep learning library that:\n\n- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n- Runs seamlessly on CPU and GPU.\n\nRead the documentation at [Keras.io](https://keras.io).\n\nKeras is compatible with: __Python 2.7-3.6__.\n\n\n------------------\n\n## Multi-backend Keras and tf.keras:\n\n**At this time, we recommend that Keras users who use multi-backend Keras with the TensorFlow backend switch to `tf.keras` in TensorFlow 2.0**. `tf.keras` is better maintained and has better integration with TensorFlow features (eager execution, distribution support and other).\n\nKeras 2.2.5 was the last release of Keras implementing the 2.2.* API. It was the last release to only support TensorFlow 1 (as well as Theano and CNTK).\n\nThe current release is Keras 2.3.0, which makes significant API changes and add support for TensorFlow 2.0. The 2.3.0 release will be the last major release of multi-backend Keras. Multi-backend Keras is superseded by `tf.keras`.\n\nBugs present in multi-backend Keras will only be fixed until April 2020 (as part of minor releases).\n\nFor more information about the future of Keras, see [the Keras meeting notes](http://bit.ly/keras-meeting-notes).\n\n\n------------------\n\n## Guiding principles\n\n- __User friendliness.__ Keras is an API designed for human beings, not machines. It puts user experience front and center. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.\n\n- __Modularity.__ A model is understood as a sequence or a graph of standalone, fully configurable modules that can be plugged together with as few restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions and regularization schemes are all standalone modules that you can combine to create new models.\n\n- __Easy extensibility.__ New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.\n\n- __Work with Python__. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.\n\n\n------------------\n\n\n## Getting started: 30 seconds to Keras\n\nThe core data structure of Keras is a __model__, a way to organize layers. The simplest type of model is the [`Sequential`](https://keras.io/getting-started/sequential-model-guide) model, a linear stack of layers. For more complex architectures, you should use the [Keras functional API](https://keras.io/getting-started/functional-api-guide), which allows to build arbitrary graphs of layers.\n\nHere is the `Sequential` model:\n\n```python\nfrom keras.models import Sequential\n\nmodel = Sequential()\n```\n\nStacking layers is as easy as `.add()`:\n\n```python\nfrom keras.layers import Dense\n\nmodel.add(Dense(units=64, activation='relu', input_dim=100))\nmodel.add(Dense(units=10, activation='softmax'))\n```\n\nOnce your model looks good, configure its learning process with `.compile()`:\n\n```python\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n```\n\nIf you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n```python\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n```\n\nYou can now iterate on your training data in batches:\n\n```python\n# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\nmodel.fit(x_train, y_train, epochs=5, batch_size=32)\n```\n\nAlternatively, you can feed batches to your model manually:\n\n```python\nmodel.train_on_batch(x_batch, y_batch)\n```\n\nEvaluate your performance in one line:\n\n```python\nloss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n```\n\nOr generate predictions on new data:\n\n```python\nclasses = model.predict(x_test, batch_size=128)\n```\n\nBuilding a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?\n\nFor a more in-depth tutorial about Keras, you can check out:\n\n- [Getting started with the Sequential model](https://keras.io/getting-started/sequential-model-guide)\n- [Getting started with the functional API](https://keras.io/getting-started/functional-api-guide)\n\nIn the [examples folder](https://github.com/keras-team/keras/tree/master/examples) of the repository, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, etc.\n\n\n------------------\n\n\n## Installation\n\nBefore installing Keras, please install one of its backend engines: TensorFlow, Theano, or CNTK. We recommend the TensorFlow backend.\n\n- [TensorFlow installation instructions](https://www.tensorflow.org/install/).\n- [Theano installation instructions](http://deeplearning.net/software/theano/install.html#install).\n- [CNTK installation instructions](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine).\n\nYou may also consider installing the following **optional dependencies**:\n\n- [cuDNN](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/) (recommended if you plan on running Keras on GPU).\n- HDF5 and [h5py](http://docs.h5py.org/en/latest/build.html) (required if you plan on saving Keras models to disk).\n- [graphviz](https://graphviz.gitlab.io/download/) and [pydot](https://github.com/erocarrera/pydot) (used by [visualization utilities](https://keras.io/visualization/) to plot model graphs).\n\nThen, you can install Keras itself. There are two ways to install Keras:\n\n- **Install Keras from PyPI (recommended):**\n\nNote: These installation steps assume that you are on a Linux or Mac environment.\nIf you are on Windows, you will need to remove `sudo` to run the commands below.\n\n```sh\nsudo pip install keras\n```\n\nIf you are using a virtualenv, you may want to avoid using sudo:\n\n```sh\npip install keras\n```\n\n- **Alternatively: install Keras from the GitHub source:**\n\nFirst, clone Keras using `git`:\n\n```sh\ngit clone https://github.com/keras-team/keras.git\n```\n\n Then, `cd` to the Keras folder and run the install command:\n```sh\ncd keras\nsudo python setup.py install\n```\n\n------------------\n\n\n## Configuring your Keras backend\n\nBy default, Keras will use TensorFlow as its tensor manipulation library. [Follow these instructions](https://keras.io/backend/) to configure the Keras backend.\n\n------------------\n\n\n## Support\n\nYou can ask questions and join the development discussion:\n\n- On the [Keras Google group](https://groups.google.com/forum/#!forum/keras-users).\n- On the [Keras Slack channel](https://kerasteam.slack.com). Use [this link](https://keras-slack-autojoin.herokuapp.com/) to request an invitation to the channel.\n\nYou can also post **bug reports and feature requests** (only) in [GitHub issues](https://github.com/keras-team/keras/issues). Make sure to read [our guidelines](https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md) first.\n\n\n------------------\n\n\n## Why this name, Keras?\n\nKeras (\u03ba\u03ad\u03c1\u03b1\u03c2) means _horn_ in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the _Odyssey_, where dream spirits (_Oneiroi_, singular _Oneiros_) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words \u03ba\u03ad\u03c1\u03b1\u03c2 (horn) / \u03ba\u03c1\u03b1\u03af\u03bd\u03c9 (fulfill), and \u1f10\u03bb\u03ad\u03c6\u03b1\u03c2 (ivory) / \u1f10\u03bb\u03b5\u03c6\u03b1\u03af\u03c1\u03bf\u03bc\u03b1\u03b9 (deceive).\n\nKeras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).\n\n>_\"Oneiroi are beyond our unravelling --who can be sure what tale they tell? Not all that men look for comes to pass. Two gates there are that give passage to fleeting Oneiroi; one is made of horn, one of ivory. The Oneiroi that pass through sawn ivory are deceitful, bearing a message that will not be fulfilled; those that come out through polished horn have truth behind them, to be accomplished for men who see them.\"_ Homer, Odyssey 19. 562 ff (Shewring translation).\n\n------------------\n"}, {"repo": "django/django", "language": "Python", "readme_contents": "======\nDjango\n======\n\nDjango is a high-level Python Web framework that encourages rapid development\nand clean, pragmatic design. Thanks for checking it out.\n\nAll documentation is in the \"``docs``\" directory and online at\nhttps://docs.djangoproject.com/en/stable/. If you're just getting started,\nhere's how we recommend you read the docs:\n\n* First, read ``docs/intro/install.txt`` for instructions on installing Django.\n\n* Next, work through the tutorials in order (``docs/intro/tutorial01.txt``,\n  ``docs/intro/tutorial02.txt``, etc.).\n\n* If you want to set up an actual deployment server, read\n  ``docs/howto/deployment/index.txt`` for instructions.\n\n* You'll probably want to read through the topical guides (in ``docs/topics``)\n  next; from there you can jump to the HOWTOs (in ``docs/howto``) for specific\n  problems, and check out the reference (``docs/ref``) for gory details.\n\n* See ``docs/README`` for instructions on building an HTML version of the docs.\n\nDocs are updated rigorously. If you find any problems in the docs, or think\nthey should be clarified in any way, please take 30 seconds to fill out a\nticket here: https://code.djangoproject.com/newticket\n\nTo get more help:\n\n* Join the ``#django`` channel on irc.freenode.net. Lots of helpful people hang\n  out there. See https://en.wikipedia.org/wiki/Wikipedia:IRC/Tutorial if you're\n  new to IRC.\n\n* Join the django-users mailing list, or read the archives, at\n  https://groups.google.com/group/django-users.\n\nTo contribute to Django:\n\n* Check out https://docs.djangoproject.com/en/dev/internals/contributing/ for\n  information about getting involved.\n\nTo run Django's test suite:\n\n* Follow the instructions in the \"Unit tests\" section of\n  ``docs/internals/contributing/writing-code/unit-tests.txt``, published online at\n  https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/unit-tests/#running-the-unit-tests\n"}, {"repo": "jakubroztocil/httpie", "language": "Python", "readme_contents": "HTTPie: a CLI, cURL-like tool for humans\n########################################\n\nHTTPie (pronounced *aitch-tee-tee-pie*) is a command line HTTP client.\nIts goal is to make CLI interaction with web services as human-friendly\nas possible. It provides a simple ``http`` command that allows for sending\narbitrary HTTP requests using a simple and natural syntax, and displays\ncolorized output. HTTPie can be used for testing, debugging, and\ngenerally interacting with HTTP servers.\n\n\n.. class:: no-web no-pdf\n\n    |pypi| |build| |coverage| |downloads| |gitter|\n\n\n.. class:: no-web no-pdf\n\n    .. image:: https://raw.githubusercontent.com/jakubroztocil/httpie/master/httpie.gif\n        :alt: HTTPie in action\n        :width: 100%\n        :align: center\n\n\n.. contents::\n\n.. section-numbering::\n\n\n\nMain features\n=============\n\n\n* Expressive and intuitive syntax\n* Formatted and colorized terminal output\n* Built-in JSON support\n* Forms and file uploads\n* HTTPS, proxies, and authentication\n* Arbitrary request data\n* Custom headers\n* Persistent sessions\n* Wget-like downloads\n* Linux, macOS and Windows support\n* Plugins\n* Documentation\n* Test coverage\n\n\n.. class:: no-web\n\n    .. image:: https://raw.githubusercontent.com/jakubroztocil/httpie/master/httpie.png\n        :alt: HTTPie compared to cURL\n        :width: 100%\n        :align: center\n\n\nInstallation\n============\n\n\nmacOS\n-----\n\n\nOn macOS, HTTPie can be installed via `Homebrew <https://brew.sh/>`_\n(recommended):\n\n.. code-block:: bash\n\n    $ brew install httpie\n\n\nA MacPorts *port* is also available:\n\n.. code-block:: bash\n\n    $ port install httpie\n\nLinux\n-----\n\nMost Linux distributions provide a package that can be installed using the\nsystem package manager, for example:\n\n.. code-block:: bash\n\n    # Debian, Ubuntu, etc.\n    $ apt-get install httpie\n\n.. code-block:: bash\n\n    # Fedora\n    $ dnf install httpie\n\n.. code-block:: bash\n\n    # CentOS, RHEL, ...\n    $ yum install httpie\n\n.. code-block:: bash\n\n    # Arch Linux\n    $ pacman -S httpie\n\n\nWindows, etc.\n-------------\n\nA universal installation method (that works on Windows, Mac OS X, Linux, \u2026,\nand always provides the latest version) is to use `pip`_:\n\n\n.. code-block:: bash\n\n    # Make sure we have an up-to-date version of pip and setuptools:\n    $ pip install --upgrade pip setuptools\n\n    $ pip install --upgrade httpie\n\n\n(If ``pip`` installation fails for some reason, you can try\n``easy_install httpie`` as a fallback.)\n\n\nPython version\n--------------\n\nStarting with version 2.0.0 (currently under development) Python 3.6+ is required.\n\n\nUnstable version\n----------------\n\nYou can also install the latest unreleased development version directly from\nthe ``master`` branch on GitHub.  It is a work-in-progress of a future stable\nrelease so the experience might be not as smooth.\n\n\n.. class:: no-pdf\n\n|build|\n\n\nOn macOS you can install it with Homebrew:\n\n.. code-block:: bash\n\n    $ brew install httpie --HEAD\n\n\nOtherwise with ``pip``:\n\n.. code-block:: bash\n\n    $ pip install --upgrade https://github.com/jakubroztocil/httpie/archive/master.tar.gz\n\n\nVerify that now we have the\n`current development version identifier <https://github.com/jakubroztocil/httpie/blob/0af6ae1be444588bbc4747124e073423151178a0/httpie/__init__.py#L5>`_\nwith the ``-dev`` suffix, for example:\n\n.. code-block:: bash\n\n    $ http --version\n    1.0.0-dev\n\n\nUsage\n=====\n\n\nHello World:\n\n\n.. code-block:: bash\n\n    $ http httpie.org\n\n\nSynopsis:\n\n.. code-block:: bash\n\n    $ http [flags] [METHOD] URL [ITEM [ITEM]]\n\n\nSee also ``http --help``.\n\n\nExamples\n--------\n\nCustom `HTTP method`_, `HTTP headers`_ and `JSON`_ data:\n\n.. code-block:: bash\n\n    $ http PUT example.org X-API-Token:123 name=John\n\n\nSubmitting `forms`_:\n\n.. code-block:: bash\n\n    $ http -f POST example.org hello=World\n\n\nSee the request that is being sent using one of the `output options`_:\n\n.. code-block:: bash\n\n    $ http -v example.org\n\n\nUse `Github API`_ to post a comment on an\n`issue <https://github.com/jakubroztocil/httpie/issues/83>`_\nwith `authentication`_:\n\n.. code-block:: bash\n\n    $ http -a USERNAME POST https://api.github.com/repos/jakubroztocil/httpie/issues/83/comments body='HTTPie is awesome! :heart:'\n\n\nUpload a file using `redirected input`_:\n\n.. code-block:: bash\n\n    $ http example.org < file.json\n\n\nDownload a file and save it via `redirected output`_:\n\n.. code-block:: bash\n\n    $ http example.org/file > file\n\n\nDownload a file ``wget`` style:\n\n.. code-block:: bash\n\n    $ http --download example.org/file\n\nUse named `sessions`_ to make certain aspects or the communication persistent\nbetween requests to the same host:\n\n.. code-block:: bash\n\n    $ http --session=logged-in -a username:password httpbin.org/get API-Key:123\n\n    $ http --session=logged-in httpbin.org/headers\n\n\nSet a custom ``Host`` header to work around missing DNS records:\n\n.. code-block:: bash\n\n    $ http localhost:8000 Host:example.com\n\n..\n\n\nHTTP method\n===========\n\nThe name of the HTTP method comes right before the URL argument:\n\n.. code-block:: bash\n\n    $ http DELETE example.org/todos/7\n\n\nWhich looks similar to the actual ``Request-Line`` that is sent:\n\n.. code-block:: http\n\n    DELETE /todos/7 HTTP/1.1\n\n\nWhen the ``METHOD`` argument is omitted from the command, HTTPie defaults to\neither ``GET`` (with no request data) or ``POST`` (with request data).\n\n\nRequest URL\n===========\n\nThe only information HTTPie needs to perform a request is a URL.\nThe default scheme is, somewhat unsurprisingly, ``http://``,\nand can be omitted from the argument \u2013 ``http example.org`` works just fine.\n\n\nQuerystring parameters\n----------------------\n\nIf you find yourself manually constructing URLs with querystring parameters\non the terminal, you may appreciate the ``param==value`` syntax for appending\nURL parameters.\n\nWith that, you don't have to worry about escaping the ``&``\nseparators for your shell. Additionally, any special characters in the\nparameter name or value get automatically URL-escaped\n(as opposed to parameters specified in the full URL, which HTTPie doesn\u2019t\nmodify).\n\n.. code-block:: bash\n\n    $ http https://api.github.com/search/repositories q==httpie per_page==1\n\n\n.. code-block:: http\n\n    GET /search/repositories?q=httpie&per_page=1 HTTP/1.1\n\n\n\nURL shortcuts for ``localhost``\n-------------------------------\n\nAdditionally, curl-like shorthand for localhost is supported.\nThis means that, for example ``:3000`` would expand to ``http://localhost:3000``\nIf the port is omitted, then port 80 is assumed.\n\n.. code-block:: bash\n\n    $ http :/foo\n\n\n.. code-block:: http\n\n    GET /foo HTTP/1.1\n    Host: localhost\n\n\n.. code-block:: bash\n\n    $ http :3000/bar\n\n\n.. code-block:: http\n\n    GET /bar HTTP/1.1\n    Host: localhost:3000\n\n\n.. code-block:: bash\n\n    $ http :\n\n\n.. code-block:: http\n\n    GET / HTTP/1.1\n    Host: localhost\n\n\nOther default schemes\n---------------------\n\nWhen HTTPie is invoked as ``https`` then the default scheme is ``https://``\n(``$ https example.org`` will make a request to ``https://example.org``).\n\nYou can also use the ``--default-scheme <URL_SCHEME>`` option to create\nshortcuts for other protocols than HTTP (possibly supported via plugins).\nExample for the `httpie-unixsocket <https://github.com/httpie/httpie-unixsocket>`_ plugin:\n\n.. code-block:: bash\n\n    # Before\n    $ http http+unix://%2Fvar%2Frun%2Fdocker.sock/info\n\n\n.. code-block:: bash\n\n    # Create an alias\n    $ alias http-unix='http --default-scheme=\"http+unix\"'\n\n\n.. code-block:: bash\n\n    # Now the scheme can be omitted\n    $ http-unix %2Fvar%2Frun%2Fdocker.sock/info\n\nRequest items\n=============\n\nThere are a few different *request item* types that provide a\nconvenient mechanism for specifying HTTP headers, simple JSON and\nform data, files, and URL parameters.\n\nThey are key/value pairs specified after the URL. All have in\ncommon that they become part of the actual request that is sent and that\ntheir type is distinguished only by the separator used:\n``:``, ``=``, ``:=``, ``==``, ``@``, ``=@``, and ``:=@``. The ones with an\n``@`` expect a file path as value.\n\n+-----------------------+-----------------------------------------------------+\n| Item Type             | Description                                         |\n+=======================+=====================================================+\n| HTTP Headers          | Arbitrary HTTP header, e.g. ``X-API-Token:123``.    |\n| ``Name:Value``        |                                                     |\n+-----------------------+-----------------------------------------------------+\n| URL parameters        | Appends the given name/value pair as a query        |\n| ``name==value``       | string parameter to the URL.                        |\n|                       | The ``==`` separator is used.                       |\n+-----------------------+-----------------------------------------------------+\n| Data Fields           | Request data fields to be serialized as a JSON      |\n| ``field=value``,      | object (default), or to be form-encoded             |\n| ``field=@file.txt``   | (``--form, -f``).                                   |\n+-----------------------+-----------------------------------------------------+\n| Raw JSON fields       | Useful when sending JSON and one or                 |\n| ``field:=json``,      | more fields need to be a ``Boolean``, ``Number``,   |\n| ``field:=@file.json`` | nested ``Object``, or an ``Array``,  e.g.,          |\n|                       | ``meals:='[\"ham\",\"spam\"]'`` or ``pies:=[1,2,3]``    |\n|                       | (note the quotes).                                  |\n+-----------------------+-----------------------------------------------------+\n| Form File Fields      | Only available with ``--form, -f``.                 |\n| ``field@/dir/file``   | For example ``screenshot@~/Pictures/img.png``.      |\n|                       | The presence of a file field results                |\n|                       | in a ``multipart/form-data`` request.               |\n+-----------------------+-----------------------------------------------------+\n\n\nNote that data fields aren't the only way to specify request data:\n`Redirected input`_ is a mechanism for passing arbitrary request data.\n\n\nEscaping rules\n--------------\n\nYou can use ``\\`` to escape characters that shouldn't be used as separators\n(or parts thereof). For instance, ``foo\\==bar`` will become a data key/value\npair (``foo=`` and ``bar``) instead of a URL parameter.\n\nOften it is necessary to quote the values, e.g. ``foo='bar baz'``.\n\nIf any of the field names or headers starts with a minus\n(e.g., ``-fieldname``), you need to place all such items after the special\ntoken ``--`` to prevent confusion with ``--arguments``:\n\n.. code-block:: bash\n\n    $ http httpbin.org/post  --  -name-starting-with-dash=foo -Unusual-Header:bar\n\n.. code-block:: http\n\n    POST /post HTTP/1.1\n    -Unusual-Header: bar\n    Content-Type: application/json\n\n    {\n        \"-name-starting-with-dash\": \"foo\"\n    }\n\n\n\nJSON\n====\n\nJSON is the *lingua franca* of modern web services and it is also the\n**implicit content type** HTTPie uses by default.\n\n\nSimple example:\n\n.. code-block:: bash\n\n    $ http PUT example.org name=John email=john@example.org\n\n.. code-block:: http\n\n    PUT / HTTP/1.1\n    Accept: application/json, */*\n    Accept-Encoding: gzip, deflate\n    Content-Type: application/json\n    Host: example.org\n\n    {\n        \"name\": \"John\",\n        \"email\": \"john@example.org\"\n    }\n\n\nDefault behaviour\n-----------------\n\n\nIf your command includes some data `request items`_, they are serialized as a JSON\nobject by default. HTTPie also automatically sets the following headers,\nboth of which can be overwritten:\n\n================    =======================================\n``Content-Type``    ``application/json``\n``Accept``          ``application/json, */*``\n================    =======================================\n\n\nExplicit JSON\n-------------\n\nYou can use ``--json, -j`` to explicitly set ``Accept``\nto ``application/json`` regardless of whether you are sending data\n(it's a shortcut for setting the header via the usual header notation:\n``http url Accept:'application/json, */*'``). Additionally,\nHTTPie will try to detect JSON responses even when the\n``Content-Type`` is incorrectly ``text/plain`` or unknown.\n\n\n\nNon-string JSON fields\n----------------------\n\nNon-string fields use the ``:=`` separator, which allows you to embed raw JSON\ninto the resulting object. Text and raw JSON files can also be embedded into\nfields using ``=@`` and ``:=@``:\n\n.. code-block:: bash\n\n    $ http PUT api.example.com/person/1 \\\n        name=John \\\n        age:=29 married:=false hobbies:='[\"http\", \"pies\"]' \\  # Raw JSON\n        description=@about-john.txt \\   # Embed text file\n        bookmarks:=@bookmarks.json      # Embed JSON file\n\n\n.. code-block:: http\n\n    PUT /person/1 HTTP/1.1\n    Accept: application/json, */*\n    Content-Type: application/json\n    Host: api.example.com\n\n    {\n        \"age\": 29,\n        \"hobbies\": [\n            \"http\",\n            \"pies\"\n        ],\n        \"description\": \"John is a nice guy who likes pies.\",\n        \"married\": false,\n        \"name\": \"John\",\n        \"bookmarks\": {\n            \"HTTPie\": \"https://httpie.org\",\n        }\n    }\n\n\nPlease note that with this syntax the command gets unwieldy when sending\ncomplex data. In that case it's always better to use `redirected input`_:\n\n.. code-block:: bash\n\n    $ http POST api.example.com/person/1 < person.json\n\n\nForms\n=====\n\nSubmitting forms is very similar to sending `JSON`_ requests. Often the only\ndifference is in adding the ``--form, -f`` option, which ensures that\ndata fields are serialized as, and ``Content-Type`` is set to,\n``application/x-www-form-urlencoded; charset=utf-8``. It is possible to make\nform data the implicit content type instead of JSON\nvia the `config`_ file.\n\n\nRegular forms\n-------------\n\n.. code-block:: bash\n\n    $ http --form POST api.example.org/person/1 name='John Smith'\n\n\n.. code-block:: http\n\n    POST /person/1 HTTP/1.1\n    Content-Type: application/x-www-form-urlencoded; charset=utf-8\n\n    name=John+Smith\n\n\nFile upload forms\n-----------------\n\nIf one or more file fields is present, the serialization and content type is\n``multipart/form-data``:\n\n.. code-block:: bash\n\n    $ http -f POST example.com/jobs name='John Smith' cv@~/Documents/cv.pdf\n\n\nThe request above is the same as if the following HTML form were\nsubmitted:\n\n.. code-block:: html\n\n    <form enctype=\"multipart/form-data\" method=\"post\" action=\"http://example.com/jobs\">\n        <input type=\"text\" name=\"name\" />\n        <input type=\"file\" name=\"cv\" />\n    </form>\n\nNote that ``@`` is used to simulate a file upload form field, whereas\n``=@`` just embeds the file content as a regular text field value.\n\n\nHTTP headers\n============\n\nTo set custom headers you can use the ``Header:Value`` notation:\n\n.. code-block:: bash\n\n    $ http example.org  User-Agent:Bacon/1.0  'Cookie:valued-visitor=yes;foo=bar'  \\\n        X-Foo:Bar  Referer:https://httpie.org/\n\n\n.. code-block:: http\n\n    GET / HTTP/1.1\n    Accept: */*\n    Accept-Encoding: gzip, deflate\n    Cookie: valued-visitor=yes;foo=bar\n    Host: example.org\n    Referer: https://httpie.org/\n    User-Agent: Bacon/1.0\n    X-Foo: Bar\n\n\nDefault request headers\n-----------------------\n\nThere are a couple of default headers that HTTPie sets:\n\n.. code-block:: http\n\n    GET / HTTP/1.1\n    Accept: */*\n    Accept-Encoding: gzip, deflate\n    User-Agent: HTTPie/<version>\n    Host: <taken-from-URL>\n\n\n\nAny of these except ``Host`` can be overwritten and some of them unset.\n\n\n\nEmpty headers and header un-setting\n-----------------------------------\n\nTo unset a previously specified header\n(such a one of the default headers), use ``Header:``:\n\n\n.. code-block:: bash\n\n    $ http httpbin.org/headers Accept: User-Agent:\n\n\nTo send a header with an empty value, use ``Header;``:\n\n\n.. code-block:: bash\n\n    $ http httpbin.org/headers 'Header;'\n\n\nLimiting response headers\n-------------------------\n\nThe ``--max-headers=n`` options allows you to control the number of headers\nHTTPie reads before giving up (the default ``0``, i.e., there\u2019s no limit).\n\n\n.. code-block:: bash\n\n    $ http --max-headers=100 httpbin.org/get\n\n\n\nCookies\n=======\n\nHTTP clients send cookies to the server as regular `HTTP headers`_. That means,\nHTTPie does not offer any special syntax for specifying cookies \u2014 the usual\n``Header:Value`` notation is used:\n\n\nSend a single cookie:\n\n.. code-block:: bash\n\n    $ http example.org Cookie:sessionid=foo\n\n.. code-block:: http\n\n    GET / HTTP/1.1\n    Accept: */*\n    Accept-Encoding: gzip, deflate\n    Connection: keep-alive\n    Cookie: sessionid=foo\n    Host: example.org\n    User-Agent: HTTPie/0.9.9\n\n\nSend multiple cookies\n(note the header is quoted to prevent the shell from interpreting the ``;``):\n\n.. code-block:: bash\n\n    $ http example.org 'Cookie:sessionid=foo;another-cookie=bar'\n\n.. code-block:: http\n\n    GET / HTTP/1.1\n    Accept: */*\n    Accept-Encoding: gzip, deflate\n    Connection: keep-alive\n    Cookie: sessionid=foo;another-cookie=bar\n    Host: example.org\n    User-Agent: HTTPie/0.9.9\n\n\nIf you often deal with cookies in your requests, then chances are you'd appreciate\nthe `sessions`_ feature.\n\n\nAuthentication\n==============\n\nThe currently supported authentication schemes are Basic and Digest\n(see `auth plugins`_ for more). There are two flags that control authentication:\n\n===================     ======================================================\n``--auth, -a``          Pass a ``username:password`` pair as\n                        the argument. Or, if you only specify a username\n                        (``-a username``), you'll be prompted for\n                        the password before the request is sent.\n                        To send an empty password, pass ``username:``.\n                        The ``username:password@hostname`` URL syntax is\n                        supported as well (but credentials passed via ``-a``\n                        have higher priority).\n\n``--auth-type, -A``     Specify the auth mechanism. Possible values are\n                        ``basic`` and ``digest``. The default value is\n                        ``basic`` so it can often be omitted.\n===================     ======================================================\n\n\n\nBasic auth\n----------\n\n\n.. code-block:: bash\n\n    $ http -a username:password example.org\n\n\nDigest auth\n-----------\n\n\n.. code-block:: bash\n\n    $ http -A digest -a username:password example.org\n\n\nPassword prompt\n---------------\n\n.. code-block:: bash\n\n    $ http -a username example.org\n\n\n``.netrc``\n----------\n\nAuthentication information from your ``~/.netrc``\nfile is by default honored as well.\n\nFor example:\n\n.. code-block:: bash\n\n    $ cat ~/.netrc\n    machine httpbin.org\n    login httpie\n    password test\n\n.. code-block:: bash\n\n    $ http httpbin.org/basic-auth/httpie/test\n    HTTP/1.1 200 OK\n    [...]\n\nThis can be disabled with the ``--ignore-netrc`` option:\n\n.. code-block:: bash\n\n    $ http --ignore-netrc httpbin.org/basic-auth/httpie/test\n    HTTP/1.1 401 UNAUTHORIZED\n    [...]\n\n\nAuth plugins\n------------\n\nAdditional authentication mechanism can be installed as plugins.\nThey can be found on the `Python Package Index <https://pypi.python.org/pypi?%3Aaction=search&term=httpie&submit=search>`_.\nHere's a few picks:\n\n* `httpie-api-auth <https://github.com/pd/httpie-api-auth>`_: ApiAuth\n* `httpie-aws-auth <https://github.com/httpie/httpie-aws-auth>`_: AWS / Amazon S3\n* `httpie-edgegrid <https://github.com/akamai-open/httpie-edgegrid>`_: EdgeGrid\n* `httpie-hmac-auth <https://github.com/guardian/httpie-hmac-auth>`_: HMAC\n* `httpie-jwt-auth <https://github.com/teracyhq/httpie-jwt-auth>`_: JWTAuth (JSON Web Tokens)\n* `httpie-negotiate <https://github.com/ndzou/httpie-negotiate>`_: SPNEGO (GSS Negotiate)\n* `httpie-ntlm <https://github.com/httpie/httpie-ntlm>`_: NTLM (NT LAN Manager)\n* `httpie-oauth <https://github.com/httpie/httpie-oauth>`_: OAuth\n* `requests-hawk <https://github.com/mozilla-services/requests-hawk>`_: Hawk\n\n\n\n\nHTTP redirects\n==============\n\nBy default, HTTP redirects are not followed and only the first\nresponse is shown:\n\n\n.. code-block:: bash\n\n    $ http httpbin.org/redirect/3\n\n\nFollow ``Location``\n-------------------\n\nTo instruct HTTPie to follow the ``Location`` header of ``30x`` responses\nand show the final response instead, use the ``--follow, -F`` option:\n\n\n.. code-block:: bash\n\n    $ http --follow httpbin.org/redirect/3\n\n\nShowing intermediary redirect responses\n---------------------------------------\n\nIf you additionally wish to see the intermediary requests/responses,\nthen use the ``--all`` option as well:\n\n\n.. code-block:: bash\n\n    $ http --follow --all httpbin.org/redirect/3\n\n\n\nLimiting maximum redirects followed\n-----------------------------------\n\nTo change the default limit of maximum ``30`` redirects, use the\n``--max-redirects=<limit>`` option:\n\n\n.. code-block:: bash\n\n    $ http --follow --all --max-redirects=5 httpbin.org/redirect/3\n\n\nProxies\n=======\n\nYou can specify proxies to be used through the ``--proxy`` argument for each\nprotocol (which is included in the value in case of redirects across protocols):\n\n.. code-block:: bash\n\n    $ http --proxy=http:http://10.10.1.10:3128 --proxy=https:https://10.10.1.10:1080 example.org\n\n\nWith Basic authentication:\n\n.. code-block:: bash\n\n    $ http --proxy=http:http://user:pass@10.10.1.10:3128 example.org\n\n\nEnvironment variables\n---------------------\n\nYou can also configure proxies by environment variables ``ALL_PROXY``,\n``HTTP_PROXY`` and ``HTTPS_PROXY``, and the underlying Requests library will\npick them up as well. If you want to disable proxies configured through\nthe environment variables for certain hosts, you can specify them in ``NO_PROXY``.\n\nIn your ``~/.bash_profile``:\n\n.. code-block:: bash\n\n export HTTP_PROXY=http://10.10.1.10:3128\n export HTTPS_PROXY=https://10.10.1.10:1080\n export NO_PROXY=localhost,example.com\n\n\nSOCKS\n-----\n\nHomebrew-installed HTTPie comes with SOCKS proxy support out of the box.\nTo enable SOCKS proxy support for non-Homebrew  installations, you'll\nmight need to install ``requests[socks]`` manually using ``pip``:\n\n\n.. code-block:: bash\n\n    $ pip install -U requests[socks]\n\nUsage is the same as for other types of `proxies`_:\n\n.. code-block:: bash\n\n    $ http --proxy=http:socks5://user:pass@host:port --proxy=https:socks5://user:pass@host:port example.org\n\n\nHTTPS\n=====\n\n\nServer SSL certificate verification\n-----------------------------------\n\nTo skip the host's SSL certificate verification, you can pass ``--verify=no``\n(default is ``yes``):\n\n.. code-block:: bash\n\n    $ http --verify=no https://example.org\n\n\nCustom CA bundle\n----------------\n\nYou can also use ``--verify=<CA_BUNDLE_PATH>`` to set a custom CA bundle path:\n\n.. code-block:: bash\n\n    $ http --verify=/ssl/custom_ca_bundle https://example.org\n\n\n\nClient side SSL certificate\n---------------------------\nTo use a client side certificate for the SSL communication, you can pass\nthe path of the cert file with ``--cert``:\n\n.. code-block:: bash\n\n    $ http --cert=client.pem https://example.org\n\n\nIf the private key is not contained in the cert file you may pass the\npath of the key file with ``--cert-key``:\n\n.. code-block:: bash\n\n    $ http --cert=client.crt --cert-key=client.key https://example.org\n\n\nSSL version\n-----------\n\nUse the ``--ssl=<PROTOCOL>`` to specify the desired protocol version to use.\nThis will default to SSL v2.3 which will negotiate the highest protocol that both\nthe server and your installation of OpenSSL support. The available protocols\nare ``ssl2.3``, ``ssl3``, ``tls1``, ``tls1.1``, ``tls1.2``, ``tls1.3``. (The actually\navailable set of protocols may vary depending on your OpenSSL installation.)\n\n.. code-block:: bash\n\n    # Specify the vulnerable SSL v3 protocol to talk to an outdated server:\n    $ http --ssl=ssl3 https://vulnerable.example.org\n\n\nOutput options\n==============\n\nBy default, HTTPie only outputs the final response and the whole response\nmessage is printed (headers as well as the body). You can control what should\nbe printed via several options:\n\n=================   =====================================================\n``--headers, -h``   Only the response headers are printed.\n``--body, -b``      Only the response body is printed.\n``--verbose, -v``   Print the whole HTTP exchange (request and response).\n                    This option also enables ``--all`` (see below).\n``--print, -p``     Selects parts of the HTTP exchange.\n=================   =====================================================\n\n``--verbose`` can often be useful for debugging the request and generating\ndocumentation examples:\n\n.. code-block:: bash\n\n    $ http --verbose PUT httpbin.org/put hello=world\n    PUT /put HTTP/1.1\n    Accept: application/json, */*\n    Accept-Encoding: gzip, deflate\n    Content-Type: application/json\n    Host: httpbin.org\n    User-Agent: HTTPie/0.2.7dev\n\n    {\n        \"hello\": \"world\"\n    }\n\n\n    HTTP/1.1 200 OK\n    Connection: keep-alive\n    Content-Length: 477\n    Content-Type: application/json\n    Date: Sun, 05 Aug 2012 00:25:23 GMT\n    Server: gunicorn/0.13.4\n\n    {\n        [\u2026]\n    }\n\n\nWhat parts of the HTTP exchange should be printed\n-------------------------------------------------\n\nAll the other `output options`_ are under the hood just shortcuts for\nthe more powerful ``--print, -p``. It accepts a string of characters each\nof which represents a specific part of the HTTP exchange:\n\n==========  ==================\nCharacter   Stands for\n==========  ==================\n``H``       request headers\n``B``       request body\n``h``       response headers\n``b``       response body\n==========  ==================\n\nPrint request and response headers:\n\n.. code-block:: bash\n\n    $ http --print=Hh PUT httpbin.org/put hello=world\n\n\nViewing intermediary requests/responses\n---------------------------------------\n\nTo see all the HTTP communication, i.e. the final request/response as\nwell as any possible  intermediary requests/responses, use the ``--all``\noption. The intermediary HTTP communication include followed redirects\n(with ``--follow``), the first unauthorized request when HTTP digest\nauthentication is used (``--auth=digest``), etc.\n\n.. code-block:: bash\n\n    # Include all responses that lead to the final one:\n    $ http --all --follow httpbin.org/redirect/3\n\n\nThe intermediary requests/response are by default formatted according to\n``--print, -p`` (and its shortcuts described above). If you'd like to change\nthat, use the ``--history-print, -P`` option. It takes the same\narguments as ``--print, -p`` but applies to the intermediary requests only.\n\n\n.. code-block:: bash\n\n    # Print the intermediary requests/responses differently than the final one:\n    $ http -A digest -a foo:bar --all -p Hh -P H httpbin.org/digest-auth/auth/foo/bar\n\n\nConditional body download\n-------------------------\n\nAs an optimization, the response body is downloaded from the server\nonly if it's part of the output. This is similar to performing a ``HEAD``\nrequest, except that it applies to any HTTP method you use.\n\nLet's say that there is an API that returns the whole resource when it is\nupdated, but you are only interested in the response headers to see the\nstatus code after an update:\n\n.. code-block:: bash\n\n    $ http --headers PATCH example.org/Really-Huge-Resource name='New Name'\n\n\nSince we are only printing the HTTP headers here, the connection to the server\nis closed as soon as all the response headers have been received.\nTherefore, bandwidth and time isn't wasted downloading the body\nwhich you don't care about. The response headers are downloaded always,\neven if they are not part of the output\n\n\nRedirected Input\n================\n\nThe universal method for passing request data is through redirected ``stdin``\n(standard input)\u2014piping. Such data is buffered and then with no further\nprocessing used as the request body. There are multiple useful ways to use\npiping:\n\nRedirect from a file:\n\n.. code-block:: bash\n\n    $ http PUT example.com/person/1 X-API-Token:123 < person.json\n\n\nOr the output of another program:\n\n.. code-block:: bash\n\n    $ grep '401 Unauthorized' /var/log/httpd/error_log | http POST example.org/intruders\n\n\nYou can use ``echo`` for simple data:\n\n.. code-block:: bash\n\n    $ echo '{\"name\": \"John\"}' | http PATCH example.com/person/1 X-API-Token:123\n\n\nYou can also use a Bash *here string*:\n\n.. code-block:: bash\n\n    $ http example.com/ <<<'{\"name\": \"John\"}'\n\n\nYou can even pipe web services together using HTTPie:\n\n.. code-block:: bash\n\n    $ http GET https://api.github.com/repos/jakubroztocil/httpie | http POST httpbin.org/post\n\n\nYou can use ``cat`` to enter multiline data on the terminal:\n\n.. code-block:: bash\n\n    $ cat | http POST example.com\n    <paste>\n    ^D\n\n\n.. code-block:: bash\n\n    $ cat | http POST example.com/todos Content-Type:text/plain\n    - buy milk\n    - call parents\n    ^D\n\n\nOn OS X, you can send the contents of the clipboard with ``pbpaste``:\n\n.. code-block:: bash\n\n    $ pbpaste | http PUT example.com\n\n\nPassing data through ``stdin`` cannot be combined with data fields specified\non the command line:\n\n\n.. code-block:: bash\n\n    $ echo 'data' | http POST example.org more=data   # This is invalid\n\n\nTo prevent HTTPie from reading ``stdin`` data you can use the\n``--ignore-stdin`` option.\n\n\nRequest data from a filename\n----------------------------\n\nAn alternative to redirected ``stdin`` is specifying a filename (as\n``@/path/to/file``) whose content is used as if it came from ``stdin``.\n\nIt has the advantage that the ``Content-Type``\nheader is automatically set to the appropriate value based on the\nfilename extension. For example, the following request sends the\nverbatim contents of that XML file with ``Content-Type: application/xml``:\n\n.. code-block:: bash\n\n    $ http PUT httpbin.org/put @/data/file.xml\n\n\nTerminal output\n===============\n\nHTTPie does several things by default in order to make its terminal output\neasy to read.\n\n\nColors and formatting\n---------------------\n\nSyntax highlighting is applied to HTTP headers and bodies (where it makes\nsense). You can choose your preferred color scheme via the ``--style`` option\nif you don't like the default one (see ``$ http --help`` for the possible\nvalues).\n\nAlso, the following formatting is applied:\n\n* HTTP headers are sorted by name.\n* JSON data is indented, sorted by keys, and unicode escapes are converted\n  to the characters they represent.\n\nOne of these options can be used to control output processing:\n\n====================   ========================================================\n``--pretty=all``       Apply both colors and formatting.\n                       Default for terminal output.\n``--pretty=colors``    Apply colors.\n``--pretty=format``    Apply formatting.\n``--pretty=none``      Disables output processing.\n                       Default for redirected output.\n====================   ========================================================\n\nBinary data\n-----------\n\nBinary data is suppressed for terminal output, which makes it safe to perform\nrequests to URLs that send back binary data. Binary data is suppressed also in\nredirected, but prettified output. The connection is closed as soon as we know\nthat the response body is binary,\n\n.. code-block:: bash\n\n    $ http example.org/Movie.mov\n\n\nYou will nearly instantly see something like this:\n\n.. code-block:: http\n\n    HTTP/1.1 200 OK\n    Accept-Ranges: bytes\n    Content-Encoding: gzip\n    Content-Type: video/quicktime\n    Transfer-Encoding: chunked\n\n    +-----------------------------------------+\n    | NOTE: binary data not shown in terminal |\n    +-----------------------------------------+\n\n\nRedirected output\n=================\n\nHTTPie uses a different set of defaults for redirected output than for\n`terminal output`_. The differences being:\n\n* Formatting and colors aren't applied (unless ``--pretty`` is specified).\n* Only the response body is printed (unless one of the `output options`_ is set).\n* Also, binary data isn't suppressed.\n\nThe reason is to make piping HTTPie's output to another programs and\ndownloading files work with no extra flags. Most of the time, only the raw\nresponse body is of an interest when the output is redirected.\n\nDownload a file:\n\n.. code-block:: bash\n\n    $ http example.org/Movie.mov > Movie.mov\n\n\nDownload an image of Octocat, resize it using ImageMagick, upload it elsewhere:\n\n.. code-block:: bash\n\n    $ http octodex.github.com/images/original.jpg | convert - -resize 25% -  | http example.org/Octocats\n\n\nForce colorizing and formatting, and show both the request and the response in\n``less`` pager:\n\n.. code-block:: bash\n\n    $ http --pretty=all --verbose example.org | less -R\n\n\nThe ``-R`` flag tells ``less`` to interpret color escape sequences included\nHTTPie`s output.\n\nYou can create a shortcut for invoking HTTPie with colorized and paged output\nby adding the following to your ``~/.bash_profile``:\n\n.. code-block:: bash\n\n    function httpless {\n        # `httpless example.org'\n        http --pretty=all --print=hb \"$@\" | less -R;\n    }\n\n\nDownload mode\n=============\n\nHTTPie features a download mode in which it acts similarly to ``wget``.\n\nWhen enabled using the ``--download, -d`` flag, response headers are printed to\nthe terminal (``stderr``), and a progress bar is shown while the response body\nis being saved to a file.\n\n.. code-block:: bash\n\n    $ http --download https://github.com/jakubroztocil/httpie/archive/master.tar.gz\n\n.. code-block:: http\n\n    HTTP/1.1 200 OK\n    Content-Disposition: attachment; filename=httpie-master.tar.gz\n    Content-Length: 257336\n    Content-Type: application/x-gzip\n\n    Downloading 251.30 kB to \"httpie-master.tar.gz\"\n    Done. 251.30 kB in 2.73862s (91.76 kB/s)\n\n\nDownloaded filename\n--------------------\n\nThere are three mutually exclusive ways through which HTTPie determines\nthe output filename (with decreasing priority):\n\n1. You can explicitly provide it via ``--output, -o``.\n   The file gets overwritten if it already exists\n   (or appended to with ``--continue, -c``).\n2. The server may specify the filename in the optional ``Content-Disposition``\n   response header. Any leading dots are stripped from a server-provided filename.\n3. The last resort HTTPie uses is to generate the filename from a combination\n   of the request URL and the response ``Content-Type``.\n   The initial URL is always used as the basis for\n   the generated filename \u2014 even if there has been one or more redirects.\n\n\nTo prevent data loss by overwriting, HTTPie adds a unique numerical suffix to the\nfilename when necessary (unless specified with ``--output, -o``).\n\n\nPiping while downloading\n------------------------\n\nYou can also redirect the response body to another program while the response\nheaders and progress are still shown in the terminal:\n\n.. code-block:: bash\n\n    $ http -d https://github.com/jakubroztocil/httpie/archive/master.tar.gz |  tar zxf -\n\n\n\nResuming downloads\n------------------\n\nIf ``--output, -o`` is specified, you can resume a partial download using the\n``--continue, -c`` option. This only works with servers that support\n``Range`` requests and ``206 Partial Content`` responses. If the server doesn't\nsupport that, the whole file will simply be downloaded:\n\n.. code-block:: bash\n\n    $ http -dco file.zip example.org/file\n\nOther notes\n-----------\n\n* The ``--download`` option only changes how the response body is treated.\n* You can still set custom headers, use sessions, ``--verbose, -v``, etc.\n* ``--download`` always implies ``--follow`` (redirects are followed).\n* HTTPie exits with status code ``1`` (error) if the body hasn't been fully\n  downloaded.\n* ``Accept-Encoding`` cannot be set with ``--download``.\n\n\nStreamed responses\n==================\n\nResponses are downloaded and printed in chunks which allows for streaming\nand large file downloads without using too much memory. However, when\n`colors and formatting`_ is applied, the whole response is buffered and only\nthen processed at once.\n\n\nDisabling buffering\n-------------------\n\nYou can use the ``--stream, -S`` flag to make two things happen:\n\n1. The output is flushed in much smaller chunks without any buffering,\n   which makes HTTPie behave kind of like ``tail -f`` for URLs.\n\n2. Streaming becomes enabled even when the output is prettified: It will be\n   applied to each line of the response and flushed immediately. This makes\n   it possible to have a nice output for long-lived requests, such as one\n   to the Twitter streaming API.\n\n\nExamples use cases\n------------------\n\nPrettified streamed response:\n\n.. code-block:: bash\n\n    $ http --stream -f -a YOUR-TWITTER-NAME https://stream.twitter.com/1/statuses/filter.json track='Justin Bieber'\n\n\nStreamed output by small chunks al\u00e1 ``tail -f``:\n\n.. code-block:: bash\n\n    # Send each new tweet (JSON object) mentioning \"Apple\" to another\n    # server as soon as it arrives from the Twitter streaming API:\n    $ http --stream -f -a YOUR-TWITTER-NAME https://stream.twitter.com/1/statuses/filter.json track=Apple \\\n    | while read tweet; do echo \"$tweet\" | http POST example.org/tweets ; done\n\nSessions\n========\n\nBy default, every request HTTPie makes is completely independent of any\nprevious ones to the same host.\n\n\nHowever, HTTPie also supports persistent\nsessions via the ``--session=SESSION_NAME_OR_PATH`` option. In a session,\ncustom `HTTP headers`_ (except for the ones starting with ``Content-`` or ``If-``),\n`authentication`_, and `cookies`_\n(manually specified or sent by the server) persist between requests\nto the same host.\n\n\n.. code-block:: bash\n\n    # Create a new session\n    $ http --session=/tmp/session.json example.org API-Token:123\n\n    # Re-use an existing session \u2014 API-Token will be set:\n    $ http --session=/tmp/session.json example.org\n\n\nAll session data, including credentials, cookie data,\nand custom headers are stored in plain text.\nThat means session files can also be created and edited manually in a text\neditor\u2014they are regular JSON. It also means that they can be read by anyone\nwho has access to the session file.\n\n\nNamed sessions\n--------------\n\n\nYou can create one or more named session per host. For example, this is how\nyou can create a new session named ``user1`` for ``example.org``:\n\n.. code-block:: bash\n\n    $ http --session=user1 -a user1:password example.org X-Foo:Bar\n\nFrom now on, you can refer to the session by its name. When you choose to\nuse the session again, any previously specified authentication or HTTP headers\nwill automatically be set:\n\n.. code-block:: bash\n\n    $ http --session=user1 example.org\n\nTo create or reuse a different session, simple specify a different name:\n\n.. code-block:: bash\n\n    $ http --session=user2 -a user2:password example.org X-Bar:Foo\n\nNamed sessions\u2019s data is stored in JSON files in the the ``sessions``\nsubdirectory of the `config`_ directory:\n``~/.httpie/sessions/<host>/<name>.json``\n(``%APPDATA%\\httpie\\sessions\\<host>\\<name>.json`` on Windows).\n\n\nAnonymous sessions\n------------------\n\nInstead of a name, you can also directly specify a path to a session file. This\nallows for sessions to be re-used across multiple hosts:\n\n.. code-block:: bash\n\n    $ http --session=/tmp/session.json example.org\n    $ http --session=/tmp/session.json admin.example.org\n    $ http --session=~/.httpie/sessions/another.example.org/test.json example.org\n    $ http --session-read-only=/tmp/session.json example.org\n\n\nReadonly session\n----------------\n\nTo use an existing session file without updating it from the request/response\nexchange once it is created, specify the session name via\n``--session-read-only=SESSION_NAME_OR_PATH`` instead.\n\n\nConfig\n======\n\nHTTPie uses a simple ``config.json`` file. The file doesn\u2019t exist by default\nbut you can create it manually.\n\n\nConfig file directory\n---------------------\n\nThe default location of the configuration file is ``~/.httpie/config.json``\n(or ``%APPDATA%\\httpie\\config.json`` on Windows).\n\nThe config directory can be changed by setting the ``$HTTPIE_CONFIG_DIR``\nenvironment variable:\n\n.. code-block:: bash\n\n    $ export HTTPIE_CONFIG_DIR=/tmp/httpie\n    $ http example.org\n\nTo view the exact location run ``http --debug``.\n\n\nConfigurable options\n--------------------\n\nCurrently HTTPie offers a single configurable option:\n\n\n``default_options``\n~~~~~~~~~~~~~~~~~~~\n\nAn ``Array`` (by default empty) of default options that should be applied to\nevery invocation of HTTPie.\n\nFor instance, you can use this config option to change your default color theme:\n\n\n.. code-block:: bash\n\n    $ cat ~/.httpie/config.json\n\n\n.. code-block:: json\n\n    {\n        \"default_options\": [\n          \"--style=fruity\"\n        ]\n    }\n\n\nEven though it is technically possible to include there any of HTTPie\u2019s\noptions, it is not recommended to modify the default behaviour in a way\nthat would break your compatibility with the wider world as that can\ngenerate a lot of confusion.\n\n\nUn-setting previously specified options\n---------------------------------------\n\nDefault options from the config file, or specified any other way,\ncan be unset for a particular invocation via ``--no-OPTION`` arguments passed\non the command line (e.g., ``--no-style`` or ``--no-session``).\n\n\n\nScripting\n=========\n\nWhen using HTTPie from shell scripts, it can be handy to set the\n``--check-status`` flag. It instructs HTTPie to exit with an error if the\nHTTP status is one of ``3xx``, ``4xx``, or ``5xx``. The exit status will\nbe ``3`` (unless ``--follow`` is set), ``4``, or ``5``,\nrespectively.\n\n.. code-block:: bash\n\n    #!/bin/bash\n\n    if http --check-status --ignore-stdin --timeout=2.5 HEAD example.org/health &> /dev/null; then\n        echo 'OK!'\n    else\n        case $? in\n            2) echo 'Request timed out!' ;;\n            3) echo 'Unexpected HTTP 3xx Redirection!' ;;\n            4) echo 'HTTP 4xx Client Error!' ;;\n            5) echo 'HTTP 5xx Server Error!' ;;\n            6) echo 'Exceeded --max-redirects=<n> redirects!' ;;\n            *) echo 'Other Error!' ;;\n        esac\n    fi\n\n\nBest practices\n--------------\n\nThe default behaviour of automatically reading ``stdin`` is typically not\ndesirable during non-interactive invocations. You most likely want to\nuse the ``--ignore-stdin`` option to disable it.\n\nIt is a common gotcha that without this option HTTPie seemingly hangs.\nWhat happens is that when HTTPie is invoked for example from a cron job,\n``stdin`` is not connected to a terminal.\nTherefore, rules for `redirected input`_ apply, i.e., HTTPie starts to read it\nexpecting that the request body will be passed through.\nAnd since there's no data nor ``EOF``, it will be stuck. So unless you're\npiping some data to HTTPie, this flag should be used in scripts.\n\nAlso, it might be good to set a connection ``--timeout`` limit to prevent\nyour program from hanging if the server never responds.\n\n\n\nMeta\n====\n\nInterface design\n----------------\n\nThe syntax of the command arguments closely corresponds to the actual HTTP\nrequests sent over the wire. It has the advantage  that it's easy to remember\nand read. It is often possible to translate an HTTP request to an HTTPie\nargument list just by inlining the request elements. For example, compare this\nHTTP request:\n\n.. code-block:: http\n\n    POST /collection HTTP/1.1\n    X-API-Key: 123\n    User-Agent: Bacon/1.0\n    Content-Type: application/x-www-form-urlencoded\n\n    name=value&name2=value2\n\n\nwith the HTTPie command that sends it:\n\n.. code-block:: bash\n\n    $ http -f POST example.org/collection \\\n      X-API-Key:123 \\\n      User-Agent:Bacon/1.0 \\\n      name=value \\\n      name2=value2\n\n\nNotice that both the order of elements and the syntax is very similar,\nand that only a small portion of the command is used to control HTTPie and\ndoesn't directly correspond to any part of the request (here it's only ``-f``\nasking HTTPie to send a form request).\n\nThe two modes, ``--pretty=all`` (default for terminal) and ``--pretty=none``\n(default for redirected output), allow for both user-friendly interactive use\nand usage from scripts, where HTTPie serves as a generic HTTP client.\n\nAs HTTPie is still under heavy development, the existing command line\nsyntax and some of the ``--OPTIONS`` may change slightly before\nHTTPie reaches its final version ``1.0``. All changes are recorded in the\n`change log`_.\n\n\n\nUser support\n------------\n\nPlease use the following support channels:\n\n* `GitHub issues <https://github.com/jkbr/httpie/issues>`_\n  for bug reports and feature requests.\n* `Our Gitter chat room <https://gitter.im/jkbrzt/httpie>`_\n  to ask questions, discuss features, and for general discussion.\n* `StackOverflow <https://stackoverflow.com>`_\n  to ask questions (please make sure to use the\n  `httpie <https://stackoverflow.com/questions/tagged/httpie>`_ tag).\n* Tweet directly to `@clihttp <https://twitter.com/clihttp>`_.\n* You can also tweet directly to `@jakubroztocil`_.\n\n\nRelated projects\n----------------\n\nDependencies\n~~~~~~~~~~~~\n\nUnder the hood, HTTPie uses these two amazing libraries:\n\n* `Requests <https://python-requests.org>`_\n  \u2014 Python HTTP library for humans\n* `Pygments <https://pygments.org/>`_\n  \u2014 Python syntax highlighter\n\n\nHTTPie friends\n~~~~~~~~~~~~~~\n\nHTTPie plays exceptionally well with the following tools:\n\n* `jq <https://stedolan.github.io/jq/>`_\n  \u2014 CLI JSON processor that\n  works great in conjunction with HTTPie\n* `http-prompt <https://github.com/eliangcs/http-prompt>`_\n  \u2014  interactive shell for HTTPie featuring autocomplete\n  and command syntax highlighting\n\n\nAlternatives\n~~~~~~~~~~~~\n\n* `httpcat <https://github.com/jakubroztocil/httpcat>`_ \u2014 a lower-level sister utility\n  of HTTPie for constructing raw HTTP requests on the command line.\n* `curl <https://curl.haxx.se>`_ \u2014 a \"Swiss knife\" command line tool and\n  an exceptional library for transferring data with URLs.\n\n\nContributing\n------------\n\nSee `CONTRIBUTING.rst <https://github.com/jakubroztocil/httpie/blob/master/CONTRIBUTING.rst>`_.\n\n\nChange log\n----------\n\nSee `CHANGELOG <https://github.com/jakubroztocil/httpie/blob/master/CHANGELOG.rst>`_.\n\n\nArtwork\n-------\n\n* `Logo <https://github.com/claudiatd/httpie-artwork>`_ by `Cl\u00e1udia Delgado <https://github.com/claudiatd>`_.\n* `Animation <https://raw.githubusercontent.com/jakubroztocil/httpie/master/httpie.gif>`_ by `Allen Smith <https://github.com/loranallensmith>`_ of GitHub.\n\n\n\nLicence\n-------\n\nBSD-3-Clause: `LICENSE <https://github.com/jakubroztocil/httpie/blob/master/LICENSE>`_.\n\n\n\nAuthors\n-------\n\n`Jakub Roztocil`_  (`@jakubroztocil`_) created HTTPie and `these fine people`_\nhave contributed.\n\n\n.. _pip: https://pip.pypa.io/en/stable/installing/\n.. _Github API: https://developer.github.com/v3/issues/comments/#create-a-comment\n.. _these fine people: https://github.com/jakubroztocil/httpie/contributors\n.. _Jakub Roztocil: https://roztocil.co\n.. _@jakubroztocil: https://twitter.com/jakubroztocil\n\n\n.. |pypi| image:: https://img.shields.io/pypi/v/httpie.svg?style=flat-square&label=latest%20stable%20version\n    :target: https://pypi.python.org/pypi/httpie\n    :alt: Latest version released on PyPi\n\n.. |coverage| image:: https://img.shields.io/codecov/c/github/jakubroztocil/httpie?style=flat-square\n    :target: https://codecov.io/gh/jakubroztocil/httpie\n    :alt: Test coverage\n\n.. |build| image:: https://github.com/jakubroztocil/httpie/workflows/Build/badge.svg\n    :target: https://github.com/jakubroztocil/httpie/actions\n    :alt: Build status of the master branch on Mac/Linux/Windows\n\n.. |gitter| image:: https://img.shields.io/gitter/room/jkbrzt/httpie.svg?style=flat-square\n    :target: https://gitter.im/jkbrzt/httpie\n    :alt: Chat on Gitter\n\n.. |downloads| image:: https://pepy.tech/badge/httpie\n    :target: https://pepy.tech/project/httpie\n    :alt: Download count\n\n"}, {"repo": "josephmisiti/awesome-machine-learning", "language": "Python", "readme_contents": "# Awesome Machine Learning [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated list of awesome machine learning frameworks, libraries and software (by language). Inspired by `awesome-php`.\n\nIf you want to contribute to this list (please do), send me a pull request or contact me [@josephmisiti](https://twitter.com/josephmisiti).\nAlso, a listed repository should be deprecated if:\n\n* Repository's owner explicitly say that \"this library is not maintained\".\n* Not committed for long time (2~3 years).\n\nFurther resources:\n\n* For a list of free machine learning books available for download, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md).\n\n* For a list of (mostly) free machine learning courses available online, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/courses.md).\n\n* For a list of blogs and newsletters on data science and machine learning, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/blogs.md).\n\n* For a list of free-to-attend meetups and local events, go [here](https://github.com/josephmisiti/awesome-machine-learning/blob/master/meetups.md).\n\n## Table of Contents\n\n### Frameworks and Libraries\n<!-- MarkdownTOC depth=4 -->\n\n- [Awesome Machine Learning ![Awesome](https://github.com/sindresorhus/awesome)](#awesome-machine-learning-awesomehttpsgithubcomsindresorhusawesome)\n  - [Table of Contents](#table-of-contents)\n    - [Frameworks and Libraries](#frameworks-and-libraries)\n    - [Tools](#tools)\n  - [APL](#apl)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning)\n  - [C](#c)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-1)\n      - [Computer Vision](#computer-vision)\n  - [C++](#c)\n      - [Computer Vision](#computer-vision-1)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-2)\n      - [Natural Language Processing](#natural-language-processing)\n      - [Speech Recognition](#speech-recognition)\n      - [Sequence Analysis](#sequence-analysis)\n      - [Gesture Detection](#gesture-detection)\n  - [Common Lisp](#common-lisp)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-3)\n  - [Clojure](#clojure)\n      - [Natural Language Processing](#natural-language-processing-1)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-4)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization)\n  - [Crystal](#crystal)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-5)\n  - [Elixir](#elixir)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-6)\n      - [Natural Language Processing](#natural-language-processing-2)\n  - [Erlang](#erlang)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-7)\n  - [Go](#go)\n      - [Natural Language Processing](#natural-language-processing-3)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-8)\n      - [Spatial analysis and geometry](#spatial-analysis-and-geometry)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-1)\n      - [Computer vision](#computer-vision-2)\n  - [Haskell](#haskell)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-9)\n  - [Java](#java)\n      - [Natural Language Processing](#natural-language-processing-4)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-10)\n      - [Speech Recognition](#speech-recognition-1)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-2)\n      - [Deep Learning](#deep-learning)\n  - [Javascript](#javascript)\n      - [Natural Language Processing](#natural-language-processing-5)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-3)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-11)\n      - [Misc](#misc)\n      - [Demos and Scripts](#demos-and-scripts)\n  - [Julia](#julia)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-12)\n      - [Natural Language Processing](#natural-language-processing-6)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-4)\n      - [Misc Stuff / Presentations](#misc-stuff--presentations)\n  - [Lua](#lua)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-13)\n      - [Demos and Scripts](#demos-and-scripts-1)\n  - [Matlab](#matlab)\n      - [Computer Vision](#computer-vision-3)\n      - [Natural Language Processing](#natural-language-processing-7)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-14)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-5)\n  - [.NET](#net)\n      - [Computer Vision](#computer-vision-4)\n      - [Natural Language Processing](#natural-language-processing-8)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-15)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-6)\n  - [Objective C](#objective-c)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-16)\n  - [OCaml](#ocaml)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-17)\n  - [Perl](#perl)\n    - [Data Analysis / Data Visualization](#data-analysis--data-visualization-7)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-18)\n  - [Perl 6](#perl-6)\n    - [Data Analysis / Data Visualization](#data-analysis--data-visualization-8)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-19)\n  - [PHP](#php)\n    - [Natural Language Processing](#natural-language-processing-9)\n    - [General-Purpose Machine Learning](#general-purpose-machine-learning-20)\n  - [Python](#python)\n      - [Computer Vision](#computer-vision-5)\n      - [Natural Language Processing](#natural-language-processing-10)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-21)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-9)\n      - [Misc Scripts / iPython Notebooks / Codebases](#misc-scripts--ipython-notebooks--codebases)\n      - [Neural Networks](#neural-networks)\n      - [Kaggle Competition Source Code](#kaggle-competition-source-code)\n      - [Reinforcement Learning](#reinforcement-learning)\n  - [Ruby](#ruby)\n      - [Natural Language Processing](#natural-language-processing-11)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-22)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-10)\n      - [Misc](#misc-1)\n  - [Rust](#rust)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-23)\n  - [R](#r)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-24)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-11)\n  - [SAS](#sas)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-25)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-12)\n      - [Natural Language Processing](#natural-language-processing-12)\n      - [Demos and Scripts](#demos-and-scripts-2)\n  - [Scala](#scala)\n      - [Natural Language Processing](#natural-language-processing-13)\n      - [Data Analysis / Data Visualization](#data-analysis--data-visualization-13)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-26)\n  - [Scheme](#scheme)\n      - [Neural Networks](#neural-networks-1)\n  - [Swift](#swift)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-27)\n  - [TensorFlow](#tensorflow)\n      - [General-Purpose Machine Learning](#general-purpose-machine-learning-28)\n  - [Tools](#tools-1)\n      - [Neural Networks](#neural-networks-2)\n      - [Misc](#misc-2)\n  - [Credits](#credits)\n\u5199\u4e2a\u811a\u672c\u628a\u5b83\u4eec\u722c\u4e0b\u6765 - [Demos and Scripts](#sas-demos)\n- [Scala](#scala)\n    - [Natural Language Processing](#scala-nlp)\n    - [Data Analysis / Data Visualization](#scala-data-analysis)\n    - [General-Purpose Machine Learning](#scala-general-purpose)\n- [Scheme](#scheme)\n    - [Neural Networks](#scheme-neural-networks)\n- [Swift](#swift)\n    - [General-Purpose Machine Learning](#swift-general-purpose)\n- [TensorFlow](#tensor)\n    - [General-Purpose Machine Learning](#tensor-general-purpose)\n\n### Tools\n\n- [Neural Networks](#tools-neural-networks)\n- [Misc](#tools-misc)\n\n\n[Credits](#credits)\n\n<!-- /MarkdownTOC -->\n\n<a name=\"apl\"></a>\n## APL\n\n<a name=\"apl-general-purpose\"></a>\n#### General-Purpose Machine Learning\n* [naive-apl](https://github.com/mattcunningham/naive-apl) - Naive Bayesian Classifier implementation in APL. **[Deprecated]**\n\n<a name=\"c\"></a>\n## C\n\n<a name=\"c-general-purpose\"></a>\n#### General-Purpose Machine Learning\n* [Darknet](https://github.com/pjreddie/darknet) - Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation.\n* [Recommender](https://github.com/GHamrouni/Recommender) - A C library for product recommendations/suggestions using collaborative filtering (CF).\n* [Hybrid Recommender System](https://github.com/SeniorSA/hybrid-rs-trainner) - A hybrid recommender system based upon scikit-learn algorithms. **[Deprecated]**\n* [neonrvm](https://github.com/siavashserver/neonrvm) - neonrvm is an open source machine learning library based on RVM technique. It's written in C programming language and comes with Python programming language bindings.\n\n<a name=\"c-cv\"></a>\n#### Computer Vision\n\n* [CCV](https://github.com/liuliu/ccv) - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library.\n* [VLFeat](http://www.vlfeat.org/) - VLFeat is an open and portable library of computer vision algorithms, which has Matlab toolbox.\n\n<a name=\"cpp\"></a>\n## C++\n\n<a name=\"cpp-cv\"></a>\n#### Computer Vision\n\n* [DLib](http://dlib.net/imaging.html) - DLib has C++ and Python interfaces for face detection and training general object detectors.\n* [EBLearn](http://eblearn.sourceforge.net/) - Eblearn is an object-oriented C++ library that implements various machine learning models **[Deprecated]**\n* [OpenCV](https://opencv.org) - OpenCV has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS.\n* [VIGRA](https://github.com/ukoethe/vigra) - VIGRA is a generic cross-platform C++ computer vision and machine learning library for volumes of arbitrary dimensionality with Python bindings.\n\n<a name=\"cpp-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [BanditLib](https://github.com/jkomiyama/banditlib) - A simple Multi-armed Bandit library. **[Deprecated]**\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind. [DEEP LEARNING]\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, contains fast inference implementation and supports CPU and GPU (even multi-GPU) computation.\n* [CNTK](https://github.com/Microsoft/CNTK) - The Computational Network Toolkit (CNTK) by Microsoft Research, is a unified deep-learning toolkit that describes neural networks as a series of computational steps via a directed graph.\n* [CUDA](https://code.google.com/p/cuda-convnet/) - This is a fast C++/CUDA implementation of convolutional [DEEP LEARNING]\n* [DeepDetect](https://github.com/jolibrain/deepdetect) - A machine learning API and server written in C++11. It makes state of the art machine learning easy to work with and integrate into existing applications.\n* [Distributed Machine learning Tool Kit (DMTK)](http://www.dmtk.io/) - A distributed machine learning (parameter server) framework by Microsoft. Enables training models on large data sets across multiple machines. Current tools bundled with it include: LightLDA and Distributed (Multisense) Word Embedding.\n* [DLib](http://dlib.net/ml.html) - A suite of ML tools designed to be easy to imbed in other applications.\n* [DSSTNE](https://github.com/amznlabs/amazon-dsstne) - A software library created by Amazon for training and deploying deep neural networks using GPUs which emphasizes speed and scale over experimental flexibility.\n* [DyNet](https://github.com/clab/dynet) - A dynamic neural network library working well with networks that have dynamic structures that change for every training instance. Written in C++ with bindings in Python.\n* [Fido](https://github.com/FidoProject/Fido) - A highly-modular C++ machine learning library for embedded electronics and robotics.\n* [igraph](http://igraph.org/) - General purpose graph library.\n* [Intel(R) DAAL](https://github.com/intel/daal) - A high performance software library developed by Intel and optimized for Intel's architectures. Library provides algorithmic building blocks for all stages of data analytics and allows to process data in batch, online and distributed modes.\n* [LightGBM](https://github.com/Microsoft/LightGBM) - Microsoft's fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks.\n* [libfm](https://github.com/srendle/libfm) - A generic approach that allows to mimic most factorization models by feature engineering.\n* [MLDB](https://mldb.ai) - The Machine Learning Database is a database designed for machine learning. Send it commands over a RESTful API to store data, explore it using SQL, then train machine learning models and expose them as APIs.\n* [mlpack](https://www.mlpack.org/) - A scalable C++ machine learning library.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [proNet-core](https://github.com/cnclabs/proNet-core) - A general-purpose network embedding framework: pair-wise representations optimization Network Edit.\n* [PyCUDA](https://mathema.tician.de/software/pycuda/) - Python interface to CUDA\n* [ROOT](https://root.cern.ch) - A modular scientific software framework. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualization and storage.\n* [shark](http://image.diku.dk/shark/sphinx_pages/build/html/index.html) - A fast, modular, feature-rich open-source C++ machine learning library.\n* [Shogun](https://github.com/shogun-toolbox/shogun) - The Shogun Machine Learning Toolbox.\n* [sofia-ml](https://code.google.com/archive/p/sofia-ml) - Suite of fast incremental algorithms.\n* [Stan](http://mc-stan.org/) - A probabilistic programming language implementing full Bayesian statistical inference with Hamiltonian Monte Carlo sampling.\n* [Timbl](https://languagemachines.github.io/timbl/) - A software package/C++ library implementing several memory-based learning algorithms, among which IB1-IG, an implementation of k-nearest neighbor classification, and IGTree, a decision-tree approximation of IB1-IG. Commonly used for NLP.\n* [Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) - A fast out-of-core learning system.\n* [Warp-CTC](https://github.com/baidu-research/warp-ctc) - A fast parallel implementation of Connectionist Temporal Classification (CTC), on both CPU and GPU.\n* [XGBoost](https://github.com/dmlc/xgboost) - A parallelized optimized general purpose gradient boosting library.\n* [ThunderGBM](https://github.com/Xtra-Computing/thundergbm) - A fast library for GBDTs and Random Forests on GPUs.\n* [ThunderSVM](https://github.com/Xtra-Computing/thundersvm) - A fast SVM library on GPUs and CPUs.\n* [LKYDeepNN](https://github.com/mosdeo/LKYDeepNN) - A header-only C++11 Neural Network library. Low dependency, native traditional chinese document.\n* [xLearn](https://github.com/aksnzhy/xlearn) - A high performance, easy-to-use, and scalable machine learning package, which can be used to solve large-scale machine learning problems. xLearn is especially useful for solving machine learning problems on large-scale sparse data, which is very common in Internet services such as online advertisement and recommender systems.\n* [Featuretools](https://github.com/featuretools/featuretools) - A library for automated feature engineering. It excels at transforming transactional and relational datasets into feature matrices for machine learning using reusable feature engineering \"primitives\".\n* [skynet](https://github.com/Tyill/skynet) - A library for learning neural network, has C-interface, net set in JSON. Written in C++ with bindings in Python, C++ and C#.\n* [Feast](https://github.com/gojek/feast) - A feature store for the management, discovery, and access of machine learning features. Feast provides a consistent view of feature data for both model training and model serving.\n* [Polyaxon](https://github.com/polyaxon/polyaxon) - A platform for reproducible and scalable machine learning and deep learning.\n\n<a name=\"cpp-nlp\"></a>\n#### Natural Language Processing\n\n* [BLLIP Parser](https://github.com/BLLIP/bllip-parser) - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser).\n* [colibri-core](https://github.com/proycon/colibri-core) - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.\n* [CRF++](https://taku910.github.io/crfpp/) - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data & other Natural Language Processing tasks. **[Deprecated]**\n* [CRFsuite](http://www.chokkan.org/software/crfsuite/) - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data. **[Deprecated]**\n* [frog](https://github.com/LanguageMachines/frog) - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer.\n* [libfolia](https://github.com/LanguageMachines/libfolia) - C++ library for the [FoLiA format](https://proycon.github.io/folia/)\n* [MeTA](https://github.com/meta-toolkit/meta) - [MeTA : ModErn Text Analysis](https://meta-toolkit.org/) is a C++ Data Sciences Toolkit that facilitates mining big text data.\n* [MIT Information Extraction Toolkit](https://github.com/mit-nlp/MITIE) - C, C++, and Python tools for named entity recognition and relation extraction\n* [ucto](https://github.com/LanguageMachines/ucto) - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format.\n\n<a name=\"cpp-speech-recognition\"></a>\n#### Speech Recognition\n* [Kaldi](https://github.com/kaldi-asr/kaldi) - Kaldi is a toolkit for speech recognition written in C++ and licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers.\n\n<a name=\"cpp-sequence\"></a>\n#### Sequence Analysis\n* [ToPS](https://github.com/ayoshiaki/tops) - This is an objected-oriented framework that facilitates the integration of probabilistic models for sequences over a user defined alphabet. **[Deprecated]**\n\n<a name=\"cpp-gestures\"></a>\n#### Gesture Detection\n* [grt](https://github.com/nickgillian/grt) - The Gesture Recognition Toolkit (GRT) is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition.\n\n<a name=\"common-lisp\"></a>\n## Common Lisp\n\n<a name=\"common-lisp-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [mgl](https://github.com/melisgl/mgl/) - Neural networks (boltzmann machines, feed-forward and recurrent nets), Gaussian Processes.\n* [mgl-gpr](https://github.com/melisgl/mgl-gpr/) - Evolutionary algorithms. **[Deprecated]**\n* [cl-libsvm](https://github.com/melisgl/cl-libsvm/) - Wrapper for the libsvm support vector machine library. **[Deprecated]**\n* [cl-online-learning](https://github.com/masatoi/cl-online-learning) - Online learning algorithms (Perceptron, AROW, SCW, Logistic Regression).\n* [cl-random-forest](https://github.com/masatoi/cl-random-forest) - Implementation of Random Forest in Common Lisp.\n\n<a name=\"clojure\"></a>\n## Clojure\n\n<a name=\"clojure-nlp\"></a>\n#### Natural Language Processing\n\n* [Clojure-openNLP](https://github.com/dakrone/clojure-opennlp) - Natural Language Processing in Clojure (opennlp).\n* [Infections-clj](https://github.com/r0man/inflections-clj) - Rails-like inflection library for Clojure and ClojureScript.\n\n<a name=\"clojure-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Touchstone](https://github.com/ptaoussanis/touchstone) - Clojure A/B testing library. **[Deprecated]**\n* [Clojush](https://github.com/lspector/Clojush) - The Push programming language and the PushGP genetic programming system implemented in Clojure.\n* [Infer](https://github.com/aria42/infer) - Inference and machine learning in Clojure. **[Deprecated]**\n* [Clj-ML](https://github.com/antoniogarrote/clj-ml) - A machine learning library for Clojure built on top of Weka and friends. **[Deprecated]**\n* [DL4CLJ](https://github.com/yetanalytics/dl4clj) - Clojure wrapper for Deeplearning4j.\n* [Encog](https://github.com/jimpil/enclog) - Clojure wrapper for Encog (v3) (Machine-Learning framework that specializes in neural-nets). **[Deprecated]**\n* [Fungp](https://github.com/vollmerm/fungp) - A genetic programming library for Clojure. **[Deprecated]**\n* [Statistiker](https://github.com/clojurewerkz/statistiker) - Basic Machine Learning algorithms in Clojure. **[Deprecated]**\n* [clortex](https://github.com/htm-community/clortex) - General Machine Learning library using Numenta\u2019s Cortical Learning Algorithm. **[Deprecated]**\n* [comportex](https://github.com/htm-community/comportex) - Functionally composable Machine Learning library using Numenta\u2019s Cortical Learning Algorithm. **[Deprecated]**\n* [cortex](https://github.com/originrose/cortex) - Neural networks, regression and feature learning in Clojure.\n* [lambda-ml](https://github.com/cloudkj/lambda-ml) - Simple, concise implementations of machine learning techniques and utilities in Clojure.\n\n<a name=\"clojure-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [Incanter](http://incanter.org/) - Incanter is a Clojure-based, R-like platform for statistical computing and graphics.\n* [PigPen](https://github.com/Netflix/PigPen) - Map-Reduce for Clojure.\n* [Envision](https://github.com/clojurewerkz/envision) - Clojure Data Visualisation library, based on Statistiker and D3.\n\n<a name=\"crystal\"></a>\n## Crystal\n\n<a name=\"crystal-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [machine](https://github.com/mathieulaporte/machine) - Simple machine learning algorithm.\n* [crystal-fann](https://github.com/NeuraLegion/crystal-fann) - FANN (Fast Artificial Neural Network) binding.\n\n<a name=\"elixir\"></a>\n## Elixir\n\n<a name=\"elixir-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Simple Bayes](https://github.com/fredwu/simple_bayes) - A Simple Bayes / Naive Bayes implementation in Elixir.\n* [emel](https://github.com/mrdimosthenis/emel) - A simple and functional machine learning library written in Elixir.\n* [Tensorflex](https://github.com/anshuman23/tensorflex) - Tensorflow bindings for the Elixir programming language.\n\n<a name=\"elixir-nlp\"></a>\n#### Natural Language Processing\n\n* [Stemmer](https://github.com/fredwu/stemmer) - An English (Porter2) stemming implementation in Elixir.\n\n<a name=\"erlang\"></a>\n## Erlang\n\n<a name=\"erlang-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Disco](https://github.com/discoproject/disco/) - Map Reduce in Erlang. **[Deprecated]**\n* [Yanni](https://bitbucket.org/nato/yanni/overview) - ANN neural networks using Erlangs leightweight processes.\n\n<a name=\"go\"></a>\n## Go\n\n<a name=\"go-nlp\"></a>\n#### Natural Language Processing\n\n* [snowball](https://github.com/tebeka/snowball) - Snowball Stemmer for Go.\n* [word-embedding](https://github.com/ynqa/word-embedding) - Word Embeddings: the full implementation of word2vec, GloVe in Go.\n* [sentences](https://github.com/neurosnap/sentences) - Golang implementation of Punkt sentence tokenizer.\n* [go-ngram](https://github.com/Lazin/go-ngram) - In-memory n-gram index with compression. *[Deprecated]*\n* [paicehusk](https://github.com/Rookii/paicehusk) - Golang implementation of the Paice/Husk Stemming Algorithm. *[Deprecated]*\n* [go-porterstemmer](https://github.com/reiver/go-porterstemmer) - A native Go clean room implementation of the Porter Stemming algorithm. **[Deprecated]**\n\n<a name=\"go-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [birdland](https://github.com/rlouf/birdland) - A recommendation library in Go.\n* [eaopt](https://github.com/MaxHalford/eaopt) - An evolutionary optimization library.\n* [leaves](https://github.com/dmitryikh/leaves) - A pure Go implementation of the prediction part of GBRTs, including XGBoost and LightGBM.\n* [gobrain](https://github.com/goml/gobrain) - Neural Networks written in Go.\n* [go-mxnet-predictor](https://github.com/songtianyi/go-mxnet-predictor) - Go binding for MXNet c_predict_api to do inference with pre-trained model.\n* [go-ml-transpiler](https://github.com/znly/go-ml-transpiler) - An open source Go transpiler for machine learning models.\n* [golearn](https://github.com/sjwhitworth/golearn) - Machine learning for Go.\n* [goml](https://github.com/cdipaolo/goml) - Machine learning library written in pure Go.\n* [gorgonia](https://github.com/gorgonia/gorgonia) - Deep learning in Go.\n* [gorse](https://github.com/zhenghaoz/gorse) - An offline recommender system backend based on collaborative filtering written in Go.\n* [therfoo](https://github.com/therfoo/therfoo) - An embedded deep learning library for Go.\n* [neat](https://github.com/jinyeom/neat) - Plug-and-play, parallel Go framework for NeuroEvolution of Augmenting Topologies (NEAT). **[Deprecated]**\n* [go-pr](https://github.com/daviddengcn/go-pr) - Pattern recognition package in Go lang. **[Deprecated]**\n* [go-ml](https://github.com/alonsovidales/go_ml) - Linear / Logistic regression, Neural Networks, Collaborative Filtering and Gaussian Multivariate Distribution. **[Deprecated]**\n* [GoNN](https://github.com/fxsjy/gonn) - GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN. **[Deprecated]**\n* [bayesian](https://github.com/jbrukh/bayesian) - Naive Bayesian Classification for Golang. **[Deprecated]**\n* [go-galib](https://github.com/thoj/go-galib) - Genetic Algorithms library written in Go / Golang. **[Deprecated]**\n* [Cloudforest](https://github.com/ryanbressler/CloudForest) - Ensembles of decision trees in Go/Golang. **[Deprecated]**\n* [go-dnn](https://github.com/sudachen/go-dnn) - Deep Neural Networks for Golang (powered by MXNet)\n\n<a name=\"go-spatial-analysis\"></a>\n#### Spatial analysis and geometry\n\n* [go-geom](https://github.com/twpayne/go-geom) - Go library to handle geometries.\n* [gogeo](https://github.com/golang/geo) - Spherical geometry in Go.\n\n<a name=\"go-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [gota](https://github.com/go-gota/gota) - Dataframes.\n* [gonum/mat](https://godoc.org/gonum.org/v1/gonum/mat) - A linear algebra package for Go.\n* [gonum/optimize](https://godoc.org/gonum.org/v1/gonum/optimize) - Implementations of optimization algorithms.\n* [gonum/plot](https://godoc.org/gonum.org/v1/plot) - A plotting library.\n* [gonum/stat](https://godoc.org/gonum.org/v1/gonum/stat) - A statistics library.\n* [SVGo](https://github.com/ajstarks/svgo) - The Go Language library for SVG generation.\n* [glot](https://github.com/arafatk/glot) - Glot is a plotting library for Golang built on top of gnuplot.\n* [globe](https://github.com/mmcloughlin/globe) - Globe wireframe visualization.\n* [gonum/graph](https://godoc.org/gonum.org/v1/gonum/graph) - General-purpose graph library.\n* [go-graph](https://github.com/StepLg/go-graph) - Graph library for Go/Golang language. **[Deprecated]**\n* [RF](https://github.com/fxsjy/RF.go) - Random forests implementation in Go. **[Deprecated]**\n\n<a name=\"go-computer-vision\"></a>\n#### Computer vision\n\n* [GoCV](https://github.com/hybridgroup/gocv) - Package for computer vision using OpenCV 4 and beyond.\n\n<a name=\"haskell\"></a>\n## Haskell\n\n<a name=\"haskell-general-purpose\"></a>\n#### General-Purpose Machine Learning\n* [haskell-ml](https://github.com/ajtulloch/haskell-ml) - Haskell implementations of various ML algorithms. **[Deprecated]**\n* [HLearn](https://github.com/mikeizbicki/HLearn) - a suite of libraries for interpreting machine learning models according to their algebraic structure. **[Deprecated]**\n* [hnn](https://github.com/alpmestan/HNN) - Haskell Neural Network library.\n* [hopfield-networks](https://github.com/ajtulloch/hopfield-networks) - Hopfield Networks for unsupervised learning in Haskell. **[Deprecated]**\n* [DNNGraph](https://github.com/ajtulloch/dnngraph) - A DSL for deep neural networks. **[Deprecated]**\n* [LambdaNet](https://github.com/jbarrow/LambdaNet) - Configurable Neural Networks in Haskell. **[Deprecated]**\n\n<a name=\"java\"></a>\n## Java\n\n<a name=\"java-nlp\"></a>\n#### Natural Language Processing\n* [Cortical.io](https://www.cortical.io/) - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc...) as quickly and intuitively as the brain.\n* [IRIS](https://github.com/cortical-io/Iris) - [Cortical.io's](https://cortical.io) FREE NLP, Retina API Analysis Tool (written in JavaFX!) - [See the Tutorial Video](https://www.youtube.com/watch?v=CsF4pd7fGF0).\n* [CoreNLP](https://nlp.stanford.edu/software/corenlp.shtml) - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words.\n* [Stanford Parser](https://nlp.stanford.edu/software/lex-parser.shtml) - A natural language parser is a program that works out the grammatical structure of sentences.\n* [Stanford POS Tagger](https://nlp.stanford.edu/software/tagger.shtml) - A Part-Of-Speech Tagger (POS Tagger).\n* [Stanford Name Entity Recognizer](https://nlp.stanford.edu/software/CRF-NER.shtml) - Stanford NER is a Java implementation of a Named Entity Recognizer.\n* [Stanford Word Segmenter](https://nlp.stanford.edu/software/segmenter.shtml) - Tokenization of raw text is a standard pre-processing step for many NLP tasks.\n* [Tregex, Tsurgeon and Semgrex](https://nlp.stanford.edu/software/tregex.shtml) - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for \"tree regular expressions\").\n* [Stanford Phrasal: A Phrase-Based Translation System](https://nlp.stanford.edu/phrasal/)\n* [Stanford English Tokenizer](https://nlp.stanford.edu/software/tokenizer.shtml) - Stanford Phrasal is a state-of-the-art statistical phrase-based machine translation system, written in Java.\n* [Stanford Tokens Regex](https://nlp.stanford.edu/software/tokensregex.shtml) - A tokenizer divides text into a sequence of tokens, which roughly correspond to \"words\".\n* [Stanford Temporal Tagger](https://nlp.stanford.edu/software/sutime.shtml) - SUTime is a library for recognizing and normalizing time expressions.\n* [Stanford SPIED](https://nlp.stanford.edu/software/patternslearning.shtml) - Learning entities from unlabeled text starting with seed sets using patterns in an iterative fashion.\n* [Stanford Topic Modeling Toolbox](https://nlp.stanford.edu/software/tmt) - Topic modeling tools to social scientists and others who wish to perform analysis on datasets.\n* [Twitter Text Java](https://github.com/twitter/twitter-text/tree/master/java) - A Java implementation of Twitter's text processing library.\n* [MALLET](http://mallet.cs.umass.edu/) - A Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text.\n* [OpenNLP](https://opennlp.apache.org/) - a machine learning based toolkit for the processing of natural language text.\n* [LingPipe](http://alias-i.com/lingpipe/index.html) - A tool kit for processing text using computational linguistics.\n* [ClearTK](https://github.com/ClearTK/cleartk) - ClearTK provides a framework for developing statistical natural language processing (NLP) components in Java and is built on top of Apache UIMA. **[Deprecated]**\n* [Apache cTAKES](https://ctakes.apache.org/) - Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text.\n* [NLP4J](https://github.com/emorynlp/nlp4j) - The NLP4J project provides software and resources for natural language processing. The project started at the Center for Computational Language and EducAtion Research, and is currently developed by the Center for Language and Information Research at Emory University. **[Deprecated]**\n* [CogcompNLP](https://github.com/CogComp/cogcomp-nlp) - This project collects a number of core libraries for Natural Language Processing (NLP) developed in the University of Illinois' Cognitive Computation Group, for example `illinois-core-utilities` which provides a set of NLP-friendly data structures and a number of NLP-related utilities that support writing NLP applications, running experiments, etc, `illinois-edison` a library for feature extraction from illinois-core-utilities data structures and many other packages.\n\n<a name=\"java-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [aerosolve](https://github.com/airbnb/aerosolve) - A machine learning library by Airbnb designed from the ground up to be human friendly.\n* [AMIDST Toolbox](http://www.amidsttoolbox.com/) - A Java Toolbox for Scalable Probabilistic Machine Learning.\n* [Datumbox](https://github.com/datumbox/datumbox-framework) - Machine Learning framework for rapid development of Machine Learning and Statistical applications.\n* [ELKI](https://elki-project.github.io/) - Java toolkit for data mining. (unsupervised: clustering, outlier detection etc.)\n* [Encog](https://github.com/encog/encog-java-core) - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.\n* [FlinkML in Apache Flink](https://ci.apache.org/projects/flink/flink-docs-master/dev/libs/ml/index.html) - Distributed machine learning library in Flink.\n* [H2O](https://github.com/h2oai/h2o-3) - ML engine that supports distributed learning on Hadoop, Spark or your laptop via APIs in R, Python, Scala, REST/JSON.\n* [htm.java](https://github.com/numenta/htm.java) - General Machine Learning library using Numenta\u2019s Cortical Learning Algorithm.\n* [liblinear-java](https://github.com/bwaldvogel/liblinear-java) - Java version of liblinear.\n* [Mahout](https://github.com/apache/mahout) - Distributed machine learning.\n* [Meka](http://meka.sourceforge.net/) - An open source implementation of methods for multi-label classification and evaluation (extension to Weka).\n* [MLlib in Apache Spark](https://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [Neuroph](http://neuroph.sourceforge.net/) - Neuroph is lightweight Java neural network framework\n* [ORYX](https://github.com/oryxproject/oryx) - Lambda Architecture Framework using Apache Spark and Apache Kafka with a specialization for real-time large-scale machine learning.\n* [Samoa](https://samoa.incubator.apache.org/) SAMOA is a framework that includes distributed machine learning for data streams with an interface to plug-in different stream processing platforms.\n* [RankLib](https://sourceforge.net/p/lemur/wiki/RankLib/) - RankLib is a library of learning to rank algorithms. **[Deprecated]**\n* [rapaio](https://github.com/padreati/rapaio) - statistics, data mining and machine learning toolbox in Java.\n* [RapidMiner](https://rapidminer.com) - RapidMiner integration into Java code.\n* [Stanford Classifier](https://nlp.stanford.edu/software/classifier.shtml) - A classifier is a machine learning tool that will take data items and place them into one of k classes.\n* [SmileMiner](https://github.com/haifengl/smile) - Statistical Machine Intelligence & Learning Engine.\n* [SystemML](https://github.com/apache/systemml) - flexible, scalable machine learning (ML) language.\n* [Weka](https://www.cs.waikato.ac.nz/ml/weka/) - Weka is a collection of machine learning algorithms for data mining tasks.\n* [LBJava](https://github.com/CogComp/lbjava) - Learning Based Java is a modeling language for the rapid development of software systems, offers a convenient, declarative syntax for classifier and constraint definition directly in terms of the objects in the programmer's application.\n\n\n<a name=\"java-speech-recognition\"></a>\n#### Speech Recognition\n* [CMU Sphinx](https://cmusphinx.github.io) - Open Source Toolkit For Speech Recognition purely based on Java speech recognition library.\n\n<a name=\"java-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [Flink](https://flink.apache.org/) - Open source platform for distributed stream and batch data processing.\n* [Hadoop](https://github.com/apache/hadoop) - Hadoop/HDFS.\n* [Onyx](https://github.com/onyx-platform/onyx) - Distributed, masterless, high performance, fault tolerant data processing. Written entirely in Clojure.\n* [Spark](https://github.com/apache/spark) - Spark is a fast and general engine for large-scale data processing.\n* [Storm](https://storm.apache.org/) - Storm is a distributed realtime computation system.\n* [Impala](https://github.com/cloudera/impala) - Real-time Query for Hadoop.\n* [DataMelt](https://jwork.org/dmelt/) - Mathematics software for numeric computation, statistics, symbolic calculations, data analysis and data visualization.\n* [Dr. Michael Thomas Flanagan's Java Scientific Library](https://www.ee.ucl.ac.uk/~mflanaga/java/) **[Deprecated]**\n\n<a name=\"java-deep-learning\"></a>\n#### Deep Learning\n\n* [Deeplearning4j](https://github.com/deeplearning4j/deeplearning4j) - Scalable deep learning for industry with parallel GPUs.\n* [Keras Beginner Tutorial](https://victorzhou.com/blog/keras-neural-network-tutorial/) - Friendly guide on using Keras to implement a simple Neural Network in Python\n\n<a name=\"javascript\"></a>\n## Javascript\n\n<a name=\"javascript-nlp\"></a>\n#### Natural Language Processing\n\n* [Twitter-text](https://github.com/twitter/twitter-text) - A JavaScript implementation of Twitter's text processing library.\n* [natural](https://github.com/NaturalNode/natural) - General natural language facilities for node.\n* [Knwl.js](https://github.com/loadfive/Knwl.js) - A Natural Language Processor in JS.\n* [Retext](https://github.com/retextjs/retext) - Extensible system for analyzing and manipulating natural language.\n* [NLP Compromise](https://github.com/spencermountain/compromise) - Natural Language processing in the browser.\n* [nlp.js](https://github.com/axa-group/nlp.js) - An NLP library built in node over Natural, with entity extraction, sentiment analysis, automatic language identify, and so more\n\n\n\n<a name=\"javascript-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [D3.js](https://d3js.org/)\n* [High Charts](https://www.highcharts.com/)\n* [NVD3.js](http://nvd3.org/)\n* [dc.js](https://dc-js.github.io/dc.js/)\n* [chartjs](https://www.chartjs.org/)\n* [dimple](http://dimplejs.org/)\n* [amCharts](https://www.amcharts.com/)\n* [D3xter](https://github.com/NathanEpstein/D3xter) - Straight forward plotting built on D3. **[Deprecated]**\n* [statkit](https://github.com/rigtorp/statkit) - Statistics kit for JavaScript. **[Deprecated]**\n* [datakit](https://github.com/nathanepstein/datakit) - A lightweight framework for data analysis in JavaScript\n* [science.js](https://github.com/jasondavies/science.js/) - Scientific and statistical computing in JavaScript. **[Deprecated]**\n* [Z3d](https://github.com/NathanEpstein/Z3d) - Easily make interactive 3d plots built on Three.js **[Deprecated]**\n* [Sigma.js](http://sigmajs.org/) - JavaScript library dedicated to graph drawing.\n* [C3.js](https://c3js.org/) - customizable library based on D3.js for easy chart drawing.\n* [Datamaps](https://datamaps.github.io/) - Customizable SVG map/geo visualizations using D3.js. **[Deprecated]**\n* [ZingChart](https://www.zingchart.com/) - library written on Vanilla JS for big data visualization.\n* [cheminfo](https://www.cheminfo.org/) - Platform for data visualization and analysis, using the [visualizer](https://github.com/npellet/visualizer) project.\n* [Learn JS Data](http://learnjsdata.com/)\n* [AnyChart](https://www.anychart.com/)\n* [FusionCharts](https://www.fusioncharts.com/)\n* [Nivo](https://nivo.rocks) - built on top of the awesome d3 and Reactjs libraries\n\n\n<a name=\"javascript-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Auto ML](https://github.com/ClimbsRocks/auto_ml) - Automated machine learning, data formatting, ensembling, and hyperparameter optimization for competitions and exploration- just give it a .csv file!\n* [Convnet.js](https://cs.stanford.edu/people/karpathy/convnetjs/) - ConvNetJS is a Javascript library for training Deep Learning models[DEEP LEARNING] **[Deprecated]**\n* [Clusterfck](https://harthur.github.io/clusterfck/) - Agglomerative hierarchical clustering implemented in Javascript for Node.js and the browser. **[Deprecated]**\n* [Clustering.js](https://github.com/emilbayes/clustering.js) - Clustering algorithms implemented in Javascript for Node.js and the browser. **[Deprecated]**\n* [Decision Trees](https://github.com/serendipious/nodejs-decision-tree-id3) - NodeJS Implementation of Decision Tree using ID3 Algorithm. **[Deprecated]**\n* [DN2A](https://github.com/antoniodeluca/dn2a.js) - Digital Neural Networks Architecture. **[Deprecated]**\n* [figue](https://code.google.com/archive/p/figue) - K-means, fuzzy c-means and agglomerative clustering.\n* [Gaussian Mixture Model](https://github.com/lukapopijac/gaussian-mixture-model) - Unsupervised machine learning with multivariate Gaussian mixture model.\n* [Node-fann](https://github.com/rlidwka/node-fann) - FANN (Fast Artificial Neural Network Library) bindings for Node.js **[Deprecated]**\n* [Keras.js](https://github.com/transcranial/keras-js) - Run Keras models in the browser, with GPU support provided by WebGL 2.\n* [Kmeans.js](https://github.com/emilbayes/kMeans.js) - Simple Javascript implementation of the k-means algorithm, for node.js and the browser. **[Deprecated]**\n* [LDA.js](https://github.com/primaryobjects/lda) - LDA topic modeling for Node.js\n* [Learning.js](https://github.com/yandongliu/learningjs) - Javascript implementation of logistic regression/c4.5 decision tree **[Deprecated]**\n* [machinelearn.js](https://github.com/machinelearnjs/machinelearnjs) - Machine Learning library for the web, Node.js and developers\n* [mil-tokyo](https://github.com/mil-tokyo) - List of several machine learning libraries.\n* [Node-SVM](https://github.com/nicolaspanel/node-svm) - Support Vector Machine for Node.js\n* [Brain](https://github.com/harthur/brain) - Neural networks in JavaScript **[Deprecated]**\n* [Brain.js](https://github.com/BrainJS/brain.js) - Neural networks in JavaScript - continued community fork of [Brain](https://github.com/harthur/brain).\n* [Bayesian-Bandit](https://github.com/omphalos/bayesian-bandit.js) - Bayesian bandit implementation for Node and the browser. **[Deprecated]**\n* [Synaptic](https://github.com/cazala/synaptic) - Architecture-free neural network library for Node.js and the browser.\n* [kNear](https://github.com/NathanEpstein/kNear) - JavaScript implementation of the k nearest neighbors algorithm for supervised learning.\n* [NeuralN](https://github.com/totemstech/neuraln) - C++ Neural Network library for Node.js. It has advantage on large dataset and multi-threaded training. **[Deprecated]**\n* [kalman](https://github.com/itamarwe/kalman) - Kalman filter for Javascript. **[Deprecated]**\n* [shaman](https://github.com/luccastera/shaman) - Node.js library with support for both simple and multiple linear regression. **[Deprecated]**\n* [ml.js](https://github.com/mljs/ml) - Machine learning and numerical analysis tools for Node.js and the Browser!\n* [ml5](https://github.com/ml5js/ml5-library) - Friendly machine learning for the web!\n* [Pavlov.js](https://github.com/NathanEpstein/Pavlov.js) - Reinforcement learning using Markov Decision Processes.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [TensorFlow.js](https://js.tensorflow.org/) - A WebGL accelerated, browser based JavaScript library for training and deploying ML models.\n* [JSMLT](https://github.com/jsmlt/jsmlt) - Machine learning toolkit with classification and clustering for Node.js; supports visualization (see [visualml.io](https://visualml.io)).\n* [xgboost-node](https://github.com/nuanio/xgboost-node) - Run XGBoost model and make predictions in Node.js.\n* [Netron](https://github.com/lutzroeder/netron) - Visualizer for machine learning models.\n* [WebDNN](https://github.com/mil-tokyo/webdnn) - Fast Deep Neural Network Javascript Framework. WebDNN uses next generation JavaScript API, WebGPU for GPU execution, and WebAssembly for CPU execution.  \n\n<a name=\"javascript-misc\"></a>\n#### Misc\n\n* [stdlib](https://github.com/stdlib-js/stdlib) - A standard library for JavaScript and Node.js, with an emphasis on numeric computing. The library provides a collection of robust, high performance libraries for mathematics, statistics, streams, utilities, and more.\n* [sylvester](https://github.com/jcoglan/sylvester) - Vector and Matrix math for JavaScript. **[Deprecated]**\n* [simple-statistics](https://github.com/simple-statistics/simple-statistics) - A JavaScript implementation of descriptive, regression, and inference statistics. Implemented in literate JavaScript with no dependencies, designed to work in all modern browsers (including IE) as well as in Node.js.\n* [regression-js](https://github.com/Tom-Alexander/regression-js) - A javascript library containing a collection of least squares fitting methods for finding a trend in a set of data.\n* [Lyric](https://github.com/flurry/Lyric) - Linear Regression library. **[Deprecated]**\n* [GreatCircle](https://github.com/mwgg/GreatCircle) - Library for calculating great circle distance.\n* [MLPleaseHelp](https://github.com/jgreenemi/MLPleaseHelp) - MLPleaseHelp is a simple ML resource search engine. You can use this search engine right now at [https://jgreenemi.github.io/MLPleaseHelp/](https://jgreenemi.github.io/MLPleaseHelp/), provided via Github Pages.\n\n<a name=\"javascript-demos\"></a>\n#### Demos and Scripts\n* [The Bot](https://github.com/sta-ger/TheBot) - Example of how the neural network learns to predict the angle between two points created with [Synaptic](https://github.com/cazala/synaptic).\n* [Half Beer](https://github.com/sta-ger/HalfBeer) - Beer glass classifier created with [Synaptic](https://github.com/cazala/synaptic).\n* [NSFWJS](http://nsfwjs.com) - Indecent content checker with TensorFlow.js\n* [Rock Paper Scissors](https://rps-tfjs.netlify.com/) - Rock Paper Scissors trained in the browser with TensorFlow.js\n\n<a name=\"julia\"></a>\n## Julia\n\n<a name=\"julia-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [MachineLearning](https://github.com/benhamner/MachineLearning.jl) - Julia Machine Learning library. **[Deprecated]**\n* [MLBase](https://github.com/JuliaStats/MLBase.jl) - A set of functions to support the development of machine learning algorithms.\n* [PGM](https://github.com/JuliaStats/PGM.jl) - A Julia framework for probabilistic graphical models.\n* [DA](https://github.com/trthatcher/DiscriminantAnalysis.jl) - Julia package for Regularized Discriminant Analysis.\n* [Regression](https://github.com/lindahua/Regression.jl) - Algorithms for regression analysis (e.g. linear regression and logistic regression). **[Deprecated]**\n* [Local Regression](https://github.com/JuliaStats/Loess.jl) - Local regression, so smooooth!\n* [Naive Bayes](https://github.com/nutsiepully/NaiveBayes.jl) - Simple Naive Bayes implementation in Julia. **[Deprecated]**\n* [Mixed Models](https://github.com/dmbates/MixedModels.jl) - A Julia package for fitting (statistical) mixed-effects models.\n* [Simple MCMC](https://github.com/fredo-dedup/SimpleMCMC.jl) - basic mcmc sampler implemented in Julia. **[Deprecated]**\n* [Distances](https://github.com/JuliaStats/Distances.jl) - Julia module for Distance evaluation.\n* [Decision Tree](https://github.com/bensadeghi/DecisionTree.jl) - Decision Tree Classifier and Regressor.\n* [Neural](https://github.com/compressed/BackpropNeuralNet.jl) - A neural network in Julia.\n* [MCMC](https://github.com/doobwa/MCMC.jl) - MCMC tools for Julia. **[Deprecated]**\n* [Mamba](https://github.com/brian-j-smith/Mamba.jl) - Markov chain Monte Carlo (MCMC) for Bayesian analysis in Julia.\n* [GLM](https://github.com/JuliaStats/GLM.jl) - Generalized linear models in Julia.\n* [Gaussian Processes](https://github.com/STOR-i/GaussianProcesses.jl) - Julia package for Gaussian processes.\n* [Online Learning](https://github.com/lendle/OnlineLearning.jl) **[Deprecated]**\n* [GLMNet](https://github.com/simonster/GLMNet.jl) - Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet.\n* [Clustering](https://github.com/JuliaStats/Clustering.jl) - Basic functions for clustering data: k-means, dp-means, etc.\n* [SVM](https://github.com/JuliaStats/SVM.jl) - SVM's for Julia. **[Deprecated]**\n* [Kernel Density](https://github.com/JuliaStats/KernelDensity.jl) - Kernel density estimators for julia.\n* [MultivariateStats](https://github.com/JuliaStats/MultivariateStats.jl) - Methods for dimensionality reduction.\n* [NMF](https://github.com/JuliaStats/NMF.jl) - A Julia package for non-negative matrix factorization.\n* [ANN](https://github.com/EricChiang/ANN.jl) - Julia artificial neural networks. **[Deprecated]**\n* [Mocha](https://github.com/pluskid/Mocha.jl) - Deep Learning framework for Julia inspired by Caffe. **[Deprecated]**\n* [XGBoost](https://github.com/dmlc/XGBoost.jl) - eXtreme Gradient Boosting Package in Julia.\n* [ManifoldLearning](https://github.com/wildart/ManifoldLearning.jl) - A Julia package for manifold learning and nonlinear dimensionality reduction.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [Merlin](https://github.com/hshindo/Merlin.jl) - Flexible Deep Learning Framework in Julia.\n* [ROCAnalysis](https://github.com/davidavdav/ROCAnalysis.jl) - Receiver Operating Characteristics and functions for evaluation probabilistic binary classifiers.\n* [GaussianMixtures](https://github.com/davidavdav/GaussianMixtures.jl) - Large scale Gaussian Mixture Models.\n* [ScikitLearn](https://github.com/cstjean/ScikitLearn.jl) - Julia implementation of the scikit-learn API.\n* [Knet](https://github.com/denizyuret/Knet.jl) - Ko\u00e7 University Deep Learning Framework.\n* [Flux](https://fluxml.ai/) - Relax! Flux is the ML library that doesn't make you tensor\n\n<a name=\"julia-nlp\"></a>\n#### Natural Language Processing\n\n* [Topic Models](https://github.com/slycoder/TopicModels.jl) - TopicModels for Julia. **[Deprecated]**\n* [Text Analysis](https://github.com/JuliaText/TextAnalysis.jl) - Julia package for text analysis.\n* [Word Tokenizers](https://github.com/JuliaText/WordTokenizers.jl) - Tokenizers for Natural Language Processing in Julia\n* [Corpus Loaders](https://github.com/JuliaText/CorpusLoaders.jl) - A julia package providing a variety of loaders for various NLP corpora.\n* [Embeddings](https://github.com/JuliaText/Embeddings.jl) - Functions and data dependencies for loading various word embeddings\n* [Languages](https://github.com/JuliaText/Languages.jl) - Julia package for working with various human languages\n* [WordNet](https://github.com/JuliaText/WordNet.jl) - A Julia package for Princeton's WordNet\n\n<a name=\"julia-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [Graph Layout](https://github.com/IainNZ/GraphLayout.jl) - Graph layout algorithms in pure Julia.\n* [LightGraphs](https://github.com/JuliaGraphs/LightGraphs.jl) - Graph modeling and analysis.\n* [Data Frames Meta](https://github.com/JuliaData/DataFramesMeta.jl) - Metaprogramming tools for DataFrames.\n* [Julia Data](https://github.com/nfoti/JuliaData) - library for working with tabular data in Julia. **[Deprecated]**\n* [Data Read](https://github.com/queryverse/ReadStat.jl) - Read files from Stata, SAS, and SPSS.\n* [Hypothesis Tests](https://github.com/JuliaStats/HypothesisTests.jl) - Hypothesis tests for Julia.\n* [Gadfly](https://github.com/GiovineItalia/Gadfly.jl) - Crafty statistical graphics for Julia.\n* [Stats](https://github.com/JuliaStats/StatsKit.jl) - Statistical tests for Julia.\n* [RDataSets](https://github.com/johnmyleswhite/RDatasets.jl) - Julia package for loading many of the data sets available in R.\n* [DataFrames](https://github.com/JuliaData/DataFrames.jl) - library for working with tabular data in Julia.\n* [Distributions](https://github.com/JuliaStats/Distributions.jl) - A Julia package for probability distributions and associated functions.\n* [Data Arrays](https://github.com/JuliaStats/DataArrays.jl) - Data structures that allow missing values. **[Deprecated]**\n* [Time Series](https://github.com/JuliaStats/TimeSeries.jl) - Time series toolkit for Julia.\n* [Sampling](https://github.com/lindahua/Sampling.jl) - Basic sampling algorithms for Julia.\n\n<a name=\"julia-misc\"></a>\n#### Misc Stuff / Presentations\n\n* [DSP](https://github.com/JuliaDSP/DSP.jl) - Digital Signal Processing (filtering, periodograms, spectrograms, window functions).\n* [JuliaCon Presentations](https://github.com/JuliaCon/presentations) - Presentations for JuliaCon.\n* [SignalProcessing](https://github.com/JuliaDSP/DSP.jl) - Signal Processing tools for Julia.\n* [Images](https://github.com/JuliaImages/Images.jl) - An image library for Julia.\n* [DataDeps](https://github.com/oxinabox/DataDeps.jl) - Reproducible data setup for reproducible science.\n\n<a name=\"lua\"></a>\n## Lua\n\n<a name=\"lua-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Torch7](http://torch.ch/)\n  * [cephes](https://github.com/deepmind/torch-cephes) - Cephes mathematical functions library, wrapped for Torch. Provides and wraps the 180+ special mathematical functions from the Cephes mathematical library, developed by Stephen L. Moshier. It is used, among many other places, at the heart of SciPy. **[Deprecated]**\n  * [autograd](https://github.com/twitter/torch-autograd) - Autograd automatically differentiates native Torch code. Inspired by the original Python version.\n  * [graph](https://github.com/torch/graph) - Graph package for Torch. **[Deprecated]**\n  * [randomkit](https://github.com/deepmind/torch-randomkit) - Numpy's randomkit, wrapped for Torch. **[Deprecated]**\n  * [signal](https://github.com/soumith/torch-signal) - A signal processing toolbox for Torch-7. FFT, DCT, Hilbert, cepstrums, stft.\n  * [nn](https://github.com/torch/nn) - Neural Network package for Torch.\n  * [torchnet](https://github.com/torchnet/torchnet) - framework for torch which provides a set of abstractions aiming at encouraging code re-use as well as encouraging modular programming.\n  * [nngraph](https://github.com/torch/nngraph) - This package provides graphical computation for nn library in Torch7.\n  * [nnx](https://github.com/clementfarabet/lua---nnx) - A completely unstable and experimental package that extends Torch's builtin nn library.\n  * [rnn](https://github.com/Element-Research/rnn) - A Recurrent Neural Network library that extends Torch's nn. RNNs, LSTMs, GRUs, BRNNs, BLSTMs, etc.\n  * [dpnn](https://github.com/Element-Research/dpnn) - Many useful features that aren't part of the main nn package.\n  * [dp](https://github.com/nicholas-leonard/dp) - A deep learning library designed for streamlining research and development using the Torch7 distribution. It emphasizes flexibility through the elegant use of object-oriented design patterns. **[Deprecated]**\n  * [optim](https://github.com/torch/optim) - An optimization library for Torch. SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp and more.\n  * [unsup](https://github.com/koraykv/unsup) - A package for unsupervised learning in Torch. Provides modules that are compatible with nn (LinearPsd, ConvPsd, AutoEncoder, ...), and self-contained algorithms (k-means, PCA). **[Deprecated]**\n  * [manifold](https://github.com/clementfarabet/manifold) - A package to manipulate manifolds.\n  * [svm](https://github.com/koraykv/torch-svm) - Torch-SVM library. **[Deprecated]**\n  * [lbfgs](https://github.com/clementfarabet/lbfgs) - FFI Wrapper for liblbfgs. **[Deprecated]**\n  * [vowpalwabbit](https://github.com/clementfarabet/vowpal_wabbit) - An old vowpalwabbit interface to torch. **[Deprecated]**\n  * [OpenGM](https://github.com/clementfarabet/lua---opengm) - OpenGM is a C++ library for graphical modeling, and inference. The Lua bindings provide a simple way of describing graphs, from Lua, and then optimizing them with OpenGM. **[Deprecated]**\n  * [spaghetti](https://github.com/MichaelMathieu/lua---spaghetti) - Spaghetti (sparse linear) module for torch7 by @MichaelMathieu **[Deprecated]**\n  * [LuaSHKit](https://github.com/ocallaco/LuaSHkit) - A lua wrapper around the Locality sensitive hashing library SHKit **[Deprecated]**\n  * [kernel smoothing](https://github.com/rlowrance/kernel-smoothers) - KNN, kernel-weighted average, local linear regression smoothers. **[Deprecated]**\n  * [cutorch](https://github.com/torch/cutorch) - Torch CUDA Implementation.\n  * [cunn](https://github.com/torch/cunn) - Torch CUDA Neural Network Implementation.\n  * [imgraph](https://github.com/clementfarabet/lua---imgraph) - An image/graph library for Torch. This package provides routines to construct graphs on images, segment them, build trees out of them, and convert them back to images. **[Deprecated]**\n  * [videograph](https://github.com/clementfarabet/videograph) - A video/graph library for Torch. This package provides routines to construct graphs on videos, segment them, build trees out of them, and convert them back to videos. **[Deprecated]**\n  * [saliency](https://github.com/marcoscoffier/torch-saliency) - code and tools around integral images. A library for finding interest points based on fast integral histograms. **[Deprecated]**\n  * [stitch](https://github.com/marcoscoffier/lua---stitch) - allows us to use hugin to stitch images and apply same stitching to a video sequence. **[Deprecated]**\n  * [sfm](https://github.com/marcoscoffier/lua---sfm) - A bundle adjustment/structure from motion package. **[Deprecated]**\n  * [fex](https://github.com/koraykv/fex) - A package for feature extraction in Torch. Provides SIFT and dSIFT modules. **[Deprecated]**\n  * [OverFeat](https://github.com/sermanet/OverFeat) - A state-of-the-art generic dense feature extractor. **[Deprecated]**\n  * [wav2letter](https://github.com/facebookresearch/wav2letter) - a simple and efficient end-to-end Automatic Speech Recognition (ASR) system from Facebook AI Research.\n* [Numeric Lua](http://numlua.luaforge.net/)\n* [Lunatic Python](https://labix.org/lunatic-python)\n* [SciLua](http://scilua.org/)\n* [Lua - Numerical Algorithms](https://bitbucket.org/lucashnegri/lna) **[Deprecated]**\n* [Lunum](https://github.com/jzrake/lunum) **[Deprecated]**\n\n<a name=\"lua-demos\"></a>\n#### Demos and Scripts\n* [Core torch7 demos repository](https://github.com/e-lab/torch7-demos).\n  * linear-regression, logistic-regression\n  * face detector (training and detection as separate demos)\n  * mst-based-segmenter\n  * train-a-digit-classifier\n  * train-autoencoder\n  * optical flow demo\n  * train-on-housenumbers\n  * train-on-cifar\n  * tracking with deep nets\n  * kinect demo\n  * filter-bank visualization\n  * saliency-networks\n* [Training a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)](https://github.com/soumith/galaxyzoo)\n* [Music Tagging](https://github.com/mbhenaff/MusicTagging) - Music Tagging scripts for torch7.\n* [torch-datasets](https://github.com/rosejn/torch-datasets) - Scripts to load several popular datasets including:\n  * BSR 500\n  * CIFAR-10\n  * COIL\n  * Street View House Numbers\n  * MNIST\n  * NORB\n* [Atari2600](https://github.com/fidlej/aledataset) - Scripts to generate a dataset with static frames from the Arcade Learning Environment.\n\n\n\n<a name=\"matlab\"></a>\n## Matlab\n\n<a name=\"matlab-cv\"></a>\n#### Computer Vision\n\n* [Contourlets](http://www.ifp.illinois.edu/~minhdo/software/contourlet_toolbox.tar) - MATLAB source code that implements the contourlet transform and its utility functions.\n* [Shearlets](https://www3.math.tu-berlin.de/numerik/www.shearlab.org/software) - MATLAB code for shearlet transform.\n* [Curvelets](http://www.curvelet.org/software.html) - The Curvelet transform is a higher dimensional generalization of the Wavelet transform designed to represent images at different scales and different angles.\n* [Bandlets](http://www.cmap.polytechnique.fr/~peyre/download/) - MATLAB code for bandlet transform.\n* [mexopencv](https://kyamagu.github.io/mexopencv/) - Collection and a development kit of MATLAB mex functions for OpenCV library.\n\n<a name=\"matlab-nlp\"></a>\n#### Natural Language Processing\n\n* [NLP](https://amplab.cs.berkeley.edu/an-nlp-library-for-matlab/) - An NLP library for Matlab.\n\n<a name=\"matlab-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Training a deep autoencoder or a classifier\non MNIST digits](https://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html) - Training a deep autoencoder or a classifier\non MNIST digits[DEEP LEARNING].\n* [Convolutional-Recursive Deep Learning for 3D Object Classification](https://www.socher.org/index.php/Main/Convolutional-RecursiveDeepLearningFor3DObjectClassification) - Convolutional-Recursive Deep Learning for 3D Object Classification[DEEP LEARNING].\n* [Spider](https://people.kyb.tuebingen.mpg.de/spider/) - The spider is intended to be a complete object orientated environment for machine learning in Matlab.\n* [LibSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/#matlab) - A Library for Support Vector Machines.\n* [ThunderSVM](https://github.com/Xtra-Computing/thundersvm) - An Open-Source SVM Library on GPUs and CPUs\n* [LibLinear](https://www.csie.ntu.edu.tw/~cjlin/liblinear/#download) - A Library for Large Linear Classification.\n* [Machine Learning Module](https://github.com/josephmisiti/machine-learning-module) - Class on machine w/ PDF, lectures, code\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind.\n* [Pattern Recognition Toolbox](https://github.com/covartech/PRT) - A complete object-oriented environment for machine learning in Matlab.\n* [Pattern Recognition and Machine Learning](https://github.com/PRML/PRMLT) - This package contains the matlab implementation of the algorithms described in the book Pattern Recognition and Machine Learning by C. Bishop.\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly with MATLAB.\n* [MXNet](https://github.com/apache/incubator-mxnet/) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [Machine Learning in MatLab/Octave](https://github.com/trekhleb/machine-learning-octave) - examples of popular machine learning algorithms (neural networks, linear/logistic regressions, K-Means, etc.) with code examples and mathematics behind them being explained.\n\n\n<a name=\"matlab-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [matlab_bgl](https://www.cs.purdue.edu/homes/dgleich/packages/matlab_bgl/) - MatlabBGL is a Matlab package for working with graphs.\n* [gaimc](https://www.mathworks.com/matlabcentral/fileexchange/24134-gaimc---graph-algorithms-in-matlab-code) - Efficient pure-Matlab implementations of graph algorithms to complement MatlabBGL's mex functions.\n\n<a name=\"net\"></a>\n## .NET\n\n<a name=\"net-cv\"></a>\n#### Computer Vision\n\n* [OpenCVDotNet](https://code.google.com/archive/p/opencvdotnet) - A wrapper for the OpenCV project to be used with .NET applications.\n* [Emgu CV](http://www.emgu.com/wiki/index.php/Main_Page) - Cross platform wrapper of OpenCV which can be compiled in Mono to be run on Windows, Linus, Mac OS X, iOS, and Android.\n* [AForge.NET](http://www.aforgenet.com/framework/) - Open source C# framework for developers and researchers in the fields of Computer Vision and Artificial Intelligence. Development has now shifted to GitHub.\n* [Accord.NET](http://accord-framework.net) - Together with AForge.NET, this library can provide image processing and computer vision algorithms to Windows, Windows RT and Windows Phone. Some components are also available for Java and Android.\n\n<a name=\"net-nlp\"></a>\n#### Natural Language Processing\n\n* [Stanford.NLP for .NET](https://github.com/sergey-tihon/Stanford.NLP.NET/) - A full port of Stanford NLP packages to .NET and also available precompiled as a NuGet package.\n\n<a name=\"net-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Accord-Framework](http://accord-framework.net/) -The Accord.NET Framework is a complete framework for building machine learning, computer vision, computer audition, signal processing and statistical applications.\n* [Accord.MachineLearning](https://www.nuget.org/packages/Accord.MachineLearning/) - Support Vector Machines, Decision Trees, Naive Bayesian models, K-means, Gaussian Mixture models and general algorithms such as Ransac, Cross-validation and Grid-Search for machine-learning applications. This package is part of the Accord.NET Framework.\n* [DiffSharp](https://diffsharp.github.io/DiffSharp/) - An automatic differentiation (AD) library providing exact and efficient derivatives (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) for machine learning and optimization applications. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation, for applications such as hyperparameter optimization.\n* [Encog](https://www.nuget.org/packages/encog-dotnet-core/) - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.\n* [GeneticSharp](https://github.com/giacomelli/GeneticSharp) - Multi-platform genetic algorithm library for .NET Core and .NET Framework. The library has several implementations of GA operators, like: selection, crossover, mutation, reinsertion and termination.\n* [Infer.NET](https://dotnet.github.io/infer/) - Infer.NET is a framework for running Bayesian inference in graphical models. One can use Infer.NET to solve many different kinds of machine learning problems, from standard problems like classification, recommendation or clustering through to customised solutions to domain-specific problems. Infer.NET has been used in a wide variety of domains including information retrieval, bioinformatics, epidemiology, vision, and many others.\n* [ML.NET](https://github.com/dotnet/machinelearning) - ML.NET is a cross-platform open-source machine learning framework which makes machine learning accessible to .NET developers. ML.NET was originally developed in Microsoft Research and evolved into a significant framework over the last decade and is used across many product groups in Microsoft like Windows, Bing, PowerPoint, Excel and more.\n* [Neural Network Designer](https://sourceforge.net/projects/nnd/) - DBMS management system and designer for neural networks. The designer application is developed using WPF, and is a user interface which allows you to design your neural network, query the network, create and configure chat bots that are capable of asking questions and learning from your feed back. The chat bots can even scrape the internet for information to return in their output as well as to use for learning.\n* [Synapses](https://github.com/mrdimosthenis/Synapses) - Neural network library in F#.\n* [Vulpes](https://github.com/fsprojects/Vulpes) - Deep belief and deep learning implementation written in F# and leverages CUDA GPU execution with Alea.cuBase.\n\n<a name=\"net-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [numl](https://www.nuget.org/packages/numl/) - numl is a machine learning library intended to ease the use of using standard modeling techniques for both prediction and clustering.\n* [Math.NET Numerics](https://www.nuget.org/packages/MathNet.Numerics/) - Numerical foundation of the Math.NET project, aiming to provide methods and algorithms for numerical computations in science, engineering and every day use. Supports .Net 4.0, .Net 3.5 and Mono on Windows, Linux and Mac; Silverlight 5, WindowsPhone/SL 8, WindowsPhone 8.1 and Windows 8 with PCL Portable Profiles 47 and 344; Android/iOS with Xamarin.\n* [Sho](https://www.microsoft.com/en-us/research/project/sho-the-net-playground-for-data/) - Sho is an interactive environment for data analysis and scientific computing that lets you seamlessly connect scripts (in IronPython) with compiled code (in .NET) to enable fast and flexible prototyping. The environment includes powerful and efficient libraries for linear algebra as well as data visualization that can be used from any .NET language, as well as a feature-rich interactive shell for rapid development.\n\n<a name=\"objectivec\"></a>\n## Objective C\n\n<a name=\"objectivec-general-purpose\"></a>\n### General-Purpose Machine Learning\n\n* [YCML](https://github.com/yconst/YCML) - A Machine Learning framework for Objective-C and Swift (OS X / iOS).\n* [MLPNeuralNet](https://github.com/nikolaypavlov/MLPNeuralNet) - Fast multilayer perceptron neural network library for iOS and Mac OS X. MLPNeuralNet predicts new examples by trained neural network. It is built on top of the Apple's Accelerate Framework, using vectorized operations and hardware acceleration if available. **[Deprecated]**\n* [MAChineLearning](https://github.com/gianlucabertani/MAChineLearning) - An Objective-C multilayer perceptron library, with full support for training through backpropagation. Implemented using vDSP and vecLib, it's 20 times faster than its Java equivalent. Includes sample code for use from Swift.\n* [BPN-NeuralNetwork](https://github.com/Kalvar/ios-BPN-NeuralNetwork) - It implemented 3 layers neural network ( Input Layer, Hidden Layer and Output Layer ) and it named Back Propagation Neural Network (BPN). This network can be used in products recommendation, user behavior analysis, data mining and data analysis. **[Deprecated]**\n* [Multi-Perceptron-NeuralNetwork](https://github.com/Kalvar/ios-Multi-Perceptron-NeuralNetwork) - it implemented multi-perceptrons neural network (\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af) based on Back Propagation Neural Network (BPN) and designed unlimited-hidden-layers.\n* [KRHebbian-Algorithm](https://github.com/Kalvar/ios-KRHebbian-Algorithm) - It is a non-supervisor and self-learning algorithm (adjust the weights) in neural network of Machine Learning. **[Deprecated]**\n* [KRKmeans-Algorithm](https://github.com/Kalvar/ios-KRKmeans-Algorithm) - It implemented K-Means the clustering and classification algorithm. It could be used in data mining and image compression. **[Deprecated]**\n* [KRFuzzyCMeans-Algorithm](https://github.com/Kalvar/ios-KRFuzzyCMeans-Algorithm) - It implemented Fuzzy C-Means (FCM) the fuzzy clustering / classification algorithm on Machine Learning. It could be used in data mining and image compression. **[Deprecated]**\n\n<a name=\"ocaml\"></a>\n## OCaml\n\n<a name=\"ocaml-general-purpose\"></a>\n### General-Purpose Machine Learning\n\n* [Oml](https://github.com/rleonid/oml) - A general statistics and machine learning library.\n* [GPR](https://mmottl.github.io/gpr/) - Efficient Gaussian Process Regression in OCaml.\n* [Libra-Tk](https://libra.cs.uoregon.edu) - Algorithms for learning and inference with discrete probabilistic models.\n* [TensorFlow](https://github.com/LaurentMazare/tensorflow-ocaml) - OCaml bindings for TensorFlow.\n\n<a name=\"perl\"></a>\n## Perl\n\n<a name=\"perl-data\"></a>\n### Data Analysis / Data Visualization\n\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning), a pluggable architecture for data and image processing, which can\nbe [used for machine learning](https://github.com/zenogantner/PDL-ML).\n\n<a name=\"perl-ml\"></a>\n### General-Purpose Machine Learning\n\n* [MXnet for Deep Learning, in Perl](https://github.com/apache/incubator-mxnet/tree/master/perl-package),\nalso [released in CPAN](https://metacpan.org/pod/AI::MXNet).\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning),\nusing AWS machine learning platform from Perl.\n* [Algorithm::SVMLight](https://metacpan.org/pod/Algorithm::SVMLight),\n  implementation of Support Vector Machines with SVMLight under it. **[Deprecated]**\n* Several machine learning and artificial intelligence models are\n  included in the [`AI`](https://metacpan.org/search?size=20&q=AI)\n  namespace. For instance, you can\n  find [Na\u00efve Bayes](https://metacpan.org/pod/AI::NaiveBayes).\n\n<a name=\"perl6\"></a>\n## Perl 6\n\n* [Support Vector Machines](https://github.com/titsuki/p6-Algorithm-LibSVM)\n* [Na\u00efve Bayes](https://github.com/titsuki/p6-Algorithm-NaiveBayes)\n\n### Data Analysis / Data Visualization\n\n* [Perl Data Language](https://metacpan.org/pod/Paws::MachineLearning),\na pluggable architecture for data and image processing, which can\nbe\n[used for machine learning](https://github.com/zenogantner/PDL-ML).\n\n### General-Purpose Machine Learning\n\n<a name=\"php\"></a>\n## PHP\n\n<a name=\"php-nlp\"></a>\n### Natural Language Processing\n\n* [jieba-php](https://github.com/fukuball/jieba-php) - Chinese Words Segmentation Utilities.\n\n<a name=\"php-general-purpose\"></a>\n### General-Purpose Machine Learning\n\n* [PHP-ML](https://github.com/php-ai/php-ml) - Machine Learning library for PHP. Algorithms, Cross Validation, Neural Network, Preprocessing, Feature Extraction and much more in one library.\n* [PredictionBuilder](https://github.com/denissimon/prediction-builder) - A library for machine learning that builds predictions using a linear regression.\n* [Rubix ML](https://github.com/RubixML) - A high-level machine learning (ML) library that lets you build programs that learn from data using the PHP language.\n* [19 Questions](https://github.com/fulldecent/19-questions) - A machine learning / bayesian inference assigning attributes to objects.\n\n<a name=\"python\"></a>\n## Python\n\n<a name=\"python-cv\"></a>\n#### Computer Vision\n\n* [Scikit-Image](https://github.com/scikit-image/scikit-image) - A collection of algorithms for image processing in Python.\n* [SimpleCV](http://simplecv.org/) - An open source computer vision framework that gives access to several high-powered computer vision libraries, such as OpenCV. Written on Python and runs on Mac, Windows, and Ubuntu Linux.\n* [Vigranumpy](https://github.com/ukoethe/vigra) - Python bindings for the VIGRA C++ computer vision library.\n* [OpenFace](https://cmusatyalab.github.io/openface/) - Free and open source face recognition with deep neural networks.\n* [PCV](https://github.com/jesolem/PCV) - Open source Python module for computer vision. **[Deprecated]**\n* [face_recognition](https://github.com/ageitgey/face_recognition) - Face recognition library that recognize and manipulate faces from Python or from the command line.\n* [dockerface](https://github.com/natanielruiz/dockerface) - Easy to install and use deep learning Faster R-CNN face detection for images and video in a docker container.\n* [Detectron](https://github.com/facebookresearch/Detectron) - FAIR's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.\n* [albumentations](https://github.com/albu/albumentations) - \u0410 fast and framework agnostic image augmentation library that implements a diverse set of augmentation techniques. Supports classification, segmentation, detection out of the box. Was used to win a number of Deep Learning competitions at Kaggle, Topcoder and those that were a part of the CVPR workshops.\n* [pytessarct](https://github.com/madmaze/pytesseract) - Python-tesseract is an optical character recognition (OCR) tool for python. That is, it will recognize and \"read\" the text embedded in images.Python-tesseract is a wrapper for [Google's Tesseract-OCR Engine](https://github.com/tesseract-ocr/tesseract)>.\n* [imutils](https://github.com/jrosebr1/imutils) - A library containg Convenience functions to make basic image processing operations such as translation, rotation, resizing, skeletonization, and displaying Matplotlib images easier with OpenCV and Python.\n* [PyTorchCV](https://github.com/donnyyou/PyTorchCV) - A PyTorch-Based Framework for Deep Learning in Computer Vision.\n* [neural-style-pt](https://github.com/ProGamerGov/neural-style-pt) - A PyTorch implementation of Justin Johnson's neural-style (neural style transfer).\n\n<a name=\"python-nlp\"></a>\n#### Natural Language Processing\n\n* [pkuseg-python](https://github.com/lancopku/pkuseg-python) - A better version of Jieba, developed by Peking University.\n* [NLTK](https://www.nltk.org/) - A leading platform for building Python programs to work with human language data.\n* [Pattern](http://www.clips.ua.ac.be/pattern) - A web mining module for the Python programming language. It has tools for natural language processing, machine learning, among others.\n* [Quepy](https://github.com/machinalis/quepy) - A python framework to transform natural language questions to queries in a database query language.\n* [TextBlob](http://textblob.readthedocs.io/en/dev/) - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of NLTK and Pattern, and plays nicely with both.\n* [YAlign](https://github.com/machinalis/yalign) - A sentence aligner, a friendly tool for extracting parallel sentences from comparable corpora. **[Deprecated]**\n* [jieba](https://github.com/fxsjy/jieba#jieba-1) - Chinese Words Segmentation Utilities.\n* [SnowNLP](https://github.com/isnowfy/snownlp) - A library for processing Chinese text.\n* [spammy](https://github.com/tasdikrahman/spammy) - A library for email Spam filtering built on top of nltk\n* [loso](https://github.com/fangpenlin/loso) - Another Chinese segmentation library. **[Deprecated]**\n* [genius](https://github.com/duanhongyi/genius) - A Chinese segment base on Conditional Random Field.\n* [KoNLPy](http://konlpy.org) - A Python package for Korean natural language processing.\n* [nut](https://github.com/pprett/nut) - Natural language Understanding Toolkit. **[Deprecated]**\n* [Rosetta](https://github.com/columbia-applied-data-science/rosetta) - Text processing tools and wrappers (e.g. Vowpal Wabbit)\n* [BLLIP Parser](https://pypi.org/project/bllipparser/) - Python bindings for the BLLIP Natural Language Parser (also known as the Charniak-Johnson parser). **[Deprecated]**\n* [PyNLPl](https://github.com/proycon/pynlpl) - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for [FoLiA](https://proycon.github.io/folia/), but also ARPA language models, Moses phrasetables, GIZA++ alignments.\n* [python-ucto](https://github.com/proycon/python-ucto) - Python binding to ucto (a unicode-aware rule-based tokenizer for various languages).\n* [python-frog](https://github.com/proycon/python-frog) - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER)\n* [python-zpar](https://github.com/EducationalTestingService/python-zpar) - Python bindings for [ZPar](https://github.com/frcchang/zpar), a statistical part-of-speech-tagger, constiuency parser, and dependency parser for English.\n* [colibri-core](https://github.com/proycon/colibri-core) - Python binding to C++ library for extracting and working with with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.\n* [spaCy](https://github.com/explosion/spaCy) - Industrial strength NLP with Python and Cython.\n* [PyStanfordDependencies](https://github.com/dmcc/PyStanfordDependencies) - Python interface for converting Penn Treebank trees to Stanford Dependencies.\n* [Distance](https://github.com/doukremt/distance) - Levenshtein and Hamming distance computation. **[Deprecated]**\n* [Fuzzy Wuzzy](https://github.com/seatgeek/fuzzywuzzy) - Fuzzy String Matching in Python.\n* [jellyfish](https://github.com/jamesturk/jellyfish) - a python library for doing approximate and phonetic matching of strings.\n* [editdistance](https://pypi.org/project/editdistance/) - fast implementation of edit distance.\n* [textacy](https://github.com/chartbeat-labs/textacy) - higher-level NLP built on Spacy.\n* [stanford-corenlp-python](https://github.com/dasmith/stanford-corenlp-python) - Python wrapper for [Stanford CoreNLP](https://github.com/stanfordnlp/CoreNLP) **[Deprecated]**\n* [CLTK](https://github.com/cltk/cltk) - The Classical Language Toolkit.\n* [rasa_nlu](https://github.com/RasaHQ/rasa_nlu) - turn natural language into structured data.\n* [yase](https://github.com/PPACI/yase) - Transcode sentence (or other sequence) to list of word vector .\n* [Polyglot](https://github.com/aboSamoor/polyglot) - Multilingual text (NLP) processing toolkit.\n* [DrQA](https://github.com/facebookresearch/DrQA) - Reading Wikipedia to answer open-domain questions.\n* [Dedupe](https://github.com/dedupeio/dedupe) - A python library for accurate and scalable fuzzy matching, record deduplication and entity-resolution.\n* [Snips NLU](https://github.com/snipsco/snips-nlu) - Natural Language Understanding library for intent classification and entity extraction\n* [NeuroNER](https://github.com/Franck-Dernoncourt/NeuroNER) - Named-entity recognition using neural networks providing state-of-the-art-results\n* [DeepPavlov](https://github.com/deepmipt/DeepPavlov/) - conversational AI library with many pretrained Russian NLP models.\n* [BigARTM](https://github.com/bigartm/bigartm) - topic modelling platform.\n\n<a name=\"python-general-purpose\"></a>\n#### General-Purpose Machine Learning\n* [PyOD](https://github.com/yzhao062/pyod) -> Python Outlier Detection, comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. Featured for Advanced models, including Neural Networks/Deep Learning and Outlier Ensembles.\n* [steppy](https://github.com/neptune-ml/steppy) -> Lightweight, Python library for fast and reproducible machine learning experimentation. Introduces very simple interface that enables clean machine learning pipeline design.\n* [steppy-toolkit](https://github.com/neptune-ml/steppy-toolkit) -> Curated collection of the neural networks, transformers and models that make your machine learning work faster and more effective.\n* [CNTK](https://github.com/Microsoft/CNTK) - Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit. Documentation can be found [here](https://docs.microsoft.com/cognitive-toolkit/).\n* [auto_ml](https://github.com/ClimbsRocks/auto_ml) - Automated machine learning for production and analytics. Lets you focus on the fun parts of ML, while outputting production-ready code, and detailed analytics of your dataset and results. Includes support for NLP, XGBoost, CatBoost, LightGBM, and soon, deep learning.\n* [machine learning](https://github.com/jeff1evesque/machine-learning) - automated build consisting of a [web-interface](https://github.com/jeff1evesque/machine-learning#web-interface), and set of [programmatic-interface](https://github.com/jeff1evesque/machine-learning#programmatic-interface) API, for support vector machines. Corresponding dataset(s) are stored into a SQL database, then generated model(s) used for prediction(s), are stored into a NoSQL datastore.\n* [XGBoost](https://github.com/dmlc/xgboost) - Python bindings for eXtreme Gradient Boosting (Tree) Library.\n* [Apache SINGA](https://singa.apache.org) - An Apache Incubating project for developing an open source machine learning library.\n* [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers) - Book/iPython notebooks on Probabilistic Programming in Python.\n* [Featureforge](https://github.com/machinalis/featureforge) A set of tools for creating and testing machine learning features, with a scikit-learn compatible API.\n* [MLlib in Apache Spark](http://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [scikit-learn](https://scikit-learn.org/) - A Python module for machine learning built on top of SciPy.\n* [metric-learn](https://github.com/metric-learn/metric-learn) - A Python module for metric learning.\n* [SimpleAI](https://github.com/simpleai-team/simpleai) Python implementation of many of the artificial intelligence algorithms described on the book \"Artificial Intelligence, a Modern Approach\". It focuses on providing an easy to use, well documented and tested library.\n* [astroML](https://www.astroml.org/) - Machine Learning and Data Mining for Astronomy.\n* [graphlab-create](https://turi.com/products/create/docs/) - A library with various machine learning models (regression, clustering, recommender systems, graph analytics, etc.) implemented on top of a disk-backed DataFrame.\n* [BigML](https://bigml.com) - A library that contacts external servers.\n* [pattern](https://github.com/clips/pattern) - Web mining module for Python.\n* [NuPIC](https://github.com/numenta/nupic) - Numenta Platform for Intelligent Computing.\n* [Pylearn2](https://github.com/lisa-lab/pylearn2) - A Machine Learning library based on [Theano](https://github.com/Theano/Theano). **[Deprecated]**\n* [keras](https://github.com/keras-team/keras) - High-level neural networks frontend for [TensorFlow](https://github.com/tensorflow/tensorflow), [CNTK](https://github.com/Microsoft/CNTK) and [Theano](https://github.com/Theano/Theano).\n* [Lasagne](https://github.com/Lasagne/Lasagne) - Lightweight library to build and train neural networks in Theano.\n* [hebel](https://github.com/hannes-brt/hebel) - GPU-Accelerated Deep Learning Library in Python. **[Deprecated]**\n* [Chainer](https://github.com/chainer/chainer) - Flexible neural network framework.\n* [prophet](https://facebook.github.io/prophet/) - Fast and automated time series forecasting framework by Facebook.\n* [gensim](https://github.com/RaRe-Technologies/gensim) - Topic Modelling for Humans.\n* [topik](https://github.com/ContinuumIO/topik) - Topic modelling toolkit. **[Deprecated]**\n* [PyBrain](https://github.com/pybrain/pybrain) - Another Python Machine Learning Library.\n* [Brainstorm](https://github.com/IDSIA/brainstorm) - Fast, flexible and fun neural networks. This is the successor of PyBrain.\n* [Surprise](https://surpriselib.com) - A scikit for building and analyzing recommender systems.\n* [Crab](https://github.com/muricoca/crab) - A flexible, fast recommender engine. **[Deprecated]**\n* [python-recsys](https://github.com/ocelma/python-recsys) - A Python library for implementing a Recommender System.\n* [thinking bayes](https://github.com/AllenDowney/ThinkBayes) - Book on Bayesian Analysis.\n* [Image-to-Image Translation with Conditional Adversarial Networks](https://github.com/williamFalcon/pix2pix-keras) - Implementation of image to image (pix2pix) translation from the paper by [isola et al](https://arxiv.org/pdf/1611.07004.pdf).[DEEP LEARNING]\n* [Restricted Boltzmann Machines](https://github.com/echen/restricted-boltzmann-machines) -Restricted Boltzmann Machines in Python. [DEEP LEARNING]\n* [Bolt](https://github.com/pprett/bolt) - Bolt Online Learning Toolbox. **[Deprecated]**\n* [CoverTree](https://github.com/patvarilly/CoverTree) - Python implementation of cover trees, near-drop-in replacement for scipy.spatial.kdtree **[Deprecated]**\n* [nilearn](https://github.com/nilearn/nilearn) - Machine learning for NeuroImaging in Python.\n* [neuropredict](https://github.com/raamana/neuropredict) - Aimed at novice machine learners and non-expert programmers, this package offers easy (no coding needed) and comprehensive machine learning (evaluation and full report of predictive performance WITHOUT requiring you to code) in Python for NeuroImaging and any other type of features. This is aimed at absorbing the much of the ML workflow, unlike other packages like nilearn and pymvpa, which require you to learn their API and code to produce anything useful.\n* [imbalanced-learn](https://imbalanced-learn.org/en/stable/index.html) - Python module to perform under sampling and over sampling with various techniques.\n* [Shogun](https://github.com/shogun-toolbox/shogun) - The Shogun Machine Learning Toolbox.\n* [Pyevolve](https://github.com/perone/Pyevolve) - Genetic algorithm framework. **[Deprecated]**\n* [Caffe](https://github.com/BVLC/caffe) - A deep learning framework developed with cleanliness, readability, and speed in mind.\n* [breze](https://github.com/breze-no-salt/breze) - Theano based library for deep and recurrent neural networks. \n* [Cortex](https://github.com/cortexlabs/cortex) - Open source platform for deploying machine learning models in production.\n* [pyhsmm](https://github.com/mattjj/pyhsmm) - library for approximate unsupervised inference in Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM and HDP-HSMM, mostly with weak-limit approximations.\n* [mrjob](https://pythonhosted.org/mrjob/) - A library to let Python program run on Hadoop.\n* [SKLL](https://github.com/EducationalTestingService/skll) - A wrapper around scikit-learn that makes it simpler to conduct experiments.\n* [neurolab](https://github.com/zueve/neurolab)\n* [Spearmint](https://github.com/HIPS/Spearmint) - Spearmint is a package to perform Bayesian optimization according to the algorithms outlined in the paper: Practical Bayesian Optimization of Machine Learning Algorithms. Jasper Snoek, Hugo Larochelle and Ryan P. Adams. Advances in Neural Information Processing Systems, 2012. **[Deprecated]**\n* [Pebl](https://github.com/abhik/pebl/) - Python Environment for Bayesian Learning. **[Deprecated]**\n* [Theano](https://github.com/Theano/Theano/) - Optimizing GPU-meta-programming code generating array oriented optimizing math compiler in Python.\n* [TensorFlow](https://github.com/tensorflow/tensorflow/) - Open source software library for numerical computation using data flow graphs.\n* [pomegranate](https://github.com/jmschrei/pomegranate) - Hidden Markov Models for Python, implemented in Cython for speed and efficiency.\n* [python-timbl](https://github.com/proycon/python-timbl) - A Python extension module wrapping the full TiMBL C++ programming interface. Timbl is an elaborate k-Nearest Neighbours machine learning toolkit.\n* [deap](https://github.com/deap/deap) - Evolutionary algorithm framework.\n* [pydeep](https://github.com/andersbll/deeppy) - Deep Learning In Python. **[Deprecated]**\n* [mlxtend](https://github.com/rasbt/mlxtend) - A library consisting of useful tools for data science and machine learning tasks.\n* [neon](https://github.com/NervanaSystems/neon) - Nervana's [high-performance](https://github.com/soumith/convnet-benchmarks) Python-based Deep Learning framework [DEEP LEARNING].\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search.\n* [Neural Networks and Deep Learning](https://github.com/mnielsen/neural-networks-and-deep-learning) - Code samples for my book \"Neural Networks and Deep Learning\" [DEEP LEARNING].\n* [Annoy](https://github.com/spotify/annoy) - Approximate nearest neighbours implementation.\n* [TPOT](https://github.com/EpistasisLab/tpot) - Tool that automatically creates and optimizes machine learning pipelines using genetic programming. Consider it your personal data science assistant, automating a tedious part of machine learning.\n* [pgmpy](https://github.com/pgmpy/pgmpy) A python library for working with Probabilistic Graphical Models.\n* [DIGITS](https://github.com/NVIDIA/DIGITS) - The Deep Learning GPU Training System (DIGITS) is a web application for training deep learning models.\n* [Orange](https://orange.biolab.si/) - Open source data visualization and data analysis for novices and experts.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [milk](https://github.com/luispedro/milk) - Machine learning toolkit focused on supervised classification. **[Deprecated]**\n* [TFLearn](https://github.com/tflearn/tflearn) - Deep learning library featuring a higher-level API for TensorFlow.\n* [REP](https://github.com/yandex/rep) - an IPython-based environment for conducting data-driven research in a consistent and reproducible way. REP is not trying to substitute scikit-learn, but extends it and provides better user experience. **[Deprecated]**\n* [rgf_python](https://github.com/RGF-team/rgf) - Python bindings for Regularized Greedy Forest (Tree) Library.\n* [skbayes](https://github.com/AmazaspShumik/sklearn-bayes) - Python package for Bayesian Machine Learning with scikit-learn API.\n* [fuku-ml](https://github.com/fukuball/fuku-ml) - Simple machine learning library, including Perceptron, Regression, Support Vector Machine, Decision Tree and more, it's easy to use and easy to learn for beginners.\n* [Xcessiv](https://github.com/reiinakano/xcessiv) - A web-based application for quick, scalable, and automated hyperparameter tuning and stacked ensembling.\n* [PyTorch](https://github.com/pytorch/pytorch) - Tensors and Dynamic neural networks in Python with strong GPU acceleration\n* [ML-From-Scratch](https://github.com/eriklindernoren/ML-From-Scratch) - Implementations of Machine Learning models from scratch in Python with a focus on transparency. Aims to showcase the nuts and bolts of ML in an accessible way.\n* [Edward](http://edwardlib.org/) - A library for probabilistic modeling, inference, and criticism. Built on top of TensorFlow.\n* [xRBM](https://github.com/omimo/xRBM) - A library for Restricted Boltzmann Machine (RBM) and its conditional variants in Tensorflow.\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, well documented and supports CPU and GPU (even multi-GPU) computation.\n* [stacked_generalization](https://github.com/fukatani/stacked_generalization) - Implementation of machine learning stacking technic as handy library in Python.\n* [modAL](https://github.com/modAL-python/modAL) - A modular active learning framework for Python, built on top of scikit-learn.\n* [Cogitare](https://github.com/cogitare-ai/cogitare): A Modern, Fast, and Modular Deep Learning and Machine Learning framework for Python.\n* [Parris](https://github.com/jgreenemi/Parris) - Parris, the automated infrastructure setup tool for machine learning algorithms.\n* [neonrvm](https://github.com/siavashserver/neonrvm) - neonrvm is an open source machine learning library based on RVM technique. It's written in C programming language and comes with Python programming language bindings.\n* [Turi Create](https://github.com/apple/turicreate) - Machine learning from Apple. Turi Create simplifies the development of custom machine learning models. You don't have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app.\n* [xLearn](https://github.com/aksnzhy/xlearn) - A high performance, easy-to-use, and scalable machine learning package, which can be used to solve large-scale machine learning problems. xLearn is especially useful for solving machine learning problems on large-scale sparse data, which is very common in Internet services such as online advertisement and recommender systems.\n* [mlens](https://github.com/flennerhag/mlens) - A high performance, memory efficient, maximally parallelized ensemble learning, integrated with scikit-learn.\n* [Netron](https://github.com/lutzroeder/netron) - Visualizer for machine learning models.\n* [Thampi](https://github.com/scoremedia/thampi) - Machine Learning Prediction System on AWS Lambda\n* [MindsDB](https://github.com/mindsdb/mindsdb) - Open Source framework to streamline use of neural networks.\n* [Microsoft Recommenders](https://github.com/Microsoft/Recommenders): Examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repo contains some of the latest state of the art algorithms from Microsoft Research as well as from other companies and institutions.\n* [StellarGraph](https://github.com/stellargraph/stellargraph): Machine Learning on Graphs, a Python library for machine learning on graph-structured (network-structured) data.\n* [BentoML](https://github.com/bentoml/bentoml): Toolkit for package and deploy machine learning models for serving in production\n* [MiraiML](https://github.com/arthurpaulino/miraiml): An asynchronous engine for continuous & autonomous machine learning, built for real-time usage.\n* [numpy-ML](https://github.com/ddbourgin/numpy-ml): Reference implementations of ML models written in numpy\n* [creme](https://github.com/creme-ml/creme): A framework for online machine learning.\n* [Neuraxle](https://github.com/Neuraxio/Neuraxle): A framework providing the right abstractions to ease research, development, and deployment of your ML pipelines.\n* [Cornac](https://github.com/PreferredAI/cornac) - A comparative framework for multimodal recommender systems with a focus on models leveraging auxiliary data.\n* [JAX](https://github.com/google/jax) - JAX is Autograd and XLA, brought together for high-performance machine learning research.\n* [fast.ai](https://github.com/fastai/fastaihttps://github.com/fastai/fastai) - A library simplifies training fast and accurate neural nets using modern best practices and already supports  vision, text, tabular, and collab (collaborative filtering) models \"out of the box\"\n* [Catalyst](https://github.com/catalyst-team/catalyst) - High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code/ideas reusing. Being able to research/develop something new, rather than write another regular train loop.\n* [Fastai](https://github.com/fastai/fastai) - High-level wrapper built on the top of Pytorch which supports vision, text, tabular data and collaborative filtering.\n\n<a name=\"python-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [SciPy](https://www.scipy.org/) - A Python-based ecosystem of open-source software for mathematics, science, and engineering.\n* [NumPy](https://www.numpy.org/) - A fundamental package for scientific computing with Python.\n* [Numba](https://numba.pydata.org/) - Python JIT (just in time) compiler to LLVM aimed at scientific Python by the developers of Cython and NumPy.\n* [Mars](https://github.com/mars-project/mars) - A tensor-based framework for large-scale data computation which often regarded as a parallel and distributed version of NumPy.\n* [NetworkX](https://networkx.github.io/) - A high-productivity software for complex networks.\n* [igraph](https://igraph.org/python/) - binding to igraph library - General purpose graph library.\n* [Pandas](https://pandas.pydata.org/) - A library providing high-performance, easy-to-use data structures and data analysis tools.\n* [Open Mining](https://github.com/mining/mining) - Business Intelligence (BI) in Python (Pandas web interface) **[Deprecated]**\n* [PyMC](https://github.com/pymc-devs/pymc) - Markov Chain Monte Carlo sampling toolkit.\n* [zipline](https://github.com/quantopian/zipline) - A Pythonic algorithmic trading library.\n* [PyDy](https://www.pydy.org/) - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion based around NumPy, SciPy, IPython, and matplotlib.\n* [SymPy](https://github.com/sympy/sympy) - A Python library for symbolic mathematics.\n* [statsmodels](https://github.com/statsmodels/statsmodels) - Statistical modeling and econometrics in Python.\n* [astropy](https://www.astropy.org/) - A community Python library for Astronomy.\n* [matplotlib](https://matplotlib.org/) - A Python 2D plotting library.\n* [bokeh](https://github.com/bokeh/bokeh) - Interactive Web Plotting for Python.\n* [plotly](https://plot.ly/python/) - Collaborative web plotting for Python and matplotlib.\n* [altair](https://github.com/altair-viz/altair) - A Python to Vega translator.\n* [d3py](https://github.com/mikedewar/d3py) - A plotting library for Python, based on [D3.js](https://d3js.org/).\n* [PyDexter](https://github.com/D3xterjs/pydexter) - Simple plotting for Python. Wrapper for D3xterjs; easily render charts in-browser.\n* [ggplot](https://github.com/yhat/ggpy) - Same API as ggplot2 for R. **[Deprecated]**\n* [ggfortify](https://github.com/sinhrks/ggfortify) - Unified interface to ggplot2 popular R packages.\n* [Kartograph.py](https://github.com/kartograph/kartograph.py) - Rendering beautiful SVG maps in Python.\n* [pygal](http://pygal.org/en/stable/) - A Python SVG Charts Creator.\n* [PyQtGraph](https://github.com/pyqtgraph/pyqtgraph) - A pure-python graphics and GUI library built on PyQt4 / PySide and NumPy.\n* [pycascading](https://github.com/twitter/pycascading) **[Deprecated]**\n* [Petrel](https://github.com/AirSage/Petrel) - Tools for writing, submitting, debugging, and monitoring Storm topologies in pure Python.\n* [Blaze](https://github.com/blaze/blaze) - NumPy and Pandas interface to Big Data.\n* [emcee](https://github.com/dfm/emcee) - The Python ensemble sampling toolkit for affine-invariant MCMC.\n* [windML](https://github.com/cigroup-ol/windml) - A Python Framework for Wind Energy Analysis and Prediction.\n* [vispy](https://github.com/vispy/vispy) - GPU-based high-performance interactive OpenGL 2D/3D data visualization library.\n* [cerebro2](https://github.com/numenta/nupic.cerebro2) A web-based visualization and debugging platform for NuPIC. **[Deprecated]**\n* [NuPIC Studio](https://github.com/htm-community/nupic.studio) An all-in-one NuPIC Hierarchical Temporal Memory visualization and debugging super-tool! **[Deprecated]**\n* [SparklingPandas](https://github.com/sparklingpandas/sparklingpandas) Pandas on PySpark (POPS).\n* [Seaborn](https://seaborn.pydata.org/) - A python visualization library based on matplotlib.\n* [bqplot](https://github.com/bloomberg/bqplot) - An API for plotting in Jupyter (IPython).\n* [pastalog](https://github.com/rewonc/pastalog) - Simple, realtime visualization of neural network training performance.\n* [Superset](https://github.com/apache/incubator-superset) - A data exploration platform designed to be visual, intuitive, and interactive.\n* [Dora](https://github.com/nathanepstein/dora) - Tools for exploratory data analysis in Python.\n* [Ruffus](http://www.ruffus.org.uk) - Computation Pipeline library for python.\n* [SOMPY](https://github.com/sevamoo/SOMPY) - Self Organizing Map written in Python (Uses neural networks for data analysis).\n* [somoclu](https://github.com/peterwittek/somoclu) Massively parallel self-organizing maps: accelerate training on multicore CPUs, GPUs, and clusters, has python API.\n* [HDBScan](https://github.com/lmcinnes/hdbscan) - implementation of the hdbscan algorithm in Python - used for clustering\n* [visualize_ML](https://github.com/ayush1997/visualize_ML) - A python package for data exploration and data analysis. **[Deprecated]**\n* [scikit-plot](https://github.com/reiinakano/scikit-plot) - A visualization library for quick and easy generation of common plots in data analysis and machine learning.\n* [Bowtie](https://github.com/jwkvam/bowtie) - A dashboard library for interactive visualizations using flask socketio and react.\n* [lime](https://github.com/marcotcr/lime) - Lime is about explaining what machine learning classifiers (or models) are doing. It is able to explain any black box classifier, with two or more classes.\n* [PyCM](https://github.com/sepandhaghighi/pycm) - PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters\n* [Dash](https://github.com/plotly/dash) - A framework for creating analytical web applications built on top of Plotly.js, React, and Flask\n* [Lambdo](https://github.com/asavinov/lambdo) - A workflow engine for solving machine learning problems by combining in one analysis pipeline (i) feature engineering and machine learning (ii) model training and prediction (iii) table population and column evaluation via user-defined (Python) functions.\n* [TensorWatch](https://github.com/microsoft/tensorwatch) - Debugging and visualization tool for machine learning and data science. It extensively leverages Jupyter Notebook to show real-time visualizations of data in running processes such as machine learning training.\n* [dowel](https://github.com/rlworkgroup/dowel) - A little logger for machine learning research. Output any object to the terminal, CSV, TensorBoard, text logs on disk, and more with just one call to `logger.log()`.\n\n<a name=\"python-misc\"></a>\n#### Misc Scripts / iPython Notebooks / Codebases\n* [Map/Reduce implementations of common ML algorithms](https://github.com/Yannael/BigDataAnalytics_INFOH515): Jupyter notebooks that cover how to implement from scratch different ML algorithms (ordinary least squares, gradient descent, k-means, alternating least squares), using Python NumPy, and how to then make these implementations scalable using Map/Reduce and Spark.\n* [BioPy](https://github.com/jaredthecoder/BioPy) - Biologically-Inspired and Machine Learning Algorithms in Python. **[Deprecated]**\n* [SVM Explorer](https://github.com/plotly/dash-svm) - Interactive SVM Explorer, using Dash and scikit-learn\n* [pattern_classification](https://github.com/rasbt/pattern_classification)\n* [thinking stats 2](https://github.com/Wavelets/ThinkStats2)\n* [hyperopt](https://github.com/hyperopt/hyperopt-sklearn)\n* [numpic](https://github.com/numenta/nupic)\n* [2012-paper-diginorm](https://github.com/dib-lab/2012-paper-diginorm)\n* [A gallery of interesting IPython notebooks](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n* [ipython-notebooks](https://github.com/ogrisel/notebooks)\n* [data-science-ipython-notebooks](https://github.com/donnemartin/data-science-ipython-notebooks) - Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines.\n* [decision-weights](https://github.com/CamDavidsonPilon/decision-weights)\n* [Sarah Palin LDA](https://github.com/Wavelets/sarah-palin-lda) - Topic Modeling the Sarah Palin emails.\n* [Diffusion Segmentation](https://github.com/Wavelets/diffusion-segmentation) - A collection of image segmentation algorithms based on diffusion methods.\n* [Scipy Tutorials](https://github.com/Wavelets/scipy-tutorials) - SciPy tutorials. This is outdated, check out scipy-lecture-notes.\n* [Crab](https://github.com/marcelcaraciolo/crab) - A recommendation engine library for Python.\n* [BayesPy](https://github.com/maxsklar/BayesPy) - Bayesian Inference Tools in Python.\n* [scikit-learn tutorials](https://github.com/GaelVaroquaux/scikit-learn-tutorial) - Series of notebooks for learning scikit-learn.\n* [sentiment-analyzer](https://github.com/madhusudancs/sentiment-analyzer) - Tweets Sentiment Analyzer\n* [sentiment_classifier](https://github.com/kevincobain2000/sentiment_classifier) - Sentiment classifier using word sense disambiguation.\n* [group-lasso](https://github.com/fabianp/group_lasso) - Some experiments with the coordinate descent algorithm used in the (Sparse) Group Lasso model.\n* [jProcessing](https://github.com/kevincobain2000/jProcessing) - Kanji / Hiragana / Katakana to Romaji Converter. Edict Dictionary & parallel sentences Search. Sentence Similarity between two JP Sentences. Sentiment Analysis of Japanese Text. Run Cabocha(ISO--8859-1 configured) in Python.\n* [mne-python-notebooks](https://github.com/mne-tools/mne-python-notebooks) - IPython notebooks for EEG/MEG data processing using mne-python.\n* [Neon Course](https://github.com/NervanaSystems/neon_course) - IPython notebooks for a complete course around understanding Nervana's Neon.\n* [pandas cookbook](https://github.com/jvns/pandas-cookbook) - Recipes for using Python's pandas library.\n* [climin](https://github.com/BRML/climin) - Optimization library focused on machine learning, pythonic implementations of gradient descent, LBFGS, rmsprop, adadelta and others.\n* [Allen Downey\u2019s Data Science Course](https://github.com/AllenDowney/DataScience) - Code for Data Science at Olin College, Spring 2014.\n* [Allen Downey\u2019s Think Bayes Code](https://github.com/AllenDowney/ThinkBayes) - Code repository for Think Bayes.\n* [Allen Downey\u2019s Think Complexity Code](https://github.com/AllenDowney/ThinkComplexity) - Code for Allen Downey's book Think Complexity.\n* [Allen Downey\u2019s Think OS Code](https://github.com/AllenDowney/ThinkOS) - Text and supporting code for Think OS: A Brief Introduction to Operating Systems.\n* [Python Programming for the Humanities](https://www.karsdorp.io/python-course/) - Course for Python programming for the Humanities, assuming no prior knowledge. Heavy focus on text processing / NLP.\n* [GreatCircle](https://github.com/mwgg/GreatCircle) - Library for calculating great circle distance.\n* [Optunity examples](http://optunity.readthedocs.io/en/latest/notebooks/index.html) - Examples demonstrating how to use Optunity in synergy with machine learning libraries.\n* [Dive into Machine Learning  with Python Jupyter notebook and scikit-learn](https://github.com/hangtwenty/dive-into-machine-learning) - \"I learned Python by hacking first, and getting serious *later.* I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself.\"\n* [TDB](https://github.com/ericjang/tdb) - TensorDebugger (TDB) is a visual debugger for deep learning. It features interactive, node-by-node debugging and visualization for TensorFlow.\n* [Suiron](https://github.com/kendricktan/suiron/) - Machine Learning for RC Cars.\n* [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos) - IPython notebooks from Data School's video tutorials on scikit-learn.\n* [Practical XGBoost in Python](https://parrotprediction.teachable.com/p/practical-xgboost-in-python) - comprehensive online course about using XGBoost in Python.\n* [Introduction to Machine Learning with Python](https://github.com/amueller/introduction_to_ml_with_python) - Notebooks and code for the book \"Introduction to Machine Learning with Python\"\n* [Pydata book](https://github.com/wesm/pydata-book) - Materials and IPython notebooks for \"Python for Data Analysis\" by Wes McKinney, published by O'Reilly Media\n* [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning) - Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained\n* [Prodmodel](https://github.com/prodmodel/prodmodel) - Build tool for data science pipelines.\n* [the-elements-of-statistical-learning](https://github.com/maitbayev/the-elements-of-statistical-learning) - This repository contains Jupyter notebooks implementing the algorithms found in the book and summary of the textbook.\n\n<a name=\"python-neural-networks\"></a>\n#### Neural Networks\n\n* [nn_builder](https://github.com/p-christ/nn_builder) - nn_builder is a python package that lets you build neural networks in 1 line\n* [NeuralTalk](https://github.com/karpathy/neuraltalk) - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.\n* [Neuron](https://github.com/molcik/python-neuron) - Neuron is simple class for time series predictions. It's utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg\u2013Marquardt algorithm.\n=======\n* [NeuralTalk](https://github.com/karpathy/neuraltalk2) - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences. **[Deprecated]**\n* [Neuron](https://github.com/molcik/python-neuron) - Neuron is simple class for time series predictions. It's utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg\u2013Marquardt algorithm. **[Deprecated]**\n* [Data Driven Code](https://github.com/atmb4u/data-driven-code) - Very simple implementation of neural networks for dummies in python without using any libraries, with detailed comments.\n* [Machine Learning, Data Science and Deep Learning with Python](https://www.manning.com/livevideo/machine-learning-data-science-and-deep-learning-with-python) - LiveVideo course that covers machine learning, Tensorflow, artificial intelligence, and neural networks.\n\n<a name=\"python-kaggle\"></a>\n#### Kaggle Competition Source Code\n* [open-solution-home-credit](https://github.com/neptune-ml/open-solution-home-credit) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Home-Credit-Default-Risk) for [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk).\n* [open-solution-googleai-object-detection](https://github.com/neptune-ml/open-solution-googleai-object-detection) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Google-AI-Object-Detection-Challenge) for [Google AI Open Images - Object Detection Track](https://www.kaggle.com/c/google-ai-open-images-object-detection-track).\n* [open-solution-salt-identification](https://github.com/neptune-ml/open-solution-salt-identification) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Salt-Detection) for [TGS Salt Identification Challenge](https://www.kaggle.com/c/tgs-salt-identification-challenge).\n* [open-solution-ship-detection](https://github.com/neptune-ml/open-solution-ship-detection) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Ships) for [Airbus Ship Detection Challenge](https://www.kaggle.com/c/airbus-ship-detection).\n* [open-solution-data-science-bowl-2018](https://github.com/neptune-ml/open-solution-data-science-bowl-2018) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Data-Science-Bowl-2018) for [2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018).\n* [open-solution-value-prediction](https://github.com/neptune-ml/open-solution-value-prediction) -> source code and [experiments results](https://app.neptune.ml/neptune-ml/Santander-Value-Prediction-Challenge) for [Santander Value Prediction Challenge](https://www.kaggle.com/c/santander-value-prediction-challenge).\n* [open-solution-toxic-comments](https://github.com/neptune-ml/open-solution-toxic-comments) -> source code for [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\n* [wiki challenge](https://github.com/hammer/wikichallenge) - An implementation of Dell Zhang's solution to Wikipedia's Participation Challenge on Kaggle.\n* [kaggle insults](https://github.com/amueller/kaggle_insults) - Kaggle Submission for \"Detecting Insults in Social Commentary\".\n* [kaggle_acquire-valued-shoppers-challenge](https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge) - Code for the Kaggle acquire valued shoppers challenge.\n* [kaggle-cifar](https://github.com/zygmuntz/kaggle-cifar) - Code for the CIFAR-10 competition at Kaggle, uses cuda-convnet.\n* [kaggle-blackbox](https://github.com/zygmuntz/kaggle-blackbox) - Deep learning made easy.\n* [kaggle-accelerometer](https://github.com/zygmuntz/kaggle-accelerometer) - Code for Accelerometer Biometric Competition at Kaggle.\n* [kaggle-advertised-salaries](https://github.com/zygmuntz/kaggle-advertised-salaries) - Predicting job salaries from ads - a Kaggle competition.\n* [kaggle amazon](https://github.com/zygmuntz/kaggle-amazon) - Amazon access control challenge.\n* [kaggle-bestbuy_big](https://github.com/zygmuntz/kaggle-bestbuy_big) - Code for the Best Buy competition at Kaggle.\n* [kaggle-bestbuy_small](https://github.com/zygmuntz/kaggle-bestbuy_small)\n* [Kaggle Dogs vs. Cats](https://github.com/kastnerkyle/kaggle-dogs-vs-cats) - Code for Kaggle Dogs vs. Cats competition.\n* [Kaggle Galaxy Challenge](https://github.com/benanne/kaggle-galaxies) - Winning solution for the Galaxy Challenge on Kaggle.\n* [Kaggle Gender](https://github.com/zygmuntz/kaggle-gender) - A Kaggle competition: discriminate gender based on handwriting.\n* [Kaggle Merck](https://github.com/zygmuntz/kaggle-merck) - Merck challenge at Kaggle.\n* [Kaggle Stackoverflow](https://github.com/zygmuntz/kaggle-stackoverflow) - Predicting closed questions on Stack Overflow.\n* [kaggle_acquire-valued-shoppers-challenge](https://github.com/MLWave/kaggle_acquire-valued-shoppers-challenge) - Code for the Kaggle acquire valued shoppers challenge.\n* [wine-quality](https://github.com/zygmuntz/wine-quality) - Predicting wine quality.\n\n<a name=\"python-reinforcement-learning\"></a>\n#### Reinforcement Learning\n* [DeepMind Lab](https://github.com/deepmind/lab) - DeepMind Lab is a 3D learning environment based on id Software's Quake III Arena via ioquake3 and other open source software. Its primary purpose is to act as a testbed for research in artificial intelligence, especially deep reinforcement learning.\n* [Gym](https://github.com/openai/gym) - OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms.\n* [Serpent.AI](https://github.com/SerpentAI/SerpentAI) - Serpent.AI is a game agent framework that allows you to turn any video game you own into a sandbox to develop AI and machine learning experiments. For both researchers and hobbyists.\n* [ViZDoom](https://github.com/mwydmuch/ViZDoom) - ViZDoom allows developing AI bots that play Doom using only the visual information (the screen buffer). It is primarily intended for research in machine visual learning, and deep reinforcement learning, in particular.\n* [Roboschool](https://github.com/openai/roboschool) - Open-source software for robot simulation, integrated with OpenAI Gym.\n* [Retro](https://github.com/openai/retro) - Retro Games in Gym\n* [SLM Lab](https://github.com/kengz/SLM-Lab) - Modular Deep Reinforcement Learning framework in PyTorch.\n* [Coach](https://github.com/NervanaSystems/coach) - Reinforcement Learning Coach by Intel\u00ae AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms\n* [garage](https://github.com/rlworkgroup/garage) - A toolkit for reproducible reinforcement learning research\n* [metaworld](https://github.com/rlworkgroup/metaworld) - An open source robotics benchmark for meta- and multi-task reinforcement learning\n\n<a name=\"ruby\"></a>\n## Ruby\n\n<a name=\"ruby-nlp\"></a>\n#### Natural Language Processing\n\n* [Awesome NLP with Ruby](https://github.com/arbox/nlp-with-ruby) - Curated link list for practical natural language processing in Ruby.\n* [Treat](https://github.com/louismullie/treat) - Text REtrieval and Annotation Toolkit, definitely the most comprehensive toolkit I\u2019ve encountered so far for Ruby.\n* [Stemmer](https://github.com/aurelian/ruby-stemmer) - Expose libstemmer_c to Ruby. **[Deprecated]**\n* [Raspel](https://sourceforge.net/projects/raspell/) - raspell is an interface binding for ruby. **[Deprecated]**\n* [UEA Stemmer](https://github.com/ealdent/uea-stemmer) - Ruby port of UEALite Stemmer - a conservative stemmer for search and indexing.\n* [Twitter-text-rb](https://github.com/twitter/twitter-text/tree/master/rb) - A library that does auto linking and extraction of usernames, lists and hashtags in tweets.\n\n<a name=\"ruby-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Awesome Machine Learning with Ruby](https://github.com/arbox/machine-learning-with-ruby) - Curated list of ML related resources for Ruby.\n* [Ruby Machine Learning](https://github.com/tsycho/ruby-machine-learning) - Some Machine Learning algorithms, implemented in Ruby. **[Deprecated]**\n* [Machine Learning Ruby](https://github.com/mizoR/machine-learning-ruby) **[Deprecated]**\n* [jRuby Mahout](https://github.com/vasinov/jruby_mahout) - JRuby Mahout is a gem that unleashes the power of Apache Mahout in the world of JRuby. **[Deprecated]**\n* [CardMagic-Classifier](https://github.com/cardmagic/classifier) - A general classifier module to allow Bayesian and other types of classifications.\n* [rb-libsvm](https://github.com/febeling/rb-libsvm) - Ruby language bindings for LIBSVM which is a Library for Support Vector Machines.\n* [Scoruby](https://github.com/asafschers/scoruby) - Creates Random Forest classifiers from PMML files.\n\n<a name=\"ruby-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [rsruby](https://github.com/alexgutteridge/rsruby) - Ruby - R bridge.\n* [data-visualization-ruby](https://github.com/chrislo/data_visualisation_ruby) - Source code and supporting content for my Ruby Manor presentation on Data Visualisation with Ruby. **[Deprecated]**\n* [ruby-plot](https://www.ruby-toolbox.com/projects/ruby-plot) - gnuplot wrapper for Ruby, especially for plotting ROC curves into SVG files. **[Deprecated]**\n* [plot-rb](https://github.com/zuhao/plotrb) - A plotting library in Ruby built on top of Vega and D3. **[Deprecated]**\n* [scruffy](https://github.com/delano/scruffy) - A beautiful graphing toolkit for Ruby.\n* [SciRuby](http://sciruby.com/)\n* [Glean](https://github.com/glean/glean) - A data management tool for humans. **[Deprecated]**\n* [Bioruby](https://github.com/bioruby/bioruby)\n* [Arel](https://github.com/nkallen/arel) **[Deprecated]**\n\n<a name=\"ruby-misc\"></a>\n#### Misc\n\n* [Big Data For Chimps](https://github.com/infochimps-labs/big_data_for_chimps)\n* [Listof](https://github.com/kevincobain2000/listof) - Community based data collection, packed in gem. Get list of pretty much anything (stop words, countries, non words) in txt, json or hash. [Demo/Search for a list](http://kevincobain2000.github.io/listof/)\n\n\n<a name=\"rust\"></a>\n## Rust\n\n<a name=\"rust-general-purpose\"></a>\n#### General-Purpose Machine Learning\n* [deeplearn-rs](https://github.com/tedsta/deeplearn-rs) - deeplearn-rs provides simple networks that use matrix multiplication, addition, and ReLU under the MIT license.\n* [rustlearn](https://github.com/maciejkula/rustlearn) - a machine learning framework featuring logistic regression, support vector machines, decision trees and random forests.\n* [rusty-machine](https://github.com/AtheMathmo/rusty-machine) - a pure-rust machine learning library.\n* [leaf](https://github.com/autumnai/leaf) - open source framework for machine intelligence, sharing concepts from TensorFlow and Caffe. Available under the MIT license. [**[Deprecated]**](https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb#.s0a3uy4cc)\n* [RustNN](https://github.com/jackm321/RustNN) - RustNN is a feedforward neural network library. **[Deprecated]**\n* [RusticSOM](https://github.com/avinashshenoy97/RusticSOM) - A Rust library for Self Organising Maps (SOM).\n\n\n<a name=\"r\"></a>\n## R\n\n<a name=\"r-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [ahaz](https://cran.r-project.org/web/packages/ahaz/index.html) - ahaz: Regularization for semiparametric additive hazards regression. **[Deprecated]**\n* [arules](https://cran.r-project.org/web/packages/arules/index.html) - arules: Mining Association Rules and Frequent Itemsets\n* [biglasso](https://cran.r-project.org/web/packages/biglasso/index.html) - biglasso: Extending Lasso Model Fitting to Big Data in R.\n* [bmrm](https://cran.r-project.org/web/packages/bmrm/index.html) - bmrm: Bundle Methods for Regularized Risk Minimization Package.\n* [Boruta](https://cran.r-project.org/web/packages/Boruta/index.html) - Boruta: A wrapper algorithm for all-relevant feature selection.\n* [bst](https://cran.r-project.org/web/packages/bst/index.html) - bst: Gradient Boosting.\n* [C50](https://cran.r-project.org/web/packages/C50/index.html) - C50: C5.0 Decision Trees and Rule-Based Models.\n* [caret](https://topepo.github.io/caret/index.html) - Classification and Regression Training: Unified interface to ~150 ML algorithms in R.\n* [caretEnsemble](https://cran.r-project.org/web/packages/caretEnsemble/index.html) - caretEnsemble: Framework for fitting multiple caret models as well as creating ensembles of such models. **[Deprecated]**\n* [CatBoost](https://github.com/catboost/catboost) - General purpose gradient boosting on decision trees library with categorical features support out of the box for R.\n* [Clever Algorithms For Machine Learning](https://machinelearningmastery.com/)\n* [CORElearn](https://cran.r-project.org/web/packages/CORElearn/index.html) - CORElearn: Classification, regression, feature evaluation and ordinal evaluation.\n* [CoxBoost](https://cran.r-project.org/web/packages/CoxBoost/index.html) - CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks **[Deprecated]**\n* [Cubist](https://cran.r-project.org/web/packages/Cubist/index.html) - Cubist: Rule- and Instance-Based Regression Modeling.\n* [e1071](https://cran.r-project.org/web/packages/e1071/index.html) - e1071: Misc Functions of the Department of Statistics (e1071), TU Wien\n* [earth](https://cran.r-project.org/web/packages/earth/index.html) - earth: Multivariate Adaptive Regression Spline Models\n* [elasticnet](https://cran.r-project.org/web/packages/elasticnet/index.html) - elasticnet: Elastic-Net for Sparse Estimation and Sparse PCA.\n* [ElemStatLearn](https://cran.r-project.org/web/packages/ElemStatLearn/index.html) - ElemStatLearn: Data sets, functions and examples from the book: \"The Elements of Statistical Learning, Data Mining, Inference, and Prediction\" by Trevor Hastie, Robert Tibshirani and Jerome Friedman Prediction\" by Trevor Hastie, Robert Tibshirani and Jerome Friedman.\n* [evtree](https://cran.r-project.org/web/packages/evtree/index.html) - evtree: Evolutionary Learning of Globally Optimal Trees.\n* [forecast](https://cran.r-project.org/web/packages/forecast/index.html) - forecast: Timeseries forecasting using ARIMA, ETS, STLM, TBATS, and neural network models.\n* [forecastHybrid](https://cran.r-project.org/web/packages/forecastHybrid/index.html) - forecastHybrid: Automatic ensemble and cross validation of ARIMA, ETS, STLM, TBATS, and neural network models from the \"forecast\" package.\n* [fpc](https://cran.r-project.org/web/packages/fpc/index.html) - fpc: Flexible procedures for clustering.\n* [frbs](https://cran.r-project.org/web/packages/frbs/index.html) - frbs: Fuzzy Rule-based Systems for Classification and Regression Tasks. **[Deprecated]**\n* [GAMBoost](https://cran.r-project.org/web/packages/GAMBoost/index.html) - GAMBoost: Generalized linear and additive models by likelihood based boosting. **[Deprecated]**\n* [gamboostLSS](https://cran.r-project.org/web/packages/gamboostLSS/index.html) - gamboostLSS: Boosting Methods for GAMLSS.\n* [gbm](https://cran.r-project.org/web/packages/gbm/index.html) - gbm: Generalized Boosted Regression Models.\n* [glmnet](https://cran.r-project.org/web/packages/glmnet/index.html) - glmnet: Lasso and elastic-net regularized generalized linear models.\n* [glmpath](https://cran.r-project.org/web/packages/glmpath/index.html) - glmpath: L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model.\n* [GMMBoost](https://cran.r-project.org/web/packages/GMMBoost/index.html) - GMMBoost: Likelihood-based Boosting for Generalized mixed models. **[Deprecated]**\n* [grplasso](https://cran.r-project.org/web/packages/grplasso/index.html) - grplasso: Fitting user specified models with Group Lasso penalty.\n* [grpreg](https://cran.r-project.org/web/packages/grpreg/index.html) - grpreg: Regularization paths for regression models with grouped covariates.\n* [h2o](https://cran.r-project.org/web/packages/h2o/index.html) - A framework for fast, parallel, and distributed machine learning algorithms at scale -- Deeplearning, Random forests, GBM, KMeans, PCA, GLM.\n* [hda](https://cran.r-project.org/web/packages/hda/index.html) - hda: Heteroscedastic Discriminant Analysis. **[Deprecated]**\n* [Introduction to Statistical Learning](https://www-bcf.usc.edu/~gareth/ISL/)\n* [ipred](https://cran.r-project.org/web/packages/ipred/index.html) - ipred: Improved Predictors.\n* [kernlab](https://cran.r-project.org/web/packages/kernlab/index.html) - kernlab: Kernel-based Machine Learning Lab.\n* [klaR](https://cran.r-project.org/web/packages/klaR/index.html) - klaR: Classification and visualization.\n* [L0Learn](https://cran.r-project.org/web/packages/L0Learn/index.html) - L0Learn: Fast algorithms for best subset selection.\n* [lars](https://cran.r-project.org/web/packages/lars/index.html) - lars: Least Angle Regression, Lasso and Forward Stagewise. **[Deprecated]**\n* [lasso2](https://cran.r-project.org/web/packages/lasso2/index.html) - lasso2: L1 constrained estimation aka \u2018lasso\u2019.\n* [LiblineaR](https://cran.r-project.org/web/packages/LiblineaR/index.html) - LiblineaR: Linear Predictive Models Based On The Liblinear C/C++ Library.\n* [LogicReg](https://cran.r-project.org/web/packages/LogicReg/index.html) - LogicReg: Logic Regression.\n* [Machine Learning For Hackers](https://github.com/johnmyleswhite/ML_for_Hackers)\n* [maptree](https://cran.r-project.org/web/packages/maptree/index.html) - maptree: Mapping, pruning, and graphing tree models. **[Deprecated]**\n* [mboost](https://cran.r-project.org/web/packages/mboost/index.html) - mboost: Model-Based Boosting.\n* [medley](https://www.kaggle.com/general/3661) - medley: Blending regression models, using a greedy stepwise approach.\n* [mlr](https://cran.r-project.org/web/packages/mlr/index.html) - mlr: Machine Learning in R.\n* [ncvreg](https://cran.r-project.org/web/packages/ncvreg/index.html) - ncvreg: Regularization paths for SCAD- and MCP-penalized regression models.\n* [nnet](https://cran.r-project.org/web/packages/nnet/index.html) - nnet: Feed-forward Neural Networks and Multinomial Log-Linear Models. **[Deprecated]**\n* [pamr](https://cran.r-project.org/web/packages/pamr/index.html) - pamr: Pam: prediction analysis for microarrays. **[Deprecated]**\n* [party](https://cran.r-project.org/web/packages/party/index.html) - party: A Laboratory for Recursive Partytioning.\n* [partykit](https://cran.r-project.org/web/packages/partykit/index.html) - partykit: A Toolkit for Recursive Partytioning.\n* [penalized](https://cran.r-project.org/web/packages/penalized/index.html) - penalized: L1 (lasso and fused lasso) and L2 (ridge) penalized estimation in GLMs and in the Cox model.\n* [penalizedLDA](https://cran.r-project.org/web/packages/penalizedLDA/index.html) - penalizedLDA: Penalized classification using Fisher's linear discriminant. **[Deprecated]**\n* [penalizedSVM](https://cran.r-project.org/web/packages/penalizedSVM/index.html) - penalizedSVM: Feature Selection SVM using penalty functions.\n* [quantregForest](https://cran.r-project.org/web/packages/quantregForest/index.html) - quantregForest: Quantile Regression Forests.\n* [randomForest](https://cran.r-project.org/web/packages/randomForest/index.html) - randomForest: Breiman and Cutler's random forests for classification and regression.\n* [randomForestSRC](https://cran.r-project.org/web/packages/randomForestSRC/index.html) - randomForestSRC: Random Forests for Survival, Regression and Classification (RF-SRC).\n* [rattle](https://cran.r-project.org/web/packages/rattle/index.html) - rattle: Graphical user interface for data mining in R.\n* [rda](https://cran.r-project.org/web/packages/rda/index.html) - rda: Shrunken Centroids Regularized Discriminant Analysis.\n* [rdetools](https://cran.r-project.org/web/packages/rdetools/index.html) - rdetools: Relevant Dimension Estimation (RDE) in Feature Spaces. **[Deprecated]**\n* [REEMtree](https://cran.r-project.org/web/packages/REEMtree/index.html) - REEMtree: Regression Trees with Random Effects for Longitudinal (Panel) Data. **[Deprecated]**\n* [relaxo](https://cran.r-project.org/web/packages/relaxo/index.html) - relaxo: Relaxed Lasso. **[Deprecated]**\n* [rgenoud](https://cran.r-project.org/web/packages/rgenoud/index.html) - rgenoud: R version of GENetic Optimization Using Derivatives\n* [Rmalschains](https://cran.r-project.org/web/packages/Rmalschains/index.html) - Rmalschains: Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R.\n* [rminer](https://cran.r-project.org/web/packages/rminer/index.html) - rminer: Simpler use of data mining methods (e.g. NN and SVM) in classification and regression. **[Deprecated]**\n* [ROCR](https://cran.r-project.org/web/packages/ROCR/index.html) - ROCR: Visualizing the performance of scoring classifiers. **[Deprecated]**\n* [RoughSets](https://cran.r-project.org/web/packages/RoughSets/index.html) - RoughSets: Data Analysis Using Rough Set and Fuzzy Rough Set Theories. **[Deprecated]**\n* [rpart](https://cran.r-project.org/web/packages/rpart/index.html) - rpart: Recursive Partitioning and Regression Trees.\n* [RPMM](https://cran.r-project.org/web/packages/RPMM/index.html) - RPMM: Recursively Partitioned Mixture Model.\n* [RSNNS](https://cran.r-project.org/web/packages/RSNNS/index.html) - RSNNS: Neural Networks in R using the Stuttgart Neural Network Simulator (SNNS).\n* [RWeka](https://cran.r-project.org/web/packages/RWeka/index.html) - RWeka: R/Weka interface.\n* [RXshrink](https://cran.r-project.org/web/packages/RXshrink/index.html) - RXshrink: Maximum Likelihood Shrinkage via Generalized Ridge or Least Angle Regression.\n* [sda](https://cran.r-project.org/web/packages/sda/index.html) - sda: Shrinkage Discriminant Analysis and CAT Score Variable Selection. **[Deprecated]**\n* [spectralGraphTopology](https://cran.r-project.org/web/packages/spectralGraphTopology/index.html) - spectralGraphTopology: Learning Graphs from Data via Spectral Constraints.\n* [SuperLearner](https://github.com/ecpolley/SuperLearner) - Multi-algorithm ensemble learning packages.\n* [svmpath](https://cran.r-project.org/web/packages/svmpath/index.html) - svmpath: svmpath: the SVM Path algorithm. **[Deprecated]**\n* [tgp](https://cran.r-project.org/web/packages/tgp/index.html) - tgp: Bayesian treed Gaussian process models. **[Deprecated]**\n* [tree](https://cran.r-project.org/web/packages/tree/index.html) - tree: Classification and regression trees.\n* [varSelRF](https://cran.r-project.org/web/packages/varSelRF/index.html) - varSelRF: Variable selection using random forests.\n* [XGBoost.R](https://github.com/tqchen/xgboost/tree/master/R-package) - R binding for eXtreme Gradient Boosting (Tree) Library.\n* [Optunity](https://optunity.readthedocs.io/en/latest/) - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly to R.\n* [igraph](https://igraph.org/r/) - binding to igraph library - General purpose graph library.\n* [MXNet](https://github.com/apache/incubator-mxnet) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.\n* [TDSP-Utilities](https://github.com/Azure/Azure-TDSP-Utilities) - Two data science utilities in R from Microsoft: 1) Interactive Data Exploration, Analysis, and Reporting (IDEAR) ; 2) Automated Modeling and Reporting (AMR).\n\n<a name=\"r-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [ggplot2](https://ggplot2.tidyverse.org/) - A data visualization package based on the grammar of graphics.\n* [tmap](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html) for visualizing geospatial data with static maps and [leaflet](https://rstudio.github.io/leaflet/) for interactive maps\n* [tm](https://www.rdocumentation.org/packages/tm/) and [quanteda](https://quanteda.io/) are the main packages for managing,  analyzing, and visualizing textual data.\n* [shiny](https://shiny.rstudio.com/) is the basis for truly interactive displays and dashboards in R. However, some measure of interactivity can be achieved with [htmlwidgets](https://www.htmlwidgets.org/) bringing javascript libraries to R. These include, [plotly](https://plot.ly/r/), [dygraphs](http://rstudio.github.io/dygraphs), [highcharter](http://jkunst.com/highcharter/), and several others.\n\n<a name=\"sas\"></a>\n## SAS\n\n<a name=\"sas-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Visual Data Mining and Machine Learning](https://www.sas.com/en_us/software/visual-data-mining-machine-learning.html) - Interactive, automated, and programmatic modeling with the latest machine learning algorithms in and end-to-end analytics environment, from data prep to deployment. Free trial available.\n* [Enterprise Miner](https://www.sas.com/en_us/software/enterprise-miner.html) - Data mining and machine learning that creates deployable models using a GUI or code.\n* [Factory Miner](https://www.sas.com/en_us/software/factory-miner.html) - Automatically creates deployable machine learning models across numerous market or customer segments using a GUI.\n\n<a name=\"sas-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [SAS/STAT](https://www.sas.com/en_us/software/stat.html) - For conducting advanced statistical analysis.\n* [University Edition](https://www.sas.com/en_us/software/university-edition.html) - FREE! Includes all SAS packages necessary for data analysis and visualization, and includes online SAS courses.\n\n<a name=\"sas-nlp\"></a>\n#### Natural Language Processing\n\n* [Contextual Analysis](https://www.sas.com/en_us/software/contextual-analysis.html) - Add structure to unstructured text using a GUI.\n* [Sentiment Analysis](https://www.sas.com/en_us/software/sentiment-analysis.html) - Extract sentiment from text using a GUI.\n* [Text Miner](https://www.sas.com/en_us/software/text-miner.html) - Text mining using a GUI or code.\n\n<a name=\"sas-demos\"></a>\n#### Demos and Scripts\n\n* [ML_Tables](https://github.com/sassoftware/enlighten-apply/tree/master/ML_tables) - Concise cheat sheets containing machine learning best practices.\n* [enlighten-apply](https://github.com/sassoftware/enlighten-apply) - Example code and materials that illustrate applications of SAS machine learning techniques.\n* [enlighten-integration](https://github.com/sassoftware/enlighten-integration) - Example code and materials that illustrate techniques for integrating SAS with other analytics technologies in Java, PMML, Python and R.\n* [enlighten-deep](https://github.com/sassoftware/enlighten-deep) - Example code and materials that illustrate using neural networks with several hidden layers in SAS.\n* [dm-flow](https://github.com/sassoftware/dm-flow) - Library of SAS Enterprise Miner process flow diagrams to help you learn by example about specific data mining topics.\n\n\n<a name=\"scala\"></a>\n## Scala\n\n<a name=\"scala-nlp\"></a>\n#### Natural Language Processing\n\n* [ScalaNLP](http://www.scalanlp.org/) - ScalaNLP is a suite of machine learning and numerical computing libraries.\n* [Breeze](https://github.com/scalanlp/breeze) - Breeze is a numerical processing library for Scala.\n* [Chalk](https://github.com/scalanlp/chalk) - Chalk is a natural language processing library. **[Deprecated]**\n* [FACTORIE](https://github.com/factorie/factorie) - FACTORIE is a toolkit for deployable probabilistic modeling, implemented as a software library in Scala. It provides its users with a succinct language for creating relational factor graphs, estimating parameters and performing inference.\n* [Montague](https://github.com/Workday/upshot-montague) - Montague is a semantic parsing library for Scala with an easy-to-use DSL.\n* [Spark NLP](https://github.com/JohnSnowLabs/spark-nlp) - Natural language processing library built on top of Apache Spark ML to provide simple, performant, and accurate NLP annotations for machine learning pipelines, that scale easily in a distributed environment.\n\n<a name=\"scala-data-analysis\"></a>\n#### Data Analysis / Data Visualization\n\n* [MLlib in Apache Spark](https://spark.apache.org/docs/latest/mllib-guide.html) - Distributed machine learning library in Spark\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.\n* [Scalding](https://github.com/twitter/scalding) - A Scala API for Cascading.\n* [Summing Bird](https://github.com/twitter/summingbird) - Streaming MapReduce with Scalding and Storm.\n* [Algebird](https://github.com/twitter/algebird) - Abstract Algebra for Scala.\n* [xerial](https://github.com/xerial/xerial) - Data management utilities for Scala. **[Deprecated]**\n* [PredictionIO](https://github.com/apache/predictionio) - PredictionIO, a machine learning server for software developers and data engineers.\n* [BIDMat](https://github.com/BIDData/BIDMat) - CPU and GPU-accelerated matrix library intended to support large-scale exploratory data analysis.\n* [Flink](https://flink.apache.org/) - Open source platform for distributed stream and batch data processing.\n* [Spark Notebook](http://spark-notebook.io) - Interactive and Reactive Data Science using Scala and Spark.\n\n<a name=\"scala-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [DeepLearning.scala](https://deeplearning.thoughtworks.school/) - Creating statically typed dynamic neural networks from object-oriented & functional programming constructs.\n* [Conjecture](https://github.com/etsy/Conjecture) - Scalable Machine Learning in Scalding.\n* [brushfire](https://github.com/stripe/brushfire) - Distributed decision tree ensemble learning in Scala.\n* [ganitha](https://github.com/tresata/ganitha) - Scalding powered machine learning. **[Deprecated]**\n* [adam](https://github.com/bigdatagenomics/adam) - A genomics processing engine and specialized file format built using Apache Avro, Apache Spark and Parquet. Apache 2 licensed.\n* [bioscala](https://github.com/bioscala/bioscala) - Bioinformatics for the Scala programming language\n* [BIDMach](https://github.com/BIDData/BIDMach) - CPU and GPU-accelerated Machine Learning Library.\n* [Figaro](https://github.com/p2t2/figaro) - a Scala library for constructing probabilistic models.\n* [H2O Sparkling Water](https://github.com/h2oai/sparkling-water) - H2O and Spark interoperability.\n* [FlinkML in Apache Flink](https://ci.apache.org/projects/flink/flink-docs-master/dev/libs/ml/index.html) - Distributed machine learning library in Flink.\n* [DynaML](https://github.com/transcendent-ai-labs/DynaML) - Scala Library/REPL for Machine Learning Research.\n* [Saul](https://github.com/CogComp/saul) - Flexible Declarative Learning-Based Programming.\n* [SwiftLearner](https://github.com/valdanylchuk/swiftlearner/) - Simply written algorithms to help study ML or write your own implementations.\n* [Smile](https://haifengl.github.io/smile/) - Statistical Machine Intelligence and Learning Engine.\n* [doddle-model](https://github.com/picnicml/doddle-model) - An in-memory machine learning library built on top of Breeze. It provides immutable objects and exposes its functionality through a scikit-learn-like API.\n* [TensorFlow Scala](https://github.com/eaplatanios/tensorflow_scala) -   Strongly-typed Scala API for TensorFlow.\n\n<a name=\"scheme\"></a>\n## Scheme\n\n<a name=\"scheme-neural-networks\"></a>\n#### Neural Networks\n\n* [layer](https://github.com/cloudkj/layer) - Neural network inference from the command line, implemented in [CHICKEN Scheme](https://www.call-cc.org/).\n\n<a name=\"swift\"></a>\n## Swift\n\n<a name=\"swift-general-purpose\"></a>\n#### General-Purpose Machine Learning\n\n* [Bender](https://github.com/xmartlabs/Bender) - Fast Neural Networks framework built on top of Metal. Supports TensorFlow models.\n* [Swift AI](https://github.com/Swift-AI/Swift-AI) - Highly optimized artificial intelligence and machine learning library written in Swift.\n* [Swift for Tensorflow](https://github.com/tensorflow/swift) - a next-generation platform for machine learning, incorporating the latest research across machine learning, compilers, differentiable programming, systems design, and beyond.\n* [BrainCore](https://github.com/alejandro-isaza/BrainCore) - The iOS and OS X neural network framework.\n* [swix](https://github.com/stsievert/swix) - A bare bones library that includes a general matrix language and wraps some OpenCV for iOS development. **[Deprecated]**\n* [AIToolbox](https://github.com/KevinCoble/AIToolbox) - A toolbox framework of AI modules written in Swift: Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians.\n* [MLKit](https://github.com/Somnibyte/MLKit) - A simple Machine Learning Framework written in Swift. Currently features Simple Linear Regression, Polynomial Regression, and Ridge Regression.\n* [Swift Brain](https://github.com/vlall/Swift-Brain) - The first neural network / machine learning library written in Swift. This is a project for AI algorithms in Swift for iOS and OS X development. This project includes algorithms focused on Bayes theorem, neural networks, SVMs, Matrices, etc...\n* [Perfect TensorFlow](https://github.com/PerfectlySoft/Perfect-TensorFlow) - Swift Language Bindings of TensorFlow. Using native TensorFlow models on both macOS / Linux.\n* [PredictionBuilder](https://github.com/denissimon/prediction-builder-swift) - A library for machine learning that builds predictions using a linear regression.\n* [Awesome CoreML](https://github.com/SwiftBrain/awesome-CoreML-models) - A curated list of pretrained CoreML models.\n* [Awesome Core ML Models](https://github.com/likedan/Awesome-CoreML-Models) - A curated list of machine learning models in CoreML format.\n\n<a name=\"tensor\"></a>\n## TensorFlow\n\n<a name=\"tensor-general-purpose\"></a>\n#### General-Purpose Machine Learning\n* [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow) - A list of all things related to TensorFlow.\n* [Golden TensorFlow](https://golden.com/wiki/TensorFlow) - A page of content on TensorFlow, including academic papers and links to related topics.\n\n<a name=\"tools\"></a>\n## Tools\n\n<a name=\"tools-neural-networks\"></a>\n#### Neural Networks\n* [layer](https://github.com/cloudkj/layer) - Neural network inference from the command line\n\n<a name=\"tools-misc\"></a>\n#### Misc\n* [ML Workspace](https://github.com/ml-tooling/ml-workspace) - All-in-one web-based IDE for machine learning and data science. The workspace is deployed as a docker container and is preloaded with a variety of popular data science libraries (e.g., Tensorflow, PyTorch) and dev tools (e.g., Jupyter, VS Code).\n* [Notebooks](https://github.com/rlan/notebooks) - A starter kit for Jupyter notebooks and machine learning. Companion docker images consist of all combinations of python versions, machine learning frameworks (Keras, PyTorch and Tensorflow) and CPU/CUDA versions.\n* [DVC](https://github.com/iterative/dvc) - Data Science Version Control is an open-source version control system for machine learning projects with pipelines support. It makes ML projects reproducible and shareable.\n* [Kedro](https://github.com/quantumblacklabs/kedro/) - Kedro is a data and development workflow framework that implements best practices for data pipelines with an eye towards productionizing machine learning models.\n* [guild.ai](https://guild.ai/) - Tool to log, analyze, compare and \"optimize\" experiments. It's cross-platform and framework independent, and provided integrated visualizers such as tensorboard.\n* [Sacred](https://github.com/IDSIA/sacred) - Python tool to help  you configure, organize, log and reproduce experiments. Like a notebook lab in the context of Chemestry/Biology. The community has built multiple add-ons leveraging the proposed standard.\n* [MLFlow](https://mlflow.org/) - platform to manage the ML lifecycle, including experimentation, reproducibility and deployment. Framework anf language agnostic, take a look at all the built-in integrations.\n* More tools to improve the ML lifecycle: [Catalyst](https://github.com/catalyst-team/catalyst), [PachydermIO](https://www.pachyderm.io/). The following are Github-alike and targetting teams [Weights & Biases](https://www.wandb.com/), [Neptune.Ml](https://neptune.ml/), [Comet.ml](https://www.comet.ml/), [Valohai.ai](https://valohai.com/).\n\n<a name=\"credits\"></a>\n## Credits\n\n* Some of the python libraries were cut-and-pasted from [vinta](https://github.com/vinta/awesome-python)\n* References for Go were mostly cut-and-pasted from [gopherdata](https://github.com/gopherdata/resources/tree/master/tooling)\n"}, {"repo": "psf/requests", "language": "Python", "readme_contents": "\n\n<span align=\"center\">\n\n<pre>\n    <a href=\"https://requests.readthedocs.io/\"><img src=\"https://raw.githubusercontent.com/psf/requests/master/ext/requests-logo.png\" align=\"center\" /></a>\n    \n    <div align=\"left\">\n    <p></p>\n    <code> Python 3.7.4 (default, Sep  7 2019, 18:27:02)</code>\n    <code> >>> <strong>import requests</strong></code>\n    <code> >>> r = requests.get('https://api.github.com/repos/psf/requests')</code>\n    <code> >>> r.json()[\"description\"]</code>\n    <code> 'A simple, yet elegant HTTP library. Handcrafted, with \u2665, for the Python community.'</code>\n    </div>\n\n    <p align=\"center\">\nThis software has been designed for you, with much joy,\nby <a href=\"https://kennethreitz.org/\">Kenneth Reitz</a> & is protected by The <a href=\"https://www.python.org/psf/\">Python Software Foundation</a>.\n   </p>\n</pre>\n\n</span>\n\n<p>&nbsp;</p><p>&nbsp;</p>\n\n<p align=\"center\"><strong>Requests</strong> is an elegant and simple HTTP library for Python, built with \u2665.</p>\n\n<p>&nbsp;</p>\n\n```pycon\n>>> import requests\n>>> r = requests.get('https://api.github.com/user', auth=('user', 'pass'))\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'application/json; charset=utf8'\n>>> r.encoding\n'utf-8'\n>>> r.text\nu'{\"type\":\"User\"...'\n>>> r.json()\n{u'disk_usage': 368627, u'private_gists': 484, ...}\n```\n\n\n\n---------------------------------------------------------------------\n\n<p>&nbsp;</p>\n\nRequests allows you to send HTTP/1.1 requests extremely easily. There\u2019s no need to manually add query strings to your URLs, or to form-encode your `PUT` & `POST` data \u2014 but nowadays, just use the `json` method!\n\n\nRequests is **the most downloaded Python package today**, pulling in around `14M downloads / week`\u2014 according to GitHub, Requests is currently [depended upon](https://github.com/psf/requests/network/dependents?package_id=UGFja2FnZS01NzA4OTExNg%3D%3D) by `367_296` repositories. You may certainly put your trust in this code.\n\n\n<p>&nbsp;</p>\n<p align=\"center\"><a href=\"https://pepy.tech/project/requests\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/e1dedc9f5ce5cd6b6c699f33d2e812daadcf3645/68747470733a2f2f706570792e746563682f62616467652f7265717565737473\" alt=\"Downloads\" data-canonical-src=\"https://pepy.tech/badge/requests\" style=\"max-width:100%;\"></a>\n<a href=\"https://pypi.org/project/requests/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/6d78aeec0a9a1cfe147ad064bfb99069e298e29b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f72657175657374732e737667\" alt=\"image\" data-canonical-src=\"https://img.shields.io/pypi/pyversions/requests.svg\" style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/psf/requests/graphs/contributors\"><img src=\"https://camo.githubusercontent.com/a70ea15870b38bba9203b969f6a6b7e7845fbb8a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f7073662f72657175657374732e737667\" alt=\"image\" data-canonical-src=\"https://img.shields.io/github/contributors/psf/requests.svg\" style=\"max-width:100%;\"></a></p>\n\n<p>&nbsp;</p>\n\n<h2 align=\"center\">Supported Features & Best\u2013Practices</h2>\n\nRequests is ready for the demands of building robust and reliable HTTP\u2013speak applications, for the needs of today.\n\n<pre class=\"test\">\n         + International Domains and URLs       + Keep-Alive & Connection Pooling\n         + Sessions with Cookie Persistence     + Browser-style SSL Verification\n         + Basic & Digest Authentication        + Familiar `dict`\u2013like Cookies\n         + Automatic Decompression of Content   + Automatic Content Decoding\n         + Automatic Connection Pooling         + Unicode Response Bodies<super>*</super>\n         + Multi-part File Uploads              + SOCKS Proxy Support\n         + Connection Timeouts                  + Streaming Downloads\n         + Automatic honoring of `.netrc`       + Chunked HTTP Requests\n\n                            &, of course, rock\u2013solid stability!\n</pre>\n</div>\n\n<p align=\"center\">\n        \u2728 \ud83c\udf70 \u2728&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n</p>\n\n<p>&nbsp;</p>\n\nRequests Module Installation\n----------------------------\n\nThe recommended way to intall the `requests` module is to simply use [`pipenv`](http://pipenv.org/) (or `pip`, of\ncourse):\n\n```console\n$ pipenv install requests\nAdding requests to Pipfile's [packages]\u2026\n\u2714 Installation Succeeded\n\u2026\n```\n\nRequests officially supports Python 2.7 & 3.4\u20133.8.\n\n-------------------------------------\n\n## P.S. \u2014\u00a0Documentation is Available at [`//requests.readthedocs.io`](https://requests.readthedocs.io/en/latest/).\n\n<p align=\"center\">\n        <a href=\"https://requests.readthedocs.io/\"><img src=\"https://raw.githubusercontent.com/psf/requests/master/ext/ss.png\" align=\"center\" /></a>\n</p>\n\n\n------------------\n\n\n<p>&nbsp;</p>\n\n<p align=\"center\">\n        <a href=\"https://kennethreitz.org/\"><img src=\"https://raw.githubusercontent.com/psf/requests/master/ext/kr.png\" align=\"center\" /></a>\n</p>\n\n<p>&nbsp;</p>\n\n<p align=\"center\">\n        <a href=\"https://www.python.org/psf/\"><img src=\"https://raw.githubusercontent.com/psf/requests/master/ext/psf.png\" align=\"center\" /></a>\n</p>\n"}, {"repo": "ansible/ansible", "language": "Python", "readme_contents": "|PyPI version| |Docs badge| |Chat badge| |Build Status| |Code Of Conduct| |Mailing Lists| |License|\n\n*******\nAnsible\n*******\n\nAnsible is a radically simple IT automation system. It handles\nconfiguration management, application deployment, cloud provisioning,\nad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex\nchanges like zero-downtime rolling updates with load balancers easy. More information on `the Ansible website <https://ansible.com/>`_.\n\nDesign Principles\n=================\n\n*  Have a dead simple setup process and a minimal learning curve.\n*  Manage machines very quickly and in parallel.\n*  Avoid custom-agents and additional open ports, be agentless by\n   leveraging the existing SSH daemon.\n*  Describe infrastructure in a language that is both machine and human\n   friendly.\n*  Focus on security and easy auditability/review/rewriting of content.\n*  Manage new remote machines instantly, without bootstrapping any\n   software.\n*  Allow module development in any dynamic language, not just Python.\n*  Be usable as non-root.\n*  Be the easiest IT automation system to use, ever.\n\nUse Ansible\n===========\n\nYou can install a released version of Ansible via ``pip``, a package manager, or\nour `release repository <https://releases.ansible.com/ansible/>`_. See our\n`installation guide <https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html>`_ for details on installing Ansible\non a variety of platforms.\n\nRed Hat offers supported builds of `Ansible Engine <https://www.ansible.com/ansible-engine>`_.\n\nPower users and developers can run the ``devel`` branch, which has the latest\nfeatures and fixes, directly. Although it is reasonably stable, you are more likely to encounter\nbreaking changes when running the ``devel`` branch. We recommend getting involved\nin the Ansible community if you want to run the ``devel`` branch.\n\nGet Involved\n============\n\n*  Read `Community\n   Information <https://docs.ansible.com/ansible/latest/community>`_ for all\n   kinds of ways to contribute to and interact with the project,\n   including mailing list information and how to submit bug reports and\n   code to Ansible.\n*  Join a `Working Group\n   <https://github.com/ansible/community/wiki>`_, an organized community devoted to a specific technology domain or platform.\n*  Submit a proposed code update through a pull request to the ``devel`` branch.\n*  Talk to us before making larger changes\n   to avoid duplicate efforts. This not only helps everyone\n   know what is going on, it also helps save time and effort if we decide\n   some changes are needed.\n*  For a list of email lists, IRC channels and Working Groups, see the\n   `Communication page <https://docs.ansible.com/ansible/latest/community/communication.html>`_\n\nBranch Info\n===========\n\n*  The ``devel`` branch corresponds to the release actively under development.\n*  The ``stable-2.X`` branches correspond to stable releases.\n*  Create a branch based on ``devel`` and set up a `dev environment <https://docs.ansible.com/ansible/latest/dev_guide/developing_modules_general.html#common-environment-setup>`_ if you want to open a PR.\n*  See the `Ansible release and maintenance <https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html>`_ page for information about active branches.\n\nRoadmap\n=======\n\nBased on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8).\nThe `Ansible Roadmap page <https://docs.ansible.com/ansible/devel/roadmap/>`_ details what is planned and how to influence the roadmap.\n\nAuthors\n=======\n\nAnsible was created by `Michael DeHaan <https://github.com/mpdehaan>`_\nand has contributions from over 4700 users (and growing). Thanks everyone!\n\n`Ansible <https://www.ansible.com>`_ is sponsored by `Red Hat, Inc.\n<https://www.redhat.com>`_\n\nLicense\n=======\n\nGNU General Public License v3.0 or later\n\nSee `COPYING <COPYING>`_ to see the full text.\n\n.. |PyPI version| image:: https://img.shields.io/pypi/v/ansible.svg\n   :target: https://pypi.org/project/ansible\n.. |Docs badge| image:: https://img.shields.io/badge/docs-latest-brightgreen.svg\n   :target: https://docs.ansible.com/ansible/latest/\n.. |Build Status| image:: https://api.shippable.com/projects/573f79d02a8192902e20e34b/badge?branch=devel\n   :target: https://app.shippable.com/projects/573f79d02a8192902e20e34b\n.. |Chat badge| image:: https://img.shields.io/badge/chat-IRC-brightgreen.svg\n   :target: https://docs.ansible.com/ansible/latest/community/communication.html\n.. |Code Of Conduct| image:: https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg\n   :target: https://docs.ansible.com/ansible/latest/community/code_of_conduct.html\n   :alt: Ansible Code of Conduct\n.. |Mailing Lists| image:: https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg\n   :target: https://docs.ansible.com/ansible/latest/community/communication.html#mailing-list-information\n   :alt: Ansible mailing lists\n.. |License| image:: https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg\n   :target: COPYING\n   :alt: Repository License\n"}, {"repo": "scikit-learn/scikit-learn", "language": "Python", "readme_contents": ".. -*- mode: rst -*-\n\n|Azure|_ |Travis|_ |Codecov|_ |CircleCI|_ |PythonVersion|_ |PyPi|_ |DOI|_\n\n.. |Azure| image:: https://dev.azure.com/scikit-learn/scikit-learn/_apis/build/status/scikit-learn.scikit-learn?branchName=master\n.. _Azure: https://dev.azure.com/scikit-learn/scikit-learn/_build/latest?definitionId=1&branchName=master\n\n.. |Travis| image:: https://api.travis-ci.org/scikit-learn/scikit-learn.svg?branch=master\n.. _Travis: https://travis-ci.org/scikit-learn/scikit-learn\n\n.. |Codecov| image:: https://codecov.io/github/scikit-learn/scikit-learn/badge.svg?branch=master&service=github\n.. _Codecov: https://codecov.io/github/scikit-learn/scikit-learn?branch=master\n\n.. |CircleCI| image:: https://circleci.com/gh/scikit-learn/scikit-learn/tree/master.svg?style=shield&circle-token=:circle-token\n.. _CircleCI: https://circleci.com/gh/scikit-learn/scikit-learn\n\n.. |PythonVersion| image:: https://img.shields.io/pypi/pyversions/scikit-learn.svg\n.. _PythonVersion: https://img.shields.io/pypi/pyversions/scikit-learn.svg\n\n.. |PyPi| image:: https://badge.fury.io/py/scikit-learn.svg\n.. _PyPi: https://badge.fury.io/py/scikit-learn\n\n.. |DOI| image:: https://zenodo.org/badge/21369/scikit-learn/scikit-learn.svg\n.. _DOI: https://zenodo.org/badge/latestdoi/21369/scikit-learn/scikit-learn\n\nscikit-learn\n============\n\nscikit-learn is a Python module for machine learning built on top of\nSciPy and is distributed under the 3-Clause BSD license.\n\nThe project was started in 2007 by David Cournapeau as a Google Summer\nof Code project, and since then many volunteers have contributed. See\nthe `About us <http://scikit-learn.org/dev/about.html#authors>`__ page\nfor a list of core contributors.\n\nIt is currently maintained by a team of volunteers.\n\nWebsite: http://scikit-learn.org\n\n\nInstallation\n------------\n\nDependencies\n~~~~~~~~~~~~\n\nscikit-learn requires:\n\n- Python (>= 3.5)\n- NumPy (>= 1.11.0)\n- SciPy (>= 0.17.0)\n- joblib (>= 0.11)\n\n**Scikit-learn 0.20 was the last version to support Python 2.7 and Python 3.4.**\nscikit-learn 0.21 and later require Python 3.5 or newer.\n\nScikit-learn plotting capabilities (i.e., functions start with ``plot_``\nand classes end with \"Display\") require Matplotlib (>= 1.5.1). For running the\nexamples Matplotlib >= 1.5.1 is required. A few examples require\nscikit-image >= 0.12.3, a few examples require pandas >= 0.18.0.\n\nUser installation\n~~~~~~~~~~~~~~~~~\n\nIf you already have a working installation of numpy and scipy,\nthe easiest way to install scikit-learn is using ``pip``   ::\n\n    pip install -U scikit-learn\n\nor ``conda``::\n\n    conda install scikit-learn\n\nThe documentation includes more detailed `installation instructions <http://scikit-learn.org/stable/install.html>`_.\n\n\nChangelog\n---------\n\nSee the `changelog <http://scikit-learn.org/dev/whats_new.html>`__\nfor a history of notable changes to scikit-learn.\n\nDevelopment\n-----------\n\nWe welcome new contributors of all experience levels. The scikit-learn\ncommunity goals are to be helpful, welcoming, and effective. The\n`Development Guide <http://scikit-learn.org/stable/developers/index.html>`_\nhas detailed information about contributing code, documentation, tests, and\nmore. We've included some basic information in this README.\n\nImportant links\n~~~~~~~~~~~~~~~\n\n- Official source code repo: https://github.com/scikit-learn/scikit-learn\n- Download releases: https://pypi.org/project/scikit-learn/\n- Issue tracker: https://github.com/scikit-learn/scikit-learn/issues\n\nSource code\n~~~~~~~~~~~\n\nYou can check the latest sources with the command::\n\n    git clone https://github.com/scikit-learn/scikit-learn.git\n\nContributing\n~~~~~~~~~~~~\n\nTo learn more about making a contribution to scikit-learn, please see our\n`Contributing guide\n<https://scikit-learn.org/dev/developers/contributing.html>`_.\n\nTesting\n~~~~~~~\n\nAfter installation, you can launch the test suite from outside the\nsource directory (you will need to have ``pytest`` >= 3.3.0 installed)::\n\n    pytest sklearn\n\nSee the web page http://scikit-learn.org/dev/developers/advanced_installation.html#testing\nfor more information.\n\n    Random number generation can be controlled during testing by setting\n    the ``SKLEARN_SEED`` environment variable.\n\nSubmitting a Pull Request\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBefore opening a Pull Request, have a look at the\nfull Contributing page to make sure your code complies\nwith our guidelines: http://scikit-learn.org/stable/developers/index.html\n\n\nProject History\n---------------\n\nThe project was started in 2007 by David Cournapeau as a Google Summer\nof Code project, and since then many volunteers have contributed. See\nthe `About us <http://scikit-learn.org/dev/about.html#authors>`__ page\nfor a list of core contributors.\n\nThe project is currently maintained by a team of volunteers.\n\n**Note**: `scikit-learn` was previously referred to as `scikits.learn`.\n\n\nHelp and Support\n----------------\n\nDocumentation\n~~~~~~~~~~~~~\n\n- HTML documentation (stable release): http://scikit-learn.org\n- HTML documentation (development version): http://scikit-learn.org/dev/\n- FAQ: http://scikit-learn.org/stable/faq.html\n\nCommunication\n~~~~~~~~~~~~~\n\n- Mailing list: https://mail.python.org/mailman/listinfo/scikit-learn\n- IRC channel: ``#scikit-learn`` at ``webchat.freenode.net``\n- Stack Overflow: https://stackoverflow.com/questions/tagged/scikit-learn\n- Website: http://scikit-learn.org\n\nCitation\n~~~~~~~~\n\nIf you use scikit-learn in a scientific publication, we would appreciate citations: http://scikit-learn.org/stable/about.html#citing-scikit-learn\n"}, {"repo": "scrapy/scrapy", "language": "Python", "readme_contents": "======\nScrapy\n======\n\n.. image:: https://img.shields.io/pypi/v/Scrapy.svg\n   :target: https://pypi.python.org/pypi/Scrapy\n   :alt: PyPI Version\n\n.. image:: https://img.shields.io/pypi/pyversions/Scrapy.svg\n   :target: https://pypi.python.org/pypi/Scrapy\n   :alt: Supported Python Versions\n\n.. image:: https://img.shields.io/travis/scrapy/scrapy/master.svg\n   :target: https://travis-ci.org/scrapy/scrapy\n   :alt: Build Status\n\n.. image:: https://img.shields.io/badge/wheel-yes-brightgreen.svg\n   :target: https://pypi.python.org/pypi/Scrapy\n   :alt: Wheel Status\n\n.. image:: https://img.shields.io/codecov/c/github/scrapy/scrapy/master.svg\n   :target: https://codecov.io/github/scrapy/scrapy?branch=master\n   :alt: Coverage report\n\n.. image:: https://anaconda.org/conda-forge/scrapy/badges/version.svg\n   :target: https://anaconda.org/conda-forge/scrapy\n   :alt: Conda Version\n\n\nOverview\n========\n\nScrapy is a fast high-level web crawling and web scraping framework, used to\ncrawl websites and extract structured data from their pages. It can be used for\na wide range of purposes, from data mining to monitoring and automated testing.\n\nCheck the Scrapy homepage at https://scrapy.org for more information,\nincluding a list of features.\n\nRequirements\n============\n\n* Python 3.5+\n* Works on Linux, Windows, Mac OSX, BSD\n\nInstall\n=======\n\nThe quick way::\n\n    pip install scrapy\n\nSee the install section in the documentation at\nhttps://docs.scrapy.org/en/latest/intro/install.html for more details.\n\nDocumentation\n=============\n\nDocumentation is available online at https://docs.scrapy.org/ and in the ``docs``\ndirectory.\n\nReleases\n========\n\nYou can check https://docs.scrapy.org/en/latest/news.html for the release notes.\n\nCommunity (blog, twitter, mail list, IRC)\n=========================================\n\nSee https://scrapy.org/community/ for details.\n\nContributing\n============\n\nSee https://docs.scrapy.org/en/master/contributing.html for details.\n\nCode of Conduct\n---------------\n\nPlease note that this project is released with a Contributor Code of Conduct\n(see https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md).\n\nBy participating in this project you agree to abide by its terms.\nPlease report unacceptable behavior to opensource@scrapinghub.com.\n\nCompanies using Scrapy\n======================\n\nSee https://scrapy.org/companies/ for a list.\n\nCommercial Support\n==================\n\nSee https://scrapy.org/support/ for details.\n"}, {"repo": "minimaxir/big-list-of-naughty-strings", "language": "Python", "readme_contents": "# Big List of Naughty Strings\nThe Big List of Naughty Strings is an evolving list of strings which have a high probability of causing issues when used as user-input data. This is intended for use in helping both automated and manual QA testing; useful for whenever your QA engineer [walks into a bar](http://www.sempf.net/post/On-Testing1).\n\n## Why Test Naughty Strings?\n\nEven multi-billion dollar companies with huge amounts of automated testing can't find every bad input. For example, look at what happens when you try to Tweet a [zero-width space](https://en.wikipedia.org/wiki/Zero-width_space) (U+200B) on Twitter:\n\n![](http://i.imgur.com/HyDg2eV.gif)\n\nAlthough this is not a malicious error, and typical users aren't Tweeting weird unicode, an \"internal server error\" for unexpected input is never a positive experience for the user, and may in fact be a symptom of deeper string-validation issues. The Big List of Naughty Strings is intended to help reveal such issues.\n\n## Usage\n\n`blns.txt` consists of newline-delimited strings and comments which are preceded with `#`. The comments divide the strings into sections for easy manual reading and copy/pasting into input forms. For those who want to access the strings programmatically, a `blns.json` file is provided containing an array with all the comments stripped out (the `scripts` folder contains a Python script used to generate the `blns.json`).\n\n## Contributions\n\nFeel free to send a pull request to add more strings, or additional sections. However, please do not send pull requests with very-long strings (255+ characters), as that makes the list much more difficult to view.\n\nLikewise, please do not send pull requests which compromise *manual usability of the file*. This includes the [EICAR test string](https://en.wikipedia.org/wiki/EICAR_test_file), which can cause the file to be flagged by antivirus scanners, and files which alter the encoding of `blns.txt`. Also, do not send a null character (U+0000) string, as it [changes the file format on GitHub to binary](http://stackoverflow.com/a/19723302) and renders it unreadable in pull requests. Finally, when adding or removing a string please update all files when you perform a pull request.\n\n## Disclaimer\n\nThe Big List of Naughty Strings is intended to be used *for software you own and manage*. Some of the Naughty Strings can indicate security vulnerabilities, and as a result using such strings with third-party software may be a crime. The maintainer is not responsible for any negative actions that result from the use of the list.\n\nAdditionally, the Big List of Naughty Strings is not a fully-comprehensive substitute for formal security/penetration testing for your service.\n\n## Library / Packages\n\nVarious implementations of the Big List of Naughty Strings have made it to various package managers.  Those are maintained by outside parties, but can be found here:\n\n| Library | Link |\n| ------- | ---- |\n| Node | https://www.npmjs.com/package/blns |\n| Node | https://www.npmjs.com/package/big-list-of-naughty-strings |\n| .NET | https://github.com/SimonCropp/NaughtyStrings |\n\nPlease open a PR to list others.\n\n## Maintainer/Creator\n\nMax Woolf ([@minimaxir](https://twitter.com/minimaxir))\n\n## Social Media Discussions\n\n* June 10, 2015 [Hacker News]: [Show HN: Big List of Naughty Strings for testing user-input data](https://news.ycombinator.com/item?id=10035008)\n* August 17, 2015 [Reddit]: [Big list of naughty strings.](https://www.reddit.com/r/programming/comments/3hdxqx/big_list_of_naughty_strings/)\n* February 9, 2016 [Reddit]: [Big List of Naughty Strings](https://www.reddit.com/r/webdev/comments/44wc5b/big_list_of_naughty_strings/)\n* January 15, 2017 [Hacker News]: [Naughty Strings: A list of strings likely to cause issues as user-input data](https://news.ycombinator.com/item?id=13406119)\n* January 16, 2017 [Reddit]: [Naughty Strings: A list of strings likely to cause issues as user-input data](https://www.reddit.com/r/programming/comments/5o9inb/naughty_strings_a_list_of_strings_likely_to_cause/)\n* November 16, 2018 [Hacker News]: [Big List of Naughty Strings](https://news.ycombinator.com/item?id=18466787)\n* November 16, 2018 [Reddit]: [Naughty Strings - A list of strings which have a high probability of causing issues when used as user-input data](https://www.reddit.com/r/programming/comments/9xla2j/naughty_strings_a_list_of_strings_which_have_a/)\n\n## License\n\nMIT\n"}, {"repo": "shadowsocks/shadowsocks", "language": "Python", "readme_contents": "Removed according to regulations.\n"}, {"repo": "ageitgey/face_recognition", "language": "Python", "readme_contents": "# Face Recognition\n\n_You can also read a translated version of this file [in Chinese \u7b80\u4f53\u4e2d\u6587\u7248](https://github.com/ageitgey/face_recognition/blob/master/README_Simplified_Chinese.md) or [in Korean \ud55c\uad6d\uc5b4](https://github.com/ageitgey/face_recognition/blob/master/README_Korean.md)._\n\nRecognize and manipulate faces from Python or from the command line with\nthe world's simplest face recognition library.\n\nBuilt using [dlib](http://dlib.net/)'s state-of-the-art face recognition\nbuilt with deep learning. The model has an accuracy of 99.38% on the\n[Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/) benchmark.\n\nThis also provides a simple `face_recognition` command line tool that lets\nyou do face recognition on a folder of images from the command line!\n\n\n[![PyPI](https://img.shields.io/pypi/v/face_recognition.svg)](https://pypi.python.org/pypi/face_recognition)\n[![Build Status](https://travis-ci.org/ageitgey/face_recognition.svg?branch=master)](https://travis-ci.org/ageitgey/face_recognition)\n[![Documentation Status](https://readthedocs.org/projects/face-recognition/badge/?version=latest)](http://face-recognition.readthedocs.io/en/latest/?badge=latest)\n\n## Features\n\n#### Find faces in pictures\n\nFind all the faces that appear in a picture:\n\n![](https://cloud.githubusercontent.com/assets/896692/23625227/42c65360-025d-11e7-94ea-b12f28cb34b4.png)\n\n```python\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_locations = face_recognition.face_locations(image)\n```\n\n#### Find and manipulate facial features in pictures\n\nGet the locations and outlines of each person's eyes, nose, mouth and chin.\n\n![](https://cloud.githubusercontent.com/assets/896692/23625282/7f2d79dc-025d-11e7-8728-d8924596f8fa.png)\n\n```python\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\n```\n\nFinding facial features is super useful for lots of important stuff. But you can also use it for really stupid stuff\nlike applying [digital make-up](https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py) (think 'Meitu'):\n\n![](https://cloud.githubusercontent.com/assets/896692/23625283/80638760-025d-11e7-80a2-1d2779f7ccab.png)\n\n#### Identify faces in pictures\n\nRecognize who appears in each photo.\n\n![](https://cloud.githubusercontent.com/assets/896692/23625229/45e049b6-025d-11e7-89cc-8a71cf89e713.png)\n\n```python\nimport face_recognition\nknown_image = face_recognition.load_image_file(\"biden.jpg\")\nunknown_image = face_recognition.load_image_file(\"unknown.jpg\")\n\nbiden_encoding = face_recognition.face_encodings(known_image)[0]\nunknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n\nresults = face_recognition.compare_faces([biden_encoding], unknown_encoding)\n```\n\nYou can even use this library with other Python libraries to do real-time face recognition:\n\n![](https://cloud.githubusercontent.com/assets/896692/24430398/36f0e3f0-13cb-11e7-8258-4d0c9ce1e419.gif)\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py) for the code.\n\n## Online Demos\n\nUser-contributed shared Jupyter notebook demo (not officially supported): [![Deepnote](https://beta.deepnote.org/buttons/try-in-a-jupyter-notebook.svg)](https://beta.deepnote.org/launch?template=face_recognition)\n\n## Installation\n\n### Requirements\n\n  * Python 3.3+ or Python 2.7\n  * macOS or Linux (Windows not officially supported, but might work)\n\n### Installation Options:\n\n#### Installing on Mac or Linux\n\nFirst, make sure you have dlib already installed with Python bindings:\n\n  * [How to install dlib from source on macOS or Ubuntu](https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf)\n\nThen, install this module from pypi using `pip3` (or `pip2` for Python 2):\n\n```bash\npip3 install face_recognition\n```\n\nAlternatively, you can try this library with [Docker](https://www.docker.com/), see [this section](#deployment).\n\nIf you are having trouble with installation, you can also try out a\n[pre-configured VM](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b).\n\n#### Installing on an Nvidia Jetson Nano board\n\n * [Jetson Nano installation instructions](https://medium.com/@ageitgey/build-a-hardware-based-face-recognition-system-for-150-with-the-nvidia-jetson-nano-and-python-a25cb8c891fd)\n   * Please follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.\n\n#### Installing on Raspberry Pi 2+\n\n  * [Raspberry Pi 2+ installation instructions](https://gist.github.com/ageitgey/1ac8dbe8572f3f533df6269dab35df65)\n\n#### Installing on Windows\n\nWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:\n\n  * [@masoudr's Windows 10 installation guide (dlib + face_recognition)](https://github.com/ageitgey/face_recognition/issues/175#issue-257710508)\n\n#### Installing a pre-configured Virtual Machine image\n\n  * [Download the pre-configured VM image](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b) (for VMware Player or VirtualBox).\n\n## Usage\n\n### Command-Line Interface\n\nWhen you install `face_recognition`, you get two simple command-line \nprograms:\n\n* `face_recognition` - Recognize faces in a photograph or folder full for \n   photographs.\n* `face_detection` - Find faces in a photograph or folder full for photographs.\n\n#### `face_recognition` command line tool\n\nThe `face_recognition` command lets you recognize faces in a photograph or \nfolder full  for photographs.\n\nFirst, you need to provide a folder with one picture of each person you\nalready know. There should be one image file for each person with the\nfiles named according to who is in the picture:\n\n![known](https://cloud.githubusercontent.com/assets/896692/23582466/8324810e-00df-11e7-82cf-41515eba704d.png)\n\nNext, you need a second folder with the files you want to identify:\n\n![unknown](https://cloud.githubusercontent.com/assets/896692/23582465/81f422f8-00df-11e7-8b0d-75364f641f58.png)\n\nThen in you simply run the command `face_recognition`, passing in\nthe folder of known people and the folder (or single image) with unknown\npeople and it tells you who is in each image:\n\n```bash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\n```\n\nThere's one line in the output for each face. The data is comma-separated\nwith the filename and the name of the person found.\n\nAn `unknown_person` is a face in the image that didn't match anyone in\nyour folder of known people.\n\n#### `face_detection` command line tool\n\nThe `face_detection` command lets you find the location (pixel coordinatates) \nof any faces in an image.\n\nJust run the command `face_detection`, passing in a folder of images \nto check (or a single image):\n\n```bash\n$ face_detection  ./folder_with_pictures/\n\nexamples/image1.jpg,65,215,169,112\nexamples/image2.jpg,62,394,211,244\nexamples/image2.jpg,95,941,244,792\n```\n\nIt prints one line for each face that was detected. The coordinates\nreported are the top, right, bottom and left coordinates of the face (in pixels).\n \n##### Adjusting Tolerance / Sensitivity\n\nIf you are getting multiple matches for the same person, it might be that\nthe people in your photos look very similar and a lower tolerance value\nis needed to make face comparisons more strict.\n\nYou can do that with the `--tolerance` parameter. The default tolerance\nvalue is 0.6 and lower numbers make face comparisons more strict:\n\n```bash\n$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\n```\n\nIf you want to see the face distance calculated for each match in order\nto adjust the tolerance setting, you can use `--show-distance true`:\n\n```bash\n$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,None\n```\n\n##### More Examples\n\nIf you simply want to know the names of the people in each photograph but don't\ncare about file names, you could do this:\n\n```bash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2\n\nBarack Obama\nunknown_person\n```\n\n##### Speeding up Face Recognition\n\nFace recognition can be done in parallel if you have a computer with\nmultiple CPU cores. For example, if your system has 4 CPU cores, you can\nprocess about 4 times as many images in the same amount of time by using\nall your CPU cores in parallel.\n\nIf you are using Python 3.4 or newer, pass in a `--cpus <number_of_cpu_cores_to_use>` parameter:\n\n```bash\n$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/\n```\n\nYou can also pass in `--cpus -1` to use all CPU cores in your system.\n\n#### Python Module\n\nYou can import the `face_recognition` module and then easily manipulate\nfaces with just a couple of lines of code. It's super easy!\n\nAPI Docs: [https://face-recognition.readthedocs.io](https://face-recognition.readthedocs.io/en/latest/face_recognition.html).\n\n##### Automatically find all the faces in an image\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image)\n\n# face_locations is now an array listing the co-ordinates of each face!\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py)\n to try it out.\n\nYou can also opt-in to a somewhat more accurate deep-learning-based face detection model.\n\nNote: GPU acceleration (via NVidia's CUDA library) is required for good\nperformance with this model. You'll also want to enable CUDA support\nwhen compliling `dlib`.\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image, model=\"cnn\")\n\n# face_locations is now an array listing the co-ordinates of each face!\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py)\n to try it out.\n\nIf you have a lot of images and a GPU, you can also\n[find faces in batches](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py).\n\n##### Automatically locate the facial features of a person in an image\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\n\n# face_landmarks_list is now an array with the locations of each facial feature in each face.\n# face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py)\n to try it out.\n\n##### Recognize faces in images and identify who they are\n\n```python\nimport face_recognition\n\npicture_of_me = face_recognition.load_image_file(\"me.jpg\")\nmy_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n\n# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!\n\nunknown_picture = face_recognition.load_image_file(\"unknown.jpg\")\nunknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n\n# Now we can see the two face encodings are of the same person with `compare_faces`!\n\nresults = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n\nif results[0] == True:\n    print(\"It's a picture of me!\")\nelse:\n    print(\"It's not a picture of me!\")\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py)\n to try it out.\n\n## Python Code Examples\n\nAll the examples are available [here](https://github.com/ageitgey/face_recognition/tree/master/examples).\n\n\n#### Face Detection\n\n* [Find faces in a photograph](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py)\n* [Find faces in a photograph (using deep learning)](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py)\n* [Find faces in batches of images w/ GPU (using deep learning)](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py)\n* [Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/blur_faces_on_webcam.py)\n\n#### Facial Features\n\n* [Identify specific facial features in a photograph](https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py)\n* [Apply (horribly ugly) digital make-up](https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py)\n\n#### Facial Recognition\n\n* [Find and recognize unknown faces in a photograph based on photographs of known people](https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py)\n* [Identify and draw boxes around each person in a photo](https://github.com/ageitgey/face_recognition/blob/master/examples/identify_and_draw_boxes_on_faces.py)\n* [Compare faces by numeric face distance instead of only True/False matches](https://github.com/ageitgey/face_recognition/blob/master/examples/face_distance.py)\n* [Recognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam.py)\n* [Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py)\n* [Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_video_file.py)\n* [Recognize faces on a Raspberry Pi w/ camera](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_on_raspberry_pi.py)\n* [Run a web service to recognize faces via HTTP (Requires Flask to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/web_service_example.py)\n* [Recognize faces with a K-nearest neighbors classifier](https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_knn.py)\n* [Train multiple images per person then recognize faces using a SVM](https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_svm.py)\n\n## Creating a Standalone Executable\nIf you want to create a standalone executable that can run without the need to install `python` or `face_recognition`, you can use [PyInstaller](https://github.com/pyinstaller/pyinstaller). However, it requires some custom configuration to work with this library. See [this issue](https://github.com/ageitgey/face_recognition/issues/357) for how to do it.\n\n## Articles and Guides that cover `face_recognition`\n\n- My article on how Face Recognition works: [Modern Face Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78)\n  - Covers the algorithms and how they generally work\n- [Face recognition with OpenCV, Python, and deep learning](https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/) by Adrian Rosebrock\n  - Covers how to use face recognition in practice\n- [Raspberry Pi Face Recognition](https://www.pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/) by Adrian Rosebrock\n  - Covers how to use this on a Raspberry Pi\n- [Face clustering with Python](https://www.pyimagesearch.com/2018/07/09/face-clustering-with-python/) by Adrian Rosebrock\n  - Covers how to automatically cluster photos based on who appears in each photo using unsupervised learning\n\n## How Face Recognition Works\n\nIf you want to learn how face location and recognition work instead of\ndepending on a black box library, [read my article](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78).\n\n## Caveats\n\n* The face recognition model is trained on adults and does not work very well on children. It tends to mix\n  up children quite easy using the default comparison threshold of 0.6.\n* Accuracy may vary between ethnic groups. Please see [this wiki page](https://github.com/ageitgey/face_recognition/wiki/Face-Recognition-Accuracy-Problems#question-face-recognition-works-well-with-european-individuals-but-overall-accuracy-is-lower-with-asian-individuals) for more details.\n\n## <a name=\"deployment\">Deployment to Cloud Hosts (Heroku, AWS, etc)</a>\n\nSince `face_recognition` depends on `dlib` which is written in C++, it can be tricky to deploy an app\nusing it to a cloud hosting provider like Heroku or AWS.\n\nTo make things easier, there's an example Dockerfile in this repo that shows how to run an app built with\n`face_recognition` in a [Docker](https://www.docker.com/) container. With that, you should be able to deploy\nto any service that supports Docker images.\n\nYou can try the Docker image locally by running: `docker-compose up --build`\n\nLinux users with a GPU (drivers >= 384.81) and [Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker) installed can run the example on the GPU: Open the [docker-compose.yml](docker-compose.yml) file and uncomment the `dockerfile: Dockerfile.gpu` and `runtime: nvidia` lines.\n\n## Having problems?\n\nIf you run into problems, please read the [Common Errors](https://github.com/ageitgey/face_recognition/wiki/Common-Errors) section of the wiki before filing a github issue.\n\n## Thanks\n\n* Many, many thanks to [Davis King](https://github.com/davisking) ([@nulhom](https://twitter.com/nulhom))\n  for creating dlib and for providing the trained facial feature detection and face encoding models\n  used in this library. For more information on the ResNet that powers the face encodings, check out\n  his [blog post](http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html).\n* Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,\n  pillow, etc, etc that makes this kind of stuff so easy and fun in Python.\n* Thanks to [Cookiecutter](https://github.com/audreyr/cookiecutter) and the\n  [audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage) project template\n  for making Python project packaging way more tolerable.\n"}, {"repo": "home-assistant/home-assistant", "language": "Python", "readme_contents": "Home Assistant |Chat Status|\n=================================================================================\n\nOpen source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server.\n\nCheck out `home-assistant.io <https://home-assistant.io>`__ for `a\ndemo <https://home-assistant.io/demo/>`__, `installation instructions <https://home-assistant.io/getting-started/>`__,\n`tutorials <https://home-assistant.io/getting-started/automation-2/>`__ and `documentation <https://home-assistant.io/docs/>`__.\n\n|screenshot-states|\n\nFeatured integrations\n---------------------\n\n|screenshot-components|\n\nThe system is built using a modular approach so support for other devices or actions can be implemented easily. See also the `section on architecture <https://developers.home-assistant.io/docs/en/architecture_index.html>`__ and the `section on creating your own\ncomponents <https://developers.home-assistant.io/docs/en/creating_component_index.html>`__.\n\nIf you run into issues while using Home Assistant or during development\nof a component, check the `Home Assistant help section <https://home-assistant.io/help/>`__ of our website for further help and information.\n\n.. |Chat Status| image:: https://img.shields.io/discord/330944238910963714.svg\n   :target: https://discord.gg/c5DvZ4e\n.. |screenshot-states| image:: https://raw.github.com/home-assistant/home-assistant/master/docs/screenshots.png\n   :target: https://home-assistant.io/demo/\n.. |screenshot-components| image:: https://raw.github.com/home-assistant/home-assistant/dev/docs/screenshot-components.png\n   :target: https://home-assistant.io/integrations/\n"}, {"repo": "XX-net/XX-Net", "language": "Python", "readme_contents": "# XX-Net\n\n###### [\u4e2d\u6587\u6587\u6863](https://github.com/XX-net/XX-Net/wiki/%E4%B8%AD%E6%96%87%E6%96%87%E6%A1%A3) &nbsp; &nbsp; &nbsp;[English](https://github.com/XX-net/XX-Net/wiki/English-Home-Page) &nbsp; &nbsp; &nbsp;[\u0641\u0627\u0631\u0633\u06cc \u0635\u0641\u062d\u0647 \u0627\u0635\u0644\u06cc](https://github.com/XX-net/XX-Net/wiki/Persian-home-page) \n\n* \u6613\u7528\u7684\u7ffb\u5899\u5de5\u5177  \n* \u5305\u542b\u7684GAE_proxy\u548cX-Tunnel\uff1a  \n\n\n| \u6a21\u5757        | GAE_proxy   | X-Tunnel  |  \n| ------------- |:-------------:| :-----:| \n| \u8054\u901a\u6027| \u4f9d\u8d56IPv6 | \u66f4\u591a\u901a\u9053 |\n| \u901f\u5ea6 | \u6d41\u7545 | \u4e0b\u8f7d\u5feb\u901f\uff0c\u7a0d\u5fae\u5ef6\u8fdf | \n| \u5b89\u5168\u6027| Google\u53ef\u770b\u5230\u901a\u4fe1\u5185\u5bb9 | \u652f\u6301\u5b8c\u6574https\u52a0\u5bc6 |  \n| \u6613\u7528 | \u9700\u5f00\u542fIpv6\uff0c\u90e8\u7f72\u670d\u52a1\u7aef\uff0c\u5bfc\u5165\u8bc1\u4e66 | \u7b80\u5355  |\n| \u517c\u5bb9\u6027| \u90e8\u5206\u7f51\u7ad9\u4e0d\u652f\u6301 | \u65e0\u95ee\u9898 |\n| \u6536\u8d39  | \u514d\u8d39 | \u4ed8\u8d39 |  \n\n<br>\n\n### [__\u4e0b\u8f7d\u9875\u9762__](https://github.com/XX-net/XX-Net/blob/master/code/default/download.md)\n<br>\n\n\n### \u6700\u65b0\u72b6\u6001\uff1a\n 2019-8-8\n* Google \u66f4\u65b0\u670d\u52a1\u5668\u8bc1\u4e66\uff0c\u8bf7\u66f4\u65b0\u52303.13.2 \u53ca\u4ee5\u4e0a\u3002\n\n\n* GAE_Proxy \u8bf7\u5f00\u542fIPv6\uff0c\u53c2\u8003:  \n  [\u5982\u4f55\u5f00\u542fIPv6](https://github.com/XX-net/XX-Net/wiki/%E5%A6%82%E4%BD%95%E5%BC%80%E5%90%AFIPv6)\n\n    \n  \n<br>\n\n#### \u63d0\u793a\uff1a  \n* \u6709\u95ee\u9898\u8bf7\u5148\u770b[Wiki\u6587\u6863](https://github.com/XX-net/XX-Net/wiki/%E4%B8%AD%E6%96%87%E6%96%87%E6%A1%A3)\n* [\u63d0\u95ee](https://github.com/XX-net/XX-Net/issues)\u524d\uff0c\u8bf7\u5148\u770b[\u6700\u8fd1\u8ba8\u8bba\u4e3b\u9898](https://github.com/XX-net/XX-Net/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc)\uff0c\u907f\u514d\u91cd\u590d\u53d1\u95ee\u3002  \n"}, {"repo": "soimort/you-get", "language": "Python", "readme_contents": "# You-Get\n\n[![PyPI version](https://img.shields.io/pypi/v/you-get.svg)](https://pypi.python.org/pypi/you-get/)\n[![Build Status](https://travis-ci.org/soimort/you-get.svg)](https://travis-ci.org/soimort/you-get)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/soimort/you-get?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n**NOTICE: Read [this](https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md) if you are looking for the conventional \"Issues\" tab.**\n\n---\n\n[You-Get](https://you-get.org/) is a tiny command-line utility to download media contents (videos, audios, images) from the Web, in case there is no other handy way to do it.\n\nHere's how you use `you-get` to download a video from [YouTube](https://www.youtube.com/watch?v=jNQXAC9IVRw):\n\n```console\n$ you-get 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\nsite:                YouTube\ntitle:               Me at the zoo\nstream:\n    - itag:          43\n      container:     webm\n      quality:       medium\n      size:          0.5 MiB (564215 bytes)\n    # download-with: you-get --itag=43 [URL]\n\nDownloading Me at the zoo.webm ...\n 100% (  0.5/  0.5MB) \u251c\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2524[1/1]    6 MB/s\n\nSaving Me at the zoo.en.srt ... Done.\n```\n\nAnd here's why you might want to use it:\n\n* You enjoyed something on the Internet, and just want to download them for your own pleasure.\n* You watch your favorite videos online from your computer, but you are prohibited from saving them. You feel that you have no control over your own computer. (And it's not how an open Web is supposed to work.)\n* You want to get rid of any closed-source technology or proprietary JavaScript code, and disallow things like Flash running on your computer.\n* You are an adherent of hacker culture and free software.\n\nWhat `you-get` can do for you:\n\n* Download videos / audios from popular websites such as YouTube, Youku, Niconico, and a bunch more. (See the [full list of supported sites](#supported-sites))\n* Stream an online video in your media player. No web browser, no more ads.\n* Download images (of interest) by scraping a web page.\n* Download arbitrary non-HTML contents, i.e., binary files.\n\nInterested? [Install it](#installation) now and [get started by examples](#getting-started).\n\nAre you a Python programmer? Then check out [the source](https://github.com/soimort/you-get) and fork it!\n\n![](https://i.imgur.com/GfthFAz.png)\n\n## Installation\n\n### Prerequisites\n\nThe following dependencies are necessary:\n\n* **[Python](https://www.python.org/downloads/)**  3.2 or above\n* **[FFmpeg](https://www.ffmpeg.org/)** 1.0 or above\n* (Optional) [RTMPDump](https://rtmpdump.mplayerhq.hu/)\n\n### Option 1: Install via pip\n\nThe official release of `you-get` is distributed on [PyPI](https://pypi.python.org/pypi/you-get), and can be installed easily from a PyPI mirror via the [pip](https://en.wikipedia.org/wiki/Pip_\\(package_manager\\)) package manager. Note that you must use the Python 3 version of `pip`:\n\n    $ pip3 install you-get\n\n### Option 2: Install via [Antigen](https://github.com/zsh-users/antigen) (for Zsh users)\n\nAdd the following line to your `.zshrc`:\n\n    antigen bundle soimort/you-get\n\n### Option 3: Download from GitHub\n\nYou may either download the [stable](https://github.com/soimort/you-get/archive/master.zip) (identical with the latest release on PyPI) or the [develop](https://github.com/soimort/you-get/archive/develop.zip) (more hotfixes, unstable features) branch of `you-get`. Unzip it, and put the directory containing the `you-get` script into your `PATH`.\n\nAlternatively, run\n\n```\n$ [sudo] python3 setup.py install\n```\n\nOr\n\n```\n$ python3 setup.py install --user\n```\n\nto install `you-get` to a permanent path.\n\n### Option 4: Git clone\n\nThis is the recommended way for all developers, even if you don't often code in Python.\n\n```\n$ git clone git://github.com/soimort/you-get.git\n```\n\nThen put the cloned directory into your `PATH`, or run `./setup.py install` to install `you-get` to a permanent path.\n\n### Option 5: Homebrew (Mac only)\n\nYou can install `you-get` easily via:\n\n```\n$ brew install you-get\n```\n\n### Option 6: pkg (FreeBSD only)\n\nYou can install `you-get` easily via:\n\n```\n# pkg install you-get\n```\n\n### Shell completion\n\nCompletion definitions for Bash, Fish and Zsh can be found in [`contrib/completion`](https://github.com/soimort/you-get/tree/develop/contrib/completion). Please consult your shell's manual for how to take advantage of them.\n\n## Upgrading\n\nBased on which option you chose to install `you-get`, you may upgrade it via:\n\n```\n$ pip3 install --upgrade you-get\n```\n\nor download the latest release via:\n\n```\n$ you-get https://github.com/soimort/you-get/archive/master.zip\n```\n\nIn order to get the latest ```develop``` branch without messing up the PIP, you can try:\n\n```\n$ pip3 install --upgrade git+https://github.com/soimort/you-get@develop\n```\n\n## Getting Started\n\n### Download a video\n\nWhen you get a video of interest, you might want to use the `--info`/`-i` option to see all available quality and formats:\n\n```\n$ you-get -i 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\nsite:                YouTube\ntitle:               Me at the zoo\nstreams:             # Available quality and codecs\n    [ DASH ] ____________________________________\n    - itag:          242\n      container:     webm\n      quality:       320x240\n      size:          0.6 MiB (618358 bytes)\n    # download-with: you-get --itag=242 [URL]\n\n    - itag:          395\n      container:     mp4\n      quality:       320x240\n      size:          0.5 MiB (550743 bytes)\n    # download-with: you-get --itag=395 [URL]\n\n    - itag:          133\n      container:     mp4\n      quality:       320x240\n      size:          0.5 MiB (498558 bytes)\n    # download-with: you-get --itag=133 [URL]\n\n    - itag:          278\n      container:     webm\n      quality:       192x144\n      size:          0.4 MiB (392857 bytes)\n    # download-with: you-get --itag=278 [URL]\n\n    - itag:          160\n      container:     mp4\n      quality:       192x144\n      size:          0.4 MiB (370882 bytes)\n    # download-with: you-get --itag=160 [URL]\n\n    - itag:          394\n      container:     mp4\n      quality:       192x144\n      size:          0.4 MiB (367261 bytes)\n    # download-with: you-get --itag=394 [URL]\n\n    [ DEFAULT ] _________________________________\n    - itag:          43\n      container:     webm\n      quality:       medium\n      size:          0.5 MiB (568748 bytes)\n    # download-with: you-get --itag=43 [URL]\n\n    - itag:          18\n      container:     mp4\n      quality:       small\n    # download-with: you-get --itag=18 [URL]\n\n    - itag:          36\n      container:     3gp\n      quality:       small\n    # download-with: you-get --itag=36 [URL]\n\n    - itag:          17\n      container:     3gp\n      quality:       small\n    # download-with: you-get --itag=17 [URL]\n```\n\nBy default, the one on the top is the one you will get. If that looks cool to you, download it:\n\n```\n$ you-get 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\nsite:                YouTube\ntitle:               Me at the zoo\nstream:\n    - itag:          242\n      container:     webm\n      quality:       320x240\n      size:          0.6 MiB (618358 bytes)\n    # download-with: you-get --itag=242 [URL]\n\nDownloading Me at the zoo.webm ...\n 100% (  0.6/  0.6MB) \u251c\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2524[2/2]    2 MB/s\nMerging video parts... Merged into Me at the zoo.webm\n\nSaving Me at the zoo.en.srt ... Done.\n```\n\n(If a YouTube video has any closed captions, they will be downloaded together with the video file, in SubRip subtitle format.)\n\nOr, if you prefer another format (mp4), just use whatever the option `you-get` shows to you:\n\n```\n$ you-get --itag=18 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\n```\n\n**Note:**\n\n* At this point, format selection has not been generally implemented for most of our supported sites; in that case, the default format to download is the one with the highest quality.\n* `ffmpeg` is a required dependency, for downloading and joining videos streamed in multiple parts (e.g. on some sites like Youku), and for YouTube videos of 1080p or high resolution.\n* If you don't want `you-get` to join video parts after downloading them, use the `--no-merge`/`-n` option.\n\n### Download anything else\n\nIf you already have the URL of the exact resource you want, you can download it directly with:\n\n```\n$ you-get https://stallman.org/rms.jpg\nSite:       stallman.org\nTitle:      rms\nType:       JPEG Image (image/jpeg)\nSize:       0.06 MiB (66482 Bytes)\n\nDownloading rms.jpg ...\n100.0% (  0.1/0.1  MB) \u251c\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2524[1/1]  127 kB/s\n```\n\nOtherwise, `you-get` will scrape the web page and try to figure out if there's anything interesting to you:\n\n```\n$ you-get http://kopasas.tumblr.com/post/69361932517\nSite:       Tumblr.com\nTitle:      kopasas\nType:       Unknown type (None)\nSize:       0.51 MiB (536583 Bytes)\n\nSite:       Tumblr.com\nTitle:      tumblr_mxhg13jx4n1sftq6do1_1280\nType:       Portable Network Graphics (image/png)\nSize:       0.51 MiB (536583 Bytes)\n\nDownloading tumblr_mxhg13jx4n1sftq6do1_1280.png ...\n100.0% (  0.5/0.5  MB) \u251c\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2524[1/1]   22 MB/s\n```\n\n**Note:**\n\n* This feature is an experimental one and far from perfect. It works best on scraping large-sized images from popular websites like Tumblr and Blogger, but there is really no universal pattern that can apply to any site on the Internet.\n\n### Search on Google Videos and download\n\nYou can pass literally anything to `you-get`. If it isn't a valid URL, `you-get` will do a Google search and download the most relevant video for you. (It might not be exactly the thing you wish to see, but still very likely.)\n\n```\n$ you-get \"Richard Stallman eats\"\n```\n\n### Pause and resume a download\n\nYou may use <kbd>Ctrl</kbd>+<kbd>C</kbd> to interrupt a download.\n\nA temporary `.download` file is kept in the output directory. Next time you run `you-get` with the same arguments, the download progress will resume from the last session. In case the file is completely downloaded (the temporary `.download` extension is gone), `you-get` will just skip the download.\n\nTo enforce re-downloading, use the `--force`/`-f` option. (**Warning:** doing so will overwrite any existing file or temporary file with the same name!)\n\n### Set the path and name of downloaded file\n\nUse the `--output-dir`/`-o` option to set the path, and `--output-filename`/`-O` to set the name of the downloaded file:\n\n```\n$ you-get -o ~/Videos -O zoo.webm 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\n```\n\n**Tips:**\n\n* These options are helpful if you encounter problems with the default video titles, which may contain special characters that do not play well with your current shell / operating system / filesystem.\n* These options are also helpful if you write a script to batch download files and put them into designated folders with designated names.\n\n### Proxy settings\n\nYou may specify an HTTP proxy for `you-get` to use, via the `--http-proxy`/`-x` option:\n\n```\n$ you-get -x 127.0.0.1:8087 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\n```\n\nHowever, the system proxy setting (i.e. the environment variable `http_proxy`) is applied by default. To disable any proxy, use the `--no-proxy` option.\n\n**Tips:**\n\n* If you need to use proxies a lot (in case your network is blocking certain sites), you might want to use `you-get` with [proxychains](https://github.com/rofl0r/proxychains-ng) and set `alias you-get=\"proxychains -q you-get\"` (in Bash).\n* For some websites (e.g. Youku), if you need access to some videos that are only available in mainland China, there is an option of using a specific proxy to extract video information from the site: `--extractor-proxy`/`-y`.\n\n### Watch a video\n\nUse the `--player`/`-p` option to feed the video into your media player of choice, e.g. `mpv` or `vlc`, instead of downloading it:\n\n```\n$ you-get -p vlc 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\n```\n\nOr, if you prefer to watch the video in a browser, just without ads or comment section:\n\n```\n$ you-get -p chromium 'https://www.youtube.com/watch?v=jNQXAC9IVRw'\n```\n\n**Tips:**\n\n* It is possible to use the `-p` option to start another download manager, e.g., `you-get -p uget-gtk 'https://www.youtube.com/watch?v=jNQXAC9IVRw'`, though they may not play together very well.\n\n### Load cookies\n\nNot all videos are publicly available to anyone. If you need to log in your account to access something (e.g., a private video), it would be unavoidable to feed the browser cookies to `you-get` via the `--cookies`/`-c` option.\n\n**Note:**\n\n* As of now, we are supporting two formats of browser cookies: Mozilla `cookies.sqlite` and Netscape `cookies.txt`.\n\n### Reuse extracted data\n\nUse `--url`/`-u` to get a list of downloadable resource URLs extracted from the page. Use `--json` to get an abstract of extracted data in the JSON format.\n\n**Warning:**\n\n* For the time being, this feature has **NOT** been stabilized and the JSON schema may have breaking changes in the future.\n\n## Supported Sites\n\n| Site | URL | Videos? | Images? | Audios? |\n| :--: | :-- | :-----: | :-----: | :-----: |\n| **YouTube** | <https://www.youtube.com/>    |\u2713| | |\n| **Twitter** | <https://twitter.com/>        |\u2713|\u2713| |\n| VK          | <http://vk.com/>              |\u2713|\u2713| |\n| Vine        | <https://vine.co/>            |\u2713| | |\n| Vimeo       | <https://vimeo.com/>          |\u2713| | |\n| Vidto       | <http://vidto.me/>            |\u2713| | |\n| Videomega   | <http://videomega.tv/>        |\u2713| | |\n| Veoh        | <http://www.veoh.com/>        |\u2713| | |\n| **Tumblr**  | <https://www.tumblr.com/>     |\u2713|\u2713|\u2713|\n| TED         | <http://www.ted.com/>         |\u2713| | |\n| SoundCloud  | <https://soundcloud.com/>     | | |\u2713|\n| SHOWROOM    | <https://www.showroom-live.com/> |\u2713| | |\n| Pinterest   | <https://www.pinterest.com/>  | |\u2713| |\n| MusicPlayOn | <http://en.musicplayon.com/>  |\u2713| | |\n| MTV81       | <http://www.mtv81.com/>       |\u2713| | |\n| Mixcloud    | <https://www.mixcloud.com/>   | | |\u2713|\n| Metacafe    | <http://www.metacafe.com/>    |\u2713| | |\n| Magisto     | <http://www.magisto.com/>     |\u2713| | |\n| Khan Academy | <https://www.khanacademy.org/> |\u2713| | |\n| Internet Archive | <https://archive.org/>   |\u2713| | |\n| **Instagram** | <https://instagram.com/>    |\u2713|\u2713| |\n| InfoQ       | <http://www.infoq.com/presentations/> |\u2713| | |\n| Imgur       | <http://imgur.com/>           | |\u2713| |\n| Heavy Music Archive | <http://www.heavy-music.ru/> | | |\u2713|\n| **Google+** | <https://plus.google.com/>    |\u2713|\u2713| |\n| Freesound   | <http://www.freesound.org/>   | | |\u2713|\n| Flickr      | <https://www.flickr.com/>     |\u2713|\u2713| |\n| FC2 Video   | <http://video.fc2.com/>       |\u2713| | |\n| Facebook    | <https://www.facebook.com/>   |\u2713| | |\n| eHow        | <http://www.ehow.com/>        |\u2713| | |\n| Dailymotion | <http://www.dailymotion.com/> |\u2713| | |\n| Coub        | <http://coub.com/>            |\u2713| | |\n| CBS         | <http://www.cbs.com/>         |\u2713| | |\n| Bandcamp    | <http://bandcamp.com/>        | | |\u2713|\n| AliveThai   | <http://alive.in.th/>         |\u2713| | |\n| interest.me | <http://ch.interest.me/tvn>   |\u2713| | |\n| **755<br/>\u30ca\u30ca\u30b4\u30fc\u30b4\u30fc** | <http://7gogo.jp/> |\u2713|\u2713| |\n| **niconico<br/>\u30cb\u30b3\u30cb\u30b3\u52d5\u753b** | <http://www.nicovideo.jp/> |\u2713| | |\n| **163<br/>\u7f51\u6613\u89c6\u9891<br/>\u7f51\u6613\u4e91\u97f3\u4e50** | <http://v.163.com/><br/><http://music.163.com/> |\u2713| |\u2713|\n| 56\u7f51     | <http://www.56.com/>           |\u2713| | |\n| **AcFun** | <http://www.acfun.cn/>        |\u2713| | |\n| **Baidu<br/>\u767e\u5ea6\u8d34\u5427** | <http://tieba.baidu.com/> |\u2713|\u2713| |\n| \u7206\u7c73\u82b1\u7f51 | <http://www.baomihua.com/>     |\u2713| | |\n| **bilibili<br/>\u54d4\u54e9\u54d4\u54e9** | <http://www.bilibili.com/> |\u2713| | |\n| \u8c46\u74e3     | <http://www.douban.com/>       |\u2713| |\u2713|\n| \u6597\u9c7c     | <http://www.douyutv.com/>      |\u2713| | |\n| Panda<br/>\u718a\u732b | <http://www.panda.tv/>      |\u2713| | |\n| \u51e4\u51f0\u89c6\u9891 | <http://v.ifeng.com/>          |\u2713| | |\n| \u98ce\u884c\u7f51   | <http://www.fun.tv/>           |\u2713| | |\n| iQIYI<br/>\u7231\u5947\u827a | <http://www.iqiyi.com/> |\u2713| | |\n| \u6fc0\u52a8\u7f51   | <http://www.joy.cn/>           |\u2713| | |\n| \u91776\u7f51    | <http://www.ku6.com/>          |\u2713| | |\n| \u9177\u72d7\u97f3\u4e50 | <http://www.kugou.com/>        | | |\u2713|\n| \u9177\u6211\u97f3\u4e50 | <http://www.kuwo.cn/>          | | |\u2713|\n| \u4e50\u89c6\u7f51   | <http://www.le.com/>           |\u2713| | |\n| \u8354\u679dFM   | <http://www.lizhi.fm/>         | | |\u2713|\n| \u79d2\u62cd     | <http://www.miaopai.com/>      |\u2713| | |\n| MioMio\u5f39\u5e55\u7f51 | <http://www.miomio.tv/>    |\u2713| | |\n| MissEvan<br/>\u732b\u8033FM | <http://www.missevan.com/> | | |\u2713|\n| \u75de\u5ba2\u90a6   | <https://www.pixnet.net/>      |\u2713| | |\n| PPTV\u805a\u529b | <http://www.pptv.com/>         |\u2713| | |\n| \u9f50\u9c81\u7f51   | <http://v.iqilu.com/>          |\u2713| | |\n| QQ<br/>\u817e\u8baf\u89c6\u9891 | <http://v.qq.com/>      |\u2713| | |\n| \u4f01\u9e45\u76f4\u64ad | <http://live.qq.com/>          |\u2713| | |\n| Sina<br/>\u65b0\u6d6a\u89c6\u9891<br/>\u5fae\u535a\u79d2\u62cd\u89c6\u9891 | <http://video.sina.com.cn/><br/><http://video.weibo.com/> |\u2713| | |\n| Sohu<br/>\u641c\u72d0\u89c6\u9891 | <http://tv.sohu.com/> |\u2713| | |\n| **Tudou<br/>\u571f\u8c46** | <http://www.tudou.com/> |\u2713| | |\n| \u867e\u7c73     | <http://www.xiami.com/>        |\u2713| |\u2713|\n| \u9633\u5149\u536b\u89c6 | <http://www.isuntv.com/>       |\u2713| | |\n| **\u97f3\u60a6Tai** | <http://www.yinyuetai.com/> |\u2713| | |\n| **Youku<br/>\u4f18\u9177** | <http://www.youku.com/> |\u2713| | |\n| \u6218\u65d7TV   | <http://www.zhanqi.tv/lives>   |\u2713| | |\n| \u592e\u89c6\u7f51   | <http://www.cntv.cn/>          |\u2713| | |\n| Naver<br/>\ub124\uc774\ubc84 | <http://tvcast.naver.com/>     |\u2713| | |\n| \u8292\u679cTV   | <http://www.mgtv.com/>         |\u2713| | |\n| \u706b\u732bTV   | <http://www.huomao.com/>       |\u2713| | |\n| \u9633\u5149\u5bbd\u9891\u7f51 | <http://www.365yg.com/>      |\u2713| | |\n| \u897f\u74dc\u89c6\u9891 | <https://www.ixigua.com/>      |\u2713| | |\n| \u5feb\u624b | <https://www.kuaishou.com/>      |\u2713|\u2713| |\n| \u6296\u97f3 | <https://www.douyin.com/>      |\u2713| | |\n| TikTok | <https://www.tiktok.com/>      |\u2713| | |\n| \u4e2d\u56fd\u4f53\u80b2(TV) | <http://v.zhibo.tv/> </br><http://video.zhibo.tv/>    |\u2713| | |\n| \u77e5\u4e4e | <https://www.zhihu.com/>      |\u2713| | |\n\nFor all other sites not on the list, the universal extractor will take care of finding and downloading interesting resources from the page.\n\n### Known bugs\n\nIf something is broken and `you-get` can't get you things you want, don't panic. (Yes, this happens all the time!)\n\nCheck if it's already a known problem on <https://github.com/soimort/you-get/wiki/Known-Bugs>. If not, follow the guidelines on [how to report an issue](https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md).\n\n## Getting Involved\n\nYou can reach us on the Gitter channel [#soimort/you-get](https://gitter.im/soimort/you-get) (here's how you [set up your IRC client](http://irc.gitter.im) for Gitter). If you have a quick question regarding `you-get`, ask it there.\n\nIf you are seeking to report an issue or contribute, please make sure to read [the guidelines](https://github.com/soimort/you-get/blob/develop/CONTRIBUTING.md) first.\n\n## Legal Issues\n\nThis software is distributed under the [MIT license](https://raw.github.com/soimort/you-get/master/LICENSE.txt).\n\nIn particular, please be aware that\n\n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nTranslated to human words:\n\n*In case your use of the software forms the basis of copyright infringement, or you use the software for any other illegal purposes, the authors cannot take any responsibility for you.*\n\nWe only ship the code here, and how you are going to use it is left to your own discretion.\n\n## Authors\n\nMade by [@soimort](https://github.com/soimort), who is in turn powered by :coffee:, :beer: and :ramen:.\n\nYou can find the [list of all contributors](https://github.com/soimort/you-get/graphs/contributors) here.\n"}, {"repo": "python/cpython", "language": "Python", "readme_contents": "This is Python version 3.9.0 alpha 1\n====================================\n\n.. image:: https://travis-ci.org/python/cpython.svg?branch=master\n   :alt: CPython build status on Travis CI\n   :target: https://travis-ci.org/python/cpython\n\n.. image:: https://dev.azure.com/python/cpython/_apis/build/status/Azure%20Pipelines%20CI?branchName=master\n   :alt: CPython build status on Azure DevOps\n   :target: https://dev.azure.com/python/cpython/_build/latest?definitionId=4&branchName=master\n\n.. image:: https://codecov.io/gh/python/cpython/branch/master/graph/badge.svg\n   :alt: CPython code coverage on Codecov\n   :target: https://codecov.io/gh/python/cpython\n\n.. image:: https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\n   :alt: Python Zulip chat\n   :target: https://python.zulipchat.com\n\n\nCopyright (c) 2001-2019 Python Software Foundation.  All rights reserved.\n\nSee the end of this file for further copyright and license information.\n\n.. contents::\n\nGeneral Information\n-------------------\n\n- Website: https://www.python.org\n- Source code: https://github.com/python/cpython\n- Issue tracker: https://bugs.python.org\n- Documentation: https://docs.python.org\n- Developer's Guide: https://devguide.python.org/\n\nContributing to CPython\n-----------------------\n\nFor more complete instructions on contributing to CPython development,\nsee the `Developer Guide`_.\n\n.. _Developer Guide: https://devguide.python.org/\n\nUsing Python\n------------\n\nInstallable Python kits, and information about using Python, are available at\n`python.org`_.\n\n.. _python.org: https://www.python.org/\n\nBuild Instructions\n------------------\n\nOn Unix, Linux, BSD, macOS, and Cygwin::\n\n    ./configure\n    make\n    make test\n    sudo make install\n\nThis will install Python as ``python3``.\n\nYou can pass many options to the configure script; run ``./configure --help``\nto find out more.  On macOS case-insensitive file systems and on Cygwin,\nthe executable is called ``python.exe``; elsewhere it's just ``python``.\n\nBuilding a complete Python installation requires the use of various\nadditional third-party libraries, depending on your build platform and\nconfigure options.  Not all standard library modules are buildable or\nuseable on all platforms.  Refer to the\n`Install dependencies <https://devguide.python.org/setup/#install-dependencies>`_\nsection of the `Developer Guide`_ for current detailed information on\ndependencies for various Linux distributions and macOS.\n\nOn macOS, there are additional configure and build options related\nto macOS framework and universal builds.  Refer to `Mac/README.rst\n<https://github.com/python/cpython/blob/master/Mac/README.rst>`_.\n\nOn Windows, see `PCbuild/readme.txt\n<https://github.com/python/cpython/blob/master/PCbuild/readme.txt>`_.\n\nIf you wish, you can create a subdirectory and invoke configure from there.\nFor example::\n\n    mkdir debug\n    cd debug\n    ../configure --with-pydebug\n    make\n    make test\n\n(This will fail if you *also* built at the top-level directory.  You should do\na ``make clean`` at the top-level first.)\n\nTo get an optimized build of Python, ``configure --enable-optimizations``\nbefore you run ``make``.  This sets the default make targets up to enable\nProfile Guided Optimization (PGO) and may be used to auto-enable Link Time\nOptimization (LTO) on some platforms.  For more details, see the sections\nbelow.\n\nProfile Guided Optimization\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nPGO takes advantage of recent versions of the GCC or Clang compilers.  If used,\neither via ``configure --enable-optimizations`` or by manually running\n``make profile-opt`` regardless of configure flags, the optimized build\nprocess will perform the following steps:\n\nThe entire Python directory is cleaned of temporary files that may have\nresulted from a previous compilation.\n\nAn instrumented version of the interpreter is built, using suitable compiler\nflags for each flavour. Note that this is just an intermediary step.  The\nbinary resulting from this step is not good for real life workloads as it has\nprofiling instructions embedded inside.\n\nAfter the instrumented interpreter is built, the Makefile will run a training\nworkload.  This is necessary in order to profile the interpreter execution.\nNote also that any output, both stdout and stderr, that may appear at this step\nis suppressed.\n\nThe final step is to build the actual interpreter, using the information\ncollected from the instrumented one.  The end result will be a Python binary\nthat is optimized; suitable for distribution or production installation.\n\n\nLink Time Optimization\n^^^^^^^^^^^^^^^^^^^^^^\n\nEnabled via configure's ``--with-lto`` flag.  LTO takes advantage of the\nability of recent compiler toolchains to optimize across the otherwise\narbitrary ``.o`` file boundary when building final executables or shared\nlibraries for additional performance gains.\n\n\nWhat's New\n----------\n\nWe have a comprehensive overview of the changes in the `What's New in Python\n3.9 <https://docs.python.org/3.9/whatsnew/3.9.html>`_ document.  For a more\ndetailed change log, read `Misc/NEWS\n<https://github.com/python/cpython/blob/master/Misc/NEWS.d>`_, but a full\naccounting of changes can only be gleaned from the `commit history\n<https://github.com/python/cpython/commits/master>`_.\n\nIf you want to install multiple versions of Python, see the section below\nentitled \"Installing multiple versions\".\n\n\nDocumentation\n-------------\n\n`Documentation for Python 3.9 <https://docs.python.org/3.9/>`_ is online,\nupdated daily.\n\nIt can also be downloaded in many formats for faster access.  The documentation\nis downloadable in HTML, PDF, and reStructuredText formats; the latter version\nis primarily for documentation authors, translators, and people with special\nformatting requirements.\n\nFor information about building Python's documentation, refer to `Doc/README.rst\n<https://github.com/python/cpython/blob/master/Doc/README.rst>`_.\n\n\nConverting From Python 2.x to 3.x\n---------------------------------\n\nSignificant backward incompatible changes were made for the release of Python\n3.0, which may cause programs written for Python 2 to fail when run with Python\n3.  For more information about porting your code from Python 2 to Python 3, see\nthe `Porting HOWTO <https://docs.python.org/3/howto/pyporting.html>`_.\n\n\nTesting\n-------\n\nTo test the interpreter, type ``make test`` in the top-level directory.  The\ntest set produces some output.  You can generally ignore the messages about\nskipped tests due to optional features which can't be imported.  If a message\nis printed about a failed test or a traceback or core dump is produced,\nsomething is wrong.\n\nBy default, tests are prevented from overusing resources like disk space and\nmemory.  To enable these tests, run ``make testall``.\n\nIf any tests fail, you can re-run the failing test(s) in verbose mode.  For\nexample, if ``test_os`` and ``test_gdb`` failed, you can run::\n\n    make test TESTOPTS=\"-v test_os test_gdb\"\n\nIf the failure persists and appears to be a problem with Python rather than\nyour environment, you can `file a bug report <https://bugs.python.org>`_ and\ninclude relevant output from that command to show the issue.\n\nSee `Running & Writing Tests <https://devguide.python.org/runtests/>`_\nfor more on running tests.\n\nInstalling multiple versions\n----------------------------\n\nOn Unix and Mac systems if you intend to install multiple versions of Python\nusing the same installation prefix (``--prefix`` argument to the configure\nscript) you must take care that your primary python executable is not\noverwritten by the installation of a different version.  All files and\ndirectories installed using ``make altinstall`` contain the major and minor\nversion and can thus live side-by-side.  ``make install`` also creates\n``${prefix}/bin/python3`` which refers to ``${prefix}/bin/pythonX.Y``.  If you\nintend to install multiple versions using the same prefix you must decide which\nversion (if any) is your \"primary\" version.  Install that version using ``make\ninstall``.  Install all other versions using ``make altinstall``.\n\nFor example, if you want to install Python 2.7, 3.6, and 3.9 with 3.9 being the\nprimary version, you would execute ``make install`` in your 3.9 build directory\nand ``make altinstall`` in the others.\n\n\nIssue Tracker and Mailing List\n------------------------------\n\nBug reports are welcome!  You can use the `issue tracker\n<https://bugs.python.org>`_ to report bugs, and/or submit pull requests `on\nGitHub <https://github.com/python/cpython>`_.\n\nYou can also follow development discussion on the `python-dev mailing list\n<https://mail.python.org/mailman/listinfo/python-dev/>`_.\n\n\nProposals for enhancement\n-------------------------\n\nIf you have a proposal to change Python, you may want to send an email to the\ncomp.lang.python or `python-ideas`_ mailing lists for initial feedback.  A\nPython Enhancement Proposal (PEP) may be submitted if your idea gains ground.\nAll current PEPs, as well as guidelines for submitting a new PEP, are listed at\n`python.org/dev/peps/ <https://www.python.org/dev/peps/>`_.\n\n.. _python-ideas: https://mail.python.org/mailman/listinfo/python-ideas/\n\n\nRelease Schedule\n----------------\n\nSee :pep:`596` for Python 3.9 release details.\n\n\nCopyright and License Information\n---------------------------------\n\nCopyright (c) 2001-2019 Python Software Foundation.  All rights reserved.\n\nCopyright (c) 2000 BeOpen.com.  All rights reserved.\n\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.  All\nrights reserved.\n\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum.  All rights reserved.\n\nSee the file \"LICENSE\" for information on the history of this software, terms &\nconditions for usage, and a DISCLAIMER OF ALL WARRANTIES.\n\nThis Python distribution contains *no* GNU General Public License (GPL) code,\nso it may be used in proprietary projects.  There are interfaces to some GNU\ncode but these are entirely optional.\n\nAll trademarks referenced herein are property of their respective holders.\n"}, {"repo": "deepfakes/faceswap", "language": "Python", "readme_contents": "# deepfakes_faceswap\n<p align=\"center\">\n  <a href=\"https://faceswap.dev\"><img src=\"https://i.imgur.com/zHvjHnb.png\"></img></a>\n<br />FaceSwap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos.\n</p>\n<p align=\"center\">\n<img src = \"https://i.imgur.com/nWHFLDf.jpg\"></img>\n</p>\n\n<p align=\"center\">\n<a href=\"https://www.patreon.com/bePatron?u=23238350\"><img src=\"https://c5.patreon.com/external/logo/become_a_patron_button.png\"></img></a>\n</p>\n<p align=\"center\">\n  <a href=\"https://www.youtube.com/watch?v=r1jng79a5xc\"><img src=\"https://img.youtube.com/vi/r1jng79a5xc/0.jpg\"></img></a>\n<br />Jennifer Lawrence/Steve Buscemi FaceSwap using the Villain model\n</p>\n\n[![Build Status](https://travis-ci.org/deepfakes/faceswap.svg?branch=master)](https://travis-ci.org/deepfakes/faceswap) [![Documentation Status](https://readthedocs.org/projects/faceswap/badge/?version=latest)](https://faceswap.readthedocs.io/en/latest/?badge=latest)\n\nMake sure you check out [INSTALL.md](INSTALL.md) before getting started.\n\n- [deepfakes_faceswap](#deepfakesfaceswap)\n- [Manifesto](#manifesto)\n  - [FaceSwap has ethical uses.](#faceswap-has-ethical-uses)\n- [How To setup and run the project](#how-to-setup-and-run-the-project)\n- [Overview](#overview)\n  - [Extract](#extract)\n  - [Train](#train)\n  - [Convert](#convert)\n  - [GUI](#gui)\n- [General notes:](#general-notes)\n- [Help I need support!](#help-i-need-support)\n  - [Discord Server](#discord-server)\n  - [FaceSwap Forum](#faceswap-forum)\n- [Donate](#donate)\n  - [Patreon](#patreon)\n  - [One time Donations](#one-time-donations)\n    - [@torzdf](#torzdf)\n    - [@andenixa](#andenixa)\n    - [@kvrooman](#kvrooman)\n- [How to contribute](#how-to-contribute)\n  - [For people interested in the generative models](#for-people-interested-in-the-generative-models)\n  - [For devs](#for-devs)\n  - [For non-dev advanced users](#for-non-dev-advanced-users)\n  - [For end-users](#for-end-users)\n  - [For haters](#for-haters)\n- [About github.com/deepfakes](#about-githubcomdeepfakes)\n  - [What is this repo?](#what-is-this-repo)\n  - [Why this repo?](#why-this-repo)\n  - [Why is it named 'deepfakes' if it is not /u/deepfakes?](#why-is-it-named-deepfakes-if-it-is-not-udeepfakes)\n  - [What if /u/deepfakes feels bad about that?](#what-if-udeepfakes-feels-bad-about-that)\n- [About machine learning](#about-machine-learning)\n  - [How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?](#how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network)\n\n# Manifesto\n\n## FaceSwap has ethical uses.\n\nWhen faceswapping was first developed and published, the technology was groundbreaking, it was a huge step in AI development. It was also completely ignored outside of academia because the code was confusing and fragmentary. It required a thorough understanding of complicated AI techniques and took a lot of effort to figure it out. Until one individual brought it together into a single, cohesive collection. It ran, it worked, and as is so often the way with new technology emerging on the internet, it was immediately used to create inappropriate content. Despite the inappropriate uses the software was given originally, it was the first AI code that anyone could download, run and learn by experimentation without having a Ph.D. in math, computer theory, psychology, and more. Before \"deepfakes\" these techniques were like black magic, only practiced by those who could understand all of the inner workings as described in esoteric and endlessly complicated books and papers.\n\n\"Deepfakes\" changed all that and anyone could participate in AI development. To us, developers, the release of this code opened up a fantastic learning opportunity. It allowed us to build on ideas developed by others, collaborate with a variety of skilled coders, experiment with AI whilst learning new skills and ultimately contribute towards an emerging technology which will only see more mainstream use as it progresses.\n\nAre there some out there doing horrible things with similar software? Yes. And because of this, the developers have been following strict ethical standards. Many of us don't even use it to create videos, we just tinker with the code to see what it does. Sadly, the media concentrates only on the unethical uses of this software. That is, unfortunately, the nature of how it was first exposed to the public, but it is not representative of why it was created, how we use it now, or what we see in its future. Like any technology, it can be used for good or it can be abused. It is our intention to develop FaceSwap in a way that its potential for abuse is minimized whilst maximizing its potential as a tool for learning, experimenting and, yes, for legitimate faceswapping.\n\nWe are not trying to denigrate celebrities or to demean anyone. We are programmers, we are engineers, we are Hollywood VFX artists, we are activists, we are hobbyists, we are human beings. To this end, we feel that it's time to come out with a standard statement of what this software is and isn't as far as us developers are concerned.\n\n- FaceSwap is not for creating inappropriate content.\n- FaceSwap is not for changing faces without consent or with the intent of hiding its use.\n- FaceSwap is not for any illicit, unethical, or questionable purposes.\n- FaceSwap exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.\n\nWe are very troubled by the fact that FaceSwap can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. We will take a zero tolerance approach to anyone using this software for any unethical purposes and will actively discourage any such uses.\n\n# How To setup and run the project\nFaceSwap is a Python program that will run on multiple Operating Systems including Windows, Linux, and MacOS.\n\nSee [INSTALL.md](INSTALL.md) for full installation instructions. You will need a modern GPU with CUDA support for best performance. AMD GPUs are partially supported.\n\n# Overview\nThe project has multiple entry points. You will have to:\n - Gather photos and/or videos\n - **Extract** faces from your raw photos\n - **Train** a model on the faces extracted from the photos/videos\n - **Convert** your sources with the model\n\nCheck out [USAGE.md](USAGE.md) for more detailed instructions.\n\n## Extract\nFrom your setup folder, run `python faceswap.py extract`. This will take photos from `src` folder and extract faces into `extract` folder.\n\n## Train\nFrom your setup folder, run `python faceswap.py train`. This will take photos from two folders containing pictures of both faces and train a model that will be saved inside the `models` folder.\n\n## Convert\nFrom your setup folder, run `python faceswap.py convert`. This will take photos from `original` folder and apply new faces into `modified` folder.\n\n## GUI\nAlternatively, you can run the GUI by running `python faceswap.py gui`\n\n# General notes:\n- All of the scripts mentioned have `-h`/`--help` options with arguments that they will accept. You're smart, you can figure out how this works, right?!\n\nNB: there is a conversion tool for video. This can be accessed by running `python tools.py effmpeg -h`. Alternatively, you can use [ffmpeg](https://www.ffmpeg.org) to convert video into photos, process images, and convert images back to the video.\n\n\n**Some tips:**\n\nReusing existing models will train much faster than starting from nothing.\nIf there is not enough training data, start with someone who looks similar, then switch the data.\n\n# Help I need support!\n## Discord Server\nYour best bet is to join the [FaceSwap Discord server](https://discord.gg/FC54sYg) where there are plenty of users willing to help. Please note that, like this repo, this is a SFW Server!\n\n## FaceSwap Forum\nAlternatively, you can post questions in the [FaceSwap Forum](https://faceswap.dev/forum). Please do not post general support questions in this repo as they are liable to be deleted without response.\n\n# Donate\nThe developers work tirelessly to improve and develop FaceSwap. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.\n\n## Patreon\nThe best way to support us is through our Patreon page:\n\n[![become-a-patron](https://c5.patreon.com/external/logo/become_a_patron_button.png)](https://www.patreon.com/bePatron?u=23238350)\n\n## One time Donations\nAlternatively you can give a one off donation to any of our Devs:\n### @torzdf\n There is very little FaceSwap code that hasn't been touched by torzdf. He is responsible for implementing the GUI, FAN aligner, MTCNN detector and porting the Villain, DFL-H128 and DFaker models to FaceSwap, as well as significantly improving many areas of the code.\n\n**Bitcoin:** 385a1r9tyZpt5LyZcNk1FALTxC8ZHta7yq\n\n**Ethereum:** 0x18CBbff5fA7C78de7B949A2b0160A0d1bd649f80\n\n**Paypal:** [![torzdf](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=JZ8PP3YE9J62L)\n\n### @andenixa\nCreator of the Unbalanced and OHR models, as well as expanding various capabilities within the training process. Andenixa is currently working on new models and will take requests for donations.\n\n**Paypal:** [![andenixa](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=NRVLQYGS6NWTU)\n\n### @kvrooman\nResponsible for consolidating the converters, adding a lot of code to fix model stability issues, and helping significantly towards making the training process more modular, kvrooman continues to be a very active contributor.\n\n**Ethereum:** 0x18CBbff5fA7C78de7B949A2b0160A0d1bd649f80\n\n# How to contribute\n\n## For people interested in the generative models\n - Go to the 'faceswap-model' to discuss/suggest/commit alternatives to the current algorithm.\n\n## For devs\n - Read this README entirely\n - Fork the repo\n - Play with it\n - Check issues with the 'dev' tag\n - For devs more interested in computer vision and openCV, look at issues with the 'opencv' tag. Also feel free to add your own alternatives/improvements\n\n## For non-dev advanced users\n - Read this README entirely\n - Clone the repo\n - Play with it\n - Check issues with the 'advuser' tag\n - Also go to the '[faceswap Forum](https://faceswap.dev/forum)' and help others.\n\n## For end-users\n - Get the code here and play with it if you can\n - You can also go to the [faceswap Forum](https://faceswap.dev/forum) and help or get help from others.\n - Be patient. This is a relatively new technology for developers as well. Much effort is already being put into making this program easy to use for the average user. It just takes time!\n - **Notice** Any issue related to running the code has to be opened in the [faceswap Forum](https://faceswap.dev/forum)!\n\n## For haters\nSorry, no time for that.\n\n# About github.com/deepfakes\n\n## What is this repo?\nIt is a community repository for active users.\n\n## Why this repo?\nThe joshua-wu repo seems not active. Simple bugs like missing _http://_ in front of urls have not been solved since days.\n\n## Why is it named 'deepfakes' if it is not /u/deepfakes?\n 1. Because a typosquat would have happened sooner or later as project grows\n 2. Because we wanted to recognize the original author\n 3. Because it will better federate contributors and users\n\n## What if /u/deepfakes feels bad about that?\nThis is a friendly typosquat, and it is fully dedicated to the project. If /u/deepfakes wants to take over this repo/user and drive the project, he is welcomed to do so (Raise an issue, and he will be contacted on Reddit). Please do not send /u/deepfakes messages for help with the code you find here.\n\n# About machine learning\n\n## How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?\nIt's complicated. Here's a good video that makes the process understandable:\n[![How Machines Learn](https://img.youtube.com/vi/R9OHn5ZF4Uo/0.jpg)](https://www.youtube.com/watch?v=R9OHn5ZF4Uo)\n\nHere's a slightly more in depth video that tries to explain the basic functioning of a neural network:\n[![How Machines Learn](https://img.youtube.com/vi/aircAruvnKk/0.jpg)](https://www.youtube.com/watch?v=aircAruvnKk)\n\ntl;dr: training data + trial and error\n"}, {"repo": "Avik-Jain/100-Days-Of-ML-Code", "language": "Python", "readme_contents": "# 100-Days-Of-ML-Code\n\n100 Days of Machine Learning Coding as proposed by [Siraj Raval](https://github.com/llSourcell)\n\nGet the datasets from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/tree/master/datasets)\n\n## Data PreProcessing | Day 1\nCheck out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%201_Data%20PreProcessing.md).\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%201.jpg\">\n</p>\n\n## Simple Linear Regression | Day 2\nCheck out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day2_Simple_Linear_Regression.md).\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%202.jpg\">\n</p>\n\n## Multiple Linear Regression | Day 3\nCheck out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day3_Multiple_Linear_Regression.md).\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%203.jpg\">\n</p>\n\n## Logistic Regression | Day 4\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%204.jpg\">\n</p>\n\n## Logistic Regression | Day 5\nMoving forward into #100DaysOfMLCode today I dived into the deeper depth of what Logistic Regression actually is and what is the math involved behind it. Learned how cost function is calculated and then how to apply gradient descent algorithm to cost function to minimize the error in prediction.  \nDue to less time I will now be posting an infographic on alternate days.\nAlso if someone wants to help me out in documentaion of code and already has some experince in the field and knows Markdown for github please contact me on LinkedIn :) .\n\n## Implementing Logistic Regression | Day 6\nCheck out the Code [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%206%20Logistic%20Regression.md)\n\n## K Nearest Neighbours | Day 7\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%207.jpg\">\n</p>\n\n## Math Behind Logistic Regression | Day 8 \n\n#100DaysOfMLCode To clear my insights on logistic regression I was searching on the internet for some resource or article and I came across this article (https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc) by Saishruthi Swaminathan. \n\nIt gives a detailed description of Logistic Regression. Do check it out.\n\n## Support Vector Machines | Day 9\nGot an intution on what SVM is and how it is used to solve Classification problem.\n\n## SVM and KNN | Day 10\nLearned more about how SVM works and implementing the K-NN algorithm.\n\n## Implementation of K-NN | Day 11  \n\nImplemented the K-NN algorithm for classification. #100DaysOfMLCode \nSupport Vector Machine Infographic is halfway complete. Will update it tomorrow.\n\n## Support Vector Machines | Day 12\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2012.jpg\">\n</p>\n\n## Naive Bayes Classifier | Day 13\n\nContinuing with #100DaysOfMLCode today I went through the Naive Bayes classifier.\nI am also implementing the SVM in python using scikit-learn. Will update the code soon.\n\n## Implementation of SVM | Day 14\nToday I implemented SVM on linearly related data. Used Scikit-Learn library. In Scikit-Learn we have SVC classifier which we use to achieve this task. Will be using kernel-trick on next implementation.\nCheck the code [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2013%20SVM.md).\n\n## Naive Bayes Classifier and Black Box Machine Learning | Day 15\nLearned about different types of naive bayes classifiers. Also started the lectures by [Bloomberg](https://bloomberg.github.io/foml/#home). First one in the playlist was Black Box Machine Learning. It gives the whole overview about prediction functions, feature extraction, learning algorithms, performance evaluation, cross-validation, sample bias, nonstationarity, overfitting, and hyperparameter tuning.\n\n## Implemented SVM using Kernel Trick | Day 16\nUsing Scikit-Learn library implemented SVM algorithm along with kernel function which maps our data points into higher dimension to find optimal hyperplane. \n\n## Started Deep learning Specialization on Coursera | Day 17\nCompleted the whole Week 1 and Week 2 on a single day. Learned Logistic regression as Neural Network. \n\n## Deep learning Specialization on Coursera | Day 18\nCompleted the Course 1 of the deep learning specialization. Implemented a neural net in python.\n\n## The Learning Problem , Professor Yaser Abu-Mostafa | Day 19\nStarted Lecture 1 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. It was basically an introduction to the upcoming lectures. He also explained Perceptron Algorithm.\n\n## Started Deep learning Specialization Course 2 | Day 20\nCompleted the Week 1 of Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.\n\n## Web Scraping | Day 21\nWatched some tutorials on how to do web scraping using Beautiful Soup in order to collect data for building a model.\n\n## Is Learning Feasible? | Day 22\nLecture 2 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. Learned about Hoeffding Inequality.\n\n## Decision Trees | Day 23\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2023.jpg\">\n</p>\n\n## Introduction To Statistical Learning Theory | Day 24\nLec 3 of Bloomberg ML course introduced some of the core concepts like input space, action space, outcome space, prediction functions, loss functions, and hypothesis spaces.\n\n## Implementing Decision Trees | Day 25\nCheck the code [here.](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2025%20Decision%20Tree.md)\n\n## Jumped To Brush up Linear Algebra | Day 26\nFound an amazing [channel](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) on youtube 3Blue1Brown. It has a playlist called Essence of Linear Algebra. Started off by completing 4 videos which gave a complete overview of Vectors, Linear Combinations, Spans, Basis Vectors, Linear Transformations and Matrix Multiplication. \n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n## Jumped To Brush up Linear Algebra | Day 27\nContinuing with the playlist completed next 4 videos discussing topics 3D Transformations, Determinants, Inverse Matrix, Column Space, Null Space and Non-Square Matrices.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n## Jumped To Brush up Linear Algebra | Day 28\nIn the playlist of 3Blue1Brown completed another 3 videos from the essence of linear algebra. \nTopics covered were Dot Product and Cross Product.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n\n## Jumped To Brush up Linear Algebra | Day 29\nCompleted the whole playlist today, videos 12-14. Really an amazing playlist to refresh the concepts of Linear Algebra.\nTopics covered were the change of basis, Eigenvectors and Eigenvalues, and Abstract Vector Spaces.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n## Essence of calculus | Day 30\nCompleting the playlist - Essence of Linear Algebra by 3blue1brown a suggestion popped up by youtube regarding a series of videos again by the same channel 3Blue1Brown. Being already impressed by the previous series on Linear algebra I dived straight into it.\nCompleted about 5 videos on topics such as Derivatives, Chain Rule, Product Rule, and derivative of exponential.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)\n\n## Essence of calculus | Day 31\nWatched 2 Videos on topic Implicit Diffrentiation and Limits from the playlist Essence of Calculus.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)\n\n## Essence of calculus | Day 32\nWatched the remaining 4 videos covering topics Like Integration and Higher order derivatives.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)\n\n## Random Forests | Day 33\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2033.jpg\">\n</p>\n\n## Implementing Random Forests | Day 34\nCheck the code [here.](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2034%20Random_Forest.md)\n\n## But what *is* a Neural Network? | Deep learning, chapter 1  | Day 35\nAn Amazing Video on neural networks by 3Blue1Brown youtube channel. This video gives a good understanding of Neural Networks and uses Handwritten digit dataset to explain the concept. \nLink To the [video.](https://www.youtube.com/watch?v=aircAruvnKk&t=7s)\n\n## Gradient descent, how neural networks learn | Deep learning, chapter 2 | Day 36\nPart two of neural networks by 3Blue1Brown youtube channel. This video explains the concepts of Gradient Descent in an interesting way. 169 must watch and highly recommended.\nLink To the [video.](https://www.youtube.com/watch?v=IHZwWFHWa-w)\n\n## What is backpropagation really doing? | Deep learning, chapter 3 | Day 37\nPart three of neural networks by 3Blue1Brown youtube channel. This video mostly discusses the partial derivatives and backpropagation.\nLink To the [video.](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n\n## Backpropagation calculus | Deep learning, chapter 4 | Day 38\nPart four of neural networks by 3Blue1Brown youtube channel. The goal here is to represent, in somewhat more formal terms, the intuition for how backpropagation works and the video moslty discusses the partial derivatives and backpropagation.\nLink To the [video.](https://www.youtube.com/watch?v=tIeHLnjs5U8)\n\n## Deep Learning with Python, TensorFlow, and Keras tutorial | Day 39\nLink To the [video.](https://www.youtube.com/watch?v=wQ8BIBpya2k&t=19s&index=2&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN)\n\n## Loading in your own data - Deep Learning basics with Python, TensorFlow and Keras p.2 | Day 40\nLink To the [video.](https://www.youtube.com/watch?v=j-3vuBynnOE&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=2)\n\n## Convolutional Neural Networks - Deep Learning basics with Python, TensorFlow and Keras p.3 | Day 41\nLink To the [video.](https://www.youtube.com/watch?v=WvoLTXIjBYU&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=3)\n\n## Analyzing Models with TensorBoard - Deep Learning with Python, TensorFlow and Keras p.4 | Day 42\nLink To the [video.](https://www.youtube.com/watch?v=BqgTU7_cBnk&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=4)\n\n## K Means Clustering | Day 43\nMoved to Unsupervised Learning and studied about Clustering.\nWorking on my website check it out [avikjain.me](http://www.avikjain.me/)\nAlso found a wonderful animation that can help to easily understand K - Means Clustering [Link](http://shabal.in/visuals/kmeans/6.html)\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2043.jpg\">\n</p>\n\n## K Means Clustering Implementation | Day 44\nImplemented K Means Clustering. Check the code [here.]()\n\n## Digging Deeper | NUMPY  | Day 45\nGot a new book \"Python Data Science HandBook\" by JK VanderPlas Check the Jupyter notebooks [here.](https://github.com/jakevdp/PythonDataScienceHandbook)\n<br>Started with chapter 2 : Introduction to Numpy. Covered topics like Data Types, Numpy arrays and Computations on Numpy arrays.\n<br>Check the code - \n<br>[Introduction to NumPy](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.00-Introduction-to-NumPy.ipynb)\n<br>[Understanding Data Types in Python](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.01-Understanding-Data-Types.ipynb)\n<br>[The Basics of NumPy Arrays](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.02-The-Basics-Of-NumPy-Arrays.ipynb)\n<br>[Computation on NumPy Arrays: Universal Functions](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.03-Computation-on-arrays-ufuncs.ipynb)\n\n## Digging Deeper | NUMPY | Day 46\nChapter 2 : Aggregations, Comparisions and Broadcasting\n<br>Link to Notebook:\n<br>[Aggregations: Min, Max, and Everything In Between](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.04-Computation-on-arrays-aggregates.ipynb)\n<br>[Computation on Arrays: Broadcasting](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.05-Computation-on-arrays-broadcasting.ipynb)\n<br>[Comparisons, Masks, and Boolean Logic](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.06-Boolean-Arrays-and-Masks.ipynb)\n\n## Digging Deeper | NUMPY | Day 47\nChapter 2 : Fancy Indexing, sorting arrays, Struchered Data\n<br>Link to Notebook:\n<br>[Fancy Indexing](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.07-Fancy-Indexing.ipynb)\n<br>[Sorting Arrays](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.08-Sorting.ipynb)\n<br>[Structured Data: NumPy's Structured Arrays](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.09-<br>Structured-Data-NumPy.ipynb)\n\n## Digging Deeper | PANDAS | Day 48\nChapter 3 : Data Manipulation with Pandas\n<br> Covered Various topics like Pandas Objects, Data Indexing and Selection, Operating on Data, Handling Missing Data, Hierarchical Indexing, ConCat and Append.\n<br>Link To the Notebooks:\n<br>[Data Manipulation with Pandas](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.00-Introduction-to-Pandas.ipynb)\n<br>[Introducing Pandas Objects](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.01-Introducing-Pandas-Objects.ipynb)\n<br>[Data Indexing and Selection](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.02-Data-Indexing-and-Selection.ipynb)\n<br>[Operating on Data in Pandas](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.03-Operations-in-Pandas.ipynb)\n<br>[Handling Missing Data](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.04-Missing-Values.ipynb)\n<br>[Hierarchical Indexing](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.05-Hierarchical-Indexing.ipynb)\n<br>[Combining Datasets: Concat and Append](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.06-Concat-And-Append.ipynb)\n\n## Digging Deeper | PANDAS | Day 49\nChapter 3: Completed following topics- Merge and Join, Aggregation and grouping and Pivot Tables.\n<br>[Combining Datasets: Merge and Join](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb)\n<br>[Aggregation and Grouping](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb)\n<br>[Pivot Tables](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.09-Pivot-Tables.ipynb)\n\n## Digging Deeper | PANDAS | Day 50\nChapter 3: Vectorized Strings Operations, Working with Time Series\n<br>Links to Notebooks:\n<br>[Vectorized String Operations](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.10-Working-With-Strings.ipynb)\n<br>[Working with Time Series](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.11-Working-with-Time-Series.ipynb)\n<br>[High-Performance Pandas: eval() and query()](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.12-Performance-Eval-and-Query.ipynb)\n\n## Digging Deeper | MATPLOTLIB | Day 51\nChapter 4: Visualization with Matplotlib \nLearned about Simple Line Plots, Simple Scatter Plotsand Density and Contour Plots.\n<br>Links to Notebooks: \n<br>[Visualization with Matplotlib](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.00-Introduction-To-Matplotlib.ipynb)\n<br>[Simple Line Plots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.01-Simple-Line-Plots.ipynb)\n<br>[Simple Scatter Plots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.02-Simple-Scatter-Plots.ipynb)\n<br>[Visualizing Errors](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.03-Errorbars.ipynb)\n<br>[Density and Contour Plots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.04-Density-and-Contour-Plots.ipynb)\n\n## Digging Deeper | MATPLOTLIB | Day 52\nChapter 4: Visualization with Matplotlib \nLearned about Histograms, How to customize plot legends, colorbars, and buliding Multiple Subplots.\n<br>Links to Notebooks: \n<br>[Histograms, Binnings, and Density](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.05-Histograms-and-Binnings.ipynb)\n<br>[Customizing Plot Legends](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.06-Customizing-Legends.ipynb)\n<br>[Customizing Colorbars](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.07-Customizing-Colorbars.ipynb)\n<br>[Multiple Subplots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.08-Multiple-Subplots.ipynb)\n<br>[Text and Annotation](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.09-Text-and-Annotation.ipynb)\n\n## Digging Deeper | MATPLOTLIB | Day 53\nChapter 4: Covered Three Dimensional Plotting in Mathplotlib.\n<br>Links to Notebooks:\n<br>[Three-Dimensional Plotting in Matplotlib](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.12-Three-Dimensional-Plotting.ipynb)\n\n## Hierarchical Clustering | Day 54\nStudied about Hierarchical Clustering.\nCheck out this amazing [Visualization.](https://cdn-images-1.medium.com/max/800/1*ET8kCcPpr893vNZFs8j4xg.gif)\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2054.jpg\">\n</p>\n"}, {"repo": "certbot/certbot", "language": "Python", "readme_contents": "certbot/README.rst"}, {"repo": "isocpp/CppCoreGuidelines", "language": "Python", "readme_contents": "[![C++ Core Guidelines](cpp_core_guidelines_logo_text.png)](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines)\n\n>\"Within C++ is a smaller, simpler, safer language struggling to get out.\"\n>-- <cite>Bjarne Stroustrup</cite>\n\nThe [C++ Core Guidelines](CppCoreGuidelines.md) are a collaborative effort led by Bjarne Stroustrup, much like the C++ language itself. They are the result of many\nperson-years of discussion and design across a number of organizations. Their design encourages general applicability and broad adoption but\nthey can be freely copied and modified to meet your organization's needs.\n\n## Getting started\n\nThe guidelines themselves are found at [CppCoreGuidelines](CppCoreGuidelines.md). The document is in [GH-flavored MarkDown](https://github.github.com/gfm/). It is intentionally kept simple, mostly in ASCII, to allow automatic post-processing such as language translation and reformatting. The editors maintain one\n[version formatted for browsing](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines). Note that it is manually integrated and can be slightly older than the version in the master branch.\n\nThe Guidelines are a constantly evolving document without a strict \"release\" cadence. Bjarne Stroustrup periodically reviews the document and increments the version number in the introduction. [Checkins that increment the version number](https://github.com/isocpp/CppCoreGuidelines/releases) are tagged in git. \n\nMany of the guidelines make use of the header-only Guidelines Support Library. One implementation is available at [GSL: Guidelines Support Library](https://github.com/Microsoft/GSL).\n\n## Background and scope\n\nThe aim of the guidelines is to help people to use modern C++ effectively. By \"modern C++\" we mean C++11, C++14, and C++17. In other\nwords, what would you like your code to look like in 5 years' time, given that you can start now? In 10 years' time?\n\nThe guidelines are focused on relatively higher-level issues, such as interfaces, resource management, memory management, and concurrency. Such\nrules affect application architecture and library design. Following the rules will lead to code that is statically type-safe, has no resource\nleaks, and catches many more programming logic errors than is common in code today. And it will run fast -- you can afford to do things right.\n\nWe are less concerned with low-level issues, such as naming conventions and indentation style. However, no topic that can help a programmer is\nout of bounds.\n\nOur initial set of rules emphasizes safety (of various forms) and simplicity. They may very well be too strict. We expect to have to introduce\nmore exceptions to better accommodate real-world needs. We also need more rules.\n\nYou will find some of the rules contrary to your expectations or even contrary to your experience. If we haven't suggested that you change your\ncoding style in any way, we have failed! Please try to verify or disprove rules! In particular, we'd really like to have some of our rules\nbacked up with measurements or better examples.\n\nYou will find some of the rules obvious or even trivial. Please remember that one purpose of a guideline is to help someone who is less\nexperienced or coming from a different background or language to get up to speed.\n\nThe rules are designed to be supported by an analysis tool. Violations of rules will be flagged with references (or links) to the relevant rule.\nWe do not expect you to memorize all the rules before trying to write code.\n\nThe rules are meant for gradual introduction into a code base. We plan to build tools for that and hope others will too.\n\n## Contributions and LICENSE\n\nComments and suggestions for improvements are most welcome. We plan to modify and extend this document as our understanding improves and the\nlanguage and the set of available libraries improve. More details are found at [CONTRIBUTING](./CONTRIBUTING.md) and [LICENSE](./LICENSE).\n\nThanks to [DigitalOcean](https://www.digitalocean.com/?refcode=32f291566cf7&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste) for hosting the Standard C++ Foundation website.\n"}, {"repo": "floodsung/Deep-Learning-Papers-Reading-Roadmap", "language": "Python", "readme_contents": "# Deep Learning Papers Reading Roadmap\n\n>If you are a newcomer to the Deep Learning area, the first question you may have is \"Which paper should I start reading from?\"\n\n>Here is a reading roadmap of Deep Learning papers!\n\nThe roadmap is constructed in accordance with the following four guidelines:\n\n- From outline to detail\n- From old to state-of-the-art\n- from generic to specific areas\n- focus on state-of-the-art\n\nYou will find many papers that are quite new but really worth reading.\n\nI would continue adding papers to this roadmap.\n\n\n---------------------------------------\n\n# 1 Deep Learning History and Basics\n\n## 1.0 Book\n\n**[0]** Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \"**Deep learning**.\" An MIT Press book. (2015). [[html]](http://www.deeplearningbook.org/) **(Deep Learning Bible, you can read this book while reading following papers.)** :star::star::star::star::star:\n\n## 1.1 Survey\n\n**[1]** LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \"**Deep learning**.\" Nature 521.7553 (2015): 436-444. [[pdf]](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf) **(Three Giants' Survey)** :star::star::star::star::star:\n\n## 1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)\n\n**[2]** Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \"**A fast learning algorithm for deep belief nets**.\" Neural computation 18.7 (2006): 1527-1554. [[pdf]](http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf)**(Deep Learning Eve)** :star::star::star:\n\n**[3]** Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \"**Reducing the dimensionality of data with neural networks**.\" Science 313.5786 (2006): 504-507. [[pdf]](http://www.cs.toronto.edu/~hinton/science.pdf) **(Milestone, Show the promise of deep learning)** :star::star::star:\n\n## 1.3 ImageNet Evolution\uff08Deep Learning broke out from here\uff09\n\n**[4]** Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"**Imagenet classification with deep convolutional neural networks**.\" Advances in neural information processing systems. 2012. [[pdf]](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) **(AlexNet, Deep Learning Breakthrough)** :star::star::star::star::star:\n\n**[5]** Simonyan, Karen, and Andrew Zisserman. \"**Very deep convolutional networks for large-scale image recognition**.\" arXiv preprint arXiv:1409.1556 (2014). [[pdf]](https://arxiv.org/pdf/1409.1556.pdf) **(VGGNet,Neural Networks become very deep!)** :star::star::star:\n\n**[6]** Szegedy, Christian, et al. \"**Going deeper with convolutions**.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf) **(GoogLeNet)** :star::star::star:\n\n**[7]** He, Kaiming, et al. \"**Deep residual learning for image recognition**.\" arXiv preprint arXiv:1512.03385 (2015). [[pdf]](https://arxiv.org/pdf/1512.03385.pdf) **(ResNet,Very very deep networks, CVPR best paper)** :star::star::star::star::star:\n\n## 1.4 Speech Recognition Evolution\n\n**[8]** Hinton, Geoffrey, et al. \"**Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups**.\" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [[pdf]](http://cs224d.stanford.edu/papers/maas_paper.pdf) **(Breakthrough in speech recognition)**:star::star::star::star:\n\n**[9]** Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \"**Speech recognition with deep recurrent neural networks**.\" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [[pdf]](http://arxiv.org/pdf/1303.5778.pdf) **(RNN)**:star::star::star:\n\n**[10]** Graves, Alex, and Navdeep Jaitly. \"**Towards End-To-End Speech Recognition with Recurrent Neural Networks**.\" ICML. Vol. 14. 2014. [[pdf]](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf):star::star::star:\n\n**[11]** Sak, Ha\u015fim, et al. \"**Fast and accurate recurrent neural network acoustic models for speech recognition**.\" arXiv preprint arXiv:1507.06947 (2015). [[pdf]](http://arxiv.org/pdf/1507.06947) **(Google Speech Recognition System)** :star::star::star:\n\n**[12]** Amodei, Dario, et al. \"**Deep speech 2: End-to-end speech recognition in english and mandarin**.\" arXiv preprint arXiv:1512.02595 (2015). [[pdf]](https://arxiv.org/pdf/1512.02595.pdf) **(Baidu Speech Recognition System)** :star::star::star::star:\n\n**[13]** W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \"**Achieving Human Parity in Conversational Speech Recognition**.\" arXiv preprint arXiv:1610.05256 (2016). [[pdf]](https://arxiv.org/pdf/1610.05256v1) **(State-of-the-art in speech recognition, Microsoft)** :star::star::star::star:\n\n>After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.\n\n#2 Deep Learning Method\n\n## 2.1 Model\n\n**[14]** Hinton, Geoffrey E., et al. \"**Improving neural networks by preventing co-adaptation of feature detectors**.\" arXiv preprint arXiv:1207.0580 (2012). [[pdf]](https://arxiv.org/pdf/1207.0580.pdf) **(Dropout)** :star::star::star:\n\n**[15]** Srivastava, Nitish, et al. \"**Dropout: a simple way to prevent neural networks from overfitting**.\" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [[pdf]](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) :star::star::star:\n\n**[16]** Ioffe, Sergey, and Christian Szegedy. \"**Batch normalization: Accelerating deep network training by reducing internal covariate shift**.\" arXiv preprint arXiv:1502.03167 (2015). [[pdf]](http://arxiv.org/pdf/1502.03167) **(An outstanding Work in 2015)** :star::star::star::star:\n\n**[17]** Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"**Layer normalization**.\" arXiv preprint arXiv:1607.06450 (2016). [[pdf]](https://arxiv.org/pdf/1607.06450.pdf?utm_source=sciontist.com&utm_medium=refer&utm_campaign=promote) **(Update of Batch Normalization)** :star::star::star::star:\n\n**[18]** Courbariaux, Matthieu, et al. \"**Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or\u22121**.\" [[pdf]](https://pdfs.semanticscholar.org/f832/b16cb367802609d91d400085eb87d630212a.pdf) **(New Model,Fast)**  :star::star::star:\n\n**[19]** Jaderberg, Max, et al. \"**Decoupled neural interfaces using synthetic gradients**.\" arXiv preprint arXiv:1608.05343 (2016). [[pdf]](https://arxiv.org/pdf/1608.05343) **(Innovation of Training Method,Amazing Work)** :star::star::star::star::star:\n\n**[20]** Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \"Net2net: Accelerating learning via knowledge transfer.\" arXiv preprint arXiv:1511.05641 (2015). [[pdf]](https://arxiv.org/abs/1511.05641) **(Modify previously trained network to reduce training epochs)** :star::star::star:\n\n**[21]** Wei, Tao, et al. \"Network Morphism.\" arXiv preprint arXiv:1603.01670 (2016). [[pdf]](https://arxiv.org/abs/1603.01670) **(Modify previously trained network to reduce training epochs)** :star::star::star:\n\n## 2.2 Optimization\n\n**[22]** Sutskever, Ilya, et al. \"**On the importance of initialization and momentum in deep learning**.\" ICML (3) 28 (2013): 1139-1147. [[pdf]](http://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf) **(Momentum optimizer)** :star::star:\n\n**[23]** Kingma, Diederik, and Jimmy Ba. \"**Adam: A method for stochastic optimization**.\" arXiv preprint arXiv:1412.6980 (2014). [[pdf]](http://arxiv.org/pdf/1412.6980) **(Maybe used most often currently)** :star::star::star:\n\n**[24]** Andrychowicz, Marcin, et al. \"**Learning to learn by gradient descent by gradient descent**.\" arXiv preprint arXiv:1606.04474 (2016). [[pdf]](https://arxiv.org/pdf/1606.04474) **(Neural Optimizer,Amazing Work)** :star::star::star::star::star:\n\n**[25]** Han, Song, Huizi Mao, and William J. Dally. \"**Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding**.\" CoRR, abs/1510.00149 2 (2015). [[pdf]](https://pdfs.semanticscholar.org/5b6c/9dda1d88095fa4aac1507348e498a1f2e863.pdf) **(ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup)** :star::star::star::star::star:\n\n**[26]** Iandola, Forrest N., et al. \"**SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size**.\" arXiv preprint arXiv:1602.07360 (2016). [[pdf]](http://arxiv.org/pdf/1602.07360) **(Also a new direction to optimize NN,DeePhi Tech Startup)** :star::star::star::star:\n\n## 2.3 Unsupervised Learning / Deep Generative Model\n\n**[27]** Le, Quoc V. \"**Building high-level features using large scale unsupervised learning**.\" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [[pdf]](http://arxiv.org/pdf/1112.6209.pdf&embed) **(Milestone, Andrew Ng, Google Brain Project, Cat)** :star::star::star::star:\n\n\n**[28]** Kingma, Diederik P., and Max Welling. \"**Auto-encoding variational bayes**.\" arXiv preprint arXiv:1312.6114 (2013). [[pdf]](http://arxiv.org/pdf/1312.6114) **(VAE)** :star::star::star::star:\n\n**[29]** Goodfellow, Ian, et al. \"**Generative adversarial nets**.\" Advances in Neural Information Processing Systems. 2014. [[pdf]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) **(GAN,super cool idea)** :star::star::star::star::star:\n\n**[30]** Radford, Alec, Luke Metz, and Soumith Chintala. \"**Unsupervised representation learning with deep convolutional generative adversarial networks**.\" arXiv preprint arXiv:1511.06434 (2015). [[pdf]](http://arxiv.org/pdf/1511.06434) **(DCGAN)** :star::star::star::star:\n\n**[31]** Gregor, Karol, et al. \"**DRAW: A recurrent neural network for image generation**.\" arXiv preprint arXiv:1502.04623 (2015). [[pdf]](http://jmlr.org/proceedings/papers/v37/gregor15.pdf) **(VAE with attention, outstanding work)** :star::star::star::star::star:\n\n**[32]** Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \"**Pixel recurrent neural networks**.\" arXiv preprint arXiv:1601.06759 (2016). [[pdf]](http://arxiv.org/pdf/1601.06759) **(PixelRNN)** :star::star::star::star:\n\n**[33]** Oord, Aaron van den, et al. \"Conditional image generation with PixelCNN decoders.\" arXiv preprint arXiv:1606.05328 (2016). [[pdf]](https://arxiv.org/pdf/1606.05328) **(PixelCNN)** :star::star::star::star:\n\n## 2.4 RNN / Sequence-to-Sequence Model\n\n**[34]** Graves, Alex. \"**Generating sequences with recurrent neural networks**.\" arXiv preprint arXiv:1308.0850 (2013). [[pdf]](http://arxiv.org/pdf/1308.0850) **(LSTM, very nice generating result, show the power of RNN)** :star::star::star::star:\n\n**[35]** Cho, Kyunghyun, et al. \"**Learning phrase representations using RNN encoder-decoder for statistical machine translation**.\" arXiv preprint arXiv:1406.1078 (2014). [[pdf]](http://arxiv.org/pdf/1406.1078) **(First Seq-to-Seq Paper)** :star::star::star::star:\n\n**[36]** Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"**Sequence to sequence learning with neural networks**.\" Advances in neural information processing systems. 2014. [[pdf]](https://arxiv.org/pdf/1409.3215.pdf) **(Outstanding Work)** :star::star::star::star::star:\n\n**[37]** Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \"**Neural Machine Translation by Jointly Learning to Align and Translate**.\" arXiv preprint arXiv:1409.0473 (2014). [[pdf]](https://arxiv.org/pdf/1409.0473v7.pdf) :star::star::star::star:\n\n**[38]** Vinyals, Oriol, and Quoc Le. \"**A neural conversational model**.\" arXiv preprint arXiv:1506.05869 (2015). [[pdf]](http://arxiv.org/pdf/1506.05869.pdf%20(http://arxiv.org/pdf/1506.05869.pdf)) **(Seq-to-Seq on Chatbot)** :star::star::star:\n\n## 2.5 Neural Turing Machine\n\n**[39]** Graves, Alex, Greg Wayne, and Ivo Danihelka. \"**Neural turing machines**.\" arXiv preprint arXiv:1410.5401 (2014). [[pdf]](http://arxiv.org/pdf/1410.5401.pdf) **(Basic Prototype of Future Computer)** :star::star::star::star::star:\n\n**[40]** Zaremba, Wojciech, and Ilya Sutskever. \"**Reinforcement learning neural Turing machines**.\" arXiv preprint arXiv:1505.00521 362 (2015). [[pdf]](https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf) :star::star::star:\n\n**[41]** Weston, Jason, Sumit Chopra, and Antoine Bordes. \"**Memory networks**.\" arXiv preprint arXiv:1410.3916 (2014). [[pdf]](http://arxiv.org/pdf/1410.3916) :star::star::star:\n\n\n**[42]** Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \"**End-to-end memory networks**.\" Advances in neural information processing systems. 2015. [[pdf]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf) :star::star::star::star:\n\n**[43]** Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \"**Pointer networks**.\" Advances in Neural Information Processing Systems. 2015. [[pdf]](http://papers.nips.cc/paper/5866-pointer-networks.pdf) :star::star::star::star:\n\n**[44]** Graves, Alex, et al. \"**Hybrid computing using a neural network with dynamic external memory**.\" Nature (2016). [[pdf]](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf) **(Milestone,combine above papers' ideas)** :star::star::star::star::star:\n\n## 2.6 Deep Reinforcement Learning\n\n**[45]** Mnih, Volodymyr, et al. \"**Playing atari with deep reinforcement learning**.\" arXiv preprint arXiv:1312.5602 (2013). [[pdf]](http://arxiv.org/pdf/1312.5602.pdf)) **(First Paper named deep reinforcement learning)** :star::star::star::star:\n\n**[46]** Mnih, Volodymyr, et al. \"**Human-level control through deep reinforcement learning**.\" Nature 518.7540 (2015): 529-533. [[pdf]](https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf) **(Milestone)** :star::star::star::star::star:\n\n**[47]** Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \"**Dueling network architectures for deep reinforcement learning**.\" arXiv preprint arXiv:1511.06581 (2015). [[pdf]](http://arxiv.org/pdf/1511.06581) **(ICLR best paper,great idea)**  :star::star::star::star:\n\n**[48]** Mnih, Volodymyr, et al. \"**Asynchronous methods for deep reinforcement learning**.\" arXiv preprint arXiv:1602.01783 (2016). [[pdf]](http://arxiv.org/pdf/1602.01783) **(State-of-the-art method)** :star::star::star::star::star:\n\n**[49]** Lillicrap, Timothy P., et al. \"**Continuous control with deep reinforcement learning**.\" arXiv preprint arXiv:1509.02971 (2015). [[pdf]](http://arxiv.org/pdf/1509.02971) **(DDPG)** :star::star::star::star:\n\n**[50]** Gu, Shixiang, et al. \"**Continuous Deep Q-Learning with Model-based Acceleration**.\" arXiv preprint arXiv:1603.00748 (2016). [[pdf]](http://arxiv.org/pdf/1603.00748) **(NAF)** :star::star::star::star:\n\n**[51]** Schulman, John, et al. \"**Trust region policy optimization**.\" CoRR, abs/1502.05477 (2015). [[pdf]](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf) **(TRPO)** :star::star::star::star:\n\n**[52]** Silver, David, et al. \"**Mastering the game of Go with deep neural networks and tree search**.\" Nature 529.7587 (2016): 484-489. [[pdf]](http://willamette.edu/~levenick/cs448/goNature.pdf) **(AlphaGo)** :star::star::star::star::star:\n\n## 2.7 Deep Transfer Learning / Lifelong Learning / especially for RL\n\n**[53]** Bengio, Yoshua. \"**Deep Learning of Representations for Unsupervised and Transfer Learning**.\" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [[pdf]](http://www.jmlr.org/proceedings/papers/v27/bengio12a/bengio12a.pdf) **(A Tutorial)** :star::star::star:\n\n**[54]** Silver, Daniel L., Qiang Yang, and Lianghao Li. \"**Lifelong Machine Learning Systems: Beyond Learning Algorithms**.\" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.7800&rep=rep1&type=pdf) **(A brief discussion about lifelong learning)**  :star::star::star:\n\n**[55]** Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \"**Distilling the knowledge in a neural network**.\" arXiv preprint arXiv:1503.02531 (2015). [[pdf]](http://arxiv.org/pdf/1503.02531) **(Godfather's Work)** :star::star::star::star:\n\n**[56]** Rusu, Andrei A., et al. \"**Policy distillation**.\" arXiv preprint arXiv:1511.06295 (2015). [[pdf]](http://arxiv.org/pdf/1511.06295) **(RL domain)** :star::star::star:\n\n**[57]** Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \"**Actor-mimic: Deep multitask and transfer reinforcement learning**.\" arXiv preprint arXiv:1511.06342 (2015). [[pdf]](http://arxiv.org/pdf/1511.06342) **(RL domain)** :star::star::star:\n\n**[58]** Rusu, Andrei A., et al. \"**Progressive neural networks**.\" arXiv preprint arXiv:1606.04671 (2016). [[pdf]](https://arxiv.org/pdf/1606.04671) **(Outstanding Work, A novel idea)** :star::star::star::star::star:\n\n\n## 2.8 One Shot Deep Learning\n\n**[59]** Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \"**Human-level concept learning through probabilistic program induction**.\" Science 350.6266 (2015): 1332-1338. [[pdf]](http://clm.utexas.edu/compjclub/wp-content/uploads/2016/02/lake2015.pdf) **(No Deep Learning,but worth reading)** :star::star::star::star::star:\n\n**[60]** Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \"**Siamese Neural Networks for One-shot Image Recognition**.\"(2015) [[pdf]](http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf) :star::star::star:\n\n**[61]** Santoro, Adam, et al. \"**One-shot Learning with Memory-Augmented Neural Networks**.\" arXiv preprint arXiv:1605.06065 (2016). [[pdf]](http://arxiv.org/pdf/1605.06065) **(A basic step to one shot learning)** :star::star::star::star:\n\n**[62]** Vinyals, Oriol, et al. \"**Matching Networks for One Shot Learning**.\" arXiv preprint arXiv:1606.04080 (2016). [[pdf]](https://arxiv.org/pdf/1606.04080) :star::star::star:\n\n**[63]** Hariharan, Bharath, and Ross Girshick. \"**Low-shot visual object recognition**.\" arXiv preprint arXiv:1606.02819 (2016). [[pdf]](http://arxiv.org/pdf/1606.02819) **(A step to large data)** :star::star::star::star:\n\n\n# 3 Applications\n\n## 3.1 NLP(Natural Language Processing)\n\n**[1]** Antoine Bordes, et al. \"**Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing**.\" AISTATS(2012) [[pdf]](https://www.hds.utc.fr/~bordesan/dokuwiki/lib/exe/fetch.php?id=en%3Apubli&cache=cache&media=en:bordes12aistats.pdf) :star::star::star::star:\n\n**[2]** Mikolov, et al. \"**Distributed representations of words and phrases and their compositionality**.\" ANIPS(2013): 3111-3119 [[pdf]](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) **(word2vec)** :star::star::star:\n\n**[3]** Sutskever, et al. \"**\u201cSequence to sequence learning with neural networks**.\" ANIPS(2014) [[pdf]](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) :star::star::star:\n\n**[4]** Ankit Kumar, et al. \"**\u201cAsk Me Anything: Dynamic Memory Networks for Natural Language Processing**.\" arXiv preprint arXiv:1506.07285(2015) [[pdf]](https://arxiv.org/abs/1506.07285) :star::star::star::star:\n\n**[5]** Yoon Kim, et al. \"**Character-Aware Neural Language Models**.\" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [[pdf]](https://arxiv.org/abs/1508.06615) :star::star::star::star:\n\n**[6]** Jason Weston, et al. \"**Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks**.\" arXiv preprint arXiv:1502.05698(2015) [[pdf]](https://arxiv.org/abs/1502.05698) **(bAbI tasks)** :star::star::star:\n\n**[7]** Karl Moritz Hermann, et al. \"**Teaching Machines to Read and Comprehend**.\" arXiv preprint arXiv:1506.03340(2015) [[pdf]](https://arxiv.org/abs/1506.03340) **(CNN/DailyMail cloze style questions)** :star::star:\n\n**[8]** Alexis Conneau, et al. \"**Very Deep Convolutional Networks for Natural Language Processing**.\" arXiv preprint arXiv:1606.01781(2016) [[pdf]](https://arxiv.org/abs/1606.01781) **(state-of-the-art in text classification)** :star::star::star:\n\n**[9]** Armand Joulin, et al. \"**Bag of Tricks for Efficient Text Classification**.\" arXiv preprint arXiv:1607.01759(2016) [[pdf]](https://arxiv.org/abs/1607.01759) **(slightly worse than state-of-the-art, but a lot faster)** :star::star::star:\n\n## 3.2 Object Detection\n\n**[1]** Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \"**Deep neural networks for object detection**.\" Advances in Neural Information Processing Systems. 2013. [[pdf]](http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf) :star::star::star:\n\n**[2]** Girshick, Ross, et al. \"**Rich feature hierarchies for accurate object detection and semantic segmentation**.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf) **(RCNN)** :star::star::star::star::star:\n\n**[3]** He, Kaiming, et al. \"**Spatial pyramid pooling in deep convolutional networks for visual recognition**.\" European Conference on Computer Vision. Springer International Publishing, 2014. [[pdf]](http://arxiv.org/pdf/1406.4729) **(SPPNet)** :star::star::star::star:\n\n**[4]** Girshick, Ross. \"**Fast r-cnn**.\" Proceedings of the IEEE International Conference on Computer Vision. 2015. [[pdf]](https://pdfs.semanticscholar.org/8f67/64a59f0d17081f2a2a9d06f4ed1cdea1a0ad.pdf) :star::star::star::star:\n\n**[5]** Ren, Shaoqing, et al. \"**Faster R-CNN: Towards real-time object detection with region proposal networks**.\" Advances in neural information processing systems. 2015. [[pdf]](https://arxiv.org/pdf/1506.01497.pdf) :star::star::star::star:\n\n**[6]** Redmon, Joseph, et al. \"**You only look once: Unified, real-time object detection**.\" arXiv preprint arXiv:1506.02640 (2015). [[pdf]](http://homes.cs.washington.edu/~ali/papers/YOLO.pdf) **(YOLO,Oustanding Work, really practical)** :star::star::star::star::star:\n\n**[7]** Liu, Wei, et al. \"**SSD: Single Shot MultiBox Detector**.\" arXiv preprint arXiv:1512.02325 (2015). [[pdf]](http://arxiv.org/pdf/1512.02325) :star::star::star:\n\n**[8]** Dai, Jifeng, et al. \"**R-FCN: Object Detection via\nRegion-based Fully Convolutional Networks**.\" arXiv preprint arXiv:1605.06409 (2016). [[pdf]](https://arxiv.org/abs/1605.06409) :star::star::star::star:\n\n**[9]** He, Gkioxari, et al. \"**Mask R-CNN**\" arXiv preprint arXiv:1703.06870 (2017). [[pdf]](https://arxiv.org/abs/1703.06870) :star::star::star::star:\n## 3.3 Visual Tracking\n\n**[1]** Wang, Naiyan, and Dit-Yan Yeung. \"**Learning a deep compact image representation for visual tracking**.\" Advances in neural information processing systems. 2013. [[pdf]](http://papers.nips.cc/paper/5192-learning-a-deep-compact-image-representation-for-visual-tracking.pdf) **(First Paper to do visual tracking using Deep Learning,DLT Tracker)** :star::star::star:\n\n**[2]** Wang, Naiyan, et al. \"**Transferring rich feature hierarchies for robust visual tracking**.\" arXiv preprint arXiv:1501.04587 (2015). [[pdf]](http://arxiv.org/pdf/1501.04587) **(SO-DLT)** :star::star::star::star:\n\n**[3]** Wang, Lijun, et al. \"**Visual tracking with fully convolutional networks**.\" Proceedings of the IEEE International Conference on Computer Vision. 2015. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf) **(FCNT)** :star::star::star::star:\n\n**[4]** Held, David, Sebastian Thrun, and Silvio Savarese. \"**Learning to Track at 100 FPS with Deep Regression Networks**.\" arXiv preprint arXiv:1604.01802 (2016). [[pdf]](http://arxiv.org/pdf/1604.01802) **(GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods)** :star::star::star::star:\n\n**[5]** Bertinetto, Luca, et al. \"**Fully-Convolutional Siamese Networks for Object Tracking**.\" arXiv preprint arXiv:1606.09549 (2016). [[pdf]](https://arxiv.org/pdf/1606.09549) **(SiameseFC,New state-of-the-art for real-time object tracking)** :star::star::star::star:\n\n**[6]** Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \"**Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking**.\" ECCV (2016) [[pdf]](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf) **(C-COT)** :star::star::star::star:\n\n**[7]** Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \"**Modeling and Propagating CNNs in a Tree Structure for Visual Tracking**.\" arXiv preprint arXiv:1608.07242 (2016). [[pdf]](https://arxiv.org/pdf/1608.07242) **(VOT2016 Winner,TCNN)** :star::star::star::star:\n\n## 3.4 Image Caption\n**[1]** Farhadi,Ali,etal. \"**Every picture tells a story: Generating sentences from images**\". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [[pdf]](https://www.cs.cmu.edu/~afarhadi/papers/sentence.pdf) :star::star::star:\n\n**[2]** Kulkarni, Girish, et al. \"**Baby talk: Understanding and generating image descriptions**\". In Proceedings of the 24th CVPR, 2011. [[pdf]](http://tamaraberg.com/papers/generation_cvpr11.pdf):star::star::star::star:\n\n**[3]** Vinyals, Oriol, et al. \"**Show and tell: A neural image caption generator**\". In arXiv preprint arXiv:1411.4555, 2014. [[pdf]](https://arxiv.org/pdf/1411.4555.pdf):star::star::star:\n\n**[4]** Donahue, Jeff, et al. \"**Long-term recurrent convolutional networks for visual recognition and description**\". In arXiv preprint arXiv:1411.4389 ,2014. [[pdf]](https://arxiv.org/pdf/1411.4389.pdf)\n\n**[5]** Karpathy, Andrej, and Li Fei-Fei. \"**Deep visual-semantic alignments for generating image descriptions**\". In arXiv preprint arXiv:1412.2306, 2014. [[pdf]](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf):star::star::star::star::star:\n\n**[6]** Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \"**Deep fragment embeddings for bidirectional image sentence mapping**\". In Advances in neural information processing systems, 2014. [[pdf]](https://arxiv.org/pdf/1406.5679v1.pdf):star::star::star::star:\n\n**[7]** Fang, Hao, et al. \"**From captions to visual concepts and back**\". In arXiv preprint arXiv:1411.4952, 2014. [[pdf]](https://arxiv.org/pdf/1411.4952v3.pdf):star::star::star::star::star:\n\n**[8]** Chen, Xinlei, and C. Lawrence Zitnick. \"**Learning a recurrent visual representation for image caption generation**\". In arXiv preprint arXiv:1411.5654, 2014. [[pdf]](https://arxiv.org/pdf/1411.5654v1.pdf):star::star::star::star:\n\n**[9]** Mao, Junhua, et al. \"**Deep captioning with multimodal recurrent neural networks (m-rnn)**\". In arXiv preprint arXiv:1412.6632, 2014. [[pdf]](https://arxiv.org/pdf/1412.6632v5.pdf):star::star::star:\n\n**[10]** Xu, Kelvin, et al. \"**Show, attend and tell: Neural image caption generation with visual attention**\". In arXiv preprint arXiv:1502.03044, 2015. [[pdf]](https://arxiv.org/pdf/1502.03044v3.pdf):star::star::star::star::star:\n\n## 3.5 Machine Translation\n\n> Some milestone papers are listed in RNN / Seq-to-Seq topic.\n\n**[1]** Luong, Minh-Thang, et al. \"**Addressing the rare word problem in neural machine translation**.\" arXiv preprint arXiv:1410.8206 (2014). [[pdf]](http://arxiv.org/pdf/1410.8206) :star::star::star::star:\n\n\n**[2]** Sennrich, et al. \"**Neural Machine Translation of Rare Words with Subword Units**\". In arXiv preprint arXiv:1508.07909, 2015. [[pdf]](https://arxiv.org/pdf/1508.07909.pdf):star::star::star:\n\n**[3]** Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \"**Effective approaches to attention-based neural machine translation**.\" arXiv preprint arXiv:1508.04025 (2015). [[pdf]](http://arxiv.org/pdf/1508.04025) :star::star::star::star:\n\n**[4]** Chung, et al. \"**A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation**\". In arXiv preprint arXiv:1603.06147, 2016. [[pdf]](https://arxiv.org/pdf/1603.06147.pdf):star::star:\n\n**[5]** Lee, et al. \"**Fully Character-Level Neural Machine Translation without Explicit Segmentation**\". In arXiv preprint arXiv:1610.03017, 2016. [[pdf]](https://arxiv.org/pdf/1610.03017.pdf):star::star::star::star::star:\n\n**[6]** Wu, Schuster, Chen, Le, et al. \"**Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation**\". In arXiv preprint arXiv:1609.08144v2, 2016. [[pdf]](https://arxiv.org/pdf/1609.08144v2.pdf) **(Milestone)** :star::star::star::star:\n\n## 3.6 Robotics\n\n**[1]** Koutn\u00edk, Jan, et al. \"**Evolving large-scale neural networks for vision-based reinforcement learning**.\" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [[pdf]](http://repository.supsi.ch/4550/1/koutnik2013gecco.pdf) :star::star::star:\n\n**[2]** Levine, Sergey, et al. \"**End-to-end training of deep visuomotor policies**.\" Journal of Machine Learning Research 17.39 (2016): 1-40. [[pdf]](http://www.jmlr.org/papers/volume17/15-522/15-522.pdf) :star::star::star::star::star:\n\n**[3]** Pinto, Lerrel, and Abhinav Gupta. \"**Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours**.\" arXiv preprint arXiv:1509.06825 (2015). [[pdf]](http://arxiv.org/pdf/1509.06825) :star::star::star:\n\n**[4]** Levine, Sergey, et al. \"**Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection**.\" arXiv preprint arXiv:1603.02199 (2016). [[pdf]](http://arxiv.org/pdf/1603.02199) :star::star::star::star:\n\n**[5]** Zhu, Yuke, et al. \"**Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning**.\" arXiv preprint arXiv:1609.05143 (2016). [[pdf]](https://arxiv.org/pdf/1609.05143) :star::star::star::star:\n\n**[6]** Yahya, Ali, et al. \"**Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search**.\" arXiv preprint arXiv:1610.00673 (2016). [[pdf]](https://arxiv.org/pdf/1610.00673) :star::star::star::star:\n\n**[7]** Gu, Shixiang, et al. \"**Deep Reinforcement Learning for Robotic Manipulation**.\" arXiv preprint arXiv:1610.00633 (2016). [[pdf]](https://arxiv.org/pdf/1610.00633) :star::star::star::star:\n\n**[8]** A Rusu, M Vecerik, Thomas Roth\u00f6rl, N Heess, R Pascanu, R Hadsell.\"**Sim-to-Real Robot Learning from Pixels with Progressive Nets**.\" arXiv preprint arXiv:1610.04286 (2016). [[pdf]](https://arxiv.org/pdf/1610.04286.pdf) :star::star::star::star:\n\n**[9]** Mirowski, Piotr, et al. \"**Learning to navigate in complex environments**.\" arXiv preprint arXiv:1611.03673 (2016). [[pdf]](https://arxiv.org/pdf/1611.03673) :star::star::star::star:\n\n## 3.7 Art\n\n**[1]** Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \"**Inceptionism: Going Deeper into Neural Networks**\". Google Research. [[html]](https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) **(Deep Dream)**\n:star::star::star::star:\n\n**[2]** Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \"**A neural algorithm of artistic style**.\" arXiv preprint arXiv:1508.06576 (2015). [[pdf]](http://arxiv.org/pdf/1508.06576) **(Outstanding Work, most successful method currently)** :star::star::star::star::star:\n\n**[3]** Zhu, Jun-Yan, et al. \"**Generative Visual Manipulation on the Natural Image Manifold**.\" European Conference on Computer Vision. Springer International Publishing, 2016. [[pdf]](https://arxiv.org/pdf/1609.03552) **(iGAN)** :star::star::star::star:\n\n**[4]** Champandard, Alex J. \"**Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks**.\" arXiv preprint arXiv:1603.01768 (2016). [[pdf]](http://arxiv.org/pdf/1603.01768) **(Neural Doodle)** :star::star::star::star:\n\n**[5]** Zhang, Richard, Phillip Isola, and Alexei A. Efros. \"**Colorful Image Colorization**.\" arXiv preprint arXiv:1603.08511 (2016). [[pdf]](http://arxiv.org/pdf/1603.08511) :star::star::star::star:\n\n**[6]** Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \"**Perceptual losses for real-time style transfer and super-resolution**.\" arXiv preprint arXiv:1603.08155 (2016). [[pdf]](https://arxiv.org/pdf/1603.08155.pdf) :star::star::star::star:\n\n**[7]** Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \"**A learned representation for artistic style**.\" arXiv preprint arXiv:1610.07629 (2016). [[pdf]](https://arxiv.org/pdf/1610.07629v1.pdf) :star::star::star::star:\n\n**[8]** Gatys, Leon and Ecker, et al.\"**Controlling Perceptual Factors in Neural Style Transfer**.\" arXiv preprint arXiv:1611.07865 (2016). [[pdf]](https://arxiv.org/pdf/1611.07865.pdf) **(control style transfer over spatial location,colour information and across spatial scale)**:star::star::star::star:\n\n**[9]** Ulyanov, Dmitry and Lebedev, Vadim, et al. \"**Texture Networks: Feed-forward Synthesis of Textures and Stylized Images**.\" arXiv preprint arXiv:1603.03417(2016). [[pdf]](http://arxiv.org/abs/1603.03417) **(texture generation and style transfer)** :star::star::star::star:\n\n\n## 3.8 Object Segmentation\n\n**[1]** J. Long, E. Shelhamer, and T. Darrell, \u201c**Fully convolutional networks for semantic segmentation**.\u201d in CVPR, 2015. [[pdf]](https://arxiv.org/pdf/1411.4038v2.pdf) :star::star::star::star::star:\n\n**[2]** L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \"**Semantic image segmentation with deep convolutional nets and fully connected crfs**.\" In ICLR, 2015. [[pdf]](https://arxiv.org/pdf/1606.00915v1.pdf) :star::star::star::star::star:\n\n**[3]** Pinheiro, P.O., Collobert, R., Dollar, P. \"**Learning to segment object candidates.**\" In: NIPS. 2015. [[pdf]](https://arxiv.org/pdf/1506.06204v2.pdf) :star::star::star::star:\n\n**[4]** Dai, J., He, K., Sun, J. \"**Instance-aware semantic segmentation via multi-task network cascades**.\" in CVPR. 2016 [[pdf]](https://arxiv.org/pdf/1512.04412v1.pdf) :star::star::star:\n\n**[5]** Dai, J., He, K., Sun, J. \"**Instance-sensitive Fully Convolutional Networks**.\" arXiv preprint arXiv:1603.08678 (2016). [[pdf]](https://arxiv.org/pdf/1603.08678v1.pdf) :star::star::star:\n\n\n"}, {"repo": "getsentry/sentry", "language": "Python", "readme_contents": ".. raw:: html\n\n   <p align=\"center\">\n     <p align=\"center\">\n       <a href=\"https://sentry.io/?utm_source=github&utm_medium=logo\" target=\"_blank\">\n         <img src=\"https://sentry-brand.storage.googleapis.com/sentry-logo-black.png\" alt=\"Sentry\" height=\"72\">\n       </a>\n     </p>\n     <p align=\"center\">\n       Users and logs provide clues. Sentry provides answers.\n     </p>\n   </p>\n\nWhat's Sentry?\n--------------\n\nSentry fundamentally is a service that helps you monitor and fix crashes in realtime.\nThe server is in Python, but it contains a full API for sending events from any\nlanguage, in any application.\n\n.. raw:: html\n\n   <p align=\"center\">\n     <img src=\"https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-1.png\" width=\"290\">\n     <img src=\"https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-2.png\" width=\"290\">\n     <img src=\"https://github.com/getsentry/sentry/raw/master/src/sentry/static/sentry/images/product/thumb-3.png\" width=\"290\">\n   </p>\n\nOfficial Sentry SDKs\n~~~~~~~~~~~~~~~~~~~~\n* `JavaScript <https://github.com/getsentry/sentry-javascript>`_\n* `React-Native <https://github.com/getsentry/react-native-sentry>`_\n* `Python <https://github.com/getsentry/sentry-python>`_\n* `Ruby <https://github.com/getsentry/raven-ruby>`_\n* `PHP <https://github.com/getsentry/sentry-php>`_\n* `Go <https://github.com/getsentry/sentry-go>`_\n* `Java <https://github.com/getsentry/sentry-java>`_\n* `Objective-C/Swift <https://github.com/getsentry/sentry-cocoa>`_\n* `C# <https://github.com/getsentry/sentry-dotnet>`_\n* `Perl <https://github.com/getsentry/perl-raven>`_\n* `Elixir <https://github.com/getsentry/sentry-elixir>`_\n* `Laravel <https://github.com/getsentry/sentry-laravel>`_\n\nResources\n---------\n\n* `Documentation <https://docs.sentry.io/>`_\n* `Community <https://forum.sentry.io/>`_ (Bugs, feature requests, general questions)\n* `Contributing <https://docs.sentry.io/internal/contributing/>`_\n* `Bug Tracker <https://github.com/getsentry/sentry/issues>`_\n* `Code <https://github.com/getsentry/sentry>`_\n* `Discord <https://discord.gg/ez5KZN7>`_\n* `Transifex <https://www.transifex.com/getsentry/sentry/>`_ (Translate Sentry!)\n"}, {"repo": "0voice/interview_internal_reference", "language": "Python", "readme_contents": "\n## 2019\u5e74\u6700\u65b0\u603b\u7ed3\uff0c\u963f\u91cc\uff0c\u817e\u8baf\uff0c\u767e\u5ea6\uff0c\u7f8e\u56e2\uff0c\u5934\u6761\u7b49\u6280\u672f\u9762\u8bd5\u9898\u76ee\uff0c\u4ee5\u53ca\u7b54\u6848\uff0c\u4e13\u5bb6\u51fa\u9898\u4eba\u5206\u6790\u6c47\u603b\u3002\u6301\u7eed\u66f4\u65b0\u4e2d\u3002\n\n* [\u963f\u91cc\u7bc7](#1)\n* [\u534e\u4e3a\u7bc7](#2)\n* [\u767e\u5ea6\u7bc7](#3)\n* [\u817e\u8baf\u7bc7](#4)\n* [\u7f8e\u56e2\u7bc7](#5)\n* [\u5934\u6761\u7bc7](#6)\n* [\u6ef4\u6ef4\u7bc7](#7)\n* [\u4eac\u4e1c\u7bc7](#8)\n* [MySQL\u7bc7](#9)\n* [Redis\u7bc7](#10)\n* [MongoDB\u7bc7](#11)\n* [Zookeeper\u7bc7](#12)\n* [Nginx\u7bc7](#13)\n* [\u7b97\u6cd5\u7bc7](#14)\n* [\u5185\u5b58\u7bc7](#15)\n* [cpu\u7bc7](#16)\n* [\u78c1\u76d8\u7bc7](#17)\n* [\u7f51\u7edc\u901a\u4fe1\u7bc7](#18)\n* [\u5b89\u5168\u7bc7](#19)\n* [\u5e76\u53d1\u7bc7](#20)\n\n<h3 id=\"1\">\u963f\u91cc\u7bc7</h3> \n\n---\n\n##### [1.1.1 \u5982\u4f55\u5b9e\u73b0\u4e00\u4e2a\u9ad8\u6548\u7684\u5355\u5411\u94fe\u8868\u9006\u5e8f\u8f93\u51fa\uff1f](01.\u963f\u91cc\u7bc7/1.1.1%20%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%AB%98%E6%95%88%E7%9A%84%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8%E9%80%86%E5%BA%8F%E8%BE%93%E5%87%BA%EF%BC%9F.md)\n\n##### [1.1.2 \u5df2\u77e5sqrt(2)\u7ea6\u7b49\u4e8e1.414\uff0c\u8981\u6c42\u4e0d\u7528\u6570\u5b66\u5e93\uff0c\u6c42sqrt(2)\u7cbe\u786e\u5230\u5c0f\u6570\u70b9\u540e10\u4f4d](01.\u963f\u91cc\u7bc7/1.1.2%20%E5%B7%B2%E7%9F%A5sqrt%282%29%E7%BA%A6%E7%AD%89%E4%BA%8E1.414%EF%BC%8C%E8%A6%81%E6%B1%82%E4%B8%8D%E7%94%A8%E6%95%B0%E5%AD%A6%E5%BA%93%EF%BC%8C%E6%B1%82sqrt%282%29%E7%B2%BE%E7%A1%AE%E5%88%B0%E5%B0%8F%E6%95%B0%E7%82%B9%E5%90%8E10%E4%BD%8D.md)\n\n##### [1.1.3 \u7ed9\u5b9a\u4e00\u4e2a\u4e8c\u53c9\u641c\u7d22\u6811(BST)\uff0c\u627e\u5230\u6811\u4e2d\u7b2c K \u5c0f\u7684\u8282\u70b9](01.\u963f\u91cc\u7bc7/1.1.3%20%E7%BB%99%E5%AE%9A%E4%B8%80%E4%B8%AA%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%28BST%29%EF%BC%8C%E6%89%BE%E5%88%B0%E6%A0%91%E4%B8%AD%E7%AC%AC%20K%20%E5%B0%8F%E7%9A%84%E8%8A%82%E7%82%B9.md)\n\n##### [1.1.4 LRU\u7f13\u5b58\u673a\u5236](01.\u963f\u91cc\u7bc7/1.1.4%20LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6.md)\n\n##### [1.1.5 \u5173\u4e8eepoll\u548cselect\u7684\u533a\u522b\uff0c\u4ee5\u4e0b\u54ea\u4e9b\u8bf4\u6cd5\u662f\u6b63\u786e\u7684](01.\u963f\u91cc\u7bc7/1.1.5%20%E5%85%B3%E4%BA%8Eepoll%E5%92%8Cselect%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%8C%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E8%AF%B4%E6%B3%95%E6%98%AF%E6%AD%A3%E7%A1%AE%E7%9A%84.md)\n\n##### [1.1.6 \u4eceinnodb\u7684\u7d22\u5f15\u7ed3\u6784\u5206\u6790\uff0c\u4e3a\u4ec0\u4e48\u7d22\u5f15\u7684 key \u957f\u5ea6\u4e0d\u80fd\u592a\u957f](01.\u963f\u91cc\u7bc7/1.1.6%20%E4%BB%8Einnodb%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B4%A2%E5%BC%95%E7%9A%84%20key%20%E9%95%BF%E5%BA%A6%E4%B8%8D%E8%83%BD%E5%A4%AA%E9%95%BF.md)\n\n##### [1.1.7 MySQL\u7684\u6570\u636e\u5982\u4f55\u6062\u590d\u5230\u4efb\u610f\u65f6\u95f4\u70b9\uff1f](01.\u963f\u91cc\u7bc7/1.1.7%20MySQL%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D%E5%88%B0%E4%BB%BB%E6%84%8F%E6%97%B6%E9%97%B4%E7%82%B9%EF%BC%9F.md)\n\n##### 1.1.8 NFS \u548c SMB \u662f\u6700\u5e38\u89c1\u7684\u4e24\u79cd NAS\uff08Network Attached Storage\uff09\u534f\u8bae\uff0c\u5f53\u628a\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u540c\u65f6\u901a\u8fc7 NFS \u548c SMB \u534f\u8bae\u5171\u4eab\u7ed9\u591a\u4e2a\u4e3b\u673a\u8bbf\u95ee\u65f6\uff0c\u4ee5\u4e0b\u54ea\u4e9b\u8bf4\u6cd5\u662f\u9519\u8bef\u7684\n\n##### [1.1.9 \u8f93\u5165 ping IP \u540e\u6572\u56de\u8f66\uff0c\u53d1\u5305\u524d\u4f1a\u53d1\u751f\u4ec0\u4e48\uff1f](01.\u963f\u91cc\u7bc7/1.1.9%20%E8%BE%93%E5%85%A5%20ping%20IP%20%E5%90%8E%E6%95%B2%E5%9B%9E%E8%BD%A6%EF%BC%8C%E5%8F%91%E5%8C%85%E5%89%8D%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F.md)\n\n##### [1.2.0 \u8bf7\u89e3\u91ca\u4e0b\u4e3a\u4ec0\u4e48\u9e7f\u6657\u53d1\u5e03\u604b\u60c5\u7684\u65f6\u5019\uff0c\u5fae\u535a\u7cfb\u7edf\u4f1a\u5d29\u6e83\uff0c\u5982\u4f55\u89e3\u51b3\uff1f](01.\u963f\u91cc\u7bc7/1.2.0%20%E8%AF%B7%E8%A7%A3%E9%87%8A%E4%B8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E9%B9%BF%E6%99%97%E5%8F%91%E5%B8%83%E6%81%8B%E6%83%85%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%BE%AE%E5%8D%9A%E7%B3%BB%E7%BB%9F%E4%BC%9A%E5%B4%A9%E6%BA%83%EF%BC%8C%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%EF%BC%9F.md)\n\n##### [1.2.1 \u73b0\u6709\u4e00\u6279\u90ae\u4ef6\u9700\u8981\u53d1\u9001\u7ed9\u8ba2\u9605\u987e\u5ba2\uff0c\u4e14\u6709\u4e00\u4e2a\u96c6\u7fa4\uff08\u96c6\u7fa4\u7684\u8282\u70b9\u6570\u4e0d\u5b9a\uff0c\u4f1a\u52a8\u6001\u6269\u5bb9\u7f29\u5bb9\uff09\u6765\u8d1f\u8d23\u5177\u4f53\u7684\u90ae\u4ef6\u53d1\u9001\u4efb\u52a1\uff0c\u5982\u4f55\u8ba9\u7cfb\u7edf\u5c3d\u5feb\u5730\u5b8c\u6210\u53d1\u9001\uff1f](01.\u963f\u91cc\u7bc7/1.2.1%20%E7%8E%B0%E6%9C%89%E4%B8%80%E6%89%B9%E9%82%AE%E4%BB%B6%E9%9C%80%E8%A6%81%E5%8F%91%E9%80%81%E7%BB%99%E8%AE%A2%E9%98%85%E9%A1%BE%E5%AE%A2%EF%BC%8C%E4%B8%94%E6%9C%89%E4%B8%80%E4%B8%AA%E9%9B%86%E7%BE%A4%EF%BC%88%E9%9B%86%E7%BE%A4%E7%9A%84%E8%8A%82%E7%82%B9%E6%95%B0%E4%B8%8D%E5%AE%9A%EF%BC%8C%E4%BC%9A%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9%E7%BC%A9%E5%AE%B9%EF%BC%89%E6%9D%A5%E8%B4%9F%E8%B4%A3%E5%85%B7%E4%BD%93%E7%9A%84%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%E4%BB%BB%E5%8A%A1%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%A9%E7%B3%BB%E7%BB%9F%E5%B0%BD%E5%BF%AB%E5%9C%B0%E5%AE%8C%E6%88%90%E5%8F%91%E9%80%81%EF%BC%9F.md)\n\n##### [1.2.2 \u6709\u4e00\u6279\u6c14\u8c61\u89c2\u6d4b\u7ad9\uff0c\u73b0\u9700\u8981\u83b7\u53d6\u8fd9\u4e9b\u7ad9\u70b9\u7684\u89c2\u6d4b\u6570\u636e\uff0c\u5e76\u5b58\u50a8\u5230 Hive \u4e2d\u3002\u4f46\u662f\u6c14\u8c61\u5c40\u53ea\u63d0\u4f9b\u4e86 api \u67e5\u8be2\uff0c\u6bcf\u6b21\u53ea\u80fd\u67e5\u8be2\u5355\u4e2a\u89c2\u6d4b\u70b9\u3002\u90a3\u4e48\u5982\u679c\u80fd\u591f\u65b9\u4fbf\u5feb\u901f\u5730\u83b7\u53d6\u5230\u6240\u6709\u7684\u89c2\u6d4b\u70b9\u7684\u6570\u636e\uff1f](01.\u963f\u91cc\u7bc7/1.2.2%20%E6%9C%89%E4%B8%80%E6%89%B9%E6%B0%94%E8%B1%A1%E8%A7%82%E6%B5%8B%E7%AB%99%EF%BC%8C%E7%8E%B0%E9%9C%80%E8%A6%81%E8%8E%B7%E5%8F%96%E8%BF%99%E4%BA%9B%E7%AB%99%E7%82%B9%E7%9A%84%E8%A7%82%E6%B5%8B%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%B9%B6%E5%AD%98%E5%82%A8%E5%88%B0%20Hive%20%E4%B8%AD%E3%80%82%E4%BD%86%E6%98%AF%E6%B0%94%E8%B1%A1%E5%B1%80%E5%8F%AA%E6%8F%90%E4%BE%9B%E4%BA%86%20api%20%E6%9F%A5%E8%AF%A2%EF%BC%8C%E6%AF%8F%E6%AC%A1%E5%8F%AA%E8%83%BD%E6%9F%A5%E8%AF%A2%E5%8D%95%E4%B8%AA%E8%A7%82%E6%B5%8B%E7%82%B9%E3%80%82%E9%82%A3%E4%B9%88%E5%A6%82%E6%9E%9C%E8%83%BD%E5%A4%9F%E6%96%B9%E4%BE%BF%E5%BF%AB%E9%80%9F%E5%9C%B0%E8%8E%B7%E5%8F%96%E5%88%B0%E6%89%80%E6%9C%89%E7%9A%84%E8%A7%82%E6%B5%8B%E7%82%B9%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%9F.md)\n\n##### [1.2.3 \u5982\u4f55\u5b9e\u73b0\u4e24\u91d1\u989d\u6570\u636e\u76f8\u52a0\uff08\u6700\u591a\u5c0f\u6570\u70b9\u4e24\u4f4d\uff09](01.\u963f\u91cc\u7bc7/1.2.3%20%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%A4%E9%87%91%E9%A2%9D%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%8A%A0%EF%BC%88%E6%9C%80%E5%A4%9A%E5%B0%8F%E6%95%B0%E7%82%B9%E4%B8%A4%E4%BD%8D%EF%BC%89.md)\n\n##### [1.2.4 \u5173\u4e8e\u5e76\u884c\u8ba1\u7b97\u7684\u4e00\u4e9b\u57fa\u7840\u5f00\u653e\u95ee\u9898](01.\u963f\u91cc\u7bc7/1.2.4%20%E5%85%B3%E4%BA%8E%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%BC%80%E6%94%BE%E9%97%AE%E9%A2%98.md)\n\n##### [1.2.5 \u8bf7\u8ba1\u7b97XILINX\u516c\u53f8VU9P\u82af\u7247\u7684\u7b97\u529b\u76f8\u5f53\u4e8e\u591a\u5c11TOPS\uff0c\u7ed9\u51fa\u8ba1\u7b97\u8fc7\u7a0b\u4e0e\u516c\u5f0f](01.\u963f\u91cc\u7bc7/1.2.5%20%E8%AF%B7%E8%AE%A1%E7%AE%97XILINX%E5%85%AC%E5%8F%B8VU9P%E8%8A%AF%E7%89%87%E7%9A%84%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%BD%93%E4%BA%8E%E5%A4%9A%E5%B0%91TOPS%EF%BC%8C%E7%BB%99%E5%87%BA%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E4%B8%8E%E5%85%AC%E5%BC%8F.md)\n\n##### [1.2.6 \u4e00\u9897\u73b0\u4ee3\u5904\u7406\u5668\uff0c\u6bcf\u79d2\u5927\u6982\u53ef\u4ee5\u6267\u884c\u591a\u5c11\u6761\u7b80\u5355\u7684MOV\u6307\u4ee4\uff0c\u6709\u54ea\u4e9b\u4e3b\u8981\u7684\u5f71\u54cd\u56e0\u7d20](01.\u963f\u91cc\u7bc7/1.2.6%20%E4%B8%80%E9%A2%97%E7%8E%B0%E4%BB%A3%E5%A4%84%E7%90%86%E5%99%A8%EF%BC%8C%E6%AF%8F%E7%A7%92%E5%A4%A7%E6%A6%82%E5%8F%AF%E4%BB%A5%E6%89%A7%E8%A1%8C%E5%A4%9A%E5%B0%91%E6%9D%A1%E7%AE%80%E5%8D%95%E7%9A%84MOV%E6%8C%87%E4%BB%A4%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%BB%E8%A6%81%E7%9A%84%E5%BD%B1%E5%93%8D%E5%9B%A0%E7%B4%A0.md)\n\n##### [1.2.7 \u8bf7\u5206\u6790 MaxCompute \u4ea7\u54c1\u4e0e\u5206\u5e03\u5f0f\u6280\u672f\u7684\u5173\u7cfb\u3001\u5f53\u524d\u5927\u6570\u636e\u8ba1\u7b97\u5e73\u53f0\u7c7b\u4ea7\u54c1\u7684\u5e02\u573a\u73b0\u72b6\u548c\u53d1\u5c55\u8d8b\u52bf](01.\u963f\u91cc\u7bc7/1.2.7%20%E8%AF%B7%E5%88%86%E6%9E%90%20MaxCompute%20%E4%BA%A7%E5%93%81%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E7%9A%84%E5%85%B3%E7%B3%BB%E3%80%81%E5%BD%93%E5%89%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E7%B1%BB%E4%BA%A7%E5%93%81%E7%9A%84%E5%B8%82%E5%9C%BA%E7%8E%B0%E7%8A%B6%E5%92%8C%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF.md)\n\n##### [1.2.8 \u5bf9\u5927\u6570\u636e\u5e73\u53f0\u4e2d\u7684\u5143\u6570\u636e\u7ba1\u7406\u662f\u600e\u4e48\u7406\u89e3\u7684\uff0c\u5143\u6570\u636e\u6536\u96c6\u7ba1\u7406\u4f53\u7cfb\u662f\u600e\u4e48\u6837\u7684\uff0c\u4f1a\u5bf9\u5927\u6570\u636e\u5e94\u7528\u6709\u4ec0\u4e48\u6837\u7684\u5f71\u54cd](01.\u963f\u91cc\u7bc7/1.2.8%20%E5%AF%B9%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E4%B8%AD%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%98%AF%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E7%9A%84%EF%BC%8C%E5%85%83%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84%EF%BC%8C%E4%BC%9A%E5%AF%B9%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E6%9C%89%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E5%BD%B1%E5%93%8D.md)\n\n##### [1.2.9 \u4f60\u7406\u89e3\u5e38\u89c1\u5982\u963f\u91cc\uff0c\u548c\u53cb\u5546\u5927\u6570\u636e\u5e73\u53f0\u7684\u6280\u672f\u4f53\u7cfb\u5dee\u5f02\u4ee5\u53ca\u53d1\u5c55\u8d8b\u52bf\u548c\u6280\u672f\u74f6\u9888\uff0c\u5728\u5b58\u50a8\u548c\u8ba1\u7b97\u4e24\u4e2a\u65b9\u9762\u8fdb\u884c\u6982\u8ff0](01.\u963f\u91cc\u7bc7/1.2.9%20%E4%BD%A0%E7%90%86%E8%A7%A3%E5%B8%B8%E8%A7%81%E5%A6%82%E9%98%BF%E9%87%8C%EF%BC%8C%E5%92%8C%E5%8F%8B%E5%95%86%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%8A%80%E6%9C%AF%E4%BD%93%E7%B3%BB%E5%B7%AE%E5%BC%82%E4%BB%A5%E5%8F%8A%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF%E5%92%8C%E6%8A%80%E6%9C%AF%E7%93%B6%E9%A2%88%EF%BC%8C%E5%9C%A8%E5%AD%98%E5%82%A8%E5%92%8C%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E6%96%B9%E9%9D%A2%E8%BF%9B%E8%A1%8C%E6%A6%82%E8%BF%B0.md)\n\n##### 1.3.0 \u5728\u4e91\u8ba1\u7b97\u5927\u6570\u636e\u5904\u7406\u573a\u666f\u4e2d\uff0c\u6bcf\u5929\u8fd0\u884c\u7740\u6210\u5343\u4e0a\u4e07\u7684\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u90fd\u8981\u8fdb\u884c IO \u8bfb\u5199\u3002\u5b58\u50a8\u7cfb\u7edf\u4e3a\u4e86\u66f4\u597d\u7684\u670d\u52a1\uff0c\u7ecf\u5e38\u4f1a\u4fdd\u8bc1\u9ad8\u4f18\u5148\u7ea7\u7684\u4efb\u52a1\u4f18\u5148\u6267\u884c\u3002\u5f53\u591a\u4e2a\u4f5c\u4e1a\u6216\u7528\u6237\u8bbf\u95ee\u5b58\u50a8\u7cfb\u7edf\u65f6,\u5982\u4f55\u4fdd\u8bc1\u4f18\u5148\u7ea7\u548c\u516c\u5e73\u6027\n\n##### [1.3.1 \u6700\u5927\u9891\u7387\u6808](01.\u963f\u91cc\u7bc7/1.3.1%20%E6%9C%80%E5%A4%A7%E9%A2%91%E7%8E%87%E6%A0%88.md)\n\n##### [1.3.2 \u7ed9\u5b9a\u4e00\u4e2a\u94fe\u8868\uff0c\u5220\u9664\u94fe\u8868\u7684\u5012\u6570\u7b2cN\u4e2a\u8282\u70b9\uff0c\u5e76\u4e14\u8fd4\u56de\u94fe\u8868\u7684\u5934\u7ed3\u70b9](01.\u963f\u91cc\u7bc7/1.3.2%20%E7%BB%99%E5%AE%9A%E4%B8%80%E4%B8%AA%E9%93%BE%E8%A1%A8%EF%BC%8C%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E5%80%92%E6%95%B0%E7%AC%ACN%E4%B8%AA%E8%8A%82%E7%82%B9%EF%BC%8C%E5%B9%B6%E4%B8%94%E8%BF%94%E5%9B%9E%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%B4%E7%BB%93%E7%82%B9.md)\n\n##### [1.3.3 \u5982\u679c\u8ba9\u4f60\u8bbe\u8ba1\u4e00\u4e2a\u901a\u7528\u7684\u3001\u652f\u6301\u5404\u79cd\u6570\u636e\u5e93\u79d2\u7ea7\u5907\u4efd\u548c\u6062\u590d\u7684\u7cfb\u7edf\uff0c\u4f60\u4f1a\u5982\u4f55\u8bbe\u8ba1](01.\u963f\u91cc\u7bc7/1.3.3%20%E5%A6%82%E6%9E%9C%E8%AE%A9%E4%BD%A0%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%80%9A%E7%94%A8%E7%9A%84%E3%80%81%E6%94%AF%E6%8C%81%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%A7%92%E7%BA%A7%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D%E7%9A%84%E7%B3%BB%E7%BB%9F%EF%BC%8C%E4%BD%A0%E4%BC%9A%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1.md)\n\n##### [1.3.4 \u5982\u679c\u8ba9\u4f60\u6765\u8bbe\u8ba1\u4e00\u4e2a\u652f\u6301\u6570\u636e\u5e93\u3001NOSQL \u548c\u5927\u6570\u636e\u4e4b\u95f4\u6570\u636e\u5b9e\u65f6\u6d41\u52a8\u7684\u6570\u636e\u6d41\u53ca\u5904\u7406\u7684\u7cfb\u7edf\uff0c\u4f60\u4f1a\u8003\u8651\u54ea\u4e9b\u95ee\u9898\uff1f\u5982\u4f55\u8bbe\u8ba1\uff1f](01.\u963f\u91cc\u7bc7/1.3.4%20%E5%A6%82%E6%9E%9C%E8%AE%A9%E4%BD%A0%E6%9D%A5%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E6%94%AF%E6%8C%81%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81NOSQL%20%E5%92%8C%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E9%97%B4%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6%E6%B5%81%E5%8A%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E5%8F%8A%E5%A4%84%E7%90%86%E7%9A%84%E7%B3%BB%E7%BB%9F%EF%BC%8C%E4%BD%A0%E4%BC%9A%E8%80%83%E8%99%91%E5%93%AA%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%9F%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%EF%BC%9F.md)\n\n##### [1.3.5 \u7ed9\u5b9a\u4e00\u4e2a\u6574\u6570\u6570\u7ec4\u548c\u4e00\u4e2a\u6574\u6570\uff0c\u8fd4\u56de\u4e24\u4e2a\u6570\u7ec4\u7684\u7d22\u5f15\uff0c\u8fd9\u4e24\u4e2a\u7d22\u5f15\u6307\u5411\u7684\u6570\u5b57\u7684\u52a0\u548c\u7b49\u4e8e\u6307\u5b9a\u7684\u6574\u6570\u3002\u9700\u8981\u6700\u4f18\u7684\u7b97\u6cd5\uff0c\u5206\u6790\u7b97\u6cd5\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u590d\u6742\u5ea6](01.\u963f\u91cc\u7bc7/1.3.5%20%E7%BB%99%E5%AE%9A%E4%B8%80%E4%B8%AA%E6%95%B4%E6%95%B0%E6%95%B0%E7%BB%84%E5%92%8C%E4%B8%80%E4%B8%AA%E6%95%B4%E6%95%B0%EF%BC%8C%E8%BF%94%E5%9B%9E%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E7%B4%A2%E5%BC%95%EF%BC%8C%E8%BF%99%E4%B8%A4%E4%B8%AA%E7%B4%A2%E5%BC%95%E6%8C%87%E5%90%91%E7%9A%84%E6%95%B0%E5%AD%97%E7%9A%84%E5%8A%A0%E5%92%8C%E7%AD%89%E4%BA%8E%E6%8C%87%E5%AE%9A%E7%9A%84%E6%95%B4%E6%95%B0%E3%80%82%E9%9C%80%E8%A6%81%E6%9C%80%E4%BC%98%E7%9A%84%E7%AE%97%E6%B3%95%EF%BC%8C%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95%E7%9A%84%E7%A9%BA%E9%97%B4%E5%92%8C%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.md)\n\n##### [1.3.6 \u5047\u5982\u7ed9\u4f60\u4e00\u4e2a\u65b0\u4ea7\u54c1\uff0c\u4f60\u5c06\u4ece\u54ea\u4e9b\u65b9\u9762\u6765\u4fdd\u969c\u5b83\u7684\u8d28\u91cf\uff1f](01.\u963f\u91cc\u7bc7/1.3.6%20%E5%81%87%E5%A6%82%E7%BB%99%E4%BD%A0%E4%B8%80%E4%B8%AA%E6%96%B0%E4%BA%A7%E5%93%81%EF%BC%8C%E4%BD%A0%E5%B0%86%E4%BB%8E%E5%93%AA%E4%BA%9B%E6%96%B9%E9%9D%A2%E6%9D%A5%E4%BF%9D%E9%9A%9C%E5%AE%83%E7%9A%84%E8%B4%A8%E9%87%8F%EF%BC%9F.md)\n\n##### [1.3.7 \u8bf7\u8bc4\u4f30\u4e00\u4e0b\u7a0b\u5e8f\u7684\u6267\u884c\u7ed3\u679c\uff1f](01.\u963f\u91cc\u7bc7/1.3.7%20%E8%AF%B7%E8%AF%84%E4%BC%B0%E4%B8%80%E4%B8%8B%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E7%BB%93%E6%9E%9C%EF%BC%9F.md)\n\n<br>\n\n<h3 id=\"2\">\u534e\u4e3a\u7bc7</h3> \n\n---\n##### 2.1.0 static\u6709\u4ec0\u4e48\u7528\u9014\uff1f\uff08\u8bf7\u81f3\u5c11\u8bf4\u660e\u4e24\u79cd\uff09\n\n###### 2.1.1 \u5f15\u7528\u4e0e\u6307\u9488\u6709\u4ec0\u4e48\u533a\u522b\uff1f\n\n##### 2.1.2 \u63cf\u8ff0\u5b9e\u65f6\u7cfb\u7edf\u7684\u57fa\u672c\u7279\u6027\n\n##### 2.1.3 \u5168\u5c40\u53d8\u91cf\u548c\u5c40\u90e8\u53d8\u91cf\u5728\u5185\u5b58\u4e2d\u662f\u5426\u6709\u533a\u522b\uff1f\u5982\u679c\u6709\uff0c\u662f\u4ec0\u4e48\u533a\u522b\uff1f\n\n##### 2.1.4 \u4ec0\u4e48\u662f\u5e73\u8861\u4e8c\u53c9\u6811\uff1f\n\n##### 2.1.5 \u5806\u6808\u6ea2\u51fa\u4e00\u822c\u662f\u7531\u4ec0\u4e48\u539f\u56e0\u5bfc\u81f4\u7684\uff1f\n\n##### 2.1.6 \u4ec0\u4e48\u51fd\u6570\u4e0d\u80fd\u58f0\u660e\u4e3a\u865a\u51fd\u6570\uff1f\n\n##### 2.1.7 \u5192\u6ce1\u6392\u5e8f\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u662f\u4ec0\u4e48\uff1f\n\n##### 2.1.8 \u5199\u51fafloat x \u4e0e\u201c\u96f6\u503c\u201d\u6bd4\u8f83\u7684if\u8bed\u53e5\n\n##### 2.1.9 Internet\u91c7\u7528\u54ea\u79cd\u7f51\u7edc\u534f\u8bae\uff1f\u8be5\u534f\u8bae\u7684\u4e3b\u8981\u5c42\u6b21\u7ed3\u6784\uff1f\n\n##### 2.2.0 Internet\u7269\u7406\u5730\u5740\u548cIP\u5730\u5740\u8f6c\u6362\u91c7\u7528\u4ec0\u4e48\u534f\u8bae\uff1f\n\n##### 2.2.1 IP\u5730\u5740\u7684\u7f16\u7801\u5206\u4e3a\u54ea\u4fe9\u90e8\u5206\uff1f\n\n##### 2.2.2 \u7528\u6237\u8f93\u5165M,N\u503c\uff0c\u4ece1\u81f3N\u5f00\u59cb\u987a\u5e8f\u5faa\u73af\u6570\u6570\uff0c\u6bcf\u6570\u5230M\u8f93\u51fa\u8be5\u6570\u503c\uff0c\u76f4\u81f3\u5168\u90e8\u8f93\u51fa\u3002\u5199\u51faC\u7a0b\u5e8f\u3002\n\n##### 2.2.3 \u4e0d\u80fd\u505aswitch()\u7684\u53c2\u6570\u7c7b\u578b\u662f\n\n##### 2.2.4 int A[nSize]\uff0c\u5176\u4e2d\u9690\u85cf\u7740\u82e5\u5e720\uff0c\u5176\u4f59\u975e0\u6574\u6570\uff0c\u5199\u4e00\u4e2a\u51fd\u6570int Func(int* A, int nSize)\uff0c\u4f7fA\u628a0\u79fb\u81f3\u540e\u9762\uff0c\u975e0\u6574\u6570\u79fb\u81f3\u6570\u7ec4\u524d\u9762\u5e76\u4fdd\u6301\u6709\u5e8f\uff0c\u8fd4\u56de\u503c\u4e3a\u539f\u6570\u636e\u4e2d\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e3a0\u7684\u4e0b\u6807\u3002\n\n##### 2.2.5 \u5199\u4e00\u4e2a\u7a0b\u5e8f, \u8981\u6c42\u529f\u80fd\uff1a\u6c42\u51fa\u75281\uff0c2\uff0c5\u8fd9\u4e09\u4e2a\u6570\u4e0d\u540c\u4e2a\u6570\u7ec4\u5408\u7684\u548c\u4e3a100\u7684\u7ec4\u5408\u4e2a\u6570\n\n##### 2.2.6 \u5b9e\u73b0\u4e00\u4e2a\u51fd\u6570\uff0c\u628a\u4e00\u4e2a\u5b57\u7b26\u4e32\u4e2d\u7684\u5b57\u7b26\u4ece\u5c0f\u5199\u8f6c\u4e3a\u5927\u5199\n\n##### 2.2.7 \u968f\u673a\u8f93\u5165\u4e00\u4e2a\u6570\uff0c\u5224\u65ad\u5b83\u662f\u4e0d\u662f\u5bf9\u79f0\u6570\uff08\u56de\u6587\u6570\uff09\uff08\u59823\uff0c121\uff0c12321\uff0c45254\uff09\u3002\u4e0d\u80fd\u7528\u5b57\u7b26\u4e32\u5e93\u51fd\u6570\n\n##### 2.2.8 \u6c422~2000\u7684\u6240\u6709\u7d20\u6570.\u6709\u8db3\u591f\u7684\u5185\u5b58,\u8981\u6c42\u5c3d\u91cf\u5feb\n\n##### 2.2.9 A,B,C,D\u56db\u4e2a\u8fdb\u7a0b\uff0cA\u5411buf\u91cc\u9762\u5199\u6570\u636e\uff0cB,C,D\u5411buf\u91cc\u9762\u8bfb\u6570\u636e\uff0c\u5f53A\u5199\u5b8c\uff0c\u4e14B\uff0cC\uff0cD\u90fd\u8bfb\u4e00\u6b21\u540e\uff0cA\u624d\u80fd\u518d\u5199\u3002\u7528P\uff0cV\u64cd\u4f5c\u5b9e\u73b0\u3002\n\n##### 2.3.0 \u5c06\u5355\u5411\u94fe\u8868reverse\uff0c\u5982ABCD\u53d8\u6210DCBA\uff0c\u53ea\u80fd\u641c\u7d22\u94fe\u8868\u4e00\u6b21\u3002\n\n##### 2.3.1 \u5c06\u4e8c\u53c9\u6811\u7684\u4e24\u4e2a\u5b69\u5b50\u6362\u4f4d\u7f6e\uff0c\u5373\u5de6\u53d8\u53f3\uff0c\u53f3\u53d8\u5de6\u3002\u4e0d\u80fd\u7528\u9012\u89c4\u3002\n\n##### 2.3.2 \u4ee5\u4e0b\u5c5e\u4e8e\u7269\u7406\u5c42\u7684\u8bbe\u5907\u662f\uff1f\n\n##### 2.3.3 \u5728\u4ee5\u592a\u7f51\u4e2d\uff0c\u662f\u6839\u636e\uff08\uff09\u5730\u5740\u6765\u533a\u5206\u4e0d\u540c\u7684\u8bbe\u5907\u7684\uff1f\n\n##### 2.3.4 \u4ee5\u4e0b\u4e3a\u4f20\u8f93\u5c42\u534f\u8bae\u7684\u662f\uff1f\n\n##### 2.3.5 \u4ee5\u4e0b\u5bf9MAC\u5730\u5740\u63cf\u8ff0\u6b63\u786e\u7684\u662f\uff1f\n\n##### 2.3.6 \u4ee5\u4e0b\u5c5e\u4e8e\u6570\u636e\u94fe\u8def\u5c42\u529f\u80fd\u7684\u662f\uff1f\n\n##### 2.3.7 IEEE802.3u\u6807\u51c6\u662f\u6307\uff1f\n\n##### 2.3.8 \u5982\u679c\u8981\u5c06\u4e24\u8ba1\u7b97\u673a\u901a\u8fc7\u53cc\u7ede\u7ebf\u76f4\u63a5\u8fde\u63a5\uff0c\u6b63\u786e\u7684\u7ebf\u5e8f\u662f\uff1f\n\n##### 2.3.9 \u5728V.35\u548cV.24\u89c4\u7a0b\u4e2d\uff0c\u63a7\u5236\u4fe1\u53f7RTS\u8868\u793a\uff1f\n\n##### 2.4.0 \u8def\u7531\u5668\u4f5c\u4e3a\u7f51\u7edc\u4e92\u8fde\u8bbe\u5907\uff0c\u5fc5\u987b\u5177\u5907\u4ee5\u4e0b\u54ea\u4e9b\u7279\u70b9\uff1f\n\n##### 2.4.1 \u8def\u7531\u5668\u7684\u4f5c\u7528\u6709\uff1f\n\n##### 2.4.2 \u8c03\u7528\u4e0a\u4e00\u6761\u5386\u53f2\u547d\u4ee4\u7684\u5feb\u6377\u952e\u662f\uff1f\n\n##### 2.4.3 \u4ea4\u6362\u673a\u5de5\u4f5c\u5728OSI\u4e03\u5c42\u7684\u54ea\u4e00\u5c42\uff1f\n\n##### 2.4.4 \u4ee5\u4e0b\u5bf9CSMA/CD\u63cf\u8ff0\u6b63\u786e\u7684\u662f\uff1f\n\n##### 2.4.5 \u4ee5\u4e0b\u5bf9STORE ANDFORWARD\u63cf\u8ff0\u6b63\u786e\u7684\u662f\uff1f\n\n##### 2.4.6 \u4ee5\u4e0b\u5bf9\u4ea4\u6362\u673a\u5de5\u4f5c\u65b9\u5f0f\u63cf\u8ff0\u6b63\u786e\u7684\u662f\uff1f\n\n##### 2.4.7 VLAN\u7684\u4e3b\u8981\u4f5c\u7528\u6709\uff1f\n\n##### 2.4.8 \u5728\u4ea4\u6362\u673a\u4e2d\u7528\u6237\u6743\u9650\u5206\u4e3a\u51e0\u4e2a\u7ea7\u522b\uff1f\n\n##### 2.4.9 \u5728\u8def\u7531\u5668\u7684\u914d\u7f6e\u8fc7\u7a0b\u4e2d\u67e5\u8be2\u4ee5S\u5f00\u5934\u6240\u6709\u547d\u4ee4\u7684\u65b9\u6cd5\u662f\uff1f\n\n##### 2.5.0 \u7b2c\u4e00\u6b21\u914d\u7f6e\u8def\u7531\u5668\u65f6\u53ef\u4ee5\u4f7f\u7528\u7684\u65b9\u6cd5\u4e3a\uff1f\n\n##### 2.5.1 \u5728\u4f55\u79cd\u72b6\u6001\u4e0b\u53ef\u4ee5\u4e3a\u8def\u7531\u5668\u6539\u540d\uff1f\n\n##### 2.5.2 \u67d0\u516c\u53f8\u7533\u8bf7\u5230\u4e00\u4e2aC\u7c7bIP\u5730\u5740\uff0c\u4f46\u8981\u8fde\u63a56\u4e2a\u7684\u5b50\u516c\u53f8\uff0c\u6700\u5927\u7684\u4e00\u4e2a\u5b50\u516c\u53f8\u6709 26\u53f0\u8ba1\u7b97\u673a\uff0c\u6bcf\u4e2a\u5b50\u516c\u53f8\u5728\u4e00\u4e2a\u7f51\u6bb5\u4e2d\uff0c\u5219\u5b50\u7f51\u63a9\u7801\u5e94\u8bbe\u4e3a\uff1f\n\n##### 2.5.3 \u4e0e10.110.12.29mask 255.255.255.224\u5c5e\u4e8e\u540c\u4e00\u7f51\u6bb5\u7684\u4e3b\u673aIP\u5730\u5740\u662f\uff1f\n\n##### 2.5.4 ARP\u534f\u8bae\u7684\u4f5c\u7528\u662f\uff1f\n\n##### 2.5.5 \u5f53\u8def\u7531\u5668\u63a5\u6536\u7684IP\u62a5\u6587\u7684TTL\u503c\u7b49\u4e8e1\u65f6\uff0c\u91c7\u53d6\u7684\u7b56\u7565\u662f\uff1f\n\n##### 2.5.6 \u5728NetWare \u7f51\u7edc\u4e2d\uff0c\u5ba2\u6237\u9700\u8981\u8bbf\u95ee\u67d0\u4e2a\u7c7b\u578b\u7684\u670d\u52a1\u5668\u65f6\uff0c\u9996\u5148\u8981\u53d1\u9001\u4e00\u4e2a \uff08\uff09\u5e7f\u64ad\u62a5\u6587\u6765\u5bfb\u627e\u670d\u52a1\u5668\uff1f\n\n##### 2.5.7 IPX\u5730\u5740\u7f51\u7edc\u5730\u5740\u6709\uff08 \uff09\u4e2a\u5b57\u8282\uff1f\n\n##### 2.5.8 \u5bf9\u4e8e\u5e27\u4e2d\u7ee7\u63cf\u8ff0\u6b63\u786e\u7684\u662f\uff1f\n\n##### 2.5.9 \u5bf9\u4e8eINVERSE ARP\u7684\u63cf\u8ff0\u6b63\u786e\u7684\u662f\uff1f\n\n<br>\n\n<h3 id=\"3\">\u767e\u5ea6\u7bc7</h3> \n\n---\n\n##### 3.1.0 \u5728\u51fd\u6570\u5185\u5b9a\u4e49\u4e00\u4e2a\u5b57\u7b26\u6570\u7ec4\uff0c\u7528gets\u51fd\u6570\u8f93\u5165\u5b57\u7b26\u4e32\u7684\u65f6\u5019\uff0c\u5982\u679c\u8f93\u5165\u8d8a\u754c\uff0c\u4e3a\u4ec0\u4e48\u7a0b\u5e8f\u4f1a\u5d29\u6e83\uff1f\n\n##### 3.1.1 C++\u4e2d\u5f15\u7528\u4e0e\u6307\u9488\u7684\u533a\u522b\n\n##### 3.1.2 C/C++\u7a0b\u5e8f\u7684\u5185\u5b58\u5206\u533a\n\n##### 3.1.3 \u5feb\u901f\u6392\u5e8f\u7684\u601d\u60f3\u3001\u65f6\u95f4\u590d\u6742\u5ea6\u3001\u5b9e\u73b0\u4ee5\u53ca\u4f18\u5316\u65b9\u6cd5\n\n##### 3.1.4 IO\u6a21\u578b\u2014\u2014IO\u591a\u8def\u590d\u7528\u673a\u5236?\n\n##### 3.1.5 \u5e38\u7528\u7684Linux\u547d\u4ee4\n\n##### 3.1.6 C\u4e2d\u53d8\u91cf\u7684\u5b58\u50a8\u7c7b\u578b\u6709\u54ea\u4e9b\uff1f\n\n##### 3.1.7 \u52a8\u6001\u89c4\u5212\u7684\u672c\u8d28\n\n##### 3.1.8 \u5b9e\u8df5\u4e2d\u5982\u4f55\u4f18\u5316MySQL?\n\n##### 3.1.9 \u4ec0\u4e48\u60c5\u51b5\u4e0b\u8bbe\u7f6e\u4e86\u7d22\u5f15\u4f46\u65e0\u6cd5\u4f7f\u7528?\n\n##### 3.2.0 SQL\u8bed\u53e5\u7684\u4f18\u5316\n\n##### 3.2.1 \u6570\u636e\u5e93\u7d22\u5f15\u7684\u5e95\u5c42\u5b9e\u73b0\u539f\u7406\u548c\u4f18\u5316\n\n##### 3.2.2 HTTP\u548cHTTPS\u7684\u4e3b\u8981\u533a\u522b?\n\n##### 3.2.3 \u5982\u4f55\u8bbe\u8ba1\u4e00\u4e2a\u9ad8\u5e76\u53d1\u7684\u7cfb\u7edf?\n\n##### 3.2.4 \u4e24\u6761\u76f8\u4ea4\u7684\u5355\u5411\u94fe\u8868\uff0c\u5982\u4f55\u6c42\u4ed6\u4eec\u7684\u7b2c\u4e00\u4e2a\u516c\u5171\u8282\u70b9?\n\n##### 3.2.5 \u6c42\u5355\u5411\u5c40\u90e8\u5faa\u73af\u94fe\u8868\u7684\u73af\u5165\u53e3?\n\n##### 3.2.6 IP\u5730\u5740\u5982\u4f55\u5728\u6570\u636e\u5e93\u4e2d\u5b58\u50a8?\n\n##### 3.2.7 new/delete\u548cmalloc/free\u7684\u5e95\u5c42\u5b9e\u73b0?\n\n##### 3.2.8 overload\u3001override\u3001overwrite\u7684\u4ecb\u7ecd?\n\n##### 3.2.9 \u5c0f\u7aef/\u5927\u7aef\u673a\u5668?\n\n##### 3.3.0 \u5b88\u62a4\u8fdb\u7a0b\n\n##### 3.3.1 \u591a\u7ebf\u7a0b\u7684\u4f18\u7f3a\u70b9\n\n##### 3.3.2 \u957f\u8fde\u63a5\u4e0e\u77ed\u8fde\u63a5\n\n##### 3.3.3 \u4e8c\u5206\u56fe\u5e94\u7528\u4e8e\u6700\u4f73\u5339\u914d\u95ee\u9898\uff08\u6e38\u5ba2\u5bf9\u623f\u95f4\u7684\u6ee1\u610f\u5ea6\u4e4b\u548c\u6700\u5927\u95ee\u9898\uff09\n\n##### 3.3.4 class\u4e0estruct\u7684\u533a\u522b\uff1f\n\n##### 3.3.5 \u865a\u51fd\u6570\u548c\u7eaf\u865a\u51fd\u6570\n\n##### 3.3.6 menset()\u51fd\u6570\n\n##### 3.3.7 \u5b9e\u73b0\u4e00\u4e2a\u51fd\u6570\uff0c\u5bf9\u4e00\u4e2a\u6b63\u6574\u6570n\uff0c\u7b97\u5f97\u52301\u9700\u8981\u7684\u6700\u5c11\u64cd\u4f5c\u6b21\u6570\u3002\u64cd\u4f5c\u89c4\u5219\u4e3a\uff1a\u5982\u679cn\u4e3a\u5076\u6570\uff0c\u5c06\u5176\u9664\u4ee52\uff1b\u5982\u679cn\u4e3a\u5947\u6570\uff0c\u53ef\u4ee5\u52a01\u6216\u51cf1\uff1b\u4e00\u76f4\u5904\u7406\u4e0b\u53bb\u3002\n\n##### 3.3.8 \u627e\u5230\u6ee1\u8db3\u6761\u4ef6\u7684\u6570\u7ec4\n\n##### 3.3.9 \u4e00\u4e2a\u5927\u7684\u542b\u670950M\u4e2aURL\u7684\u8bb0\u5f55\uff0c\u4e00\u4e2a\u5c0f\u7684\u542b\u6709500\u4e2aURL\u7684\u8bb0\u5f55\uff0c\u627e\u51fa\u4e24\u4e2a\u8bb0\u5f55\u91cc\u76f8\u540c\u7684URL\n\n##### 3.4.0 \u6d77\u91cf\u65e5\u5fd7\u6570\u636e\uff0c\u63d0\u53d6\u51fa\u67d0\u65e5\u8bbf\u95ee\u767e\u5ea6\u6b21\u6570\u6700\u591a\u7684\u90a3\u4e2aIP\n\n##### 3.4.1 \u670910\u4e2a\u6587\u4ef6\uff0c\u6bcf\u4e2a\u6587\u4ef61G\uff0c\u6bcf\u4e2a\u6587\u4ef6\u7684\u6bcf\u4e00\u884c\u90fd\u5b58\u653e\u7684\u662f\u7528\u6237\u7684query\uff0c\u6bcf\u4e2a\u6587\u4ef6\u7684query\u90fd\u53ef\u80fd\u91cd\u590d\u3002\u5982\u4f55\u6309\u7167query\u7684\u9891\u5ea6\u6392\u5e8f\uff1f\n\n##### 3.4.2 \u8682\u8681\u722c\u6746\u95ee\u9898\n\n##### 3.4.3 \u5f53\u5728\u6d4f\u89c8\u5668\u4e2d\u8f93\u5165\u4e00\u4e2aurl\u540e\u56de\u8f66\uff0c\u540e\u53f0\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\u6bd4\u5982\u8f93\u5165url\u540e\uff0c\u4f60\u770b\u5230\u4e86\u767e\u5ea6\u7684\u9996\u9875\uff0c\u90a3\u4e48\u8fd9\u4e00\u5207\u662f\u5982\u4f55\u53d1\u751f\u7684\u5462\uff1f\n\n##### 3.4.4 \u5224\u65ad\u4e24\u68f5\u6811\u662f\u5426\u76f8\u7b49\uff0c\u8bf7\u5b9e\u73b0\u4e24\u68f5\u6811\u662f\u5426\u76f8\u7b49\u7684\u6bd4\u8f83\uff0c\u76f8\u7b49\u8fd4\u56de1\uff0c\u5426\u5219\u8fd4\u56de\u5176\u4ed6\u503c\uff0c\u5e76\u8bf4\u660e\u7b97\u6cd5\u590d\u6742\u5ea6\n\n##### 3.4.5 \u4e09\u4e2a\u8b66\u5bdf\u548c\u4e09\u4e2a\u56da\u5f92\u7684\u8fc7\u6cb3\u95ee\u9898\n\n##### 3.4.6 \u4ece300\u4e07\u5b57\u7b26\u4e32\u4e2d\u627e\u5230\u6700\u70ed\u95e8\u768410\u6761\n\n##### 3.4.7 \u5982\u4f55\u627e\u51fa\u5b57\u5178\u4e2d\u7684\u5144\u5f1f\u5355\u8bcd\u3002\u7ed9\u5b9a\u4e00\u4e2a\u5355\u8bcda\uff0c\u5982\u679c\u901a\u8fc7\u4ea4\u6362\u5355\u8bcd\u4e2d\u5b57\u6bcd\u7684\u987a\u5e8f\u53ef\u4ee5\u5f97\u5230\u53e6\u5916\u7684\u5355\u8bcdb\uff0c\u90a3\u4e48\u5b9a\u4e49b\u662fa\u7684\u5144\u5f1f\u5355\u8bcd\u3002\u73b0\u5728\u7ed9\u5b9a\u4e00\u4e2a\u5b57\u5178\uff0c\u7528\u6237\u8f93\u5165\u4e00\u4e2a\u5355\u8bcd\uff0c\u5982\u4f55\u6839\u636e\u5b57\u5178\u627e\u51fa\u8fd9\u4e2a\u5355\u8bcd\u6709\u591a\u5c11\u4e2a\u5144\u5f1f\u5355\u8bcd\uff1f\n\n##### 3.4.8 \u627e\u51fa\u6570\u7ec4\u4e2d\u51fa\u73b0\u6b21\u6570\u8d85\u8fc7\u4e00\u534a\u7684\u6570\uff0c\u73b0\u5728\u6709\u4e00\u4e2a\u6570\u7ec4\uff0c\u5df2\u77e5\u4e00\u4e2a\u6570\u51fa\u73b0\u7684\u6b21\u6570\u8d85\u8fc7\u4e86\u4e00\u534a\uff0c\u8bf7\u7528O(n)\u7684\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\u627e\u51fa\u8fd9\u4e2a\u6570\u3002\n\n##### 3.4.9 \u627e\u51fa\u88ab\u4fee\u6539\u8fc7\u7684\u6570\u5b57\n\n##### 3.5.0 \u8bbe\u8ba1DNS\u670d\u52a1\u5668\u4e2dcache\u7684\u6570\u636e\u7ed3\u6784\u3002\u8981\u6c42\u8bbe\u8ba1\u4e00\u4e2aDNS\u7684Cache\u7ed3\u6784\uff0c\u8981\u6c42\u80fd\u591f\u6ee1\u8db3\u6bcf\u79d25000\u4ee5\u4e0a\u7684\u67e5\u8be2\uff0c\u6ee1\u8db3IP\u6570\u636e\u7684\u5feb\u901f\u63d2\u5165\uff0c\u67e5\u8be2\u7684\u901f\u5ea6\u8981\u5feb\u3002\uff08\u9898\u76ee\u8fd8\u7ed9\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u6570\u636e\uff0c\u6bd4\u5982\uff1a\u7ad9\u70b9\u6570\u603b\u5171\u4e3a5000\u4e07\uff0cIP\u5730\u5740\u67091000\u4e07\uff0c\u7b49\u7b49\uff09\n\n##### 3.5.1 \u627e\u51fa\u7ed9\u5b9a\u5b57\u7b26\u4e32\u5bf9\u5e94\u7684\u5e8f\u53f7\n\n##### 3.5.2 \u627e\u51fa\u7b2ck\u5927\u7684\u6570\u5b57\u6240\u5728\u7684\u4f4d\u7f6e\u3002\u5199\u4e00\u6bb5\u7a0b\u5e8f\uff0c\u627e\u51fa\u6570\u7ec4\u4e2d\u7b2ck\u5927\u5c0f\u7684\u6570\uff0c\u8f93\u51fa\u6570\u6240\u5728\u7684\u4f4d\u7f6e\u3002\u4f8b\u5982{2\uff0c4\uff0c3\uff0c4\uff0c7}\u4e2d\uff0c\u7b2c\u4e00\u5927\u7684\u6570\u662f7\uff0c\u4f4d\u7f6e\u57284\u3002\u7b2c\u4e8c\u5927\u3001\u7b2c\u4e09\u5927\u7684\u6570\u90fd\u662f4\uff0c\u4f4d\u7f6e\u57281\u30013\u968f\u4fbf\u8f93\u51fa\u54ea\u4e00\u4e2a\u5747\u53ef\u3002\n\n##### 3.5.3 \u7ed940\u4ebf\u4e2a\u4e0d\u91cd\u590d\u7684unsigned int\u7684\u6574\u6570\uff0c\u6ca1\u6392\u8fc7\u5e8f\u7684\uff0c\u7136\u540e\u518d\u7ed9\u51e0\u4e2a\u6570\uff0c\u5982\u4f55\u5feb\u901f\u5224\u65ad\u8fd9\u51e0\u4e2a\u6570\u662f\u5426\u5728\u90a340\u4ebf\u4e2a\u6570\u5f53\u4e2d?\n\n##### 3.5.4 \u5728\u4e00\u4e2a\u6587\u4ef6\u4e2d\u670910G\u4e2a\u6574\u6570\uff0c\u4e71\u5e8f\u6392\u5217\uff0c\u8981\u6c42\u627e\u51fa\u4e2d\u4f4d\u6570\u3002\u5185\u5b58\u9650\u5236\u4e3a2G\u3002\n\n##### 3.5.5 \u65f6\u5206\u79d2\u9488\u5728\u4e00\u5929\u4e4b\u7c7b\u91cd\u5408\u591a\u5c11\u6b21\uff1f\uff0824\u5c0f\u65f6\uff09\n\n##### 3.5.6 \u5c06\u591a\u4e2a\u96c6\u5408\u5408\u5e76\u6210\u6ca1\u6709\u4ea4\u96c6\u7684\u96c6\u5408\u3002\n\n##### 3.5.7 \u5e73\u9762\u5185\u670911\u4e2a\u70b9\uff0c\u7531\u5b83\u4eec\u8fde\u621048\u6761\u4e0d\u540c\u7684\u76f4\u7ebf\uff0c\u7531\u8fd9\u4e9b\u70b9\u53ef\u8fde\u6210\u591a\u5c11\u4e2a\u4e09\u89d2\u5f62\uff1f\n\n<br>\n\n<h3 id=\"4\">\u817e\u8baf\u7bc7</h3>\n\n---\n\n#### Java\u57fa\u7840\n\n##### 4.1.0 JAVA\u4e2d\u7684\u51e0\u79cd\u57fa\u672c\u6570\u636e\u7c7b\u578b\u662f\u4ec0\u4e48\uff0c\u5404\u81ea\u5360\u7528\u591a\u5c11\u5b57\u8282\u3002\n\n##### 4.1.1 String\u7c7b\u80fd\u88ab\u7ee7\u627f\u5417\uff0c\u4e3a\u4ec0\u4e48\u3002\n\n##### 4.1.2 String\uff0cStringbuffer\uff0cStringBuilder\u7684\u533a\u522b\u3002\n\n##### 4.1.3 ArrayList\u548cLinkedList\u6709\u4ec0\u4e48\u533a\u522b\u3002\n\n##### 4.1.4 \u8bb2\u8bb2\u7c7b\u7684\u5b9e\u4f8b\u5316\u987a\u5e8f\uff0c\u6bd4\u5982\u7236\u7c7b\u9759\u6001\u6570\u636e\uff0c\u6784\u9020\u51fd\u6570\uff0c\u5b57\u6bb5\uff0c\u5b50\u7c7b\u9759\u6001\u6570\u636e\uff0c\u6784\u9020\u51fd\u6570\uff0c\u5b57\u6bb5\uff0c\u5f53new\u7684\u65f6\u5019\uff0c\u4ed6\u4eec\u7684\u6267\u884c\u987a\u5e8f\u3002\n\n##### 4.1.5 \u7528\u8fc7\u54ea\u4e9bMap\u7c7b\uff0c\u90fd\u6709\u4ec0\u4e48\u533a\u522b\uff0cHashMap\u662f\u7ebf\u7a0b\u5b89\u5168\u7684\u5417,\u5e76\u53d1\u4e0b\u4f7f\u7528\u7684Map\u662f\u4ec0\u4e48\uff0c\u4ed6\u4eec\u5185\u90e8\u539f\u7406\u5206\u522b\u662f\u4ec0\u4e48\uff0c\u6bd4\u5982\u5b58\u50a8\u65b9\u5f0f\uff0chashcode\uff0c\u6269\u5bb9\uff0c\u9ed8\u8ba4\u5bb9\u91cf\u7b49\u3002\n\n##### 4.1.6 JAVA8\u7684ConcurrentHashMap\u4e3a\u4ec0\u4e48\u653e\u5f03\u4e86\u5206\u6bb5\u9501\uff0c\u6709\u4ec0\u4e48\u95ee\u9898\u5417\uff0c\u5982\u679c\u4f60\u6765\u8bbe\u8ba1\uff0c\u4f60\u5982\u4f55\u8bbe\u8ba1\u3002\n\n##### 4.1.7 \u6709\u6ca1\u6709\u6709\u987a\u5e8f\u7684Map\u5b9e\u73b0\u7c7b\uff0c\u5982\u679c\u6709\uff0c\u4ed6\u4eec\u662f\u600e\u4e48\u4fdd\u8bc1\u6709\u5e8f\u7684\u3002\n\n##### 4.1.8 \u62bd\u8c61\u7c7b\u548c\u63a5\u53e3\u7684\u533a\u522b\uff0c\u7c7b\u53ef\u4ee5\u7ee7\u627f\u591a\u4e2a\u7c7b\u4e48\uff0c\u63a5\u53e3\u53ef\u4ee5\u7ee7\u627f\u591a\u4e2a\u63a5\u53e3\u4e48,\u7c7b\u53ef\u4ee5\u5b9e\u73b0\u591a\u4e2a\u63a5\u53e3\u4e48\u3002\n\n##### 4.1.9 \u7ee7\u627f\u548c\u805a\u5408\u7684\u533a\u522b\u5728\u54ea\u3002\n\n##### 4.2.0 IO\u6a21\u578b\u6709\u54ea\u4e9b\uff0c\u8bb2\u8bb2\u4f60\u7406\u89e3\u7684nio \uff0c\u4ed6\u548cbio\uff0caio\u7684\u533a\u522b\u662f\u5565\uff0c\u8c08\u8c08reactor\u6a21\u578b\u3002\n\n##### 4.2.1 \u53cd\u5c04\u7684\u539f\u7406\uff0c\u53cd\u5c04\u521b\u5efa\u7c7b\u5b9e\u4f8b\u7684\u4e09\u79cd\u65b9\u5f0f\u662f\u4ec0\u4e48\u3002\n\n##### 4.2.2 \u53cd\u5c04\u4e2d\uff0cClass.forName\u548cClassLoader\u533a\u522b \u3002\n\n##### 4.2.3 \u63cf\u8ff0\u52a8\u6001\u4ee3\u7406\u7684\u51e0\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff0c\u5206\u522b\u8bf4\u51fa\u76f8\u5e94\u7684\u4f18\u7f3a\u70b9\u3002\n\n##### 4.2.4 \u52a8\u6001\u4ee3\u7406\u4e0ecglib\u5b9e\u73b0\u7684\u533a\u522b\u3002\n\n##### 4.2.5 \u4e3a\u4ec0\u4e48CGlib\u65b9\u5f0f\u53ef\u4ee5\u5bf9\u63a5\u53e3\u5b9e\u73b0\u4ee3\u7406\u3002\n\n##### 4.2.6 final\u7684\u7528\u9014\u3002\n\n##### 4.2.7 \u5199\u51fa\u4e09\u79cd\u5355\u4f8b\u6a21\u5f0f\u5b9e\u73b0 \u3002\n\n##### 4.2.8 \u5982\u4f55\u5728\u7236\u7c7b\u4e2d\u4e3a\u5b50\u7c7b\u81ea\u52a8\u5b8c\u6210\u6240\u6709\u7684hashcode\u548cequals\u5b9e\u73b0\uff1f\u8fd9\u4e48\u505a\u6709\u4f55\u4f18\u52a3\u3002\n\n##### 4.2.9 \u8bf7\u7ed3\u5408OO\u8bbe\u8ba1\u7406\u5ff5\uff0c\u8c08\u8c08\u8bbf\u95ee\u4fee\u9970\u7b26public\u3001private\u3001protected\u3001default\u5728\u5e94\u7528\u8bbe\u8ba1\u4e2d\u7684\u4f5c\u7528\u3002\n\n##### 4.3.0 \u6df1\u62f7\u8d1d\u548c\u6d45\u62f7\u8d1d\u533a\u522b\u3002\n\n##### 4.3.1 \u6570\u7ec4\u548c\u94fe\u8868\u6570\u636e\u7ed3\u6784\u63cf\u8ff0\uff0c\u5404\u81ea\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002\n\n##### 4.3.2 error\u548cexception\u7684\u533a\u522b\uff0cCheckedException\uff0cRuntimeException\u7684\u533a\u522b\u3002\n\n##### 4.3.3 \u8bf7\u5217\u51fa5\u4e2a\u8fd0\u884c\u65f6\u5f02\u5e38\u3002\n\n##### 4.3.4 \u5728\u81ea\u5df1\u7684\u4ee3\u7801\u4e2d\uff0c\u5982\u679c\u521b\u5efa\u4e00\u4e2ajava.lang.String\u7c7b\uff0c\u8fd9\u4e2a\u7c7b\u662f\u5426\u53ef\u4ee5\u88ab\u7c7b\u52a0\u8f7d\u5668\u52a0\u8f7d\uff1f\u4e3a\u4ec0\u4e48\u3002\n\n##### 4.3.5 \u8bf4\u4e00\u8bf4\u4f60\u5bf9java.lang.Object\u5bf9\u8c61\u4e2dhashCode\u548cequals\u65b9\u6cd5\u7684\u7406\u89e3\u3002\u5728\u4ec0\u4e48\u573a\u666f\u4e0b\u9700\u8981\u91cd\u65b0\u5b9e\u73b0\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u3002\n\n##### 4.3.6 \u5728jdk1.5\u4e2d\uff0c\u5f15\u5165\u4e86\u6cdb\u578b\uff0c\u6cdb\u578b\u7684\u5b58\u5728\u662f\u7528\u6765\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898\u3002\n\n##### 4.3.7 \u8fd9\u6837\u7684a.hashcode() \u6709\u4ec0\u4e48\u7528\uff0c\u4e0ea.equals(b)\u6709\u4ec0\u4e48\u5173\u7cfb\u3002\n\n##### 4.3.8 \u6709\u6ca1\u6709\u53ef\u80fd2\u4e2a\u4e0d\u76f8\u7b49\u7684\u5bf9\u8c61\u6709\u76f8\u540c\u7684hashcode\u3002\n\n##### 4.3.9 Java\u4e2d\u7684HashSet\u5185\u90e8\u662f\u5982\u4f55\u5de5\u4f5c\u7684\u3002\n\n##### 4.4.0 \u4ec0\u4e48\u662f\u5e8f\u5217\u5316\uff0c\u600e\u4e48\u5e8f\u5217\u5316\uff0c\u4e3a\u4ec0\u4e48\u5e8f\u5217\u5316\uff0c\u53cd\u5e8f\u5217\u5316\u4f1a\u9047\u5230\u4ec0\u4e48\u95ee\u9898\uff0c\u5982\u4f55\u89e3\u51b3\u3002\n\n##### 4.4.1 java8\u7684\u65b0\u7279\u6027\u3002\n\n#### JVM\n\n##### 4.4.2 \u4ec0\u4e48\u60c5\u51b5\u4e0b\u4f1a\u53d1\u751f\u6808\u5185\u5b58\u6ea2\u51fa\u3002\n\n##### 4.4.3 JVM\u7684\u5185\u5b58\u7ed3\u6784\uff0cEden\u548cSurvivor\u6bd4\u4f8b\u3002\n\n##### 4.4.4 JVM\u5185\u5b58\u4e3a\u4ec0\u4e48\u8981\u5206\u6210\u65b0\u751f\u4ee3\uff0c\u8001\u5e74\u4ee3\uff0c\u6301\u4e45\u4ee3\u3002\u65b0\u751f\u4ee3\u4e2d\u4e3a\u4ec0\u4e48\u8981\u5206\u4e3aEden\u548cSurvivor\u3002\n\n##### 4.4.5 JVM\u4e2d\u4e00\u6b21\u5b8c\u6574\u7684GC\u6d41\u7a0b\u662f\u600e\u6837\u7684\uff0c\u5bf9\u8c61\u5982\u4f55\u664b\u5347\u5230\u8001\u5e74\u4ee3\uff0c\u8bf4\u8bf4\u4f60\u77e5\u9053\u7684\u51e0\u79cd\u4e3b\u8981\u7684JVM\u53c2\u6570\u3002\n\n##### 4.4.6 \u4f60\u77e5\u9053\u54ea\u51e0\u79cd\u5783\u573e\u6536\u96c6\u5668\uff0c\u5404\u81ea\u7684\u4f18\u7f3a\u70b9\uff0c\u91cd\u70b9\u8bb2\u4e0bcms\u548cG1\uff0c\u5305\u62ec\u539f\u7406\uff0c\u6d41\u7a0b\uff0c\u4f18\u7f3a\u70b9\u3002\n\n##### 4.4.7 \u5783\u573e\u56de\u6536\u7b97\u6cd5\u7684\u5b9e\u73b0\u539f\u7406\u3002\n\n##### 4.4.8 \u5f53\u51fa\u73b0\u4e86\u5185\u5b58\u6ea2\u51fa\uff0c\u4f60\u600e\u4e48\u6392\u9519\u3002\n\n##### 4.4.9 JVM\u5185\u5b58\u6a21\u578b\u7684\u76f8\u5173\u77e5\u8bc6\u4e86\u89e3\u591a\u5c11\uff0c\u6bd4\u5982\u91cd\u6392\u5e8f\uff0c\u5185\u5b58\u5c4f\u969c\uff0chappen-before\uff0c\u4e3b\u5185\u5b58\uff0c\u5de5\u4f5c\u5185\u5b58\u7b49\u3002\n\n##### 4.5.0 \u7b80\u5355\u8bf4\u8bf4\u4f60\u4e86\u89e3\u7684\u7c7b\u52a0\u8f7d\u5668\uff0c\u53ef\u4ee5\u6253\u7834\u53cc\u4eb2\u59d4\u6d3e\u4e48\uff0c\u600e\u4e48\u6253\u7834\u3002\n\n##### 4.5.1 \u8bb2\u8bb2JAVA\u7684\u53cd\u5c04\u673a\u5236\u3002\n\n##### 4.5.2 \u4f60\u4eec\u7ebf\u4e0a\u5e94\u7528\u7684JVM\u53c2\u6570\u6709\u54ea\u4e9b\u3002\n\n##### 4.5.3 g1\u548ccms\u533a\u522b,\u541e\u5410\u91cf\u4f18\u5148\u548c\u54cd\u5e94\u4f18\u5148\u7684\u5783\u573e\u6536\u96c6\u5668\u9009\u62e9\u3002\n\n##### 4.5.4 \u600e\u4e48\u6253\u51fa\u7ebf\u7a0b\u6808\u4fe1\u606f\u3002\n\n#### \u5f00\u6e90\u6846\u67b6\n\n##### 4.5.5 \u7b80\u5355\u8bb2\u8bb2tomcat\u7ed3\u6784\uff0c\u4ee5\u53ca\u5176\u7c7b\u52a0\u8f7d\u5668\u6d41\u7a0b\uff0c\u7ebf\u7a0b\u6a21\u578b\u7b49\u3002\n\n##### 4.5.6 tomcat\u5982\u4f55\u8c03\u4f18\uff0c\u6d89\u53ca\u54ea\u4e9b\u53c2\u6570 \u3002\n\n##### 4.5.7 \u8bb2\u8bb2Spring\u52a0\u8f7d\u6d41\u7a0b\u3002\n\n##### 4.5.8 Spring AOP\u7684\u5b9e\u73b0\u539f\u7406\u3002\n\n##### 4.5.9 \u8bb2\u8bb2Spring\u4e8b\u52a1\u7684\u4f20\u64ad\u5c5e\u6027\u3002\n\n##### 4.6.0 Spring\u5982\u4f55\u7ba1\u7406\u4e8b\u52a1\u7684\u3002\n\n##### 4.6.1 Spring\u600e\u4e48\u914d\u7f6e\u4e8b\u52a1\uff08\u5177\u4f53\u8bf4\u51fa\u4e00\u4e9b\u5173\u952e\u7684xml \u5143\u7d20\uff09\u3002\n\n##### 4.6.2 \u8bf4\u8bf4\u4f60\u5bf9Spring\u7684\u7406\u89e3\uff0c\u975e\u5355\u4f8b\u6ce8\u5165\u7684\u539f\u7406\uff1f\u5b83\u7684\u751f\u547d\u5468\u671f\uff1f\u5faa\u73af\u6ce8\u5165\u7684\u539f\u7406\uff0caop\u7684\u5b9e\u73b0\u539f\u7406\uff0c\u8bf4\u8bf4aop\u4e2d\u7684\u51e0\u4e2a\u672f\u8bed\uff0c\u5b83\u4eec\u662f\u600e\u4e48\u76f8\u4e92\u5de5\u4f5c\u7684\u3002\n\n##### 4.6.3 Springmvc \u4e2dDispatcherServlet\u521d\u59cb\u5316\u8fc7\u7a0b\u3002\n\n##### 4.6.4 netty\u7684\u7ebf\u7a0b\u6a21\u578b\uff0cnetty\u5982\u4f55\u57fa\u4e8ereactor\u6a21\u578b\u4e0a\u5b9e\u73b0\u7684\u3002\n\n##### 4.6.5 \u4e3a\u4ec0\u4e48\u9009\u62e9netty\u3002\n\n##### 4.6.6 \u4ec0\u4e48\u662fTCP\u7c98\u5305\uff0c\u62c6\u5305\u3002\u89e3\u51b3\u65b9\u5f0f\u662f\u4ec0\u4e48\u3002\n\n##### 4.6.7 netty\u7684fashwheeltimer\u7684\u7528\u6cd5\uff0c\u5b9e\u73b0\u539f\u7406\uff0c\u662f\u5426\u51fa\u73b0\u8fc7\u8c03\u7528\u4e0d\u591f\u51c6\u65f6\uff0c\u600e\u4e48\u89e3\u51b3\u3002\n\n##### 4.6.8 netty\u7684\u5fc3\u8df3\u5904\u7406\u5728\u5f31\u7f51\u4e0b\u600e\u4e48\u529e\u3002\n\n##### 4.6.9 netty\u7684\u901a\u8baf\u534f\u8bae\u662f\u4ec0\u4e48\u6837\u7684\u3002\n\n##### 4.7.0 springmvc\u7528\u5230\u7684\u6ce8\u89e3\uff0c\u4f5c\u7528\u662f\u4ec0\u4e48\uff0c\u539f\u7406\u3002\n\n##### 4.7.1 springboot\u542f\u52a8\u673a\u5236\u3002\n\n#### \u64cd\u4f5c\u7cfb\u7edf\n\n##### 4.7.2 Linux\u7cfb\u7edf\u4e0b\u4f60\u5173\u6ce8\u8fc7\u54ea\u4e9b\u5185\u6838\u53c2\u6570\uff0c\u8bf4\u8bf4\u4f60\u77e5\u9053\u7684\u3002\n\n##### 4.7.3 Linux\u4e0bIO\u6a21\u578b\u6709\u51e0\u79cd\uff0c\u5404\u81ea\u7684\u542b\u4e49\u662f\u4ec0\u4e48\u3002\n\n##### 4.7.4 epoll\u548cpoll\u6709\u4ec0\u4e48\u533a\u522b\u3002\n\n##### 4.7.5 \u5e73\u65f6\u7528\u5230\u54ea\u4e9bLinux\u547d\u4ee4\u3002\n\n##### 4.7.6 \u7528\u4e00\u884c\u547d\u4ee4\u67e5\u770b\u6587\u4ef6\u7684\u6700\u540e\u4e94\u884c\u3002\n\n##### 4.7.7 \u7528\u4e00\u884c\u547d\u4ee4\u8f93\u51fa\u6b63\u5728\u8fd0\u884c\u7684java\u8fdb\u7a0b\u3002\n\n##### 4.7.8 \u4ecb\u7ecd\u4e0b\u4f60\u7406\u89e3\u7684\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7ebf\u7a0b\u5207\u6362\u8fc7\u7a0b\u3002\n\n##### 4.7.9 \u8fdb\u7a0b\u548c\u7ebf\u7a0b\u7684\u533a\u522b\u3002\n\n##### 4.8.0 top \u547d\u4ee4\u4e4b\u540e\u6709\u54ea\u4e9b\u5185\u5bb9\uff0c\u6709\u4ec0\u4e48\u4f5c\u7528\u3002\n\n##### 4.8.1 \u7ebf\u4e0aCPU\u7206\u9ad8\uff0c\u8bf7\u95ee\u4f60\u5982\u4f55\u627e\u5230\u95ee\u9898\u6240\u5728\u3002\n\n<br>\n\n<h3 id=\"5\">\u7f8e\u56e2\u7bc7</h3>\n\n---\n\n##### 5.1.0 java\u865a\u62df\u673a\u5185\u5b58\u6a21\u578b\n\n##### 5.1.1 \u5185\u5b58\u6ea2\u51fa\u4e00\u822c\u53d1\u751f\u5728\u54ea\u4e2a\u533a\uff1f\u6c38\u4e45\u4ee3\u4f1a\u4e0d\u4f1a\u5bfc\u81f4\u5185\u5b58\u6ea2\u51fa\uff1f\n\n##### 5.1.2 \u52a8\u6001\u52a0\u8f7d\u7c7b\u7684\u6846\u67b6\u4e86\u89e3\u54ea\u4e9b\uff1f\n\n##### 5.1.3 \u52a8\u6001\u4ee3\u7406\u4e00\u822c\u6709\u54ea\u51e0\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff1f\u52a8\u6001\u4ee3\u7406\u7684\u5e94\u7528\u573a\u666f\u6709\u54ea\u4e9b\uff1f\n\n##### 5.1.4 \u6808\u4f1a\u4e0d\u4f1a\u6ea2\u51fa\uff1f\u6808\u6ea2\u51fa\u4e00\u822c\u629b\u4ec0\u4e48\u5f02\u5e38\uff1fjvm\u5728\u54ea\u91cc\u8bbe\u7f6e\u6808\u7684\u5927\u5c0f\uff1f\u8bbe\u7f6e\u7684\u53c2\u6570\u662f\u4ec0\u4e48\uff1f\n\n##### 5.1.5 \u7528\u8fc7\u54ea\u4e9b\u547d\u4ee4\u67e5\u770bjvm\u7684\u72b6\u6001\u3001\u5806\u6808\u4fe1\u606f\uff1f\n\n##### 5.1.6 jvm\u7684\u5783\u573e\u56de\u6536\u673a\u5236\uff1f\n\n##### 5.1.7 java\u7c7b\u52a0\u8f7d\u673a\u5236\uff1f\u5982\u4f55\u5b9e\u73b0\u81ea\u5b9a\u4e49\u7c7b\u52a0\u8f7d\u5668\uff1ffindClass\u4e0eloadClass\u7684\u533a\u522b\uff1f\n\n##### 5.1.8 String\u3001StringBuffer\u3001StringBuilder\u7684\u533a\u522b\uff1f\u5bf9\u5e94\u7684\u4f7f\u7528\u573a\u666f\uff1f\n\n##### 5.1.9 \u5982\u4f55\u5b9e\u73b0\u4e0d\u53ef\u53d8\u7684\u7c7b\uff1f\n\n##### 5.2.0 \u6d45\u590d\u5236\u548c\u6df1\u590d\u5236\uff1f\u600e\u6837\u5b9e\u73b0\u6df1\u590d\u5236\uff1f\n\n##### 5.2.1 HashMap\u3001HashTable\u3001ConcurrentHashMap\u7684\u533a\u522b\uff1f\n\n##### 5.2.2 CAS\u662f\u4e00\u79cd\u4ec0\u4e48\u6837\u7684\u540c\u6b65\u673a\u5236\uff1f\n\n##### 5.2.3 NIO\u7684\u539f\u7406\uff0c\u5305\u62ec\u54ea\u51e0\u4e2a\u7ec4\u4ef6\uff1f\n\n##### 5.2.4 \u7b80\u5355\u4ecb\u7ecd\u4e00\u4e0bjava\u7684\u53cd\u5c04\u673a\u5236\uff1f\u53cd\u5c04\u5728\u54ea\u4e9b\u5730\u65b9\u6709\u5e94\u7528\u573a\u666f\uff1f\n\n##### 5.2.5 spring\u52a0\u8f7dbean\u7684\u6d41\u7a0b\uff1f\n\n##### 5.2.6 java\u7ebf\u7a0b\u6c60\uff1f\u7ebf\u7a0b\u6c60\u6784\u9020\u51fd\u6570\u7684\u51e0\u4e2a\u53c2\u6570\u542b\u4e49\uff1fkeepAliveTime\u89e3\u91ca\u4e00\u4e0b\uff1f\n\n##### 5.2.7 \u4e00\u4e2a\u63a5\u53e3\uff0c\u8981\u53bb\u8c03\u7528\u53e6\u59165\u4e2a\u63a5\u53e3\uff0c\u6bcf\u4e00\u4e2a\u63a5\u53e3\u90fd\u4f1a\u8fd4\u56de\u6570\u636e\u7ed9\u8fd9\u4e2a\u8c03\u7528\u63a5\u53e3\uff0c\u8c03\u7528\u63a5\u53e3\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u5408\u5e76\u5e76\u8fd4\u56de\u7ed9\u4e0a\u5c42\u3002\u8fd9\u6837\u4e00\u79cd\u573a\u666f\u53ef\u80fd\u7528\u5230\u5e76\u53d1\u5305\u4e0b\u7684\u54ea\u4e9b\u7c7b\uff1f\u4f60\u4f1a\u600e\u4e48\u53bb\u5b9e\u73b0\u8fd9\u6837\u7684\u4e1a\u52a1\u573a\u666f\uff1f\n\n##### 5.2.8 CountDownLatch\u548cCyclicBarrier\u7684\u533a\u522b\uff1f\n\n##### 5.2.9 \u7ebf\u7a0b\u52a0\u9501\u6709\u54ea\u4e9b\u65b9\u5f0f\uff1fsynchronized\u548clock\u7684\u533a\u522b\uff1f\n\n##### 5.3.0 volatile\u5173\u952e\u5b57\u7684\u4f5c\u7528\uff1f\u4e3a\u4ec0\u4e48\u4f7f\u7528AtomicLong\u800c\u4e0d\u4f7f\u7528Long?AtomicLong\u7684\u5e95\u5c42\u662f\u600e\u4e48\u5b9e\u73b0\u7684\uff1f\n\n##### 5.3.1 mysql\u7684\u5b58\u50a8\u5f15\u64ce\u6709\u54ea\u51e0\u79cd\uff1f\n\n##### 5.3.2 sql\u4f18\u5316\u6709\u54ea\u4e9b\u7740\u624b\u70b9\uff1f\u7ec4\u5408\u7d22\u5f15\u7684\u6700\u5de6\u524d\u7f00\u539f\u5219\u7684\u542b\u4e49\uff1f\n\n##### 5.3.3 springmvc\u5904\u7406\u8bf7\u6c42\u7684\u6d41\u7a0b\uff1f\n\n##### 5.3.4 spring\u7684\u4e8b\u52a1\u600e\u4e48\u4f7f\u7528\uff1f\u4e8b\u52a1\u56de\u6eda\uff1f\u81ea\u5b9a\u4e49\u5f02\u5e38\uff1f\n\n##### 5.3.5 \u810f\u8bfb\uff1f\u5e7b\u8bfb\uff1f\n\n##### 5.3.6 tcp\u56db\u6b21\u6325\u624b\u7684\u8fc7\u7a0b\uff1fTIME_WAIT\u4e3a\u4ec0\u4e48\u81f3\u5c11\u8bbe\u7f6e\u4e24\u500d\u7684MSL\u65f6\u95f4\uff1f\n\n##### 5.3.7 get\u548cpost\u8bf7\u6c42\u7684\u533a\u522b\uff1f\n\n##### 5.3.8 cookie\u548csession\u7684\u8bf7\u6c42\uff1f\n\n##### 5.3.9 \u4e86\u89e3\u54ea\u4e9b\u5f00\u6e90\u7684\u4e2d\u95f4\u4ef6\uff1f\u7f13\u5b58\uff1f\u6d88\u606f\uff1f\u5206\u5e03\u5f0f\u6846\u67b6\uff1f\n\n##### 5.4.0 \u7528\u5230\u8fc7\u54ea\u4e9b\u8bbe\u8ba1\u6a21\u5f0f\uff1f\u5355\u4f8b\u6a21\u5f0f\u7684\u5b9e\u73b0\uff1f\n\n##### 5.4.1 \u6570\u636e\u5e93\u7684\u4e8b\u52a1\u5b9e\u73b0\u539f\u7406\u3001\u64cd\u4f5c\u8fc7\u7a0b\u3001\u5982\u4f55\u505a\u5230\u4e8b\u7269\u4e4b\u95f4\u7684\u72ec\u7acb\u6027\u7b49\u95ee\u9898\n\n##### 5.4.2 \u6570\u636e\u5e93\u7684\u810f\u8bfb\uff0c\u5e7b\u8bfb\uff0c\u4e0d\u53ef\u91cd\u590d\u8bfb\u51fa\u73b0\u7684\u539f\u56e0\u539f\u7406\uff0c\u89e3\u51b3\u529e\u6cd5\n\n##### 5.4.3 \u6570\u636e\u5e93\u7684\u9694\u79bb\u7ea7\u522b\u3001MVCC\n\n##### 5.4.4 \u4e50\u89c2\u9501\u3001\u60b2\u89c2\u9501\u3001\u4e92\u65a5\u9501\u3001\u8bfb\u5199\u9501\u7684\u539f\u7406\u5b9e\u73b0\u4e0e\u533a\u522b\n\n##### 5.4.5 \u7ebf\u7a0b\u7684\u751f\u547d\u5468\u671f\n\n##### 5.4.6 \u4e00\u81f4\u6027hash\u7b97\u6cd5\u539f\u7406\u4e0e\u5e94\u7528\n\n##### 5.4.7 CAP\u539f\u5219\n\n##### 5.4.8 CAS\u64cd\u4f5c\n\n##### 5.4.9 \u5206\u5e03\u5f0fraft\u7b97\u6cd5\n\n<br>\n\n<h3 id=\"6\">\u5934\u6761\u7bc7</h3>\n\n---\n\n##### 6.1.0 5\u4e2a\u4eba\u53bb\u4e00\u4e2a\u6d77\u5c9b\u5bfb\u5b9d\uff0c\u6700\u540e\u4e00\u5171\u627e\u5230\u4e86100\u679a\u91d1\u5e01\u3002\u4ed6\u4eec\u7ea6\u5b9a\u4e86\u4e00\u4e2a\u5206\u914d\u65b9\u6848\u3002\n\n##### 6.1.1 \u7ed9\u4f60\u4e00\u4e2a\u6709\u5e8f\u6574\u6570\u6570\u7ec4\uff0c\u6570\u7ec4\u4e2d\u7684\u6570\u53ef\u4ee5\u662f\u6b63\u6570\u3001\u8d1f\u6570\u3001\u96f6\uff0c\u8bf7\u5b9e\u73b0\u4e00\u4e2a\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u6574\u6570\uff1a\u8fd4\u56de\u8fd9\u4e2a\u6570\u7ec4\u6240\u6709\u6570\u7684\u5e73\u65b9\u503c\u4e2d\u6709\u591a\u5c11\u79cd\u4e0d\u540c\u7684\u53d6\u503c\u3002\n\n##### 6.1.2 \u4e00\u4e2a\u73af\u670910\u4e2a\u8282\u70b9\uff0c\u7f16\u53f70-9\u3002\u4ece0\u70b9\u51fa\u53d1\uff0c\u8d70N\u6b65\u53c8\u80fd\u56de\u52300\u70b9\uff0c\u5171\u6709\u591a\u5c11\u79cd\u8d70\u6cd5\uff1f\n\n##### 6.1.3 \u4e00\u4e2a\u4e71\u5e8f\u6570\u7ec4\uff0c\u6c42\u7b2cK\u5927\u7684\u6570\u3002\u6392\u5e8f\u65b9\u5f0f\u4f7f\u7528\u5b57\u5178\u5e8f\u3002\n\n##### 6.1.4 \u4e00\u68f5\u4e8c\u53c9\u6811\uff0c\u6c42\u6700\u5927\u901a\u8def\u957f\u5ea6\u3002\uff08\u5373\u6700\u5927\u5de6\u53f3\u5b50\u6811\u9ad8\u5ea6\u4e4b\u548c\uff09\n\n##### 6.1.5 \u8fdb\u7a0b\u548c\u7ebf\u7a0b\u7684\u533a\u522b\uff0c\u4f7f\u7528\u7ebf\u7a0b\u771f\u7684\u80fd\u8282\u7701\u65f6\u95f4\uff1f\n\n##### 6.1.6 go\u534f\u7a0b\u7684\u8c03\u5ea6\u65b9\u5f0f\uff0c\u4f7f\u7528\u534f\u7a0b\u771f\u7684\u80fd\u8282\u7701\u65f6\u95f4\uff1f\n\n##### 6.1.7 \u6c34\u5e73\u89e6\u53d1\u8fb9\u6cbf\u89e6\u53d1\u7684\u533a\u522b\uff1f\u5728\u8fb9\u6cbf\u89e6\u53d1\u4e0b\uff0c\u4e00\u4e2asocket\u6709500\u7684\u6570\u636e\uff0c\u5df2\u8bfb\u53d6200\u7136\u540e\u4e0d\u518d\u5904\u7406\uff0c\u662f\u4e0d\u662f\u5269\u4e0b\u7684300\u5c31\u6c38\u8fdc\u65e0\u6cd5\u8bfb\u53d6\uff1f\n\n##### 6.1.8 \u6709\u51fd\u6570\u5982\u4e0b\uff0c\u8f93\u51651\uff0c\u8fd4\u56de\u4ec0\u4e48\uff1f\n\n##### 6.1.9 \u8bbe\u8ba1http\u534f\u8bae\uff0cA\u7aef\u53d1\u9001 AAAA\uff0c\u81f3\u5c11\u8ba9B\u7aef\u77e5\u9053AAAA\u5df2\u53d1\u9001\u5b8c\u6210\u3002\n\n##### 6.2.0 \u6d41\u91cf\u603b\u5165\u53e3\u4e3aapi_gateway\uff0capi_gateway\u6302\u4e86\u4f1a\u5bfc\u81f4\u5168\u90e8\u6302\u6302\uff0c\u7528\u4ec0\u4e48\u673a\u5236\u589e\u5927\u53ef\u7528\u6027\uff1f\n\n##### 6.2.1 mysql\u4e3a\u4ec0\u4e48\u8981\u7528b+\u6811\uff0c\u4e0d\u7528\u5e73\u8861\u4e8c\u53c9\u6811\u505a\u7d22\u5f15\u7ed3\u6784\uff1f\n\n##### 6.2.2 \u521b\u5efa\u6570\u636e\u5e93\u7d22\u5f15\u5e94\u8be5\u600e\u4e48\u8003\u8651\uff1f\n\n##### 6.2.3 \u4f7f\u7528int \u505aprimary key\u548c\u4f7f\u7528string \u6709\u4ec0\u4e48\u4f18\u52a3\uff1f\n\n##### 6.2.4 \u6570\u636e\u5e93\u5206\u8868\u7684\u65b9\u6cd5\uff1f\n\n##### 6.2.5 \u8868\u7ed3\u6784\uff0c\u8ba2\u5355\u7eaa\u5f55\u5982\u4e0b\uff0c\u5199\u4e00\u4e2a\u8bed\u53e5\uff0c\u6c42\u5356\u7684\u6700\u597d\u7684 top 10 product_id\u3002\n\n##### 6.2.6 \u5fae\u670d\u52a1\uff0cA\u670d\u52a1\u8bf7\u6c42B\u670d\u52a1B1\u63a5\u53e3\uff0cB1\u63a5\u53e3\u53c8\u8bf7\u6c42A\u670d\u52a1A2\u63a5\u53e3\u3002\u4f1a\u4e0d\u4f1a\u6709\u95ee\u9898\uff1f\n\n##### 6.2.7 \u4e0d\u4f7f\u7528\u9ad8\u7ea7\u5de5\u5177\uff0c\u53ea\u4f7f\u7528Linux\u81ea\u5e26\u7684\u5de5\u5177\uff0c\u4f60\u4f1a\u5982\u4f55debug?\n\n##### 6.2.8 \u5982\u4f55\u9884\u4f30\u4e00\u4e2amysql\u8bed\u53e5\u7684\u6027\u80fd\uff1f\n\n##### 6.2.9 go\u51fd\u6570\u4e2d\uff0c\u8fd4\u56de\u503c\u672a\u547d\u540d\uff0c\u53d1\u751f\u4e86panic\uff0c\u4f46\u662f\u5728\u51fd\u6570\u5185recover\u4e86\u3002\u51fd\u6570\u8fd4\u56de\u4ec0\u4e48\u503c\uff1f\n\n##### 6.3.0 socket\u4e2d\uff0c\u5728tcp\u534f\u8bae\u5c42\u9762\uff0c\u6570\u636e\u5206\u4e3a10\u4e2a\u62a5\u6587\u53d1\u653e\u30021-7\u6b21\u5f88\u987a\u5229\uff0c\u7b2c8\u6b21\u4e22\u5931\u3002\u8fd9\u6b21\u901a\u4fe1\u4e00\u5b9a\u5931\u8d25\u5417\uff1f\u5982\u679c\u7b2c8\u6b21\u6570\u636e\u4f1a\u91cd\u53d1\uff0c\u90a3\u5728\u63a5\u6536\u7aef\u662f\u4e0d\u662f\uff1a\u5148\u8bfb\u53d6\u52301-7\u6b21\u7684\u6570\u636e\uff0c\u7136\u540e\u8bfb\u53d6\u52308-10\u6b21\u7684\u6570\u636e?\u8fd8\u662f9-10\u6b21\u7684\u6570\u636e\u4f1a\u5148\u5230\u8fbe\uff1f\n\n##### 6.3.1 free -h\uff0cbuffers \u548ccached\u6709\u4ec0\u4e48\u4e0d\u540c\n\n##### 6.3.2 \u540e\u53f0\u8fdb\u7a0b\u6709\u4ec0\u4e48\u7279\u70b9\uff0c\u5982\u679c\u8981\u4f60\u8bbe\u8ba1\u4e00\u4e2a\u8fdb\u7a0b\u662f\u540e\u53f0\u8fdb\u7a0b\uff0c\u4f60\u4f1a\u8003\u8651\u4ec0\u4e48\n\n##### 6.3.3 \u50f5\u5c38\u8fdb\u7a0b\u662f\u4ec0\u4e48\uff0c\u5982\u679c\u4ea7\u751f\u4e00\u4e2a\u50f5\u5c38\u8fdb\u7a0b\uff0c\u5982\u4f55\u67e5\u627e\u50f5\u5c38\u8fdb\u7a0b\n\n##### 6.3.4 \u5b64\u513f\u8fdb\u7a0b\u662f\u4ec0\u4e48\n\n##### 6.3.5 \u4e00\u4e2a\u8fdb\u7a0b\u670920\u4e2a\u7ebf\u7a0b\uff0c\u5728\u67d0\u4e2a\u7ebf\u7a0b\u4e2d\u8c03\u7528fork\uff0c\u65b0\u7684\u8fdb\u7a0b\u4f1a\u670920\u4e2a\u7ebf\u7a0b\u5417\uff1f\n\n##### 6.3.6 tcp/ip \u6d41\u91cf\u63a7\u5236\u548c\u62e5\u585e\u63a7\u5236\n\n##### 6.3.7 301/302\u6709\u4ec0\u4e48\u533a\u522b\uff1f\u5e94\u7528\u4e0a\u6709\u4ec0\u4e48\u5f02\u540c\u3002\n\n##### 6.3.8 50X\u76f8\u5173\u9519\u8bef\u7801\u7684\u5185\u6db5\u662f\u4ec0\u4e48\uff1f\n\n##### 6.3.9 close wait\u548ctime wait\u662f\u4ec0\u4e48\uff1f\u5982\u4f55\u6392\u67e5\uff1f\u6709\u4ec0\u4e48\u610f\u4e49\uff1f\n\n##### 6.4.0 http req\u548cresp\u7684\u4e2d\u6570\u636e\u6709\u54ea\u4e9b\n\n##### 6.4.1 \u4ec0\u4e48\u662f\u8fde\u63a5\u7684\u534a\u6253\u5f00\uff0c\u534a\u5173\u95ed\u72b6\u6001\n\n##### 6.4.2 \u5047\u5982\u4e00\u4e2a\u4e1a\u52a1\u4f9d\u8d56\u5355\u70b9redis\uff0c\u6b64redis\u6545\u969c\u5c06\u5bfc\u81f4\u4e1a\u52a1\u4e0d\u53ef\u7528\uff0c\u5982\u4f55\u6539\u8fdb\n\n##### 6.4.3 redis sharding\u6709\u54ea\u4e9b\u505a\u6cd5\n\n##### 6.4.4 \u5f53\u5927\u91cf\u6570\u636e\u8981\u6c42\u7528redis\u4fdd\u5b58\uff0c\u5355\u673a\u5355\u70b9\u96be\u4ee5\u6ee1\u8db3\u9700\u8981\uff0c\u8bbe\u8ba1\uff08\u6362\u5bfb\u627e\uff09\u4e00\u4e2a\u8d1f\u8f7d\u5747\u8861\u7684\u65b9\u6848\n\n##### 6.4.5 \u5f53redis \u91c7\u7528hash\u505asharding\uff0c\u73b0\u5728\u67098\u4e2a\u8282\u70b9\uff0c\u8d1f\u8f7d\u65b9\u6848\u662f pos = hash(key) % 8\uff0c\u7136\u540e\u4fdd\u5b58\u5728pos\u8282\u70b9\u4e0a\u3002\u8fd9\u6837\u505a\u6709\u4ec0\u4e48\u597d\u5904\u574f\u5904\uff1f\u5f538\u4e2a\u8282\u70b9\u8981\u6269\u5145\u523010\u4e2a\u8282\u70b9\uff0c\u5e94\u8be5\u600e\u4e48\u529e\uff1f\u6709\u4ec0\u4e48\u66f4\u65b9\u4fbf\u6269\u5145\u7684\u65b9\u6848\u5417\uff1f\uff08\u4e00\u81f4\u6027hash, presharding\uff09\n\n##### 6.4.6 \u5982\u4f55\u4fdd\u8bc1redis\u548c\u6570\u636e\u5e93\u6570\u636e\u7684\u4e00\u81f4\u6027\u3002\u6bd4\u5982\u7528\u6237\u540d\u65e2\u4fdd\u5b58\u5728\u6570\u636e\u5e93\uff0c\u53c8\u4fdd\u5b58\u5728redis\u505a\u7f13\u5b58\u3002\u6709\u5982\u4e0b\u64cd\u4f5c update_db(username); update_redis(username)\u3002\u4f46\u662f\u6267\u884cupdate_db\u540e\u6545\u969c\uff0cupdate_redis\u6ca1\u6709\u6267\u884c\u3002\u6709\u4ec0\u4e48\u7b80\u5355\u529e\u6cd5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\n\n##### 6.5.0 \u6570\u636e\u5e93\u8868\u5305\u542b\u4e09\u5217\uff1a\u5e7f\u544a\u7f16\u53f7ad_id\uff0c\u5e7f\u544a\u5f00\u59cb\u6295\u653e\u65f6\u95f4ad_start\uff0c\u5e7f\u544a\u6295\u653e\u7ed3\u675f\u65f6\u95f4ad_end\u3002\u7528\u4e00\u884cSQL\u8bed\u53e5\u67e5\u8be2\u7ed9\u5b9a\u65f6\u95f4\u6bb5\u5185\u5b58\u5728\u7684\u5e7f\u544a\u3002\n\n##### 6.5.1 \u8bb2\u8bb2MapReduce\u7684\u539f\u7406\u3002\n\n##### 6.5.2 \u4e3e\u51fa\u51e0\u79cd\u8fdb\u7a0b\u901a\u4fe1\u3001\u7ebf\u7a0b\u901a\u4fe1\u7684\u65b9\u5f0f\u3002\n\n##### 6.5.3 \u5bf9\u5217\u8868\u4e2d\u6bcf\u4e00\u4e2a\u5143\u7d20\u627e\u51fa\u6bd4\u5b83\u5927\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\uff1a\u8f93\u5165\u4e00\u4e2alistin\uff0c\u8fd4\u56de\u4e00\u4e2alistout\u3002\u5bf9\u4e8e\u4efb\u610flistin[x]\uff0c\u5c06\u6ee1\u8db3 y > x \u4e14 listin[y] > listin[x] \u7684\u7b2c\u4e00\u4e2a listin[y] \u503c\u4f5c\u4e3a listout[x] \u7684\u503c\u3002\u65f6\u95f4\u590d\u6742\u5ea6\u9650\u5236\u4e3aO(n)\u3002\n\n\n<h3 id=\"7\">\u6ef4\u6ef4\u7bc7</h3>\n\n---\n\n##### 7.1.0 B+\u6811\u3001B-\u6811\u7684\u533a\u522b?\n\n##### 7.1.1 \u6570\u636e\u5e93\u9694\u79bb\u7ea7\u522b\uff0c\u5e7b\u8bfb\u548c\u4e0d\u53ef\u91cd\u590d\u8bfb\u7684\u533a\u522b\uff1f\n\n##### 7.1.2 \u6709hell, well, hello, world\u7b49\u5b57\u7b26\u4e32\u7ec4\uff0c\u73b0\u5728\u95ee\u80fd\u5426\u62fc\u63a5\u6210helloworld\uff0c\u4ee3\u7801\u5b9e\u73b0\u3002\n\n##### 7.1.3 \u5feb\u6392\u7b97\u6cd5\u5b9e\u73b0\n\n##### 7.1.4 \u7ebf\u7a0b\u5b89\u5168\u7684\u5355\u4f8b\u6a21\u5f0f\n\n##### 7.1.5 25\u5339\u9a6c\u8d5b\u8dd1\uff0c\u6709\u4e00\u4e2a\u8d5b\u573a\uff0c\u53ea\u6709\u4e94\u4e2a\u8d5b\u9053\uff0c\u6ca1\u6709\u8ba1\u65f6\u5668\uff0c\u53ea\u80fd\u901a\u8fc7\u76ee\u6d4b\u6765\u8bb0\u5f55\u5feb\u6162\uff0c\u6c42\u51fa\u7b2c\u4e093\u5feb\u7684\u9a6c\u8981\u591a\u5c11\u573a\u6bd4\u8d5b\uff1f\n\n##### 7.1.6 kmp\u7b97\u6cd5next\u6570\u7ec4\u7684\u6c42\u89e3\u601d\u8def\n\n##### 7.1.7 \u6570\u7ec4\u4e2d\u6709\u4e09\u4e2a\u6570\u5b57\u51fa\u73b0\u8d85\u8fc73/4\uff0c\u6c42\u8fd9\u4e09\u4e2a\u6570\u5b57\uff1f\n\n##### 7.1.8 1\u5230n+2\u4e2a\u6570\u7ec4\u4e2d\u7f3a\u4e86\u4e24\u4e2a\u6570\uff0c\u5982\u4f55\u7528O(n)\u65f6\u95f4\uff0cO(1)\u7a7a\u95f4\u627e\u5230\u8fd9\u4e24\u4e2a\u6570\u5b57\u3002\n\n##### 7.1.9 \u4e00\u6761\u7ebf\u6bb5\u957f\u4e3a1\uff0c\u968f\u673a\u9009\u4e24\u4e2a\u70b9\uff0c\u5c06\u6539\u7ebf\u6bb5\u5206\u4e3a\u4e09\u6bb5\uff0c\u4e09\u6bb5\u80fd\u6210\u4e09\u89d2\u5f62\u7684\u6982\u7387\u662f\u591a\u5c11\uff1f\n\n##### 7.2.0 \u6709\u4e00\u4e2a\u6559\u6388\uff0c\u4ed6\u4e09\u4e2a\u5b66\u751f\uff0c\u8111\u888b\u80cc\u540e\u5206\u522b\u5404\u5199\u4e86\u4e00\u4e2a\u6570\u5b57\uff0c\u5176\u4e2d\u4e00\u4e2a\u6570\u5b57\u662f\u53e6\u5916\u4e24\u4e2a\u6570\u5b57\u7684\u548c\uff0c\u7ecf\u8fc7\u51e0\u8f6e\u540e\uff0c\u6709\u4e00\u4e2a\u5b66\u751f\u731c\u51fa\u4e86\u81ea\u5df1\u7684\u6570\u5b57\u8bf7\u95ee\u662f\u4ec0\u4e48\u539f\u56e0\uff1f\n\n##### 7.2.1 B+\u6811\u505a\u7d22\u5f15\u65f6\uff0cB+\u6811\u901a\u5e38\u9ad8\u5ea6\u4e3a\u591a\u5c11\u5c42\uff1f\u8981\u53c2\u8003\u54ea\u4e9b\u6761\u4ef6\uff1f\n\n<br>\n\n<h3 id=\"8\">\u4eac\u4e1c\u7bc7</h3>\n\n---\n\n##### 8.1.0 \u4e00\u822csql\u6ce8\u5165\u600e\u4e48\u53d1\u73b0\u89e6\u70b9\u7684\uff0c\u4ece\u6e90\u7801\u9610\u8ff0sqlmap\u5982\u4f55\u6d4b\u8bd5\u6ce8\u5165\u70b9\u7684\u3002\n\n##### 8.1.1 masscan\u626b\u63cf\u7aef\u53e3\u65f6\u9760\u4ec0\u4e48\u68c0\u6d4b\uff0c\u4e3a\u4ec0\u4e48\u8fd9\u4e48\u5feb? \u8bf7\u8be6\u8ff0.\n\n##### 8.1.2 \u4f60\u5199\u8fc7\u54ea\u4e9b\u5c0f\u5de5\u5177\uff0c\u4f60\u4e3a\u4f60\u4f7f\u7528\u8fc7\u7684\u5de5\u5177\u505a\u8fc7\u4ec0\u4e48\u4fee\u6539.\n\n##### 8.1.3 \u5982\u4f55\u63d0\u9ad8\u91c7\u7528python\u7f16\u5199\u7684\u626b\u63cf\u901f\u5ea6\uff0c\u8c08\u8c08\u5bf9GIL\u9501\u7684\u4e86\u89e3.\n\n##### 8.1.4 \u4f60\u89c9\u5f97\u4f60\u53d1\u73b0\u7684\u90a3\u4e2a\u6f0f\u6d1e\u5f71\u54cd\u6bd4\u8f83\u5927.\n\n##### 8.1.5 \u5e38\u89c1\u7684web\u6f0f\u6d1e\u6709\u54ea\u4e9b.\n\n##### 8.1.6 \u6709\u6ca1\u6709\u73a9\u8fc7\u786c\u4ef6\u5b89\u5168\uff0c\u7814\u7a76\u7a0b\u5ea6\u5982\u4f55.\n\n##### 8.1.7 \u53cd\u722c\u866b\uff0c\u5982\u679c\u662f\u4f60\u5982\u4f55\u8fdb\u884c\u53cd\u722c\u866b\uff0c\u5982\u4f55\u7ed5\u8fc7\u53cd\u722c\u63aa\u65bd\u3002 \u4f7f\u7528\u65e0\u5934\u6d4f\u89c8\u5668\u88ab\u68c0\u6d4b\u5230\u4e86\uff0c\u5982\u4f55\u7ed5\u8fc7\n\n##### 8.1.8 nmap\u626b\u63cf\u5982\u4f55\u8fdb\u884c\u626b\u63cf\u3002\u53d1\u5305\u4e0e\u534f\u8bae\uff0c\u63e1\u624b\u548c\u4e0d\u63e1\u624b\uff0c\u54ea\u4e9b\u534f\u8bae\u63e1\u624b\uff0c\u54ea\u4e9b\u4e0d\u63e1\u624b. \u5982\u4f55\u4e0d\u76f4\u63a5\u63a5\u89e6\u76ee\u6807\u670d\u52a1\u5668\u63a2\u6d4b\u5bf9\u65b9\u7aef\u53e3\u662f\u5426\u5f00\u653e\n\n##### 8.1.9 \u6709\u6ca1\u6709\u81ea\u5df1\u7f16\u5199\u8fc7yara\u626b\u63cf\u6a21\u5757\uff0c\u5982\u679c\u8981\u89e3\u51b3\u626b\u63cf{k1:v1, k2:v2, k3:v3} \uff0c\u4fdd\u8bc1\u540c\u65f6\u5728k1\u4e2d\u7684v1\u91cc\u51fa\u73b0\u7279\u5b9a\u503c\uff0ck2\u4e2d\u51fa\u73b0v2\u7279\u5b9a\u503c\uff0c\u4ee5\u53cak3,v3\u3002\u600e\u4e48\u5b9e\u73b0\n\n##### 8.2.0 xss\u4ec0\u4e48\u539f\u7406\uff0c\u5982\u4f55\u81ea\u5df1\u5b9e\u73b0\u4e00\u4e2abeef\u7c7b\u4f3c\u7684xss\u5e73\u53f0. \u65e2\u7136\u8fd9\u6837\u5b9e\u73b0\uff0c\u9762\u4e34\u7684\u8de8\u57df\u5982\u4f55\u89e3\u51b3?\n\n##### 8.2.1 ip \u9891\u7387\u9650\u5236, ip\u4fe1\u8a89\u5ea6\u6a21\u578b\uff1f\n\n##### 8.2.2 SCTP\u534f\u8bae\u662f\u4ec0\u4e48\uff1f\u5982\u4f55\u4f7f\u7528 SCTP \u4f18\u5316\u7f51\u7edc\uff1f\n\n<br>\n\n<h3 id=\"9\">mysql\u7bc7</h3> \n\n---\n\n##### [9.1.0 \u4e3b\u952e \u8d85\u952e \u5019\u9009\u952e \u5916\u952e](09.MySQL\u7bc7/9.1.0%20%E4%B8%BB%E9%94%AE%20%E8%B6%85%E9%94%AE%20%E5%80%99%E9%80%89%E9%94%AE%20%E5%A4%96%E9%94%AE.md)\n\n##### [9.1.1 \u6570\u636e\u5e93\u4e8b\u52a1\u7684\u56db\u4e2a\u7279\u6027\u53ca\u542b\u4e49](09.MySQL\u7bc7/9.1.1%20%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%9B%9B%E4%B8%AA%E7%89%B9%E6%80%A7%E5%8F%8A%E5%90%AB%E4%B9%89.md)\n\n##### [9.1.2 \u89c6\u56fe\u7684\u4f5c\u7528\uff0c\u89c6\u56fe\u53ef\u4ee5\u66f4\u6539\u4e48\uff1f](09.MySQL\u7bc7/9.1.2%20%E8%A7%86%E5%9B%BE%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%8C%E8%A7%86%E5%9B%BE%E5%8F%AF%E4%BB%A5%E6%9B%B4%E6%94%B9%E4%B9%88%EF%BC%9F.md)\n\n##### [9.1.3 drop,delete\u4e0etruncate\u7684\u533a\u522b](09.MySQL\u7bc7/9.1.3%20drop%2Cdelete%E4%B8%8Etruncate%E7%9A%84%E5%8C%BA%E5%88%AB.md)\n\n##### [9.1.4 \u7d22\u5f15\u7684\u5de5\u4f5c\u539f\u7406\u53ca\u5176\u79cd\u7c7b](09.MySQL\u7bc7/9.1.4%20%E7%B4%A2%E5%BC%95%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E7%A7%8D%E7%B1%BB.md)\n\n##### [9.1.5 \u8fde\u63a5\u7684\u79cd\u7c7b](09.MySQL\u7bc7/9.1.5%20%E8%BF%9E%E6%8E%A5%E7%9A%84%E7%A7%8D%E7%B1%BB.md)\n\n##### [9.1.6 \u6570\u636e\u5e93\u8303\u5f0f](09.MySQL\u7bc7/9.1.6%20%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F.md)\n\n##### [9.1.7 \u6570\u636e\u5e93\u4f18\u5316\u7684\u601d\u8def](09.MySQL\u7bc7/9.1.7%20%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%E7%9A%84%E6%80%9D%E8%B7%AF.md)\n\n##### [9.1.8 \u5b58\u50a8\u8fc7\u7a0b\u4e0e\u89e6\u53d1\u5668\u7684\u533a\u522b](09.MySQL\u7bc7/9.1.8%20%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E4%B8%8E%E8%A7%A6%E5%8F%91%E5%99%A8%E7%9A%84%E5%8C%BA%E5%88%AB.md)\n\n\n<br>\n\n\n<h3 id=\"10\">redis\u7bc7</h3> \n\n---\n##### [10.1.0 \u4f7f\u7528Redis\u6709\u54ea\u4e9b\u597d\u5904\uff1f](10.Redis\u7bc7/10.1.0%20%E4%BD%BF%E7%94%A8Redis%E6%9C%89%E5%93%AA%E4%BA%9B%E5%A5%BD%E5%A4%84%EF%BC%9F.md)\n\n##### [10.1.1 redis\u76f8\u6bd4memcached\u6709\u54ea\u4e9b\u4f18\u52bf\uff1f](10.Redis\u7bc7/10.1.1%20redis%E7%9B%B8%E6%AF%94memcached%E6%9C%89%E5%93%AA%E4%BA%9B%E4%BC%98%E5%8A%BF%EF%BC%9F.md)\n\n##### [10.1.2 redis\u5e38\u89c1\u6027\u80fd\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848](10.Redis\u7bc7/10.1.2%20redis%E5%B8%B8%E8%A7%81%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md)\n\n##### [10.1.3 MySQL\u91cc\u67092000w\u6570\u636e\uff0credis\u4e2d\u53ea\u5b5820w\u7684\u6570\u636e\uff0c\u5982\u4f55\u4fdd\u8bc1redis\u4e2d\u7684\u6570\u636e\u90fd\u662f\u70ed\u70b9\u6570\u636e](10.Redis\u7bc7/10.1.3%20MySQL%E9%87%8C%E6%9C%892000w%E6%95%B0%E6%8D%AE%EF%BC%8Credis%E4%B8%AD%E5%8F%AA%E5%AD%9820w%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%83%BD%E6%98%AF%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE.md)\n\n##### [10.1.4 Memcache\u4e0eRedis\u7684\u533a\u522b\u90fd\u6709\u54ea\u4e9b\uff1f](10.Redis\u7bc7/10.1.4%20Memcache%E4%B8%8ERedis%E7%9A%84%E5%8C%BA%E5%88%AB%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F.md)\n\n##### [10.1.5 Redis \u5e38\u89c1\u7684\u6027\u80fd\u95ee\u9898\u90fd\u6709\u54ea\u4e9b\uff1f\u5982\u4f55\u89e3\u51b3\uff1f](10.Redis\u7bc7/10.1.5%20Redis%20%E5%B8%B8%E8%A7%81%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%EF%BC%9F.md)\n\n##### 10.1.6 redis \u6700\u9002\u5408\u7684\u573a\u666f\n\n##### [10.1.7 Redis\u7684\u540c\u6b65\u673a\u5236\u4e86\u89e3\u4e48\uff1f](10.Redis\u7bc7/10.1.7%20Redis%E7%9A%84%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E4%B9%88%EF%BC%9F.md)\n\n##### [10.1.8 \u662f\u5426\u4f7f\u7528\u8fc7Redis\u96c6\u7fa4\uff0c\u96c6\u7fa4\u7684\u539f\u7406\u662f\u4ec0\u4e48\uff1f](10.Redis\u7bc7/10.1.8%20%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E8%BF%87Redis%E9%9B%86%E7%BE%A4%EF%BC%8C%E9%9B%86%E7%BE%A4%E7%9A%84%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F.md)\n\n##### 10.1.9 redis\u96c6\u7fa4\u5982\u4f55\u4fdd\u8bc1\u4e00\u81f4\u6027\uff1f\n\n\n<br>\n\n<h3 id=\"11\">MongoDB\u7bc7</h3> \n\n---\n##### [11.1.0 \u4ec0\u4e48\u662fMongoDB\uff1f](11.MongoDB\u7bc7/11.1.0%20%E4%BB%80%E4%B9%88%E6%98%AFMongoDB%EF%BC%9F.md)\n\n##### [11.1.1 MongoDB\u662f\u7531\u54ea\u79cd\u8bed\u8a00\u5199\u7684\uff1f](11.MongoDB\u7bc7/11.1.1%20MongoDB%E6%98%AF%E7%94%B1%E5%93%AA%E7%A7%8D%E8%AF%AD%E8%A8%80%E5%86%99%E7%9A%84%EF%BC%9F.md)\n\n##### [11.1.2 MongoDB\u7684\u4f18\u52bf\u6709\u54ea\u4e9b\uff1f](11.MongoDB\u7bc7/11.1.2%20MongoDB%E7%9A%84%E4%BC%98%E5%8A%BF%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F.md)\n\n##### [11.1.3 \u4ec0\u4e48\u662f\u6570\u636e\u5e93\uff1f](11.MongoDB\u7bc7/11.1.3%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9F.md)\n\n##### [11.1.4 \u4ec0\u4e48\u662f\u96c6\u5408\uff1f](11.MongoDB\u7bc7/11.1.4%20%E4%BB%80%E4%B9%88%E6%98%AF%E9%9B%86%E5%90%88%EF%BC%9F.md)\n\n##### [11.1.5 \u4ec0\u4e48\u662f\u6587\u6863\uff1f](11.MongoDB\u7bc7/11.1.5%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%96%87%E6%A1%A3%EF%BC%9F.md)\n\n##### [11.1.6 MongoDB\u548c\u5173\u7cfb\u578b\u6570\u636e\u5e93\u672f\u8bed\u5bf9\u6bd4\u56fe](11.MongoDB\u7bc7/11.1.6%20MongoDB%E5%92%8C%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%AF%E8%AF%AD%E5%AF%B9%E6%AF%94%E5%9B%BE.md)\n\n##### [11.1.7 \u4ec0\u4e48\u662f\u201cmongod\u201d\uff1f](11.MongoDB\u7bc7/11.1.7%20%E4%BB%80%E4%B9%88%E6%98%AF%E2%80%9Cmongod%E2%80%9D%EF%BC%9F.md)\n\n##### [11.1.8 \u201cmongod\u201d\u53c2\u6570\u6709\u4ec0\u4e48\uff1f](11.MongoDB\u7bc7/11.1.8%20%E2%80%9Cmongod%E2%80%9D%E5%8F%82%E6%95%B0%E6%9C%89%E4%BB%80%E4%B9%88%EF%BC%9F.md)\n\n##### [11.1.9 \u4ec0\u4e48\u662f\u201cmongo\u201d\uff1f](11.MongoDB\u7bc7/11.1.9%20%E4%BB%80%E4%B9%88%E6%98%AF%E2%80%9Cmongo%E2%80%9D%EF%BC%9F.md)\n\n##### [11.2.0 MongoDB\u54ea\u4e2a\u547d\u4ee4\u53ef\u4ee5\u5207\u6362\u6570\u636e\u5e93\uff1f](11.MongoDB\u7bc7/11.2.0%20MongoDB%E5%93%AA%E4%B8%AA%E5%91%BD%E4%BB%A4%E5%8F%AF%E4%BB%A5%E5%88%87%E6%8D%A2%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9F.md)\n\n##### [11.2.1 \u4ec0\u4e48\u662f\u975e\u5173\u7cfb\u578b\u6570\u636e\u5e93\uff1f](11.MongoDB\u7bc7/11.2.1%20%E4%BB%80%E4%B9%88%E6%98%AF%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9F.md)\n\n##### [11.2.2 \u975e\u5173\u7cfb\u578b\u6570\u636e\u5e93\u6709\u54ea\u4e9b\u7c7b\u578b\uff1f](11.MongoDB\u7bc7/11.2.2%20%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%89%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%9E%8B%EF%BC%9F.md)\n\n##### [11.2.3 \u4e3a\u4ec0\u4e48\u7528MongoDB\uff1f](11.MongoDB\u7bc7/11.2.3%20%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8MOngoDB%EF%BC%9F.md)\n\n##### [11.2.4 \u5728\u54ea\u4e9b\u573a\u666f\u4f7f\u7528MongoDB\uff1f](11.MongoDB\u7bc7/11.2.4%20%E5%9C%A8%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%BD%BF%E7%94%A8MongoDB%EF%BC%9F.md)\n\n##### 11.2.5 MongoDB\u4e2d\u7684\u547d\u540d\u7a7a\u95f4\u662f\u4ec0\u4e48\u610f\u601d?\n\n##### 11.2.6 \u54ea\u4e9b\u8bed\u8a00\u652f\u6301MongoDB?\n\n##### [11.2.7 \u5728MongoDB\u4e2d\u5982\u4f55\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u5e93\uff1f](11.MongoDB\u7bc7/11.2.7%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9F.md)\n\n##### [11.2.8 \u5728MongoDB\u4e2d\u5982\u4f55\u67e5\u770b\u6570\u636e\u5e93\u5217\u8868\uff1f](11.MongoDB\u7bc7/11.2.8%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%97%E8%A1%A8%EF%BC%9F.md)\n\n##### [11.2.9 MongoDB\u4e2d\u7684\u5206\u7247\u662f\u4ec0\u4e48\u610f\u601d\uff1f](11.MongoDB\u7bc7/11.2.9%20MongoDB%E4%B8%AD%E7%9A%84%E5%88%86%E7%89%87%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D%EF%BC%9F.md)\n\n##### [11.3.0 \u5982\u4f55\u67e5\u770b\u4f7f\u7528MongoDB\u7684\u8fde\u63a5\uff1f](11.MongoDB\u7bc7/11.3.0%20%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E4%BD%BF%E7%94%A8MongoDB%E7%9A%84%E8%BF%9E%E6%8E%A5%EF%BC%9F.md)\n\n##### [11.3.1 \u4ec0\u4e48\u662f\u590d\u5236\uff1f](11.MongoDB\u7bc7/11.3.1%20%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%8D%E5%88%B6%EF%BC%9F.md)\n\n##### [11.3.2 \u5728MongoDB\u4e2d\u5982\u4f55\u5728\u96c6\u5408\u4e2d\u63d2\u5165\u4e00\u4e2a\u6587\u6863\uff1f](11.MongoDB\u7bc7/11.3.2%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E5%9C%A8%E9%9B%86%E5%90%88%E4%B8%AD%E6%8F%92%E5%85%A5%E4%B8%80%E4%B8%AA%E6%96%87%E6%A1%A3%EF%BC%9F.md)\n\n##### [11.3.3 \u5728MongoDB\u4e2d\u5982\u4f55\u9664\u53bb\u4e00\u4e2a\u6570\u636e\u5e93\uff1f](11.MongoDB\u7bc7/11.3.3%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E9%99%A4%E5%8E%BB%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9F.md)\n\n##### [11.3.4 \u5728MongoDB\u4e2d\u5982\u4f55\u521b\u5efa\u4e00\u4e2a\u96c6\u5408\uff1f](11.MongoDB\u7bc7/11.3.4%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E9%9B%86%E5%90%88%EF%BC%9F.md)\n\n##### [11.3.5 \u5728MongoDB\u4e2d\u5982\u4f55\u67e5\u770b\u4e00\u4e2a\u5df2\u7ecf\u521b\u5efa\u7684\u96c6\u5408\uff1f](11.MongoDB\u7bc7/11.3.5%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E4%B8%80%E4%B8%AA%E5%B7%B2%E7%BB%8F%E5%88%9B%E5%BB%BA%E7%9A%84%E9%9B%86%E5%90%88%EF%BC%9F.md)\n\n##### [11.3.6 \u5728MongoDB\u4e2d\u5982\u4f55\u5220\u9664\u4e00\u4e2a\u96c6\u5408\uff1f](11.MongoDB\u7bc7/11.3.6%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E4%B8%80%E4%B8%AA%E9%9B%86%E5%90%88%EF%BC%9F.md)\n\n##### [11.3.7 \u4e3a\u4ec0\u4e48\u8981\u5728MongoDB\u4e2d\u4f7f\u7528\u5206\u6790\u5668\uff1f](11.MongoDB\u7bc7/11.3.7%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%9C%A8MongoDB%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%88%86%E6%9E%90%E5%99%A8%EF%BC%9F.md)\n\n##### [11.3.8 MongoDB\u652f\u6301\u4e3b\u952e\u5916\u952e\u5173\u7cfb\u5417\uff1f](11.MongoDB\u7bc7/11.3.8%20MongoDB%E6%94%AF%E6%8C%81%E4%B8%BB%E9%94%AE%E5%A4%96%E9%94%AE%E5%85%B3%E7%B3%BB%E5%90%97%EF%BC%9F.md)\n\n##### [11.3.9 MongoDB\u652f\u6301\u54ea\u4e9b\u6570\u636e\u7c7b\u578b\uff1f](11.MongoDB\u7bc7/11.3.9%20MongoDB%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%EF%BC%9F.md)\n\n##### 11.4.0 \u4e3a\u4ec0\u4e48\u8981\u5728MongoDB\u4e2d\u7528\"Code\"\u6570\u636e\u7c7b\u578b\uff1f\n\n##### 11.4.1 \u4e3a\u4ec0\u4e48\u8981\u5728MongoDB\u4e2d\u7528\"Regular Expression\"\u6570\u636e\u7c7b\u578b\uff1f\n\n##### 11.4.2 \u4e3a\u4ec0\u4e48\u5728MongoDB\u4e2d\u4f7f\u7528\"Object ID\"\u6570\u636e\u7c7b\u578b\uff1f\n\n##### [11.4.3 \u5982\u4f55\u5728\u96c6\u5408\u4e2d\u63d2\u5165\u4e00\u4e2a\u6587\u6863\uff1f](11.MongoDB\u7bc7/11.4.3%20%E5%A6%82%E4%BD%95%E5%9C%A8%E9%9B%86%E5%90%88%E4%B8%AD%E6%8F%92%E5%85%A5%E4%B8%80%E4%B8%AA%E6%96%87%E6%A1%A3%EF%BC%9F.md)\n\n##### [11.4.4 \u201cObjectID\u201d\u6709\u54ea\u4e9b\u90e8\u5206\u7ec4\u6210\uff1f](11.MongoDB\u7bc7/11.4.4%20%E2%80%9CObjectID%E2%80%9D%E6%9C%89%E5%93%AA%E4%BA%9B%E9%83%A8%E5%88%86%E7%BB%84%E6%88%90%EF%BC%9F.md)\n\n##### [11.4.5 \u5728MongoDB\u4e2d\u4ec0\u4e48\u662f\u7d22\u5f15\uff1f](11.MongoDB\u7bc7/11.4.5%20%E5%9C%A8MongoDb%E4%B8%AD%E4%BB%80%E4%B9%88%E6%98%AF%E7%B4%A2%E5%BC%95%EF%BC%9F.md)\n\n##### [11.4.6 \u5982\u4f55\u6dfb\u52a0\u7d22\u5f15\uff1f](11.MongoDB\u7bc7/11.4.6%20%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95%EF%BC%9F.md)\n\n##### [11.4.7 MongoDB\u6709\u54ea\u4e9b\u53ef\u66ff\u4ee3\u4ea7\u54c1\uff1f](11.MongoDB\u7bc7/11.4.7%20MongoDB%E6%9C%89%E5%93%AA%E4%BA%9B%E5%8F%AF%E6%9B%BF%E4%BB%A3%E4%BA%A7%E5%93%81%EF%BC%9F.md)\n\n##### [11.4.8 \u5982\u4f55\u67e5\u8be2\u96c6\u5408\u4e2d\u7684\u6587\u6863\uff1f](11.MongoDB\u7bc7/11.4.8%20%E5%A6%82%E4%BD%95%E6%9F%A5%E8%AF%A2%E9%9B%86%E5%90%88%E4%B8%AD%E7%9A%84%E6%96%87%E6%A1%A3%EF%BC%9F.md)\n\n##### [11.4.9 \u7528\u4ec0\u4e48\u65b9\u6cd5\u53ef\u4ee5\u683c\u5f0f\u5316\u8f93\u51fa\u7ed3\u679c\uff1f](11.MongoDB\u7bc7/11.4.9%20%E7%94%A8%E4%BB%80%E4%B9%88%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C%EF%BC%9F.md)\n\n##### 11.5.0 \u5982\u4f55\u4f7f\u7528\"AND\"\u6216\"OR\"\u6761\u4ef6\u5faa\u73af\u67e5\u8be2\u96c6\u5408\u4e2d\u7684\u6587\u6863\uff1f\n\n##### [11.5.1 \u5728MongoDB\u4e2d\u5982\u4f55\u66f4\u65b0\u6570\u636e\uff1f](11.MongoDB\u7bc7/11.5.1%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%EF%BC%9F.md)\n\n##### [11.5.2 \u5982\u4f55\u5220\u9664\u6587\u6863\uff1f](11.MongoDB\u7bc7/11.5.2%20%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E6%96%87%E6%A1%A3%EF%BC%9F.md)\n\n##### [11.5.3 \u5728MongoDB\u4e2d\u5982\u4f55\u6392\u5e8f\uff1f](11.MongoDB\u7bc7/11.5.3%20%E5%9C%A8MongoDB%E4%B8%AD%E5%A6%82%E4%BD%95%E6%8E%92%E5%BA%8F%EF%BC%9F.md)\n\n##### [11.5.4 \u4ec0\u4e48\u662f\u805a\u5408\uff1f](11.MongoDB\u7bc7/11.5.4%20%E4%BB%80%E4%B9%88%E6%98%AF%E8%81%9A%E5%90%88%EF%BC%9F.md)\n\n##### [11.5.5 \u5728MongoDB\u4e2d\u4ec0\u4e48\u662f\u526f\u672c\u96c6\uff1f](11.MongoDB\u7bc7/11.5.5%20%E5%9C%A8MongoDB%E4%B8%AD%E4%BB%80%E4%B9%88%E6%98%AF%E5%89%AF%E6%9C%AC%E9%9B%86%EF%BC%9F.md)\n\n##### 11.5.6 Mongodb\u5b58\u50a8\u7279\u6027\u4e0e\u5185\u90e8\u539f\u7406?\n\n\n<br>\n\n<h3 id=\"12\">Zookeeper\u7bc7</h3> \n\n---\n##### [12.1.0 zookeeper\u662f\u4ec0\u4e48\uff1f](12.Zookeeper\u7bc7/12.1.0%20zookeeper%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F.md)\n\n##### [12.1.1 zookeeper\u63d0\u4f9b\u4e86\u4ec0\u4e48\uff1f](12.Zookeeper\u7bc7/12.1.1%20zookeeper%E6%8F%90%E4%BE%9B%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F.md)\n\n##### [12.1.2 zookeeper\u6587\u4ef6\u7cfb\u7edf](12.Zookeeper\u7bc7/12.1.2%20zookeeper%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.md)\n\n##### [12.1.3 zookeeper\u7684\u56db\u79cd\u7c7b\u578b\u7684znode](https://github.com/0voice/interview_internal_reference/blob/master/12.1.3%20zookeeper%E7%9A%84%E5%9B%9B%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84znode.md)\n\n##### [12.1.4 zookeeper\u901a\u77e5\u673a\u5236](12.Zookeeper\u7bc7/12.1.4%20zookeeper%E9%80%9A%E7%9F%A5%E6%9C%BA%E5%88%B6.md)\n\n##### [12.1.5 zookeeper\u6709\u54ea\u4e9b\u5e94\u7528\u573a\u666f\uff1f](12.Zookeeper\u7bc7/12.1.5%20zookeeper%E6%9C%89%E5%93%AA%E4%BA%9B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9F.md)\n\n##### [12.1.6 zk\u7684\u547d\u540d\u670d\u52a1](12.Zookeeper\u7bc7/12.1.6%20zk%E7%9A%84%E5%91%BD%E5%90%8D%E6%9C%8D%E5%8A%A1.md)\n\n##### [12.1.7 zk\u7684\u914d\u7f6e\u7ba1\u7406\u670d\u52a1](12.Zookeeper\u7bc7/12.1.7%20zk%E7%9A%84%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1.md)\n\n##### [12.1.8 zk\u7684\u96c6\u7fa4\u7ba1\u7406](12.Zookeeper\u7bc7/12.1.8%20zk%E7%9A%84%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86.md)\n\n##### [12.1.9 zk\u7684\u5206\u5e03\u5f0f\u9501](12.Zookeeper\u7bc7/12.1.9%20zk%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.md)\n\n##### [12.2.0 zk\u961f\u5217\u7ba1\u7406](12.Zookeeper\u7bc7/12.2.0%20zk%E9%98%9F%E5%88%97%E7%AE%A1%E7%90%86.md)\n\n##### [12.2.1 zk\u6570\u636e\u590d\u5236](12.Zookeeper\u7bc7/12.2.1%20zk%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6.md)\n\n##### [12.2.2 zk\u7684\u5de5\u4f5c\u539f\u7406](12.Zookeeper\u7bc7/12.2.2%20zk%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.md)\n\n##### [12.2.3 zk\u662f\u5982\u4f55\u4fdd\u8bc1\u4e8b\u7269\u7684\u987a\u5e8f\u4e00\u81f4\u6027](12.Zookeeper\u7bc7/12.2.3%20zk%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%BA%8B%E7%89%A9%E7%9A%84%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7.md)\n\n##### [12.2.4 zk\u96c6\u7fa4\u4e0bserver\u5de5\u4f5c\u72b6\u6001](12.Zookeeper\u7bc7/12.2.4%20zk%E9%9B%86%E7%BE%A4%E4%B8%8Bserver%E5%B7%A5%E4%BD%9C%E7%8A%B6%E6%80%81.md)\n\n##### [12.2.5 zk\u662f\u5982\u4f55\u9009\u4e3eLeader\u7684\uff1f](12.Zookeeper\u7bc7/12.2.5%20zk%E6%98%AF%E5%A6%82%E4%BD%95%E9%80%89%E4%B8%BELeader%E7%9A%84%EF%BC%9F.md)\n\n##### [12.2.6 zk\u540c\u6b65\u6d41\u7a0b](12.Zookeeper\u7bc7/12.2.6%20zk%E5%90%8C%E6%AD%A5%E6%B5%81%E7%A8%8B.md)\n\n##### [12.2.7 \u5206\u5e03\u5f0f\u901a\u77e5\u548c\u534f\u8c03](12.Zookeeper\u7bc7/12.2.7%20%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E7%9F%A5%E5%92%8C%E5%8D%8F%E8%B0%83.md)\n\n##### [12.2.8 zk\u7684session\u673a\u5236](12.Zookeeper\u7bc7/12.2.8%20zk\u7684session\u673a\u5236.md)\n\n\n<br>\n\n<h3 id=\"13\">nginx\u7bc7</h3> \n\n---\n##### 13.1.0 \u8bf7\u89e3\u91ca\u4e00\u4e0b\u4ec0\u4e48\u662fNginx?\n\n##### 13.1.1 \u8bf7\u5217\u4e3eNginx\u7684\u4e00\u4e9b\u7279\u6027?\n\n##### 13.1.2 \u8bf7\u5217\u4e3eNginx\u548cApache \u4e4b\u95f4\u7684\u4e0d\u540c\u70b9?\n\n##### 13.1.3 \u8bf7\u89e3\u91caNginx\u5982\u4f55\u5904\u7406HTTP\u8bf7\u6c42\u3002\n\n##### 13.1.4 \u5728Nginx\u4e2d\uff0c\u5982\u4f55\u4f7f\u7528\u672a\u5b9a\u4e49\u7684\u670d\u52a1\u5668\u540d\u79f0\u6765\u963b\u6b62\u5904\u7406\u8bf7\u6c42?\n\n##### 13.1.5 \u4f7f\u7528\u201c\u53cd\u5411\u4ee3\u7406\u670d\u52a1\u5668\u201d\u7684\u4f18\u70b9\u662f\u4ec0\u4e48?\n\n##### 13.1.6 \u8bf7\u5217\u4e3eNginx\u670d\u52a1\u5668\u7684\u6700\u4f73\u7528\u9014\u3002\n\n##### 13.1.7 \u8bf7\u89e3\u91caNginx\u670d\u52a1\u5668\u4e0a\u7684Master\u548cWorker\u8fdb\u7a0b\u5206\u522b\u662f\u4ec0\u4e48?\n\n##### 13.1.8 \u8bf7\u89e3\u91ca\u4f60\u5982\u4f55\u901a\u8fc7\u4e0d\u540c\u4e8e80\u7684\u7aef\u53e3\u5f00\u542fNginx?\n\n##### 13.1.9  \u8bf7\u89e3\u91ca\u662f\u5426\u6709\u53ef\u80fd\u5c06Nginx\u7684\u9519\u8bef\u66ff\u6362\u4e3a502\u9519\u8bef\u3001503?\n\n##### 13.2.0 \u5728Nginx\u4e2d\uff0c\u89e3\u91ca\u5982\u4f55\u5728URL\u4e2d\u4fdd\u7559\u53cc\u659c\u7ebf?\n\n##### 13.2.1 \u8bf7\u89e3\u91cangx_http_upstream_module\u7684\u4f5c\u7528\u662f\u4ec0\u4e48?\n\n##### 13.2.2 \u8bf7\u89e3\u91ca\u4ec0\u4e48\u662fC10K\u95ee\u9898\uff0c\u540e\u6765\u662f\u600e\u4e48\u89e3\u51b3\u7684\uff1f\n\n##### 13.2.3 \u8bf7\u9648\u8ff0stub_status\u548csub_filter\u6307\u4ee4\u7684\u4f5c\u7528\u662f\u4ec0\u4e48?\n\n##### 13.2.4 \u89e3\u91caNginx\u662f\u5426\u652f\u6301\u5c06\u8bf7\u6c42\u538b\u7f29\u5230\u4e0a\u6e38?\n\n##### 13.2.5 \u89e3\u91ca\u5982\u4f55\u5728Nginx\u4e2d\u83b7\u5f97\u5f53\u524d\u7684\u65f6\u95f4?\n\n##### 13.2.6 \u7528Nginx\u670d\u52a1\u5668\u89e3\u91ca-s\u7684\u76ee\u7684\u662f\u4ec0\u4e48?\n\n##### 13.2.7 \u89e3\u91ca\u5982\u4f55\u5728Nginx\u670d\u52a1\u5668\u4e0a\u6dfb\u52a0\u6a21\u5757?\n\n##### 13.2.8 nginx\u4e2d\u591a\u4e2awork\u8fdb\u7a0b\u662f\u5982\u4f55\u76d1\u542c\u540c\u4e00\u4e2a\u7aef\u53e3\u7684\uff1f\u5982\u4f55\u5904\u7406\u5ba2\u6237\u8fde\u63a5\u7684\u60ca\u7fa4\u95ee\u9898\uff1f\n\n##### 13.2.9 nginx\u7a0b\u5e8f\u7684\u70ed\u66f4\u65b0\u662f\u5982\u4f55\u505a\u7684\uff1f\n\n\n<br/>\n<br/>\n\n**\u83b7\u53d6\u5927\u725b\u89c6\u9891\u8d44\u6599\uff0c\u51b3\u80dc\u6821\u62db\uff0cLinux\u9879\u76eeC/C++\u7cbe\u8bb2\u7fa4\uff1a725377106**\n\n**C/C++ Linux\u6280\u672f\u4ea4\u6d41\u7fa4\uff1a762073882**\n\n**\u82e5\u7fa4\u5df2\u6ee1\uff0c\u6dfb\u52a0QQ\uff1a936204305 , \u5907\u6ce8github**\n\n**\u5173\u6ce8\u516c\u4f17\u53f7\uff0c\u66f4\u591a\u6743\u5a01\u67b6\u6784\u8bbe\u8ba1\u65b9\u6848\u3002 \u53e6\u9644\u4f01\u4e1a\u5185\u63a8\uff0c\u67b6\u6784\u8bbe\u8ba1\u8d44\u6599\uff0c\u76f8\u5173\u89c6\u9891\u8d44\u6599**\n\n<img src = \"arch.jpg\" />\n\n\n## \u9e23\u8c22\n\n##### \u611f\u8c22\u5404\u4f4d\u8d21\u732epatch\u7684\u670b\u53cb\uff0c \u8fd8\u5f88\u591a\u5728issue\u91cc\u9762\u51fa\u8c0b\u5212\u7b56\u7684\u670b\u53cb\uff0c\u4e3a\u6b64\u8877\u5fc3\u611f\u8c22\u3002\u4f7f\u5f97\u8be5repo\u80fd\u591f\u5728github\u8d8b\u52bf\u699c\uff0c\u6301\u7eed\u4e00\u5468\u65f6\u95f4\u95ee\u9f0e\u6392\u884c\u699c\u3002\n\n<a href=\"https://github.com/zhiyong0804\">\n    <img src=\"https://avatars2.githubusercontent.com/u/15864088?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/wangbojing\">\n    <img src=\"https://avatars2.githubusercontent.com/u/18027560?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/pyinx\">\n    <img src=\"https://avatars1.githubusercontent.com/u/3828540?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/ileler\">\n    <img src=\"https://avatars3.githubusercontent.com/u/3371163?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/jiaoqiyuan\">\n    <img src=\"https://avatars3.githubusercontent.com/u/13357933?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/seniorcandy\">\n    <img src=\"https://avatars1.githubusercontent.com/u/11422477?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/kphn\">\n    <img src=\"https://avatars1.githubusercontent.com/u/35964821?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/OhIAmFine\">\n    <img src=\"https://avatars0.githubusercontent.com/u/10390004?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/ArtarisCN\">\n    <img src=\"https://avatars2.githubusercontent.com/u/19167403?s=400&v=4\" width=\"40px\">\n</a>\n<a href=\"https://github.com/Octobug\">\n    <img src=\"https://avatars1.githubusercontent.com/u/8007022?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/SenZhangAI\">\n    <img src=\"https://avatars0.githubusercontent.com/u/8464676?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/wansho\">\n    <img src=\"https://avatars2.githubusercontent.com/u/28779244?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/dengchaoyun007\">\n    <img src=\"https://avatars1.githubusercontent.com/u/38239467?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/FanShikun\">\n    <img src=\"https://avatars1.githubusercontent.com/u/30170514?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/Carmon-Lee\">\n    <img src=\"https://avatars3.githubusercontent.com/u/29457756?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/gytHW\">\n    <img src=\"https://avatars3.githubusercontent.com/u/13961667?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/keytouch\">\n    <img src=\"https://avatars0.githubusercontent.com/u/20770013?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/SJshenjian\">\n    <img src=\"https://avatars0.githubusercontent.com/u/25132537?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/likunyao\">\n    <img src=\"https://avatars3.githubusercontent.com/u/16969814?s=400&v=4\" width=\"40px\">\n</a> \n<tr>\n<a href=\"https://github.com/xiepeiyang\">\n    <img src=\"https://avatars0.githubusercontent.com/u/8435589?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/fnlearner\">\n    <img src=\"https://avatars3.githubusercontent.com/u/38586156?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/Macyrate\">\n    <img src=\"https://avatars2.githubusercontent.com/u/20154121?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/63isOK\">\n    <img src=\"https://avatars2.githubusercontent.com/u/45553405?s=400&v=4\" width=\"40px\">\n</a> \n<a href=\"https://github.com/Innei\">\n    <img src=\"https://avatars3.githubusercontent.com/u/41265413?s=400&v=4\" width=\"40px\">\n</a> \n<br>\n<br>\n\n## \u52a0\u5165 gitter \u8ba8\u8bba\u7ec4 \nhttps://gitter.im/im0voice/interview_internal_reference\n"}, {"repo": "faif/python-patterns", "language": "Python", "readme_contents": "python-patterns\n===============\n\nA collection of design patterns and idioms in Python.\n\nCurrent Patterns\n----------------\n\n__Creational Patterns__:\n\n| Pattern | Description |\n|:-------:| ----------- |\n| [abstract_factory](patterns/creational/abstract_factory.py) | use a generic function with specific factories |\n| [borg](patterns/creational/borg.py) | a singleton with shared-state among instances |\n| [builder](patterns/creational/builder.py) | instead of using multiple constructors, builder object receives parameters and returns constructed objects |\n| [factory](patterns/creational/factory.py) | delegate a specialized function/method to create instances |\n| [lazy_evaluation](patterns/creational/lazy_evaluation.py) | lazily-evaluated property pattern in Python |\n| [pool](patterns/creational/pool.py) | preinstantiate and maintain a group of instances of the same type |\n| [prototype](patterns/creational/prototype.py) | use a factory and clones of a prototype for new instances (if instantiation is expensive) |\n\n__Structural Patterns__:\n\n| Pattern | Description |\n|:-------:| ----------- |\n| [3-tier](patterns/structural/3-tier.py) | data<->business logic<->presentation separation (strict relationships) |\n| [adapter](patterns/structural/adapter.py) | adapt one interface to another using a white-list |\n| [bridge](patterns/structural/bridge.py) | a client-provider middleman to soften interface changes |\n| [composite](patterns/structural/composite.py) | lets clients treat individual objects and compositions uniformly |\n| [decorator](patterns/structural/decorator.py) | wrap functionality with other functionality in order to affect outputs |\n| [facade](patterns/structural/facade.py) | use one class as an API to a number of others |\n| [flyweight](patterns/structural/flyweight.py) | transparently reuse existing instances of objects with similar/identical state |\n| [front_controller](patterns/structural/front_controller.py) | single handler requests coming to the application |\n| [mvc](patterns/structural/mvc.py) | model<->view<->controller (non-strict relationships) |\n| [proxy](patterns/structural/proxy.py) | an object funnels operations to something else |\n\n__Behavioral Patterns__:\n\n| Pattern | Description |\n|:-------:| ----------- |\n| [chain_of_responsibility](patterns/behavioral/chain_of_responsibility.py) | apply a chain of successive handlers to try and process the data |\n| [catalog](patterns/behavioral/catalog.py) | general methods will call different specialized methods based on construction parameter |\n| [chaining_method](patterns/behavioral/chaining_method.py) | continue callback next object method |\n| [command](patterns/behavioral/command.py) | bundle a command and arguments to call later |\n| [iterator](patterns/behavioral/iterator.py) | traverse a container and access the container's elements |\n| [mediator](patterns/behavioral/mediator.py) | an object that knows how to connect other objects and act as a proxy |\n| [memento](patterns/behavioral/memento.py) | generate an opaque token that can be used to go back to a previous state |\n| [observer](patterns/behavioral/observer.py) | provide a callback for notification of events/changes to data |\n| [publish_subscribe](patterns/behavioral/publish_subscribe.py) | a source syndicates events/data to 0+ registered listeners |\n| [registry](patterns/behavioral/registry.py) | keep track of all subclasses of a given class |\n| [specification](patterns/behavioral/specification.py) |  business rules can be recombined by chaining the business rules together using boolean logic |\n| [state](patterns/behavioral/state.py) | logic is organized into a discrete number of potential states and the next state that can be transitioned to |\n| [strategy](patterns/behavioral/strategy.py) | selectable operations over the same data |\n| [template](patterns/behavioral/template.py) | an object imposes a structure but takes pluggable components |\n| [visitor](patterns/behavioral/visitor.py) | invoke a callback for all items of a collection |\n\n__Design for Testability Patterns__:\n\n| Pattern | Description |\n|:-------:| ----------- |\n| [dependency_injection](patterns/dependency_injection.py) | 3 variants of dependency injection |\n\n__Fundamental Patterns__:\n\n| Pattern | Description |\n|:-------:| ----------- |\n| [delegation_pattern](patterns/fundamental/delegation_pattern.py) | an object handles a request by delegating to a second object (the delegate) |\n\n__Others__:\n\n| Pattern | Description |\n|:-------:| ----------- |\n| [blackboard](patterns/other/blackboard.py) | architectural model, assemble different sub-system knowledge to build a solution, AI approach - non gang of four pattern |\n| [graph_search](patterns/other/graph_search.py) | graphing algorithms - non gang of four pattern |\n| [hsm](patterns/other/hsm/hsm.py) | hierarchical state machine - non gang of four pattern |\n\n\nVideos\n------\n[Design Patterns in Python by Peter Ullrich](https://www.youtube.com/watch?v=bsyjSW46TDg)\n\n[Sebastian Buczy\u0144ski - Why you don't need design patterns in Python?](https://www.youtube.com/watch?v=G5OeYHCJuv0)\n\n[You Don't Need That!](https://www.youtube.com/watch?v=imW-trt0i9I)\n\n[Pluggable Libs Through Design Patterns](https://www.youtube.com/watch?v=PfgEU3W0kyU)\n\n\nContributing\n------------\nWhen an implementation is added or modified, please review the following guidelines:\n\n##### Output\nAll files with example patterns have `### OUTPUT ###` section at the bottom \n(migration to OUTPUT = \"\"\"...\"\"\" is in progress).\n\nRun `append_output.sh` (e.g. `./append_output.sh borg.py`) to generate/update it.\n\n##### Docstrings\nAdd module level description in form of a docstring with links to corresponding references or other useful information.\n\nAdd \"Examples in Python ecosystem\" section if you know some. It shows how patterns could be applied to real-world problems.\n\n[facade.py](patterns/structural/facade.py) has a good example of detailed description,\nbut sometimes the shorter one as in [template.py](patterns/behavioral/template.py) would suffice.\n\nIn some cases class-level docstring with doctest would also help (see [adapter.py](patterns/structural/adapter.py))\nbut readable OUTPUT section is much better.\n\n\n##### Python 2 compatibility\nTo see Python 2 compatible versions of some patterns please check-out the [legacy](https://github.com/faif/python-patterns/tree/legacy) tag.\n\n##### Update README\nWhen everything else is done - update corresponding part of README.\n\n\n##### Travis CI\nPlease run `tox` or `tox -e ci37` before submitting a patch to be sure your changes will pass CI.\n\nYou can also run `flake8` or `pytest` commands manually. Examples can be found in `tox.ini`.\n\n## Contributing via issue triage [![Open Source Helpers](https://www.codetriage.com/faif/python-patterns/badges/users.svg)](https://www.codetriage.com/faif/python-patterns)\n\nYou can triage issues and pull requests which may include reproducing bug reports or asking for vital information, such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to [subscribe to python-patterns on CodeTriage](https://www.codetriage.com/faif/python-patterns).\n"}, {"repo": "pandas-dev/pandas", "language": "Python", "readme_contents": "<div align=\"center\">\n  <img src=\"https://dev.pandas.io/static/img/pandas.svg\"><br>\n</div>\n\n-----------------\n\n# pandas: powerful Python data analysis toolkit\n\n<table>\n<tr>\n  <td>Latest Release</td>\n  <td>\n    <a href=\"https://pypi.org/project/pandas/\">\n    <img src=\"https://img.shields.io/pypi/v/pandas.svg\" alt=\"latest release\" />\n    </a>\n  </td>\n</tr>\n  <td></td>\n  <td>\n    <a href=\"https://anaconda.org/anaconda/pandas/\">\n    <img src=\"https://anaconda.org/conda-forge/pandas/badges/version.svg\" alt=\"latest release\" />\n    </a>\n</td>\n</tr>\n<tr>\n  <td>Package Status</td>\n  <td>\n\t\t<a href=\"https://pypi.org/project/pandas/\">\n\t\t<img src=\"https://img.shields.io/pypi/status/pandas.svg\" alt=\"status\" />\n\t\t</a>\n  </td>\n</tr>\n<tr>\n  <td>License</td>\n  <td>\n    <a href=\"https://github.com/pandas-dev/pandas/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/pypi/l/pandas.svg\" alt=\"license\" />\n    </a>\n</td>\n</tr>\n<tr>\n  <td>Build Status</td>\n  <td>\n    <a href=\"https://travis-ci.org/pandas-dev/pandas\">\n    <img src=\"https://travis-ci.org/pandas-dev/pandas.svg?branch=master\" alt=\"travis build status\" />\n    </a>\n  </td>\n</tr>\n<tr>\n  <td></td>\n  <td>\n    <a href=\"https://dev.azure.com/pandas-dev/pandas/_build/latest?definitionId=1&branch=master\">\n      <img src=\"https://dev.azure.com/pandas-dev/pandas/_apis/build/status/pandas-dev.pandas?branch=master\" alt=\"Azure Pipelines build status\" />\n    </a>\n  </td>\n</tr>\n<tr>\n  <td>Coverage</td>\n \u00a0<td>\n    <a href=\"https://codecov.io/gh/pandas-dev/pandas\">\n    <img src=\"https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=master\" alt=\"coverage\" />\n    </a>\n  </td>\n</tr>\n<tr>\n  <td>Downloads</td>\n  <td>\n    <a href=\"https://pandas.pydata.org\">\n    <img src=\"https://anaconda.org/conda-forge/pandas/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n    </a>\n  </td>\n</tr>\n<tr>\n\t<td>Gitter</td>\n\t<td>\n\t\t<a href=\"https://gitter.im/pydata/pandas\">\n\t\t<img src=\"https://badges.gitter.im/Join%20Chat.svg\" />\n\t\t</a>\n\t</td>\n</tr>\n</table>\n\n\n\n## What is it?\n\n**pandas** is a Python package providing fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, **real world** data analysis in Python. Additionally, it has\nthe broader goal of becoming **the most powerful and flexible open source data\nanalysis / manipulation tool available in any language**. It is already well on\nits way towards this goal.\n\n## Main Features\nHere are just a few of the things that pandas does well:\n\n  - Easy handling of [**missing data**][missing-data] (represented as\n    `NaN`) in floating point as well as non-floating point data\n  - Size mutability: columns can be [**inserted and\n    deleted**][insertion-deletion] from DataFrame and higher dimensional\n    objects\n  - Automatic and explicit [**data alignment**][alignment]: objects can\n    be explicitly aligned to a set of labels, or the user can simply\n    ignore the labels and let `Series`, `DataFrame`, etc. automatically\n    align the data for you in computations\n  - Powerful, flexible [**group by**][groupby] functionality to perform\n    split-apply-combine operations on data sets, for both aggregating\n    and transforming data\n  - Make it [**easy to convert**][conversion] ragged,\n    differently-indexed data in other Python and NumPy data structures\n    into DataFrame objects\n  - Intelligent label-based [**slicing**][slicing], [**fancy\n    indexing**][fancy-indexing], and [**subsetting**][subsetting] of\n    large data sets\n  - Intuitive [**merging**][merging] and [**joining**][joining] data\n    sets\n  - Flexible [**reshaping**][reshape] and [**pivoting**][pivot-table] of\n    data sets\n  - [**Hierarchical**][mi] labeling of axes (possible to have multiple\n    labels per tick)\n  - Robust IO tools for loading data from [**flat files**][flat-files]\n    (CSV and delimited), [**Excel files**][excel], [**databases**][db],\n    and saving/loading data from the ultrafast [**HDF5 format**][hdfstore]\n  - [**Time series**][timeseries]-specific functionality: date range\n    generation and frequency conversion, moving window statistics,\n    moving window linear regressions, date shifting and lagging, etc.\n\n\n   [missing-data]: https://pandas.pydata.org/pandas-docs/stable/missing_data.html#working-with-missing-data\n   [insertion-deletion]: https://pandas.pydata.org/pandas-docs/stable/dsintro.html#column-selection-addition-deletion\n   [alignment]: https://pandas.pydata.org/pandas-docs/stable/dsintro.html?highlight=alignment#intro-to-data-structures\n   [groupby]: https://pandas.pydata.org/pandas-docs/stable/groupby.html#group-by-split-apply-combine\n   [conversion]: https://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n   [slicing]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#slicing-ranges\n   [fancy-indexing]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#advanced-indexing-with-ix\n   [subsetting]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing\n   [merging]: https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging\n   [joining]: https://pandas.pydata.org/pandas-docs/stable/merging.html#joining-on-index\n   [reshape]: https://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-and-pivot-tables\n   [pivot-table]: https://pandas.pydata.org/pandas-docs/stable/reshaping.html#pivot-tables-and-cross-tabulations\n   [mi]: https://pandas.pydata.org/pandas-docs/stable/indexing.html#hierarchical-indexing-multiindex\n   [flat-files]: https://pandas.pydata.org/pandas-docs/stable/io.html#csv-text-files\n   [excel]: https://pandas.pydata.org/pandas-docs/stable/io.html#excel-files\n   [db]: https://pandas.pydata.org/pandas-docs/stable/io.html#sql-queries\n   [hdfstore]: https://pandas.pydata.org/pandas-docs/stable/io.html#hdf5-pytables\n   [timeseries]: https://pandas.pydata.org/pandas-docs/stable/timeseries.html#time-series-date-functionality\n\n## Where to get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/pandas-dev/pandas\n\nBinary installers for the latest released version are available at the [Python\npackage index](https://pypi.org/project/pandas) and on conda.\n\n```sh\n# conda\nconda install pandas\n```\n\n```sh\n# or PyPI\npip install pandas\n```\n\n## Dependencies\n- [NumPy](https://www.numpy.org)\n- [python-dateutil](https://labix.org/python-dateutil)\n- [pytz](https://pythonhosted.org/pytz)\n\nSee the [full installation instructions](https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies) for minimum supported versions of required, recommended and optional dependencies.\n\n## Installation from sources\nTo install pandas from source you need Cython in addition to the normal\ndependencies above. Cython can be installed from pypi:\n\n```sh\npip install cython\n```\n\nIn the `pandas` directory (same one where you found this file after\ncloning the git repo), execute:\n\n```sh\npython setup.py install\n```\n\nor for installing in [development mode](https://pip.pypa.io/en/latest/reference/pip_install.html#editable-installs):\n\n\n```sh\npython -m pip install -e . --no-build-isolation --no-use-pep517\n```\n\nIf you have `make`, you can also use `make develop` to run the same command.\n\nor alternatively\n\n```sh\npython setup.py develop\n```\n\nSee the full instructions for [installing from source](https://pandas.pydata.org/pandas-docs/stable/install.html#installing-from-source).\n\n## License\n[BSD 3](LICENSE)\n\n## Documentation\nThe official documentation is hosted on PyData.org: https://pandas.pydata.org/pandas-docs/stable\n\n## Background\nWork on ``pandas`` started at AQR (a quantitative hedge fund) in 2008 and\nhas been under active development since then.\n\n## Getting Help\n\nFor usage questions, the best place to go to is [StackOverflow](https://stackoverflow.com/questions/tagged/pandas).\nFurther, general questions and discussions can also take place on the [pydata mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata).\n\n## Discussion and Development\nMost development discussion is taking place on github in this repo. Further, the [pandas-dev mailing list](https://mail.python.org/mailman/listinfo/pandas-dev) can also be used for specialized discussions or design issues, and a [Gitter channel](https://gitter.im/pydata/pandas) is available for quick development related questions.\n\n## Contributing to pandas [![Open Source Helpers](https://www.codetriage.com/pandas-dev/pandas/badges/users.svg)](https://www.codetriage.com/pandas-dev/pandas)\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements and ideas are welcome.\n\nA detailed overview on how to contribute can be found in the **[contributing guide](https://dev.pandas.io/docs/contributing.html)**. There is also an [overview](.github/CONTRIBUTING.md) on GitHub.\n\nIf you are simply looking to start working with the pandas codebase, navigate to the [GitHub \"issues\" tab](https://github.com/pandas-dev/pandas/issues) and start looking through interesting issues. There are a number of issues listed under [Docs](https://github.com/pandas-dev/pandas/issues?labels=Docs&sort=updated&state=open) and [good first issue](https://github.com/pandas-dev/pandas/issues?labels=good+first+issue&sort=updated&state=open) where you could start out.\n\nYou can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to [subscribe to pandas on CodeTriage](https://www.codetriage.com/pandas-dev/pandas).\n\nOr maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking \u2018this can be improved\u2019...you can do something about it!\n\nFeel free to ask questions on the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata) or on [Gitter](https://gitter.im/pydata/pandas).\n\nAs contributors and maintainers to this project, you are expected to abide by pandas' code of conduct. More information can be found at: [Contributor Code of Conduct](https://github.com/pandas-dev/pandas/blob/master/.github/CODE_OF_CONDUCT.md)\n"}, {"repo": "facebookresearch/Detectron", "language": "Python", "readme_contents": "**Detectron is deprecated. Please see [detectron2](https://github.com/facebookresearch/detectron2), a ground-up rewrite of Detectron in PyTorch.**\n\n# Detectron\n\nDetectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including [Mask R-CNN](https://arxiv.org/abs/1703.06870). It is written in Python and powered by the [Caffe2](https://github.com/caffe2/caffe2) deep learning framework.\n\nAt FAIR, Detectron has enabled numerous research projects, including: [Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144), [Mask R-CNN](https://arxiv.org/abs/1703.06870), [Detecting and Recognizing Human-Object Interactions](https://arxiv.org/abs/1704.07333), [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002), [Non-local Neural Networks](https://arxiv.org/abs/1711.07971), [Learning to Segment Every Thing](https://arxiv.org/abs/1711.10370), [Data Distillation: Towards Omni-Supervised Learning](https://arxiv.org/abs/1712.04440), [DensePose: Dense Human Pose Estimation In The Wild](https://arxiv.org/abs/1802.00434), and [Group Normalization](https://arxiv.org/abs/1803.08494).\n\n<div align=\"center\">\n  <img src=\"demo/output/33823288584_1d21cf0a26_k_example_output.jpg\" width=\"700px\" />\n  <p>Example Mask R-CNN output.</p>\n</div>\n\n## Introduction\n\nThe goal of Detectron is to provide a high-quality, high-performance\ncodebase for object detection *research*. It is designed to be flexible in order\nto support rapid implementation and evaluation of novel research. Detectron\nincludes implementations of the following object detection algorithms:\n\n- [Mask R-CNN](https://arxiv.org/abs/1703.06870) -- *Marr Prize at ICCV 2017*\n- [RetinaNet](https://arxiv.org/abs/1708.02002) -- *Best Student Paper Award at ICCV 2017*\n- [Faster R-CNN](https://arxiv.org/abs/1506.01497)\n- [RPN](https://arxiv.org/abs/1506.01497)\n- [Fast R-CNN](https://arxiv.org/abs/1504.08083)\n- [R-FCN](https://arxiv.org/abs/1605.06409)\n\nusing the following backbone network architectures:\n\n- [ResNeXt{50,101,152}](https://arxiv.org/abs/1611.05431)\n- [ResNet{50,101,152}](https://arxiv.org/abs/1512.03385)\n- [Feature Pyramid Networks](https://arxiv.org/abs/1612.03144) (with ResNet/ResNeXt)\n- [VGG16](https://arxiv.org/abs/1409.1556)\n\nAdditional backbone architectures may be easily implemented. For more details about these models, please see [References](#references) below.\n\n## Update\n\n- 4/2018: Support Group Normalization - see [`GN/README.md`](./projects/GN/README.md)\n\n## License\n\nDetectron is released under the [Apache 2.0 license](https://github.com/facebookresearch/detectron/blob/master/LICENSE). See the [NOTICE](https://github.com/facebookresearch/detectron/blob/master/NOTICE) file for additional details.\n\n## Citing Detectron\n\nIf you use Detectron in your research or wish to refer to the baseline results published in the [Model Zoo](MODEL_ZOO.md), please use the following BibTeX entry.\n\n```\n@misc{Detectron2018,\n  author =       {Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and\n                  Piotr Doll\\'{a}r and Kaiming He},\n  title =        {Detectron},\n  howpublished = {\\url{https://github.com/facebookresearch/detectron}},\n  year =         {2018}\n}\n```\n\n## Model Zoo and Baselines\n\nWe provide a large set of baseline results and trained models available for download in the [Detectron Model Zoo](MODEL_ZOO.md).\n\n## Installation\n\nPlease find installation instructions for Caffe2 and Detectron in [`INSTALL.md`](INSTALL.md).\n\n## Quick Start: Using Detectron\n\nAfter installation, please see [`GETTING_STARTED.md`](GETTING_STARTED.md) for brief tutorials covering inference and training with Detectron.\n\n## Getting Help\n\nTo start, please check the [troubleshooting](INSTALL.md#troubleshooting) section of our installation instructions as well as our [FAQ](FAQ.md). If you couldn't find help there, try searching our GitHub issues. We intend the issues page to be a forum in which the community collectively troubleshoots problems.\n\nIf bugs are found, **we appreciate pull requests** (including adding Q&A's to `FAQ.md` and improving our installation instructions and troubleshooting documents). Please see [CONTRIBUTING.md](CONTRIBUTING.md) for more information about contributing to Detectron.\n\n## References\n\n- [Data Distillation: Towards Omni-Supervised Learning](https://arxiv.org/abs/1712.04440).\n  Ilija Radosavovic, Piotr Doll\u00e1r, Ross Girshick, Georgia Gkioxari, and Kaiming He.\n  Tech report, arXiv, Dec. 2017.\n- [Learning to Segment Every Thing](https://arxiv.org/abs/1711.10370).\n  Ronghang Hu, Piotr Doll\u00e1r, Kaiming He, Trevor Darrell, and Ross Girshick.\n  Tech report, arXiv, Nov. 2017.\n- [Non-Local Neural Networks](https://arxiv.org/abs/1711.07971).\n  Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.\n  Tech report, arXiv, Nov. 2017.\n- [Mask R-CNN](https://arxiv.org/abs/1703.06870).\n  Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Girshick.\n  IEEE International Conference on Computer Vision (ICCV), 2017.\n- [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002).\n  Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r.\n  IEEE International Conference on Computer Vision (ICCV), 2017.\n- [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/abs/1706.02677).\n  Priya Goyal, Piotr Doll\u00e1r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.\n  Tech report, arXiv, June 2017.\n- [Detecting and Recognizing Human-Object Interactions](https://arxiv.org/abs/1704.07333).\n  Georgia Gkioxari, Ross Girshick, Piotr Doll\u00e1r, and Kaiming He.\n  Tech report, arXiv, Apr. 2017.\n- [Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144).\n  Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie.\n  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.\n- [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431).\n  Saining Xie, Ross Girshick, Piotr Doll\u00e1r, Zhuowen Tu, and Kaiming He.\n  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.\n- [R-FCN: Object Detection via Region-based Fully Convolutional Networks](http://arxiv.org/abs/1605.06409).\n  Jifeng Dai, Yi Li, Kaiming He, and Jian Sun.\n  Conference on Neural Information Processing Systems (NIPS), 2016.\n- [Deep Residual Learning for Image Recognition](http://arxiv.org/abs/1512.03385).\n  Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\n  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.\n- [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](http://arxiv.org/abs/1506.01497)\n  Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.\n  Conference on Neural Information Processing Systems (NIPS), 2015.\n- [Fast R-CNN](http://arxiv.org/abs/1504.08083).\n  Ross Girshick.\n  IEEE International Conference on Computer Vision (ICCV), 2015.\n"}, {"repo": "apachecn/AiLearning", "language": "Python", "readme_contents": "<p align=\"center\">\n    <a href=\"https://www.apachecn.org\">\n        <img width=\"200\" src=\"http://data.apachecn.org/img/logo.jpg\">\n    </a>\n    <br >\n    <a href=\"https://www.apachecn.org/\"><img src=\"https://img.shields.io/badge/%3E-HOME-green.svg\"></a>\n    <a href=\"http://home.apachecn.org/about/\"><img src=\"https://img.shields.io/badge/%3E-ABOUT-green.svg\"></a>\n    <a href=\"mailto:apache@163.com\"><img src=\"https://img.shields.io/badge/%3E-Email-green.svg\"></a>\n</p>\n\n<h1 align=\"center\"><a href=\"https://github.com/apachecn/AiLearning\">AI learning</a></h1>\n\n## \u7ec4\u7ec7\u4ecb\u7ecd\n\n* \u5408\u4f5cor\u4fb5\u6743\uff0c\u8bf7\u8054\u7cfb: `apachecn@163.com`\n* **\u6211\u4eec\u4e0d\u662f Apache \u7684\u5b98\u65b9\u7ec4\u7ec7/\u673a\u6784/\u56e2\u4f53\uff0c\u53ea\u662f Apache \u6280\u672f\u6808\uff08\u4ee5\u53ca AI\uff09\u7684\u7231\u597d\u8005\uff01**\n* **ApacheCN - \u5b66\u4e60\u673a\u5668\u5b66\u4e60\u7fa4\u3010629470233\u3011<a target=\"_blank\" href=\"//shang.qq.com/wpa/qunwpa?idkey=30e5f1123a79867570f665aa3a483ca404b1c3f77737bc01ec520ed5f078ddef\"><img border=\"0\" src=\"http://data.apachecn.org/img/logo/ApacheCN-group.png\" alt=\"ApacheCN - \u5b66\u4e60\u673a\u5668\u5b66\u4e60\u7fa4[629470233]\" title=\"ApacheCN - \u5b66\u4e60\u673a\u5668\u5b66\u4e60\u7fa4[629470233]\"></a>**\n\n> **\u6b22\u8fce\u4efb\u4f55\u4eba\u53c2\u4e0e\u548c\u5b8c\u5584\uff1a\u4e00\u4e2a\u4eba\u53ef\u4ee5\u8d70\u7684\u5f88\u5feb\uff0c\u4f46\u662f\u4e00\u7fa4\u4eba\u5374\u53ef\u4ee5\u8d70\u7684\u66f4\u8fdc**\n\n# \u8def\u7ebf\u56fe\n\n* \u5165\u95e8\u53ea\u770b: \u6b65\u9aa4 1 => 2 => 3\uff0c\u4f60\u53ef\u4ee5\u5f53\u5927\u725b\uff01\n* \u4e2d\u7ea7\u8865\u5145 - \u8d44\u6599\u5e93: <https://github.com/apachecn/ai-roadmap>\n\n## 1.\u673a\u5668\u5b66\u4e60 - \u57fa\u7840\n\n### \u57fa\u672c\u4ecb\u7ecd\n\n* \u8d44\u6599\u6765\u6e90: Machine Learning in Action(\u673a\u5668\u5b66\u4e60\u5b9e\u6218-\u4e2a\u4eba\u7b14\u8bb0)\n* \u7edf\u4e00\u6570\u636e\u5730\u5740: <https://github.com/apachecn/data>\n* \u4e66\u7c4d\u4e0b\u8f7d\u5730\u5740: <https://github.com/apachecn/data/tree/master/book>\n* \u673a\u5668\u5b66\u4e60\u4e0b\u8f7d\u5730\u5740: <https://github.com/apachecn/data/tree/master/\u673a\u5668\u5b66\u4e60>\n* \u6df1\u5ea6\u5b66\u4e60\u6570\u636e\u5730\u5740: <https://github.com/apachecn/data/tree/master/\u6df1\u5ea6\u5b66\u4e60>\n* \u63a8\u8350\u7cfb\u7edf\u6570\u636e\u5730\u5740: <https://github.com/apachecn/data/tree/master/\u63a8\u8350\u7cfb\u7edf>\n* \u89c6\u9891\u7f51\u7ad9\uff1a\u4f18\u9177 \uff0fbilibili / Acfun / \u7f51\u6613\u4e91\u8bfe\u5802\uff0c\u53ef\u76f4\u63a5\u5728\u7ebf\u64ad\u653e\u3002\uff08\u6700\u4e0b\u65b9\u6709\u76f8\u5e94\u94fe\u63a5\uff09\n* -- \u63a8\u8350 [\u7ea2\u8272\u77f3\u5934](https://github.com/RedstoneWill): [\u53f0\u6e7e\u5927\u5b66\u6797\u8f69\u7530\u673a\u5668\u5b66\u4e60\u7b14\u8bb0](https://github.com/apachecn/ntu-hsuantienlin-ml)\n* -- \u63a8\u8350 [\u673a\u5668\u5b66\u4e60\u7b14\u8bb0](https://feisky.xyz/machine-learning): https://feisky.xyz/machine-learning\n\n### \u5b66\u4e60\u6587\u6863\n\n<table>\n  <tr>\n    <th>\u6a21\u5757</th>\n    <th>\u7ae0\u8282</th>\n    <th>\u7c7b\u578b</th>\n    <th>\u8d1f\u8d23\u4eba(GitHub)</th>\n    <th>QQ</th>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/1.\u673a\u5668\u5b66\u4e60\u57fa\u7840.md\"> \u7b2c 1 \u7ae0: \u673a\u5668\u5b66\u4e60\u57fa\u7840</a></td>\n    <td>\u4ecb\u7ecd</td>\n    <td><a href=\"https://github.com/ElmaDavies\">@\u6bdb\u7ea2\u52a8</a></td>\n    <td>1306014226</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/2.k-\u8fd1\u90bb\u7b97\u6cd5.md\">\u7b2c 2 \u7ae0: KNN \u8fd1\u90bb\u7b97\u6cd5</a></td>\n    <td>\u5206\u7c7b</td>\n    <td><a href=\"https://github.com/youyj521\">@\u5c24\u6c38\u6c5f</a></td>\n    <td>279393323</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/3.\u51b3\u7b56\u6811.md\">\u7b2c 3 \u7ae0: \u51b3\u7b56\u6811</a></td>\n    <td>\u5206\u7c7b</td>\n    <td><a href=\"https://github.com/jingwangfei\">@\u666f\u6d9b</a></td>\n    <td>844300439</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/4.\u6734\u7d20\u8d1d\u53f6\u65af.md\">\u7b2c 4 \u7ae0: \u6734\u7d20\u8d1d\u53f6\u65af</a></td>\n    <td>\u5206\u7c7b</td>\n    <td><a href=\"https://github.com/wnma3mz\">@wnma3mz</a><br/><a href=\"https://github.com/kailian\">@\u5206\u6790</a></td>\n    <td>1003324213<br/>244970749</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/5.Logistic\u56de\u5f52.md\">\u7b2c 5 \u7ae0: Logistic\u56de\u5f52</a></td>\n    <td>\u5206\u7c7b</td>\n    <td><a href=\"https://github.com/DataMonk2017\">@\u5fae\u5149\u540c\u5c18</a></td>\n    <td>529925688</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/6.\u652f\u6301\u5411\u91cf\u673a.md\">\u7b2c 6 \u7ae0: SVM \u652f\u6301\u5411\u91cf\u673a</a></td>\n    <td>\u5206\u7c7b</td>\n    <td><a href=\"https://github.com/VPrincekin\">@\u738b\u5fb7\u7ea2</a></td>\n    <td>934969547</td>\n  </tr>\n  <tr>\n    <td>\u7f51\u4e0a\u7ec4\u5408\u5185\u5bb9</td>\n    <td><a href=\"docs/ml/7.\u96c6\u6210\u65b9\u6cd5-\u968f\u673a\u68ee\u6797\u548cAdaBoost.md\">\u7b2c 7 \u7ae0: \u96c6\u6210\u65b9\u6cd5\uff08\u968f\u673a\u68ee\u6797\u548c AdaBoost\uff09</a></td>\n    <td>\u5206\u7c7b</td>\n    <td><a href=\"https://github.com/jiangzhonglian\">@\u7247\u523b</a></td>\n    <td>529815144</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/8.\u56de\u5f52.md\">\u7b2c 8 \u7ae0: \u56de\u5f52</a></td>\n    <td>\u56de\u5f52</td>\n    <td><a href=\"https://github.com/DataMonk2017\">@\u5fae\u5149\u540c\u5c18</a></td>\n    <td>529925688</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/9.\u6811\u56de\u5f52.md\">\u7b2c 9 \u7ae0: \u6811\u56de\u5f52</a></td>\n    <td>\u56de\u5f52</td>\n    <td><a href=\"https://github.com/DataMonk2017\">@\u5fae\u5149\u540c\u5c18</a></td>\n    <td>529925688</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/10.k-means\u805a\u7c7b.md\">\u7b2c 10 \u7ae0: K-Means \u805a\u7c7b</a></td>\n    <td>\u805a\u7c7b</td>\n    <td><a href=\"https://github.com/xuzhaoqing\">@\u5f90\u662d\u6e05</a></td>\n    <td>827106588</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/11.\u4f7f\u7528Apriori\u7b97\u6cd5\u8fdb\u884c\u5173\u8054\u5206\u6790.md\">\u7b2c 11 \u7ae0: \u5229\u7528 Apriori \u7b97\u6cd5\u8fdb\u884c\u5173\u8054\u5206\u6790</a></td>\n    <td>\u9891\u7e41\u9879\u96c6</td>\n    <td><a href=\"https://github.com/WindZQ\">@\u5218\u6d77\u98de</a></td>\n    <td>1049498972</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/12.\u4f7f\u7528FP-growth\u7b97\u6cd5\u6765\u9ad8\u6548\u53d1\u73b0\u9891\u7e41\u9879\u96c6.md\">\u7b2c 12 \u7ae0: FP-growth \u9ad8\u6548\u53d1\u73b0\u9891\u7e41\u9879\u96c6</a></td>\n    <td>\u9891\u7e41\u9879\u96c6</td>\n    <td><a href=\"https://github.com/mikechengwei\">@\u7a0b\u5a01</a></td>\n    <td>842725815</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/13.\u5229\u7528PCA\u6765\u7b80\u5316\u6570\u636e.md\">\u7b2c 13 \u7ae0: \u5229\u7528 PCA \u6765\u7b80\u5316\u6570\u636e</a></td>\n    <td>\u5de5\u5177</td>\n    <td><a href=\"https://github.com/lljuan330\">@\u5ed6\u7acb\u5a1f</a></td>\n    <td>835670618</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/14.\u5229\u7528SVD\u7b80\u5316\u6570\u636e.md\">\u7b2c 14 \u7ae0: \u5229\u7528 SVD \u6765\u7b80\u5316\u6570\u636e</a></td>\n    <td>\u5de5\u5177</td>\n    <td><a href=\"https://github.com/marsjhao\">@\u5f20\u4fca\u7693</a></td>\n    <td>714974242</td>\n  </tr>\n  <tr>\n    <td>\u673a\u5668\u5b66\u4e60\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/15.\u5927\u6570\u636e\u4e0eMapReduce.md\">\u7b2c 15 \u7ae0: \u5927\u6570\u636e\u4e0e MapReduce</a></td>\n    <td>\u5de5\u5177</td>\n    <td><a href=\"https://github.com/wnma3mz\">@wnma3mz</a></td>\n    <td>1003324213</td>\n  </tr>\n  <tr>\n    <td>Ml\u9879\u76ee\u5b9e\u6218</td>\n    <td><a href=\"docs/ml/16.\u63a8\u8350\u7cfb\u7edf.md\">\u7b2c 16 \u7ae0: \u63a8\u8350\u7cfb\u7edf\uff08\u5df2\u8fc1\u79fb\uff09</a></td>\n    <td>\u9879\u76ee</td>\n    <td><a href=\"https://github.com/apachecn/RecommenderSystems\">\u63a8\u8350\u7cfb\u7edf\uff08\u8fc1\u79fb\u540e\u5730\u5740\uff09</a></td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>\u7b2c\u4e00\u671f\u7684\u603b\u7ed3</td>\n    <td><a href=\"report/2017-04-08_\u7b2c\u4e00\u671f\u7684\u603b\u7ed3.md\">2017-04-08: \u7b2c\u4e00\u671f\u7684\u603b\u7ed3</a></td>\n    <td>\u603b\u7ed3</td>\n    <td>\u603b\u7ed3</td>\n    <td>529815144</td>\n  </tr>\n</table>\n\n\n### \u7f51\u7ad9\u89c6\u9891\n\n> [\u77e5\u4e4e\u95ee\u7b54-\u7206\u70b8\u5566-\u673a\u5668\u5b66\u4e60\u8be5\u600e\u4e48\u5165\u95e8\uff1f](https://www.zhihu.com/question/20691338/answer/248678328)\n\n\u5f53\u7136\u6211\u77e5\u9053\uff0c\u7b2c\u4e00\u53e5\u5c31\u4f1a\u88ab\u5410\u69fd\uff0c\u56e0\u4e3a\u79d1\u73ed\u51fa\u8eab\u7684\u4eba\uff0c\u4e0d\u5c51\u7684\u5410\u4e86\u4e00\u53e3\u553e\u6cab\uff0c\u8bf4\u50bbX\uff0c\u8fd8\u8bc4\u8bba Andrew Ng \u7684\u89c6\u9891\u3002\u3002\n\n\u6211\u8fd8\u77e5\u9053\u8fd8\u6709\u4e00\u90e8\u5206\u4eba\uff0c\u770b Andrew Ng \u7684\u89c6\u9891\u5c31\u662f\u770b\u4e0d\u61c2\uff0c\u90a3\u795e\u79d8\u7684\u6570\u5b66\u63a8\u5bfc\uff0c\u90a3\u8ff7\u4e4b\u5fae\u7b11\u7684\u82f1\u6587\u7248\u7684\u6559\u5b66\uff0c\u6211\u4f55\u5c1d\u53c8\u4e0d\u662f\u8fd9\u6837\u8d70\u8fc7\u6765\u7684\uff1f\uff1f \u6211\u7684\u5fc3\u53ef\u80fd\u6bd4\u4f60\u4eec\u90fd\u75db\uff0c\u56e0\u4e3a\u6211\u5728\u7f51\u4e0a\u6536\u85cf\u8fc7\u4e0a10\u90e8\u300a\u673a\u5668\u5b66\u4e60\u300b\u76f8\u5173\u89c6\u9891\uff0c\u5916\u52a0\u56fd\u5185\u672c\u571f\u98ce\u683c\u7684\u6559\u7a0b\uff1a7\u6708+\u5c0f\u8c61 \u7b49\u7b49\uff0c\u6211\u90fd\u5f88\u96be\u53bb\u542c\u61c2\uff0c\u76f4\u5230\u6709\u4e00\u5929\uff0c\u88ab\u4e00\u4e2a\u767e\u5ea6\u7684\u9ad8\u7ea7\u7b97\u6cd5\u5206\u6790\u5e08\u63a8\u8350\u8bf4\uff1a\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\u8fd8\u4e0d\u9519\uff0c\u901a\u4fd7\u6613\u61c2\uff0c\u4f60\u53bb\u8bd5\u8bd5\uff1f\uff1f\n\n\u6211\u8bd5\u4e86\u8bd5\uff0c\u8fd8\u597d\u6211\u7684Python\u57fa\u7840\u548c\u8c03\u8bd5\u80fd\u529b\u8fd8\u4e0d\u9519\uff0c\u57fa\u672c\u4e0a\u4ee3\u7801\u90fd\u8c03\u8bd5\u8fc7\u4e00\u904d\uff0c\u5f88\u591a\u9ad8\u5927\u4e0a\u7684 \"\u7406\u8bba+\u63a8\u5bfc\"\uff0c\u5728\u6211\u773c\u4e2d\u53d8\u6210\u4e86\u51e0\u4e2a \"\u52a0\u51cf\u4e58\u9664+\u5faa\u73af\"\uff0c\u6211\u60f3\u8fd9\u4e0d\u5c31\u662f\u50cf\u6211\u8fd9\u6837\u7684\u7a0b\u5e8f\u5458\u60f3\u8981\u7684\u5165\u95e8\u6559\u7a0b\u4e48\uff1f\n\n\u5f88\u591a\u7a0b\u5e8f\u5458\u8bf4\u673a\u5668\u5b66\u4e60 TM \u592a\u96be\u5b66\u4e86\uff0c\u662f\u7684\uff0c\u771f TM \u96be\u5b66\uff0c\u6211\u60f3\u6700\u96be\u7684\u662f\uff1a\u6ca1\u6709\u4e00\u672c\u50cf\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\u90a3\u6837\u7684\u4f5c\u8005\u613f\u610f\u4ee5\u7a0b\u5e8f\u5458 Coding \u89d2\u5ea6\u53bb\u7ed9\u5927\u5bb6\u8bb2\u89e3\uff01\uff01\n\n\u6700\u8fd1\u51e0\u5929\uff0cGitHub \u6da8\u4e86 300\u9897 star\uff0c\u52a0\u7fa4\u7684200\u4eba\uff0c \u73b0\u5728\u8fd8\u5728\u4e0d\u65ad\u7684\u589e\u52a0++\uff0c\u6211\u60f3\u5927\u5bb6\u53ef\u80fd\u90fd\u662f\u611f\u540c\u8eab\u53d7\u5427\uff01\n\n\u5f88\u591a\u60f3\u5165\u95e8\u65b0\u624b\u5c31\u662f\u88ab\u5ffd\u60a0\u7740\u6536\u85cf\u6536\u85cf\u518d\u6536\u85cf\uff0c\u4f46\u662f\u6700\u540e\u8fd8\u662f\u4ec0\u4e48\u90fd\u6ca1\u6709\u5b66\u5230\uff0c\u4e5f\u5c31\u662f\"\u8d44\u6e90\u6536\u85cf\u5bb6\"\uff0c\u4e5f\u8bb8\u65b0\u624b\u8981\u7684\u5c31\u662f [MachineLearning(\u673a\u5668\u5b66\u4e60) \u5b66\u4e60\u8def\u7ebf\u56fe](https://docs.apachecn.org/map)\u3002\u6ca1\u9519\uff0c\u6211\u53ef\u4ee5\u7ed9\u4f60\u4eec\u7684\u4e00\u4efd\uff0c\u56e0\u4e3a\u6211\u4eec\u8fd8\u901a\u8fc7\u89c6\u9891\u8bb0\u5f55\u4e0b\u6765\u6211\u4eec\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u6c34\u5e73\u5f53\u7136\u4e5f\u6709\u9650\uff0c\u4e0d\u8fc7\u5bf9\u4e8e\u65b0\u624b\u5165\u95e8\uff0c\u7edd\u5bf9\u6ca1\u95ee\u9898\uff0c\u5982\u679c\u4f60\u8fd8\u4e0d\u4f1a\uff0c\u90a3\u7b97\u6211\u8f93\uff01\uff01\n\n> \u89c6\u9891\u600e\u4e48\u770b\uff1f\n\n![](http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-bilibili-compare.jpg)\n\n1. \u7406\u8bba\u79d1\u73ed\u51fa\u8eab-\u5efa\u8bae\u53bb\u5b66\u4e60 Andrew Ng \u7684\u89c6\u9891\uff08Ng \u7684\u89c6\u9891\u7edd\u5bf9\u662f\u6743\u5a01\uff0c\u8fd9\u4e2a\u6bcb\u5eb8\u7f6e\u7591\uff09\n2. \u7f16\u7801\u80fd\u529b\u5f3a - \u5efa\u8bae\u770b\u6211\u4eec\u7684[\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218-\u6559\u5b66\u7248\u300b](https://space.bilibili.com/97678687/#!/channel/detail?cid=22486)\n3. \u7f16\u7801\u80fd\u529b\u5f31 - \u5efa\u8bae\u770b\u6211\u4eec\u7684[\u300a\u673a\u5668\u5b66\u4e60\u5b9e\u6218-\u8ba8\u8bba\u7248\u300b](https://space.bilibili.com/97678687/#!/channel/detail?cid=13045)\uff0c\u4e0d\u8fc7\u5728\u770b\u7406\u8bba\u7684\u65f6\u5019\uff0c\u770b \u6559\u5b66\u7248-\u7406\u8bba\u90e8\u5206\uff1b\u8ba8\u8bba\u7248\u7684\u5e9f\u8bdd\u592a\u591a\uff0c\u4e0d\u8fc7\u5728\u8bb2\u89e3\u4ee3\u7801\u7684\u65f6\u5019\u662f\u4e00\u884c\u4e00\u884c\u8bb2\u89e3\u7684\uff1b\u6240\u4ee5\uff0c\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\uff0c\u81ea\u7531\u7684\u7ec4\u5408\u3002\n\n> \u3010\u514d\u8d39\u3011\u6570\u5b66\u6559\u5b66\u89c6\u9891 - \u53ef\u6c57\u5b66\u9662 \u5165\u95e8\u7bc7\n\n* [@\u4e8e\u632f\u6893]() \u63a8\u8350: \u53ef\u6c57\u5b66\u9662-\u7f51\u6613\u516c\u5f00\u8bfe\n\n| \u6982\u7387 | \u7edf\u8ba1 | \u7ebf\u6027\u4ee3\u6570 |\n| - | - | - |\n| [\u53ef\u6c57\u5b66\u9662(\u6982\u7387)](http://open.163.com/special/Khan/probability.html)  | [\u53ef\u6c57\u5b66\u9662(\u7edf\u8ba1\u5b66)](http://open.163.com/special/Khan/khstatistics.html)| [\u53ef\u6c57\u5b66\u9662(\u7ebf\u6027\u4ee3\u6570)](http://open.163.com/special/Khan/linearalgebra.html)\n\n> \u673a\u5668\u5b66\u4e60\u89c6\u9891 - ApacheCN \u6559\u5b66\u7248\n\n|||\n| - | - |\n| AcFun | B\u7ad9 |\n| <a title=\"AcFun\uff08\u673a\u5668\u5b66\u4e60\u89c6\u9891\uff09\" href=\"http://www.acfun.cn/u/12540256.aspx#page=1\" target=\"_blank\"><img width=\"290\" src=\"http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-AcFun.jpg\"></a> | <a title=\"bilibili\uff08\u673a\u5668\u5b66\u4e60\u89c6\u9891\uff09\" href=\"https://space.bilibili.com/97678687/#!/channel/index\" target=\"_blank\"><img width=\"290\" src=\"http://data.apachecn.org/img/AiLearning/MainPage/ApacheCN-ML-bilibili.jpg\"></a> |\n| \u4f18\u9177 | \u7f51\u6613\u4e91\u8bfe\u5802 |\n| <a title=\"YouKu\uff08\u673a\u5668\u5b66\u4e60\u89c6\u9891\uff09\" href=\"http://i.youku.com/apachecn\" target=\"_blank\"><img width=\"290\" src=\"http://data.apachecn.org/img/AiLearning/MainPage/ApacheCM-ML-youku.jpg\"></a> | <a title=\"WangYiYunKeTang\uff08\u673a\u5668\u5b66\u4e60\u89c6\u9891\uff09\" href=\"http://study.163.com/course/courseMain.htm?courseId=1004582003\" target=\"_blank\"><img width=\"290\" src=\"http://data.apachecn.org/img/AiLearning/MainPage/ApacheCM-ML-WangYiYunKeTang.png\"></a> |\n\n> \u3010\u514d\u8d39\u3011\u673a\u5668/\u6df1\u5ea6\u5b66\u4e60\u89c6\u9891 - \u5434\u6069\u8fbe\n\n| \u673a\u5668\u5b66\u4e60 | \u6df1\u5ea6\u5b66\u4e60 |\n| - | - |\n| [\u5434\u6069\u8fbe\u673a\u5668\u5b66\u4e60](http://study.163.com/course/courseMain.htm?courseId=1004570029) | [\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5b66\u4e60](http://mooc.study.163.com/course/2001281002?tid=2001392029) |\n\n\n## 2.\u6df1\u5ea6\u5b66\u4e60\n\n### \u5165\u95e8\u57fa\u7840\n\n1. [\u53cd\u5411\u4f20\u9012](/docs/dl/\u53cd\u5411\u4f20\u9012.md): https://www.cnblogs.com/charlotte77/p/5629865.html\n2. [CNN\u539f\u7406](/docs/dl/CNN\u539f\u7406.md): http://www.cnblogs.com/charlotte77/p/7759802.html\n3. [RNN\u539f\u7406](/docs/dl/RNN\u539f\u7406.md): https://blog.csdn.net/qq_39422642/article/details/78676567\n4. [LSTM\u539f\u7406](/docs/dl/LSTM\u539f\u7406.md): https://blog.csdn.net/weixin_42111770/article/details/80900575\n\n### Pytorch - \u6559\u7a0b\n\n-- \u5f85\u66f4\u65b0\n\n### TensorFlow 2.0 - \u6559\u7a0b\n\n-- \u5f85\u66f4\u65b0\n\n> \u76ee\u5f55\u7ed3\u6784:\n\n* [\u5b89\u88c5\u6307\u5357](docs/TensorFlow2.x/\u5b89\u88c5\u6307\u5357.md)\n* [Kears \u5feb\u901f\u5165\u95e8](docs/TensorFlow2.x/Keras\u5feb\u901f\u5165\u95e8.md)\n* [\u5b9e\u6218\u9879\u76ee 1 \u7535\u5f71\u60c5\u611f\u5206\u7c7b](docs/TensorFlow2.x/\u5b9e\u6218\u9879\u76ee_1_\u7535\u5f71\u60c5\u611f\u5206\u7c7b.md)\n* [\u5b9e\u6218\u9879\u76ee 2 \u6c7d\u8f66\u71c3\u6cb9\u6548\u7387](docs/TensorFlow2.x/\u5b9e\u6218\u9879\u76ee_2_\u6c7d\u8f66\u71c3\u6cb9\u6548\u7387.md)\n* [\u5b9e\u6218\u9879\u76ee 3 \u4f18\u5316 \u8fc7\u62df\u5408\u548c\u6b20\u62df\u5408](docs/TensorFlow2.x/\u5b9e\u6218\u9879\u76ee_3_\u4f18\u5316_\u8fc7\u62df\u5408\u548c\u6b20\u62df\u5408.md)\n* [\u5b9e\u6218\u9879\u76ee 4 \u53e4\u8bd7\u8bcd\u81ea\u52a8\u751f\u6210](docs/TensorFlow2.x/\u5b9e\u6218\u9879\u76ee_4_\u53e4\u8bd7\u8bcd\u81ea\u52a8\u751f\u6210.md)\n\n## 3.\u81ea\u7136\u8bed\u8a00\u5904\u7406\n\n\u5b66\u4e60\u8fc7\u7a0b\u4e2d-\u5185\u5fc3\u590d\u6742\u7684\u53d8\u5316\uff01\uff01\uff01\n\n```python\n\u81ea\u4ece\u5b66\u4e60NLP\u4ee5\u540e\uff0c\u624d\u53d1\u73b0\u56fd\u5185\u4e0e\u56fd\u5916\u7684\u5178\u578b\u533a\u522b:\n1. \u5bf9\u8d44\u6e90\u7684\u6001\u5ea6\u662f\u5b8c\u5168\u76f8\u53cd\u7684:\n  1) \u56fd\u5185\uff1a\u5c31\u597d\u50cf\u4e3a\u4e86\u540d\u6c14\uff0c\u4e3e\u529e\u5de5\u4f5c\u88c5\u903c\u7684\u4f1a\u8bae\uff0c\u5c31\u662f\u6ca1\u6709\u5e72\u8d27\uff0c\u5168\u90e8\u90fd\u662f\u8c61\u5f81\u6027\u7684PPT\u4ecb\u7ecd\uff0c\u4e0d\u662f\u9488\u5bf9\u5728\u505a\u7684\u5404\u4f4d\n  2\uff09\u56fd\u5916\uff1a\u5c31\u597d\u50cf\u662f\u4e3a\u4e86\u63a8\u52a8nlp\u8fdb\u6b65\u4e00\u6837\uff0c\u5206\u4eab\u8005\u5404\u79cd\u5e72\u8d27\u8d44\u6599\u548c\u5177\u4f53\u7684\u5b9e\u73b0\u3002\uff08\u7279\u522b\u662f: python\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09\n2. \u8bba\u6587\u7684\u5b9e\u73b0\uff1a\n  1) \u5404\u79cd\u9ad8\u5927\u4e0a\u7684\u8bba\u6587\u5b9e\u73b0\uff0c\u5374\u8fd8\u662f\u6ca1\u770b\u5230\u4e00\u4e2a\u50cf\u6837\u7684GitHub\u9879\u76ee\uff01\uff08\u53ef\u80fd\u6211\u7684\u641c\u7d22\u80fd\u529b\u5dee\u4e86\u70b9\uff0c\u4e00\u76f4\u6ca1\u627e\u5230\uff09\n  2\uff09\u56fd\u5916\u5c31\u4e0d\u4e3e\u4f8b\u4e86\uff0c\u6211\u770b\u4e0d\u61c2\uff01\n3. \u5f00\u6e90\u7684\u6846\u67b6\n  1\uff09\u56fd\u5916\u7684\u5f00\u6e90\u6846\u67b6\uff1a tensorflow/pytorch \u6587\u6863+\u6559\u7a0b+\u89c6\u9891\uff08\u5b98\u65b9\u63d0\u4f9b\uff09\n  2) \u56fd\u5185\u7684\u5f00\u6e90\u6846\u67b6: \u989d\u989d\uff0c\u8fd8\u771f\u4e3e\u4f8b\u4e0d\u51fa\u6765\uff01\u4f46\u662f\u725b\u903c\u5439\u5f97\u4e0d\u6bd4\u56fd\u5916\u5dee\uff01\uff08MXNet\u867d\u7136\u6709\u4f17\u591a\u56fd\u4eba\u53c2\u4e0e\u5f00\u53d1\uff0c\u4f46\u4e0d\u80fd\u7b97\u662f\u56fd\u5185\u5f00\u6e90\u6846\u67b6\u3002\u57fa\u4e8eMXNet\u7684\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60(http://zh.d2l.ai & https://discuss.gluon.ai/t/topic/753)\u4e2d\u6587\u6559\u7a0b,\u5df2\u7ecf\u7531\u6c90\u795e(\u674e\u6c90)\u4ee5\u53ca\u963f\u65af\u987f\u00b7\u5f20\u8bb2\u6388\u5f55\u5236\uff0c\u516c\u5f00\u53d1\u5e03(\u6587\u6863+\u7b2c\u4e00\u5b63\u6559\u7a0b+\u89c6\u9891\uff09\u3002)\n\u6bcf\u4e00\u6b21\u6df1\u5165\u90fd\u8981\u53bb\u7ffb\u5899\uff0c\u6bcf\u4e00\u6b21\u6df1\u5165\u90fd\u8981Google\uff0c\u6bcf\u4e00\u6b21\u770b\u7740\u56fd\u5185\u7684\u8bf4\uff1a\u54c8\u5de5\u5927\u3001\u8baf\u98de\u3001\u4e2d\u79d1\u5927\u3001\u767e\u5ea6\u3001\u963f\u91cc\u591a\u725b\u903c\uff0c\u4f46\u662f\u8d44\u6599\u8fd8\u662f\u5f97\u56fd\u5916\u53bb\u627e\uff01\n\u6709\u65f6\u5019\u771f\u7684\u633a\u6068\u7684\uff01\u771f\u7684\u6709\u70b9\u77a7\u4e0d\u8d77\u81ea\u5df1\u56fd\u5185\u7684\u6280\u672f\u73af\u5883\uff01\n\n\u5f53\u7136\u8c22\u8c22\u56fd\u5185\u5f88\u591a\u535a\u5ba2\u5927\u4f6c\uff0c\u7279\u522b\u662f\u4e00\u4e9b\u5165\u95e8\u7684Demo\u548c\u57fa\u672c\u6982\u5ff5\u3002\u3010\u6df1\u5165\u7684\u6c34\u5e73\u6709\u9650\uff0c\u6ca1\u770b\u61c2\u3011\n```\n\n![](http://data.apachecn.org/img/AiLearning/nlp/F94581F64C21A1094A473397DFA42F9C.jpg)\n\n* **\u3010\u5165\u95e8\u987b\u77e5\u3011\u5fc5\u987b\u4e86\u89e3**: <https://github.com/apachecn/AiLearning/tree/master/docs/nlp>\n* **\u3010\u5165\u95e8\u6559\u7a0b\u3011\u5f3a\u70c8\u63a8\u8350: PyTorch \u81ea\u7136\u8bed\u8a00\u5904\u7406**: <https://github.com/apachecn/NLP-with-PyTorch>\n* Python \u81ea\u7136\u8bed\u8a00\u5904\u7406 \u7b2c\u4e8c\u7248: <https://usyiyi.github.io/nlp-py-2e-zh>\n* \u63a8\u8350\u4e00\u4e2a[liuhuanyong\u5927\u4f6c](https://github.com/liuhuanyong)\u6574\u7406\u7684nlp\u5168\u9762\u77e5\u8bc6\u4f53\u7cfb: <https://liuhuanyong.github.io>\n* \u5f00\u6e90 - \u8bcd\u5411\u91cf\u5e93\u96c6\u5408: \n  * <https://www.cnblogs.com/Darwin2000/p/5786984.html>\n  * <https://ai.tencent.com/ailab/nlp/embedding.html>\n  * <https://blog.csdn.net/xiezj007/article/details/85073890>\n  * <https://github.com/Embedding/Chinese-Word-Vectors>\n  * <https://github.com/brightmart/nlp_chinese_corpus>\n  * <https://github.com/codemayq/chinese_chatbot_corpus>\n  * <https://github.com/candlewill/Dialog_Corpus>\n\n\n### 1.\u4f7f\u7528\u573a\u666f \uff08\u767e\u5ea6\u516c\u5f00\u8bfe\uff09\n\n> \u7b2c\u4e00\u90e8\u5206 \u5165\u95e8\u4ecb\u7ecd\n\n* 1.) [\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5165\u95e8\u4ecb\u7ecd](/docs/nlp/1.\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5165\u95e8\u4ecb\u7ecd.md)\n\n> \u7b2c\u4e8c\u90e8\u5206 \u673a\u5668\u7ffb\u8bd1\n\n* 2.) [\u673a\u5668\u7ffb\u8bd1](/docs/nlp/2.\u673a\u5668\u7ffb\u8bd1.md)\n\n> \u7b2c\u4e09\u90e8\u5206 \u7bc7\u7ae0\u5206\u6790\n\n* 3.1.) [\u7bc7\u7ae0\u5206\u6790-\u5185\u5bb9\u6982\u8ff0](/docs/nlp/3.1.\u7bc7\u7ae0\u5206\u6790-\u5185\u5bb9\u6982\u8ff0.md)\n* 3.2.) [\u7bc7\u7ae0\u5206\u6790-\u5185\u5bb9\u6807\u7b7e](/docs/nlp/3.2.\u7bc7\u7ae0\u5206\u6790-\u5185\u5bb9\u6807\u7b7e.md)\n* 3.3.) [\u7bc7\u7ae0\u5206\u6790-\u60c5\u611f\u5206\u6790](/docs/nlp/3.3.\u7bc7\u7ae0\u5206\u6790-\u60c5\u611f\u5206\u6790.md)\n* 3.4.) [\u7bc7\u7ae0\u5206\u6790-\u81ea\u52a8\u6458\u8981](/docs/nlp/3.4.\u7bc7\u7ae0\u5206\u6790-\u81ea\u52a8\u6458\u8981.md)\n\n> \u7b2c\u56db\u90e8\u5206 UNIT-\u8bed\u8a00\u7406\u89e3\u4e0e\u4ea4\u4e92\u6280\u672f\n\n* 4.) [UNIT-\u8bed\u8a00\u7406\u89e3\u4e0e\u4ea4\u4e92\u6280\u672f](/docs/nlp/4.UNIT-\u8bed\u8a00\u7406\u89e3\u4e0e\u4ea4\u4e92\u6280\u672f.md)\n\n### \u5e94\u7528\u9886\u57df\n\n#### \u4e2d\u6587\u5206\u8bcd\uff1a\n\n* \u6784\u5efaDAG\u56fe\n* \u52a8\u6001\u89c4\u5212\u67e5\u627e\uff0c\u7efc\u5408\u6b63\u53cd\u5411\uff08\u6b63\u5411\u52a0\u6743\u53cd\u5411\u8f93\u51fa\uff09\u6c42\u5f97DAG\u6700\u5927\u6982\u7387\u8def\u5f84\n* \u4f7f\u7528\u4e86SBME\u8bed\u6599\u8bad\u7ec3\u4e86\u4e00\u5957 HMM + Viterbi \u6a21\u578b\uff0c\u89e3\u51b3\u672a\u767b\u5f55\u8bcd\u95ee\u9898\n\n#### 1.\u6587\u672c\u5206\u7c7b\uff08Text Classification\uff09\n\n\u6587\u672c\u5206\u7c7b\u662f\u6307\u6807\u8bb0\u53e5\u5b50\u6216\u6587\u6863\uff0c\u4f8b\u5982\u7535\u5b50\u90ae\u4ef6\u5783\u573e\u90ae\u4ef6\u5206\u7c7b\u548c\u60c5\u611f\u5206\u6790\u3002\n\n\u4e0b\u9762\u662f\u4e00\u4e9b\u5f88\u597d\u7684\u521d\u5b66\u8005\u6587\u672c\u5206\u7c7b\u6570\u636e\u96c6\u3002\n\n1. [\u8def\u900f\u793eNewswire\u4e3b\u9898\u5206\u7c7b](http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html)\uff08\u8def\u900f\u793e-21578\uff09\u30021987\u5e74\u8def\u900f\u793e\u51fa\u73b0\u7684\u4e00\u7cfb\u5217\u65b0\u95fb\u6587\u4ef6\uff0c\u6309\u7c7b\u522b\u7f16\u5236\u7d22\u5f15\u3002[\u53e6\u89c1RCV1\uff0cRCV2\u548cTRC2](http://trec.nist.gov/data/reuters/reuters.html)\u3002\n2. [IMDB\u7535\u5f71\u8bc4\u8bba\u60c5\u611f\u5206\u7c7b\uff08\u65af\u5766\u798f\uff09](http://ai.stanford.edu/~amaas/data/sentiment)\u3002\u6765\u81ea\u7f51\u7ad9imdb.com\u7684\u4e00\u7cfb\u5217\u7535\u5f71\u8bc4\u8bba\u53ca\u5176\u79ef\u6781\u6216\u6d88\u6781\u7684\u60c5\u7eea\u3002\n3. [\u65b0\u95fb\u7ec4\u7535\u5f71\u8bc4\u8bba\u60c5\u611f\u5206\u7c7b\uff08\u5eb7\u5948\u5c14\uff09](http://www.cs.cornell.edu/people/pabo/movie-review-data/)\u3002\u6765\u81ea\u7f51\u7ad9imdb.com\u7684\u4e00\u7cfb\u5217\u7535\u5f71\u8bc4\u8bba\u53ca\u5176\u79ef\u6781\u6216\u6d88\u6781\u7684\u60c5\u7eea\u3002\n\n\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u5e16\u5b50\uff1a\n[\u5355\u6807\u7b7e\u6587\u672c\u5206\u7c7b\u7684\u6570\u636e\u96c6](http://ana.cachopo.org/datasets-for-single-label-text-categorization)\u3002\n\n> \u60c5\u611f\u5206\u6790\n\n\u6bd4\u8d5b\u5730\u5740: https://www.kaggle.com/c/word2vec-nlp-tutorial\n\n* \u65b9\u6848\u4e00(0.86)\uff1aWordCount + \u6734\u7d20 Bayes\n* \u65b9\u6848\u4e8c(0.94)\uff1aLDA + \u5206\u7c7b\u6a21\u578b\uff08knn/\u51b3\u7b56\u6811/\u903b\u8f91\u56de\u5f52/svm/xgboost/\u968f\u673a\u68ee\u6797\uff09\n  * a) \u51b3\u7b56\u6811\u6548\u679c\u4e0d\u662f\u5f88\u597d\uff0c\u8fd9\u79cd\u8fde\u7eed\u7279\u5f81\u4e0d\u592a\u9002\u5408\u7684\n  * b) \u901a\u8fc7\u53c2\u6570\u8c03\u6574 200 \u4e2atopic\uff0c\u4fe1\u606f\u91cf\u4fdd\u5b58\u6548\u679c\u8f83\u4f18\uff08\u8ba1\u7b97\u4e3b\u9898\uff09\n* \u65b9\u6848\u4e09(0.72)\uff1aword2vec + CNN\n  * \u8bf4\u5b9e\u8bdd\uff1a\u6ca1\u6709\u4e00\u4e2a\u597d\u7684\u673a\u5668\uff0c\u662f\u8c03\u4e0d\u51fa\u6765\u4e00\u4e2a\u597d\u7684\u7ed3\u679c (: \u9003\n\n**\u901a\u8fc7AUC \u6765\u8bc4\u4f30\u6a21\u578b\u7684\u6548\u679c**\n\n#### 2.\u8bed\u8a00\u6a21\u578b\uff08Language Modeling\uff09\n\n\u8bed\u8a00\u5efa\u6a21\u6d89\u53ca\u5f00\u53d1\u4e00\u79cd\u7edf\u8ba1\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u53e5\u5b50\u4e2d\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\u6216\u4e00\u4e2a\u5355\u8bcd\u4e2d\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\u3002\u5b83\u662f\u8bed\u97f3\u8bc6\u522b\u548c\u673a\u5668\u7ffb\u8bd1\u7b49\u4efb\u52a1\u4e2d\u7684\u524d\u7f6e\u4efb\u52a1\u3002\n\n\u5b83\u662f\u8bed\u97f3\u8bc6\u522b\u548c\u673a\u5668\u7ffb\u8bd1\u7b49\u4efb\u52a1\u4e2d\u7684\u524d\u7f6e\u4efb\u52a1\u3002\n\n\u4e0b\u9762\u662f\u4e00\u4e9b\u5f88\u597d\u7684\u521d\u5b66\u8005\u8bed\u8a00\u5efa\u6a21\u6570\u636e\u96c6\u3002\n\n1. [\u53e4\u817e\u5821\u9879\u76ee](https://www.gutenberg.org/)\uff0c\u4e00\u7cfb\u5217\u514d\u8d39\u4e66\u7c4d\uff0c\u53ef\u4ee5\u7528\u7eaf\u6587\u672c\u68c0\u7d22\u5404\u79cd\u8bed\u8a00\u3002\n2. \u8fd8\u6709\u66f4\u591a\u6b63\u5f0f\u7684\u8bed\u6599\u5e93\u5f97\u5230\u4e86\u5f88\u597d\u7684\u7814\u7a76;\u00a0\u4f8b\u5982\uff1a\n    [\u5e03\u6717\u5927\u5b66\u73b0\u4ee3\u7f8e\u56fd\u82f1\u8bed\u6807\u51c6\u8bed\u6599\u5e93](https://en.wikipedia.org/wiki/Brown_Corpus)\u3002\u5927\u91cf\u82f1\u8bed\u5355\u8bcd\u6837\u672c\u3002\n    [\u8c37\u6b4c10\u4ebf\u5b57\u8bed\u6599\u5e93](https://github.com/ciprian-chelba/1-billion-word-language-modeling-benchmark)\u3002\n\n> \u65b0\u8bcd\u53d1\u73b0\n\n* \u4e2d\u6587\u5206\u8bcd\u65b0\u8bcd\u53d1\u73b0\n* python3\u5229\u7528\u4e92\u4fe1\u606f\u548c\u5de6\u53f3\u4fe1\u606f\u71b5\u7684\u4e2d\u6587\u5206\u8bcd\u65b0\u8bcd\u53d1\u73b0\n* <https://github.com/zhanzecheng/Chinese_segment_augment>\n\n> \u53e5\u5b50\u76f8\u4f3c\u5ea6\u8bc6\u522b\n\n* \u9879\u76ee\u5730\u5740: https://www.kaggle.com/c/quora-question-pairs\n* \u89e3\u51b3\u65b9\u6848: word2vec + Bi-GRU\n\n> \u6587\u672c\u7ea0\u9519\n\n* bi-gram + levenshtein\n\n#### 3.\u56fe\u50cf\u5b57\u5e55\uff08Image Captioning\uff09\n\nmage\u5b57\u5e55\u662f\u4e3a\u7ed9\u5b9a\u56fe\u50cf\u751f\u6210\u6587\u672c\u63cf\u8ff0\u7684\u4efb\u52a1\u3002\n\n\u4e0b\u9762\u662f\u4e00\u4e9b\u5f88\u597d\u7684\u521d\u5b66\u8005\u56fe\u50cf\u5b57\u5e55\u6570\u636e\u96c6\u3002\n\n1. [\u4e0a\u4e0b\u6587\u4e2d\u7684\u516c\u5171\u5bf9\u8c61\uff08COCO\uff09](http://mscoco.org/dataset/#overview)\u3002\u5305\u542b\u8d85\u8fc712\u4e07\u5f20\u5e26\u63cf\u8ff0\u7684\u56fe\u50cf\u7684\u96c6\u5408\n2. [Flickr 8K](http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html)\u3002\u4eceflickr.com\u83b7\u53d6\u76848\u5343\u4e2a\u63cf\u8ff0\u56fe\u50cf\u7684\u96c6\u5408\u3002\n3. [Flickr 30K](http://shannon.cs.illinois.edu/DenotationGraph/)\u3002\u4eceflickr.com\u83b7\u53d6\u76843\u4e07\u4e2a\u63cf\u8ff0\u56fe\u50cf\u7684\u96c6\u5408\u3002\n    \u6b32\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u770b\u5e16\u5b50\uff1a\n\n[\u63a2\u7d22\u56fe\u50cf\u5b57\u5e55\u6570\u636e\u96c6\uff0c2016\u5e74](http://sidgan.me/technical/2016/01/09/Exploring-Datasets)\n\n#### 4.\u673a\u5668\u7ffb\u8bd1\uff08Machine Translation\uff09\n\n\u673a\u5668\u7ffb\u8bd1\u662f\u5c06\u6587\u672c\u4ece\u4e00\u79cd\u8bed\u8a00\u7ffb\u8bd1\u6210\u53e6\u4e00\u79cd\u8bed\u8a00\u7684\u4efb\u52a1\u3002\n\n\u4e0b\u9762\u662f\u4e00\u4e9b\u5f88\u597d\u7684\u521d\u5b66\u8005\u673a\u5668\u7ffb\u8bd1\u6570\u636e\u96c6\u3002\n\n1. [\u52a0\u62ff\u5927\u7b2c36\u5c4a\u8bae\u4f1a\u7684\u534f\u8c03\u56fd\u4f1a\u8bae\u5458](https://www.isi.edu/natural-language/download/hansard/)\u3002\u6210\u5bf9\u7684\u82f1\u8bed\u548c\u6cd5\u8bed\u53e5\u5b50\u3002\n2. [\u6b27\u6d32\u8bae\u4f1a\u8bc9\u8bbc\u5e73\u884c\u8bed\u6599\u5e931996-2011](http://www.statmt.org/europarl/)\u3002\u53e5\u5b50\u5bf9\u4e00\u5957\u6b27\u6d32\u8bed\u8a00\u3002\n    \u6709\u5927\u91cf\u6807\u51c6\u6570\u636e\u96c6\u7528\u4e8e\u5e74\u5ea6\u673a\u5668\u7ffb\u8bd1\u6311\u6218;\u00a0\u770b\u5230\uff1a\n\n[\u7edf\u8ba1\u673a\u5668\u7ffb\u8bd1](http://www.statmt.org/)\n\n> \u673a\u5668\u7ffb\u8bd1\n\n* Encoder + Decoder(Attention)\n* \u53c2\u8003\u6848\u4f8b: http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html\n\n#### 5.\u95ee\u7b54\u7cfb\u7edf\uff08Question Answering\uff09\n\n\u95ee\u7b54\u662f\u4e00\u9879\u4efb\u52a1\uff0c\u5176\u4e2d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53e5\u5b50\u6216\u6587\u672c\u6837\u672c\uff0c\u4ece\u4e2d\u63d0\u51fa\u95ee\u9898\u5e76\u4e14\u5fc5\u987b\u56de\u7b54\u95ee\u9898\u3002\n\n\u4e0b\u9762\u662f\u4e00\u4e9b\u5f88\u597d\u7684\u521d\u5b66\u8005\u95ee\u9898\u56de\u7b54\u6570\u636e\u96c6\u3002\n\n1. [\u65af\u5766\u798f\u95ee\u9898\u56de\u7b54\u6570\u636e\u96c6\uff08SQuAD\uff09](https://rajpurkar.github.io/SQuAD-explorer/)\u3002\u56de\u7b54\u6709\u5173\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u7684\u95ee\u9898\u3002\n2. [Deepmind\u95ee\u9898\u56de\u7b54\u8bed\u6599\u5e93](https://github.com/deepmind/rc-data)\u3002\u4ece\u6bcf\u65e5\u90ae\u62a5\u56de\u7b54\u6709\u5173\u65b0\u95fb\u6587\u7ae0\u7684\u95ee\u9898\u3002\n3. [\u4e9a\u9a6c\u900a\u95ee\u7b54\u6570\u636e](http://jmcauley.ucsd.edu/data/amazon/qa/)\u3002\u56de\u7b54\u6709\u5173\u4e9a\u9a6c\u900a\u4ea7\u54c1\u7684\u95ee\u9898\u3002\n    \u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u5e16\u5b50\uff1a\n\n[\u6570\u636e\u96c6\uff1a\u6211\u5982\u4f55\u83b7\u5f97\u95ee\u7b54\u7f51\u7ad9\u7684\u8bed\u6599\u5e93\uff0c\u5982Quora\u6216Yahoo Answers\u6216Stack Overflow\u6765\u5206\u6790\u7b54\u6848\u8d28\u91cf\uff1f](https://www.quora.com/Datasets-How-can-I-get-corpus-of-a-question-answering-website-like-Quora-or-Yahoo-Answers-or-Stack-Overflow-for-analyzing-answer-quality)\n\n#### 6.\u8bed\u97f3\u8bc6\u522b\uff08Speech Recognition\uff09\n\n\u8bed\u97f3\u8bc6\u522b\u662f\u5c06\u53e3\u8bed\u7684\u97f3\u9891\u8f6c\u6362\u4e3a\u4eba\u7c7b\u53ef\u8bfb\u6587\u672c\u7684\u4efb\u52a1\u3002\n\n\u4e0b\u9762\u662f\u4e00\u4e9b\u5f88\u597d\u7684\u521d\u5b66\u8005\u8bed\u97f3\u8bc6\u522b\u6570\u636e\u96c6\u3002\n\n1. [TIMIT\u58f0\u5b66 - \u8bed\u97f3\u8fde\u7eed\u8bed\u97f3\u8bed\u6599\u5e93](https://catalog.ldc.upenn.edu/LDC93S1)\u3002\u4e0d\u662f\u514d\u8d39\u7684\uff0c\u4f46\u56e0\u5176\u5e7f\u6cdb\u4f7f\u7528\u800c\u4e0a\u5e02\u3002\u53e3\u8bed\u7f8e\u56fd\u82f1\u8bed\u548c\u76f8\u5173\u7684\u8f6c\u5f55\u3002\n2. [VoxForge](http://voxforge.org/)\u3002\u7528\u4e8e\u6784\u5efa\u7528\u4e8e\u8bed\u97f3\u8bc6\u522b\u7684\u5f00\u6e90\u6570\u636e\u5e93\u7684\u9879\u76ee\u3002\n3. [LibriSpeech ASR\u8bed\u6599\u5e93](http://www.openslr.org/12/)\u3002\u4eceLibriVox\u6536\u96c6\u7684\u5927\u91cf\u82f1\u8bed\u6709\u58f0\u8bfb\u7269\u3002\n\n#### 7.\u81ea\u52a8\u6587\u6458\uff08Document Summarization\uff09\n\n\u6587\u6863\u6458\u8981\u662f\u521b\u5efa\u8f83\u5927\u6587\u6863\u7684\u7b80\u77ed\u6709\u610f\u4e49\u63cf\u8ff0\u7684\u4efb\u52a1\u3002\n\n\u4e0b\u9762\u662f\u4e00\u4e9b\u5f88\u597d\u7684\u521d\u5b66\u8005\u6587\u6863\u6458\u8981\u6570\u636e\u96c6\u3002\n\n1. [\u6cd5\u5f8b\u6848\u4f8b\u62a5\u544a\u6570\u636e\u96c6](https://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports)\u3002\u6536\u96c6\u4e864000\u4efd\u6cd5\u5f8b\u6848\u4ef6\u53ca\u5176\u6458\u8981\u3002\n2. [TIPSTER\u6587\u672c\u6458\u8981\u8bc4\u4f30\u4f1a\u8bae\u8bed\u6599\u5e93](http://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html)\u3002\u6536\u96c6\u4e86\u8fd1200\u4efd\u6587\u4ef6\u53ca\u5176\u6458\u8981\u3002\n3. [\u82f1\u8bed\u65b0\u95fb\u6587\u672c\u7684AQUAINT\u8bed\u6599\u5e93](https://catalog.ldc.upenn.edu/LDC2002T31)\u3002\u4e0d\u662f\u514d\u8d39\u7684\uff0c\u800c\u662f\u5e7f\u6cdb\u4f7f\u7528\u7684\u3002\u65b0\u95fb\u6587\u7ae0\u7684\u8bed\u6599\u5e93\u3002\n    \u6b32\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff1a\n\n[\u6587\u6863\u7406\u89e3\u4f1a\u8bae\uff08DUC\uff09\u4efb\u52a1](http://www-nlpir.nist.gov/projects/duc/data.html)\u3002\n[\u5728\u54ea\u91cc\u53ef\u4ee5\u627e\u5230\u7528\u4e8e\u6587\u672c\u6458\u8981\u7684\u826f\u597d\u6570\u636e\u96c6\uff1f](https://www.quora.com/Where-can-I-find-good-data-sets-for-text-summarization)\n\n> \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\n\n* Bi-LSTM CRF\n* \u53c2\u8003\u6848\u4f8b: http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.html\n* CRF\u63a8\u8350\u6587\u6863: https://www.jianshu.com/p/55755fc649b1\n\n> \u6587\u672c\u6458\u8981\n\n* **\u62bd\u53d6\u5f0f**\n* word2vec + textrank\n* word2vec\u63a8\u8350\u6587\u6863: https://www.zhihu.com/question/44832436/answer/266068967\n* textrank\u63a8\u8350\u6587\u6863: https://blog.csdn.net/BaiHuaXiu123/article/details/77847232\n\n\n## Graph\u56fe\u8ba1\u7b97\u3010\u6162\u6162\u66f4\u65b0\u3011\n\n* \u6570\u636e\u96c6: [data/nlp/graph](data/nlp/graph)\n* \u5b66\u4e60\u8d44\u6599: spark graphX\u5b9e\u6218.pdf \u3010\u6587\u4ef6\u592a\u5927\u4e0d\u65b9\u4fbf\u63d0\u4f9b\uff0c\u81ea\u5df1\u767e\u5ea6\u3011\n\n## \u77e5\u8bc6\u56fe\u8c31\n\n* \u77e5\u8bc6\u56fe\u8c31\uff0c\u6211\u53ea\u8ba4 [SimmerChan](https://www.zhihu.com/people/simmerchan): [\u3010\u77e5\u8bc6\u56fe\u8c31-\u7ed9AI\u88c5\u4e2a\u5927\u8111\u3011](https://zhuanlan.zhihu.com/knowledgegraph)\n* \u8bf4\u5b9e\u8bdd\uff0c\u6211\u662f\u770b\u8fd9\u535a\u4e3b\u8001\u54e5\u5199\u7684\u535a\u5ba2\u957f\u5927\u7684\uff0c\u5199\u7684\u771f\u7684\u662f\u6df1\u5165\u6d45\u51fa\u3002\u6211\u5f88\u559c\u6b22\uff0c\u6240\u4ee5\u5c31\u5206\u4eab\u7ed9\u5927\u5bb6\uff0c\u5e0c\u671b\u4f60\u4eec\u4e5f\u559c\u6b22\u3002\n\n### \u8fdb\u4e00\u6b65\u9605\u8bfb\n\n\u5982\u679c\u60a8\u5e0c\u671b\u66f4\u6df1\u5165\uff0c\u672c\u8282\u63d0\u4f9b\u4e86\u5176\u4ed6\u6570\u636e\u96c6\u5217\u8868\u3002\n\n1. [\u7ef4\u57fa\u767e\u79d1\u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u6587\u672c\u6570\u636e\u96c6](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Text_data)\n2. [\u6570\u636e\u96c6\uff1a\u8ba1\u7b97\u8bed\u8a00\u5b66\u5bb6\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u7684\u4e3b\u8981\u6587\u672c\u8bed\u6599\u5e93\u662f\u4ec0\u4e48\uff1f](https://www.quora.com/Datasets-What-are-the-major-text-corpora-used-by-computational-linguists-and-natural-language-processing-researchers-and-what-are-the-characteristics-biases-of-each-corpus)\n3. [\u65af\u5766\u798f\u7edf\u8ba1\u81ea\u7136\u8bed\u8a00\u5904\u7406\u8bed\u6599\u5e93](https://nlp.stanford.edu/links/statnlp.html#Corpora)\n4. [\u6309\u5b57\u6bcd\u987a\u5e8f\u6392\u5217\u7684NLP\u6570\u636e\u96c6\u5217\u8868](https://github.com/niderhoff/nlp-datasets)\n5. [\u8be5\u673a\u6784NLTK](http://www.nltk.org/nltk_data/)\n6. [\u5728DL4J\u4e0a\u6253\u5f00\u6df1\u5ea6\u5b66\u4e60\u6570\u636e](https://deeplearning4j.org/opendata)\n7. [NLP\u6570\u636e\u96c6](https://github.com/caesar0301/awesome-public-datasets#natural-language)\n8. \u56fd\u5185\u5f00\u653e\u6570\u636e\u96c6: https://bosonnlp.com/dev/resource\n\n## \u9879\u76ee\u8d1f\u8d23\u4eba\n\n> Ml \u7b2c\u4e00\u671f (2017-02-27)\n\n* [@\u7247\u523b](https://github.com/jiangzhonglian)\n* [@\u90a3\u4f0a\u62b9\u5fae\u7b11](https://github.com/wangyangting)\n* [@\u7476\u59b9](https://github.com/chenyyx)\n* [2017-04-08_\u7b2c\u4e00\u671f\u7684\u603b\u7ed3](/report/2017-04-08_\u7b2c\u4e00\u671f\u7684\u603b\u7ed3.md)\n\n> Ml \u7b2c\u4e8c\u671f (2017-08-14)\n\n* [@\u7247\u523b](https://github.com/jiangzhonglian)\n* [@\u90a3\u4f0a\u62b9\u5fae\u7b11](https://github.com/wangyangting)\n* [@\u7476\u59b9](https://github.com/chenyyx)\n* [@Mike](https://github.com/mikechengwei)\n\n> Ml \u7b2c\u4e09\u671f (2018-04-16)\n\n## \u9879\u76ee\u8d21\u732e\u8005\n\n> Ml \u7b2c\u4e00\u671f (2017-02-27)\n\n* [@\u4faf\u6cd5\u8d85](https://github.com/geekidentity)\n* [@hello19883](https://github.com/hello19883)\n* [@\u5f90\u946b](https://github.com/sheepmen)\n* [@ibe](https://github.com/highfei2011)\n\n> Ml \u7b2c\u4e8c\u671f (2017-08-14)\n\n* [@Arithmetic](https://github.com/LeeMoonCh)\n* [@Veyron C](https://github.com/caopeirui)\n* [@Cugtyt](https://github.com/Cugtyt)\n* [@BBruceyuan](https://github.com/hey-bruce)\n\n> Ml \u7b2c\u4e09\u671f (2018-04-16)\n\n## \u7fa4\u7ba1\u7406\u5458\u6362\u5c4a\n\n* [@\u7476\u59b9](https://github.com/chenyyx)\n* [@\u98de\u9f99](https://github.com/wizardforcel)\n* [@\u7247\u523b](https://github.com/jiangzhonglian)\n* [@\u4f2a\u6587\u827a.](https://github.com/Watermelon233)\n* [@\u90a3\u4f0a\u62b9\u5fae\u7b11](https://github.com/wangyangting)\n* [@LAMDA-\u5065\u5fd8\u75c7]() \u6c38\u4e45\u7559\u4efb-\u975e\u5e38\u611f\u8c22\u5bf9\u7fa4\u7684\u8d21\u732e\n\n> Ml \u7b2c\u4e00\u5c4a (2017-09-01)\n\n* [@\u6613\u6f20]()\n* [@Mike](https://github.com/mikechengwei)\n* [@Books]()\n* [@\u674e\u5b5f\u79b9]()\n* [@\u5f20\u5047\u98de]()\n* [@Glassy]()\n* [@\u7ea2\u8272\u77f3\u5934]()\n* [@\u5fae\u5149\u540c\u5c18]()\n\n> Ml \u7b2c\u4e8c\u5c4a (2018-07-04)\n\n* [@\u5f20\u5047\u98de]()\n* [@\u674e\u5b5f\u79b9]()\n* [@\u5c0f\u660e\u6559\u4e3b]()\n* [@\u5e73\u6de1\u7684\u5929]()\n* [@\u51cc\u5c11skier\u309e]()\n* [@\u3058\u2606\u03bd\u0401\u5750\u770b\u4e91\u8d77]()\n* [\u53e4\u67f3-DesertsX]()\n* [woodchuck]()\n* [\u81ea\u7531\u7cbe\u7075]()\n* [\u695a\u76df]()\n* [99\u6746\u6e05\u53f0]()\n* [\u65f6\u7a7a\u5b88\u671b\u8005@]()\n* [\u53ea\u60f3\u53d1\u8bba\u6587\u7684\u6e23\u6e23]()\n* [\u76ee\u6807: ml\u529d\u9000\u4e13\u5bb6]()\n\n> Ml \u7b2c\u4e09\u5c4a (2019-01-01)\n\n* [\u53ea\u4f1a\u558a666\u7684\u5b58\u5728]()\n* [codefun007.xyz]()\n* [\u837c\u9761]()\n* [\u5927\u9c7c]()\n* [\u9752\u9e1f]()\n* [\u53e4\u67f3-DesertsX]()\n* [Edge]()\n* [Alluka]()\n* [\u4e0d\u53d1\u7bc7paper\u4e0d\u6539\u540d\u7247]()\n* [FontTian]()\n* [Bigjing]()\n* [\u4ec1 \u793c \u667a \u7231]()\n* [\u53ef\u556a\u7684\u5c0f\u4e56\u53d7]()\n* [\u8001\u53e4\u8463]()\n* [\u65f6\u7a7a\u5b88\u671b\u8005]()\n* [\u6211\u597d\u83dc\u554a]()\n* [Messi\u00a019]()\n* [\u840cJay\u5c0f\u516c\u4e3e]()\n\n> Ml \u7b2c\u56db\u5c4a (2019-06-01)\n\n* [\u4f5b\u5b66\u7231\u597d\u8005]()\n* [\u695a\u76df]()\n* [codefun007.xyz]()\n* [\u5927\u9c7c-\u7fa4\u82b1-\u58f0\u4f18]()\n* [\u5927\u6d77]()\n* [Edge]()\n* [if only]()\n* [\u674e\u5b5f\u79b9]()\n* [\u5e73\u9759]()\n* [\u4efb\u52a1\u505a\u4e0d\u5b8c]()\n* [\u4ec1\u793c\u667a\u7231]()\n* [\u56ed\u65f6\u7a7a\u5b88\u671b\u8005@]()\n* [\u5750\u770b\u4e91\u8d77]()\n* [\u963f\u82b1\u541b\u9738\u5360\u8def\u4eba]()\n* [\u70e6\u7116\u9e21]()\n* [\u53e4\u67f3-DesertsX]()\n* [\u9752\u9e1f(\u670d\u52a1\u5458)]()\n* [\u5c0f\u660e\u6559\u4e3b]()\n* [zhiqing]()\n* [SrL.z]()\n\n**\u6b22\u8fce\u8d21\u732e\u8005\u4e0d\u65ad\u7684\u8ffd\u52a0**\n\n## \u514d\u8d23\u58f0\u660e - \u3010\u53ea\u4f9b\u5b66\u4e60\u53c2\u8003\u3011\n\n* ApacheCN \u7eaf\u7cb9\u51fa\u4e8e\u5b66\u4e60\u76ee\u7684\u4e0e\u4e2a\u4eba\u5174\u8da3\u7ffb\u8bd1\u672c\u4e66\n* ApacheCN \u4fdd\u7559\u5bf9\u6b64\u7248\u672c\u8bd1\u6587\u7684\u7f72\u540d\u6743\u53ca\u5176\u5b83\u76f8\u5173\u6743\u5229\n\n## **\u534f\u8bae**\n\n* \u4ee5\u5404\u9879\u76ee\u534f\u8bae\u4e3a\u51c6\u3002\n* ApacheCN \u8d26\u53f7\u4e0b\u6ca1\u6709\u534f\u8bae\u7684\u9879\u76ee\uff0c\u4e00\u5f8b\u89c6\u4e3a [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)\u3002\n\n---\n\n## \u8d44\u6599\u6765\u6e90:\n\n* \u3010\u6bd4\u8d5b\u6536\u96c6\u5e73\u53f0\u3011: https://github.com/iphysresearch/DataSciComp\n* https://github.com/pbharrin/machinelearninginaction\n* https://machinelearningmastery.com/datasets-natural-language-processing\n\n## \u611f\u8c22\u4fe1\n\n\u6700\u8fd1\u65e0\u610f\u6536\u5230\u7fa4\u53cb\u63a8\u9001\u7684\u94fe\u63a5\uff0c\u53d1\u73b0\u5f97\u5230\u5927\u4f6c\u9ad8\u5ea6\u7684\u8ba4\u53ef\uff0c\u5e76\u5728\u70ed\u5fc3\u7684\u63a8\u5e7f\n\n\u5728\u6b64\u611f\u8c22:\n\n* [\u91cf\u5b50\u4f4d](https://www.zhihu.com/org/liang-zi-wei-48): <https://www.zhihu.com/question/20472776/answer/691646493>\n* \u4eba\u5de5\u667a\u80fd\u524d\u6cbf\u8bb2\u4e60: <https://mp.weixin.qq.com/s/f2dqulxOPkt7k5hqPsydyQ>\n\n## \u8d5e\u52a9\u6211\u4eec\n\n<img src=\"http://data.apachecn.org/img/about/donate.jpg\" alt=\"\u5fae\u4fe1&\u652f\u4ed8\u5b9d\" />\n\n---\n\n> \u7279\u522b\u8d5e\u52a9\u5546(\u6b22\u8fce\u201c\u79c1\u804a\u201d\u8d5e\u52a9)\n\n<table>\n      <tbody>\n        <tr>\n          <td align=\"center\" valign=\"middle\">\n            <a href=\"https://coding.net/?utm_source=ApacheCN&utm_medium=banner&utm_campaign=march2019\" target=\"_blank\">\n              <img width=\"1080\" src=\"http://data.apachecn.org/img/SpecialSponsors/CodingNet.png\">\n            </a>\n          </td>\n      </tbody>\n</table>\n"}, {"repo": "localstack/localstack", "language": "Python", "readme_contents": "[![Build Status](https://travis-ci.org/localstack/localstack.svg)](https://travis-ci.org/localstack/localstack) [![Backers on Open Collective](https://opencollective.com/localstack/backers/badge.svg)](#backers) [![Sponsors on Open Collective](https://opencollective.com/localstack/sponsors/badge.svg)](#sponsors) [![Coverage Status](https://coveralls.io/repos/github/localstack/localstack/badge.svg?branch=master)](https://coveralls.io/github/localstack/localstack?branch=master)\n[![Gitter](https://img.shields.io/gitter/room/localstack/Platform.svg)](https://gitter.im/localstack/Platform)\n[![PyPI Version](https://badge.fury.io/py/localstack.svg)](https://badge.fury.io/py/localstack)\n[![PyPI License](https://img.shields.io/pypi/l/localstack.svg)](https://img.shields.io/pypi/l/localstack.svg)\n[![Code Climate](https://codeclimate.com/github/localstack/localstack/badges/gpa.svg)](https://codeclimate.com/github/localstack/localstack)\n[![Twitter](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/_localstack)\n\n# LocalStack - A fully functional local AWS cloud stack\n\n![LocalStack](https://github.com/localstack/localstack/raw/master/localstack/dashboard/web/img/localstack.png)\n\n*LocalStack* provides an easy-to-use test/mocking framework for developing Cloud applications.\n\nCurrently, the focus is primarily on supporting the AWS cloud stack.\n\n# Announcements\n\n* **2019-10-09**: **LocalStack Pro is out!** We're incredibly excited to announce the launch of LocalStack Pro - the enterprise version of LocalStack with additional APIs and advanced features. Check out the free trial at https://localstack.cloud\n* **2018-01-10**: **Help wanted!** Please [fill out this survey](https://lambdastudy.typeform.com/to/kDUvvy?source=localstack-github) to support a research study on the usage of Serverless and Function-as-a-Service (FaaS) services, conducted at Chalmers University of Technology. The survey only takes 5-10 minutes of your time. Many thanks for your participation!!\n  * The result from this study can be found [here](https://research.chalmers.se/en/publication/508147)\n* **2017-08-27**: **We need your support!** LocalStack is growing fast, we now have thousands of developers using the platform on a regular basis. Last month we have recorded a staggering 100k test runs, with 25k+ DynamoDB tables, 20k+ SQS queues, 15k+ Kinesis streams, 13k+ S3 buckets, and 10k+ Lambda functions created locally - for 0$ costs (more details to be published soon). Bug and feature requests are pouring in, and we now need some support from _you_ to keep the open source version actively maintained. Please check out [Open Collective](https://opencollective.com/localstack) and become a [backer](https://github.com/localstack/localstack#backers) or [supporter](https://github.com/localstack/localstack#backers) of the project today! Thanks everybody for contributing. \u2665\n* **2017-07-20**: Please note: Starting with version `0.7.0`, the Docker image will be pushed\nand kept up to date under the **new name** `localstack/localstack`. (This means that you may\nhave to update your CI configurations.) Please refer to the updated\n**[End-User License Agreement (EULA)](doc/end_user_license_agreement)** for the new versions.\nThe old Docker image (`atlassianlabs/localstack`) is still available but will not be maintained\nany longer.\n\n# Overview\n\nLocalStack spins up the following core Cloud APIs on your local machine:\n\n* **API Gateway** at http://localhost:4567\n* **Kinesis** at http://localhost:4568\n* **DynamoDB** at http://localhost:4569\n* **DynamoDB Streams** at http://localhost:4570\n* **Elasticsearch** at http://localhost:4571\n* **S3** at http://localhost:4572\n* **Firehose** at http://localhost:4573\n* **Lambda** at http://localhost:4574\n* **SNS** at http://localhost:4575\n* **SQS** at http://localhost:4576\n* **Redshift** at http://localhost:4577\n* **ES (Elasticsearch Service)** at http://localhost:4578\n* **SES** at http://localhost:4579\n* **Route53** at http://localhost:4580\n* **CloudFormation** at http://localhost:4581\n* **CloudWatch** at http://localhost:4582\n* **SSM** at http://localhost:4583\n* **SecretsManager** at http://localhost:4584\n* **StepFunctions** at http://localhost:4585\n* **CloudWatch Logs** at http://localhost:4586\n* **EventBridge (CloudWatch Events)** at http://localhost:4587\n* **STS** at http://localhost:4592\n* **IAM** at http://localhost:4593\n* **EC2** at http://localhost:4597\n* **KMS** at http://localhost:4599\n\nIn addition to the above, the [**Pro version** of LocalStack](https://localstack.cloud/#pricing) supports additional APIs and advanced features, including:\n* **AppSync**\n* **Athena**\n* **Cognito**\n* **ElastiCache**\n* **ECS/EKS**\n* **IoT**\n* **Lambda Layers**\n* **RDS**\n* **XRay**\n* **Interactive UIs to manage resources**\n* **Test report dashboards**\n* ...and much, much more to come!\n\n## Why LocalStack?\n\nLocalStack builds on existing best-of-breed mocking/testing tools, most notably\n[kinesalite](https://github.com/mhart/kinesalite)/[dynalite](https://github.com/mhart/dynalite)\nand [moto](https://github.com/spulec/moto). While these tools are *awesome* (!), they lack functionality\nfor certain use cases. LocalStack combines the tools, makes them interoperable, and adds important\nmissing functionality on top of them:\n\n* **Error injection:** LocalStack allows to inject errors frequently occurring in real Cloud environments,\n  for instance `ProvisionedThroughputExceededException` which is thrown by Kinesis or DynamoDB if the amount of\n  read/write throughput is exceeded.\n* **Isolated processes**: All services in LocalStack run in separate processes. The overhead of additional\n  processes is negligible, and the entire stack can easily be executed on any developer machine and CI server.\n  In moto, components are often hard-wired in RAM (e.g., when forwarding a message on an SNS topic to an SQS queue,\n  the queue endpoint is looked up in a local hash map). In contrast, LocalStack services live in isolation\n  (separate processes available via HTTP), which fosters true decoupling and more closely resembles the real\n  cloud environment.\n* **Pluggable services**: All services in LocalStack are easily pluggable (and replaceable), due to the fact that\n  we are using isolated processes for each service. This allows us to keep the framework up-to-date and select\n  best-of-breed mocks for each individual service.\n\n\n## Requirements\n\n* `python` (both Python 2.x and 3.x supported)\n* `pip` (python package manager)\n* `Docker`\n\n## Installing\n\nThe easiest way to install LocalStack is via `pip`:\n\n```\npip install localstack\n```\n\n**Note**: Please do **not** use `sudo` or the `root` user - LocalStack\nshould be installed and started entirely under a local non-root user. If you have problems\nwith permissions in MacOS X Sierra, install with `pip install --user localstack`\n\n## Running in Docker\n\nBy default, LocalStack gets started inside a Docker container using this command:\n\n```\nlocalstack start\n```\n\n(Note that on MacOS you may have to run `TMPDIR=/private$TMPDIR localstack start --docker` if\n`$TMPDIR` contains a symbolic link that cannot be mounted by Docker.)\n\n### Using `docker-compose`\n\nYou can also use the `docker-compose.yml` file from the repository and use this command (currently requires `docker-compose` version 2.1+):\n\n```\ndocker-compose up\n```\n\n(Note that on MacOS you may have to run `TMPDIR=/private$TMPDIR docker-compose up` if\n`$TMPDIR` contains a symbolic link that cannot be mounted by Docker.)\n\nUse on existing docker-compose project. Add in existing services. The project can be found in docker hub, no need to download or clone source:\n\n```\nversion: '2.1'\nservices:\n...\n  localstack:\n    image: localstack/localstack\n    ports:\n      - \"4567-4584:4567-4584\"\n      - \"${PORT_WEB_UI-8080}:${PORT_WEB_UI-8080}\"\n    environment:\n      - SERVICES=${SERVICES- }\n      - DEBUG=${DEBUG- }\n      - DATA_DIR=${DATA_DIR- }\n      - PORT_WEB_UI=${PORT_WEB_UI- }\n      - LAMBDA_EXECUTOR=${LAMBDA_EXECUTOR- }\n      - KINESIS_ERROR_PROBABILITY=${KINESIS_ERROR_PROBABILITY- }\n      - DOCKER_HOST=unix:///var/run/docker.sock\n    volumes:\n      - \"${TMPDIR:-/tmp/localstack}:/tmp/localstack\"\n```\n\nTo facilitate interoperability, configuration variables can be prefixed with `LOCALSTACK_` in docker. For instance, setting `LOCALSTACK_SERVICES=s3` is equivalent to `SERVICES=s3`.\n\n## Starting locally (non-Docker mode)\n\nAlternatively, the infrastructure can be spun up on the local host machine (without using Docker) using the following command:\n\n```\nlocalstack start --host\n```\n\n(Note that this will require [additional dependencies](#Developing), and currently is not supported on some operating systems, including Windows.)\n\nLocalStack will attempt to automatically fetch the missing dependencies when you first start it up in \"host\" mode; alternatively, you can use the `full` profile to install all dependencies at `pip` installation time:\n\n```\npip install \"localstack[full]\"\n```\n\n## Configurations\n\nYou can pass the following environment variables to LocalStack:\n\n* `SERVICES`: Comma-separated list of service names and (optional) ports they should run on.\n  If no port is specified, a default port is used. Service names basically correspond to the\n  [service names of the AWS CLI](http://docs.aws.amazon.com/cli/latest/reference/#available-services)\n  (`kinesis`, `lambda`, `sqs`, etc), although LocalStack only supports a subset of them.\n  Example value: `kinesis,lambda:4569,sqs:4570` to start Kinesis on the default port,\n  Lambda on port 4569, and SQS on port 4570. In addition, the following shorthand values can be\n  specified to run a predefined ensemble of services:\n  - `serverless`: run services often used for Serverless apps (`iam`, `lambda`, `dynamodb`, `apigateway`, `s3`, `sns`)\n* `DEFAULT_REGION`: AWS region to use when talking to the API (defaults to `us-east-1`).\n* `HOSTNAME`: Name of the host to expose the services internally (defaults to `localhost`).\n  Use this to customize the framework-internal communication, e.g., if services are\n  started in different containers using docker-compose.\n* `HOSTNAME_EXTERNAL`: Name of the host to expose the services externally (defaults to `localhost`).\n  This host is used, e.g., when returning queue URLs from the SQS service to the client.\n* `<SERVICE>_PORT`: Port number to bind a specific service to (defaults to service ports above).\n* `<SERVICE>_PORT_EXTERNAL`: Port number to expose a specific service externally (defaults to service ports above). `SQS_PORT_EXTERNAL`, for example, is used when returning queue URLs from the SQS service to the client.\n* `USE_SSL`: Whether to use `https://...` URLs with SSL encryption (defaults to `false`).\n* `KINESIS_ERROR_PROBABILITY`: Decimal value between 0.0 (default) and 1.0 to randomly\n  inject `ProvisionedThroughputExceededException` errors into Kinesis API responses.\n* `KINESIS_SHARD_LIMIT`: Integer value (defaults to `100`) or `Infinity` (to disable), in which to kinesalite will start throwing exceptions to mimick the [default shard limit](https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html).\n* `KINESIS_LATENCY`: Integer value (defaults to `500`) or `0` (to disable), in which to kinesalite will delay returning a response in order to mimick latency from a live AWS call.\n* `DYNAMODB_ERROR_PROBABILITY`: Decimal value between 0.0 (default) and 1.0 to randomly\n  inject `ProvisionedThroughputExceededException` errors into DynamoDB API responses.\n* `LAMBDA_EXECUTOR`: Method to use for executing Lambda functions. Possible values are:\n    - `local`: run Lambda functions in a temporary directory on the local machine\n    - `docker`: run each function invocation in a separate Docker container\n    - `docker-reuse`: create one Docker container per function and reuse it across invocations\n\n  For `docker` and `docker-reuse`, if LocalStack itself is started inside Docker, then\n  the `docker` command needs to be available inside the container (usually requires to run the\n  container in privileged mode). Default is `docker`, fallback to `local` if Docker is not available.\n* `LAMBDA_REMOTE_DOCKER` determines whether Lambda code is copied or mounted into containers.\n  Possible values are:\n    - `true` (default): your Lambda function definitions will be passed to the container by\n      copying the zip file (potentially slower). It allows for remote execution, where the host\n      and the client are not on the same machine.\n    - `false`: your Lambda function definitions will be passed to the container by mounting a\n      volume (potentially faster). This requires to have the Docker client and the Docker\n      host on the same machine.\n* `LAMBDA_DOCKER_NETWORK` Specifies the docker network for the container running your lambda function.\n* `LAMBDA_CONTAINER_REGISTRY` Use an alternative docker registry to pull lambda execution containers. Default is `lambci/lambda`.\n* `DATA_DIR`: Local directory for saving persistent data (currently only supported for these services:\n  Kinesis, DynamoDB, Elasticsearch, S3). Set it to `/tmp/localstack/data` to enable persistence\n  (`/tmp/localstack` is mounted into the Docker container), leave blank to disable\n  persistence (default).\n* `PORT_WEB_UI`: Port for the Web user interface (dashboard). Default is `8080`.\n* `<SERVICE>_BACKEND`: Custom endpoint URL to use for a specific service, where `<SERVICE>` is the uppercase\n  service name (currently works for: `APIGATEWAY`, `CLOUDFORMATION`, `DYNAMODB`, `ELASTICSEARCH`,\n  `KINESIS`, `S3`, `SNS`, `SQS`). This allows to easily integrate third-party services into LocalStack.\n* `FORCE_NONINTERACTIVE`: when running with Docker, disables the `--interactive` and `--tty` flags. Useful when running headless.\n* `DOCKER_FLAGS`: Allows to pass custom flags (e.g., volume mounts) to \"docker run\" when running LocalStack in Docker.\n* `DOCKER_CMD`: Shell command used to run Docker containers, e.g., set to `\"sudo docker\"` to run as sudo (default: `docker`).\n* `START_WEB`: Flag to control whether the Web API should be started in Docker (values: `0`/`1`; default: `1`).\n* `LAMBDA_FALLBACK_URL`: Fallback URL to use when a non-existing Lambda is invoked. Either records invocations in DynamoDB (value `dynamodb://<table_name>`) or forwards invocations as a POST request (value `http(s)://...`).\n* `EXTRA_CORS_ALLOWED_HEADERS`: Comma-separated list of header names to be be added to `Access-Control-Allow-Headers` CORS header\n* `EXTRA_CORS_EXPOSE_HEADERS`: Comma-separated list of header names to be be added to `Access-Control-Expose-Headers` CORS header\n* `LAMBDA_JAVA_OPTS`: Allow passing custom JVM options (e.g., `-Xmx512M`) to Java Lambdas executed in Docker. Use `_debug_port_` placeholder to configure the debug port (e.g., `-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=_debug_port_`).\n\n\nAdditionally, the following *read-only* environment variables are available:\n\n* `LOCALSTACK_HOSTNAME`: Name of the host where LocalStack services are available.\n  This is needed in order to access the services from within your Lambda functions\n  (e.g., to store an item to DynamoDB or S3 from Lambda).\n  The variable `LOCALSTACK_HOSTNAME` is available for both, local Lambda execution\n  (`LAMBDA_EXECUTOR=local`) and execution inside separate Docker containers (`LAMBDA_EXECUTOR=docker`).\n\n### Dynamically updating configuration at runtime\n\nEach of the service APIs listed [above](https://github.com/localstack/localstack#overview) defines\na backdoor API under the path `/?_config_` which allows to dynamically update configuration variables\ndefined in [`config.py`](https://github.com/localstack/localstack/blob/master/localstack/config.py).\n\nFor example, to dynamically set `KINESIS_ERROR_PROBABILITY=1` at runtime, use the following command:\n```\ncurl -v -d '{\"variable\":\"KINESIS_ERROR_PROBABILITY\",\"value\":1}' 'http://localhost:4568/?_config_'\n```\n\n### Initializing a fresh instance\n\nWhen a container is started for the first time, it will execute files with extensions .sh that are found in `/docker-entrypoint-initaws.d`. Files will be executed in alphabetical order. You can easily create aws resources on localstack using `awslocal` (or `aws`) cli tool in the initialization scripts.\n\n## A note about using custom SSL certificates (for `USE_SSL=1`)\n\nIf you need to use your own SSL Certificate and keep it persistent and not use the random automatic generated Certificate, you can place into the localstack temporary directory :\n\n```\n/tmp/localstack/\n```\n\nthe three named files below :\n\n```bash\nserver.test.pem\nserver.test.pem.crt\nserver.test.pem.key\n```\n\n- the file `server.test.pem` must contains your key file content, your certificate and chain certificate files contents (do a cat in this order)\n - the file `server.test.pem.crt` must contains your certificate and chains files contents (do a 'cat' in this order)\n- the file server.test.pem.key must contains your key file content\n***\n### Using USE_SSL and own persistent certificate with docker-compose\n\nTypically with docker-compose you can add into docker-compose.yml this volume to the localstack services :\n\n```\nvolumes:\n      - \"${PWD}/ls_tmp:/tmp/localstack\"\n      - \"/var/run/docker.sock:/var/run/docker.sock\"\n```\n\nlocal directory **ls_tmp** must contains the three files (server.test.pem, server.test.pem.crt, server.test.pem.key)\n\n***\n\n## Accessing the infrastructure via CLI or code\n\nYou can point your `aws` CLI to use the local infrastructure, for example:\n\n```\naws --endpoint-url=http://localhost:4568 kinesis list-streams\n{\n    \"StreamNames\": []\n}\n```\n\n**NEW**: Check out [awslocal](https://github.com/localstack/awscli-local), a thin CLI wrapper\nthat runs commands directly against LocalStack (no need to specify `--endpoint-url` anymore).\nInstall it via `pip install awscli-local`, and then use it as follows:\n\n```\nawslocal kinesis list-streams\n{\n    \"StreamNames\": []\n}\n```\n\n**UPDATE**: Use the environment variable `$LOCALSTACK_HOSTNAME` to determine the target host\ninside your Lambda function. See [Configurations](#Configurations) section for more details.\n\n### Client Libraries\n\n* Python: https://github.com/localstack/localstack-python-client\n  * alternatively, you can also use `boto3` and use the `endpoint_url` parameter when creating a connection\n* (more coming soon...)\n\n## Integration with nosetests\n\nIf you want to use LocalStack in your integration tests (e.g., nosetests), simply fire up the\ninfrastructure in your test setup method and then clean up everything in your teardown method:\n\n```\nfrom localstack.services import infra\n\ndef setup():\n    infra.start_infra(asynchronous=True)\n\ndef teardown():\n    infra.stop_infra()\n\ndef my_app_test():\n    # here goes your test logic\n```\n\nSee the example test file `tests/integration/test_integration.py` for more details.\n\n## Integration with Serverless\n\nYou can use the [`serverless-localstack`](https://www.npmjs.com/package/serverless-localstack) plugin to easily run [Serverless](https://serverless.com/framework/) applications on LocalStack.\nFor more information, please check out the plugin repository here:\nhttps://github.com/localstack/serverless-localstack\n\n## Using local code with Lambda\n\nIn order to mount a local folder, ensure that `LAMBDA_REMOTE_DOCKER` is set to `false` then set the S3 bucket name to `__local__` and the S3 key to your local path:\n\n```\n    awslocal lambda create-function --function-name myLambda \\\n      --code S3Bucket=\"__local__\",S3Key=\"/my/local/lambda/folder\" \\\n      --handler index.myHandler \\\n      --runtime nodejs8.10 \\\n      --role whatever\n```\n\n## Integration with Java/JUnit\n\nIn order to use LocalStack with Java, the project ships with a simple JUnit runner and a JUnit 5 extension. Take a look\nat the example JUnit test in `ext/java`. When you run the test, all dependencies are automatically\ndownloaded and installed to a temporary directory in your system.\n\n```\n...\nimport cloud.localstack.LocalstackTestRunner;\nimport cloud.localstack.TestUtils;\n\n@RunWith(LocalstackTestRunner.class)\npublic class MyCloudAppTest {\n\n  @Test\n  public void testLocalS3API() {\n    AmazonS3 s3 = TestUtils.getClientS3()\n    List<Bucket> buckets = s3.listBuckets();\n    ...\n  }\n\n}\n```\n\nOr with JUnit 5 :\n\n```\n@ExtendWith(LocalstackExtension.class)\npublic class MyCloudAppTest {\n   ...\n}\n```\n\nAdditionally, there is a version of the LocalStack Test Runner which runs in a docker container\ninstead of installing LocalStack on the current machine. The only dependency is to have docker\ninstalled locally. The test runner will automatically pull the image and start the container for the\nduration of the test.  The container can be configured by using the @LocalstackDockerProperties annotation.\n\n```\n@RunWith(LocalstackDockerTestRunner.class)\n@LocalstackDockerProperties(services = { \"sqs\", \"kinesis:77077\" })\npublic class MyDockerCloudAppTest {\n\n  @Test\n  public void testKinesis() {\n    AmazonKinesis kinesis = DockerTestUtils.getClientKinesis();\n\n    ListStreamsResult streams = kinesis.listStreams();\n    ...\n```\n\nOr with JUnit 5 :\n\n```\n@ExtendWith(LocalstackDockerExtension.class)\n@LocalstackDockerProperties(services = { \"sqs\", \"kinesis:77077\" })\npublic class MyDockerCloudAppTest {\n   ...\n}\n```\n\nThe LocalStack JUnit test runner is published as an artifact in Maven Central.\nSimply add the following dependency to your `pom.xml` file:\n\n```\n<dependency>\n    <groupId>cloud.localstack</groupId>\n    <artifactId>localstack-utils</artifactId>\n    <version>0.2.0</version>\n</dependency>\n```\n\nYou can configure the Docker behaviour using the `@LocalstackDockerProperties` annotation with the following parameters:\n\n| property                    | usage                                                                                                                        | type                         | default value |\n|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------|---------------|\n| pullNewImage                | Determines if a new image is pulled from the docker repo before the tests are run.                                           | boolean                      | false         |\n| randomizePorts              | Determines if the container should expose the default local stack ports (4567-4583) or if it should expose randomized ports. | boolean                      | false         |\n| services                    | Determines which services should be run when the localstack starts.                                                          | String[]                     | All           |\n| imageTag                    | Use a specific image tag for docker container                                                                                | String                       | latest        |\n| hostNameResolver            | Used for determining the host name of the machine running the docker containers so that the containers can be addressed.     | IHostNameResolver            | localhost     |\n| environmentVariableProvider | Used for injecting environment variables into the container.                                                                 | IEnvironmentVariableProvider | Empty Map     |\n\n_NB : When specifying the port in the `services` property, you cannot use `randomizePorts = true`_\n\n### Troubleshooting\n\n* If you're using AWS Java libraries with Kinesis, please, refer to [CBOR protocol issues with the Java SDK guide](https://github.com/mhart/kinesalite#cbor-protocol-issues-with-the-java-sdk) how to disable CBOR protocol which is not supported by kinesalite.\n\n* Accessing local S3 from Java: To avoid domain name resolution issues, you need to enable **path style access** on your client:\n```\ns3.setS3ClientOptions(S3ClientOptions.builder().setPathStyleAccess(true).build());\n// There is also an option to do this if you're using any of the client builder classes:\nAmazonS3ClientBuilder builder = AmazonS3ClientBuilder.standard();\nbuilder.withPathStyleAccessEnabled(true);\n...\n```\n\n* Mounting the temp. directory: Note that on MacOS you may have to run `TMPDIR=/private$TMPDIR docker-compose up` if\n`$TMPDIR` contains a symbolic link that cannot be mounted by Docker.\n(See details here: https://bitbucket.org/atlassian/localstack/issues/40/getting-mounts-failed-on-docker-compose-up)\n\n* If you run into file permission issues on `pip install` under Mac OS (e.g., `Permission denied: '/Library/Python/2.7/site-packages/six.py'`), then you may have to re-install `pip` via Homebrew (see [this discussion thread](https://github.com/localstack/localstack/issues/260#issuecomment-334458631)). Alternatively, try installing\nwith the `--user` flag: `pip install --user localstack`\n\n\n* If you are deploying within OpenShift, please be aware: the pod must run as `root`, and the user must have capabilities added to the running pod, in order to allow Elasticsearch to be run as the non-root `localstack` user.\n\n* The environment variable `no_proxy` is rewritten by LocalStack.\n(Internal requests will go straight via localhost, bypassing any proxy configuration).\n\n* For troubleshooting LocalStack start issues, you can check debug logs by running `DEBUG=1 localstack start`\n\n* In case you get errors related to node/nodejs, you may find (this issue comment: https://github.com/localstack/localstack/issues/227#issuecomment-319938530) helpful.\n\n* If you are using AWS Java libraries and need to disable SSL certificate checking, add `-Dcom.amazonaws.sdk.disableCertChecking` to the java invocation.\n\n## Developing\n\n### Requirements for developing or starting locally\n\nTo develop new features, or to start the stack locally (outside of Docker), the following additional tools are required:\n\n* `make`\n* `npm` (node.js package manager)\n* `java`/`javac` (Java 8 runtime environment and compiler)\n* `mvn` (Maven, the build system for Java)\n\n### Development Environment\n\nIf you pull the repo in order to extend/modify LocalStack, run this command to install\nall the dependencies:\n\n```\nmake install\n```\n\nThis will install the required pip dependencies in a local Python virtualenv directory\n`.venv` (your global python packages will remain untouched), as well as some node modules\nin `./localstack/node_modules/`. Depending on your system, some pip/npm modules may require\nadditional native libs installed.\n\nThe Makefile contains a target to conveniently run the local infrastructure for development:\n\n```\nmake infra\n```\n\nCheck out the\n[developer guide](https://github.com/localstack/localstack/tree/master/doc/developer_guides) which\ncontains a few instructions on how to get started with developing (and debugging) features for\nLocalStack.\n\n## Testing\n\nThe project contains a set of unit and integration tests that can be kicked off via a make\ntarget:\n\n```\nmake test\n```\n\n## Web Dashboard\n\nThe projects also comes with a simple Web dashboard that allows to view the deployed AWS\ncomponents and the relationship between them.\n\n```\nlocalstack web\n```\n\n## Other UI Clients\n\n* [Commandeer desktop app](https://getcommandeer.com)\n* [DynamoDB Admin Web UI](https://www.npmjs.com/package/dynamodb-admin)\n\n## Change Log\n\n* v0.10.5: Various CloudFormation fixes: deployment of API GW method integrations, properly skip resource updates, Lambda SQS event source mapping, avoid duplicate resource creation, support for ApiGateway::GatewayResponse and Events::Rule, log groups for Lambdas; support adding Lambda policies; customize Docker registry for Lambda images; support multiple configurations in S3 notifications; fix encoding of non-ASCII results from API Gateway; allow docker-reuse to use mounted volumes; support presigned S3 URL upload notifications; fix lookup of Python Lambda handler in sub directories; upgrade kinesalite; fix duplicate CORS headers; fix mapping of Lambda versions and ARNs; fix SNS x-amz-sns-message-type header; send SNS confirmation message for HTTP(S) subscriptions; fix DynamoDB local libs for Docker Alpine; add CF support for SNS subscriptions; fix RecordId for firehose put-record-batch; fix SQS messages with multi-byte characters; avoid creating multiple SNS subscriptions; add .bat script and support running under Windows; fix S3 location constraint for CF\n* v0.10.4: Add checks for open UDP ports; fix S3 chunked encoding uploads; fix LatestStreamLabel; fix CORS headers for SQS/SNS; set Java lambda debug port only when needed; expose default region in a util function; fix MacOS tmp folder; clear tmp supervisord logs at container startup; fix signed header requests for S3; expose Web UI via HTTPS; add Timestamp to SNS messages; fix attributes for SQS queues addressed via URL\n* v0.10.3: Allow specifying data types for CF attributes; add API for service status and starting services at runtime; support NextShardIterator in DDB streams; add mock responses for S3 encryption and replication; fix rendering of resources in web UI; custom SQS queue attributes; fix Lambda docker command and imports; fix SQS queue physical ID in CF; allow proxy listener to define custom backend per request; support Lambda event body over stdin; exclude `ingest-geoip` ES module to optimize image size; skip checking MD5 on S3 copy; fix DynamoDB table ARN for CF; fix CF deployment of StepFunction activities; fix uploading of Java Lambda as JAR in ZIP; fix installing libs for plugins; added `LAMBDA_JAVA_OPTS` for Java Lambda debugging; bump Maven dependency versions; refactor Lambda API; fix boolean strings in CF templates; allow overriding AWS account id with `TEST_AWS_ACCOUNT_ID`; fix incorrect region for API GW resources created via CF; fix permissions for cache files in `/tmp`\n* v0.10.2: Fix logging issue with async Lambdas; fix kinesis records processing; add basic support for `Ref` in CloudFormation; fix ddb streams uuid generation; upgrade travis CI setup; fix DynamoDB error messages; cache server processes\n* v0.10.0: Lazy loading of libraries; fix handling of regions; add API multiserver; improve CPU profiling; fix ES xpack installation; add basic EventBridge support; refactor Lambda API and executor; add MessageAttributes on SNS payloads; tagging for SNS; ability to customize docker command\n* v0.9.6: Add API Gateway SQS proxy; fix command to push Docker image; fix Docker bridge IP configuration; fix SSL issue in dashboard infra; updates to README\n* v0.9.5: Reduce Docker image size by squashing; fix response body for presigned URL S3 PUT requests; fix CreateDate returned by IAM; fix account IDs for CF and SNS; fix topic checks for SMS using SNS; improve documentation around `@LocalstackDockerProperties`; add basic EC2 support; upgrade to ElasticSearch 6.7; set Last-Modified header in S3; preserve logic with uppercase event keys in Java; add support for nodejs 10.x Lambdas\n* v0.9.4: Fix ARNs in CloudFormation deployments; write stderr to file in supervisord; fix Lambda invocation times; fix canonicalization of service names when running in Docker; add support for `@Nested` in Junit5; add support for batch/transaction in DynamoDB; fix output buffering for subprocesses; assign unique ports under docker-reuse; check if topic ARN exists before publish\n* v0.9.3: Fix output buffering of child processes; new release of Java libs; add imageTag attribute for Java annotation\n* v0.9.2: Update to Python 3 in Dockerfile; preserve attributes when SNS Subscribe; fix event source mapping in Lambda; fix CORS ExposeHeaders; set Lambda timeout in secs; add tags support for Lambda/Firehose; add message attributes for SQS/Lambda; fix shard count support for Kinesis; fix port mappings for CloudFormation\n* v0.9.1: Define dependent and composite services in config; forward Lambda logs to CloudWatch Logs; add SQS event deserializing for Lambda; fix AWS_PROXY for JSON list payload; add START_WEB config parameter; return correct location for S3 multipart uploads; add support for Lambda custom runtime; fix account ID for IAM responses; fix using correct SSL cert; limit memory usage for Java processes; fix unicode encoding for SNS messages; allow using `LOCALSTACK_` prefix in Docker environment variables; enable request forwarding for non-existing Lambdas; fix large downloads for S3; add API endpoint for dynamically updating config variables; fix CloudFormation stack update\n* v0.9.0: Enhance integration with Serverless; refactor CloudFormation implementation; add support for Step Functions, IAM, STS; fix CloudFormation integration; support mounting Lambda code locally; add `docker-entrypoint-initaws.d` dir for initializing resources; add S3Event Parser for Lambda; fix S3 chunk encoding; fix S3 multipart upload notification; add dotnetcore2.1 and ruby2.5 Lambda runtimes; fix issues with JDK 9; install ES plugins available in AWS\n* v0.8.10: Add kclpy to pip package; fix badges in README\n* v0.8.9: Replace moto-ext with upstream moto; fix SNS message attributes; fix swagger; make external SQS port configurable; support for SNS DeleteTopic; S3 notifications for multipart uploads; support requestContext in AWS_PROXY integration; update docs for SSL usage\n* v0.8.8: Support Docker network config for Lambda containers; support queryStringParameters for Lambda AWS_PROXY apigateway; add AWS SecretsManager service; add SQS/Lambda integration; add support for Firehose Kinesis source; add GetAlias to Lambda API; add function properties to LambdaContext for invocations; fix extraction of Java Lambda archives; check region headers for SNS; fix Lambda output buffering; fix S3 download of gzip; bump ElasticMQ to 0.14.5; fix Lambda response codes; fix syntax issues for Python 3.7\n* v0.8.7: Support .Net Core 2.0 and nodejs8.10 Lambdas; refactor Java libs and integrate with JUnit 5; support tags for ES domains; add CloudFormation support for SNS topics; fix kinesis error injection; fix override of `ES_JAVA_OPTS`; fix SQS CORS preflight response; fix S3 content md5 checks and Host header; fix ES startup issue; Bump elasticmq to 0.13.10; bump kinesalite version\n* v0.8.6: Fixes for Windows installation; bump ES to 6.2.0; support filter policy for SNS; upgrade kinesalite; refactor JUnit runner; support Lambda PutFunctionConcurrency and GetEventSourceMapping; fixes for Terraform; add golang support to Lambda; fix file permission issue in Java Lambda tests; fix S3 bucket notification config\n* v0.8.5: Fix DDB streams event type; implement CF Fn::GetAZs; async lambda for DDB events; fix S3 content-type; fix CF deployer for SQS; fix S3 ExposePorts; fix message subject in SNS; support for Firehose -> ES; pass external env vars to containers from Java; add mock for list-queue-tags; enhance docker test runner; fix Windows installation issues; new version of Java libs\n* v0.8.4: Fix `pipenv` dependency issue; Docker JUnit test runner; POJO type for Java Lambda RequestHandler; Java Lambda DynamoDB event; reuse Docker containers for Lambda invocations; API Gateway wildcard path segments; fix SNS RawMessageDelivery\n* v0.8.3: Fix DDB stream events for UPDATE operations; fix DDB streams sequence numbers; fix transfer-encoding for DDB; fix requests with missing content-length header; support non-ascii content in DynamoDB items; map external port for SQS queue URLs; default to LAMBDA_REMOTE_DOCKER=true if running in Docker; S3 lifecycle support; reduce Docker image size\n* v0.8.2: Fix S3 bucket notification configuration; CORS headers for API Gateway; fix >128k S3 multipart uploads; return valid ShardIDs in DynamoDB Streams; fix hardcoded \"ddblocal\" DynamoDB TableARN; import default service ports from localstack-client; fix S3 bucket policy response; Execute lambdas asynchronously if the source is a topic\n* v0.8.1: Improvements in Lambda API: publish-version, list-version, function aliases; use single map with Lambda function details; workaround for SQS .fifo queues; add test for S3 upload; initial support for SSM; fix regex to replace SQS queue URL hostnames; update linter (single quotes); use `docker.for.mac.localhost` to connect to LocalStack from Docker on Mac; fix b64 encoding for Java Lambdas; fix path of moto_server command\n* v0.8.0: Fix request data in `GenericProxyHandler`; add `$PORT_WEB_UI` and `$HOSTNAME_EXTERNAL` configs; API Gateway path parameters; enable flake8 linting; add config for service backend URLs; use ElasticMQ instead of moto for SQS; expose `$LOCALSTACK_HOSTNAME`; custom environment variable support for Lambda; improve error logging and installation for Java/JUnit; add support for S3 REST Object POST\n* v0.7.5: Fix issue with incomplete parallel downloads; bypass http_proxy for internal requests; use native Python code to unzip archives; download KCL client libs only for testing and not on pip install\n* v0.7.4: Refactor CLI and enable plugins; support unicode names for S3; fix SQS names containing a dot character; execute Java Lambda functions in Docker containers; fix DynamoDB error handling; update docs\n* v0.7.3: Extract proxy listeners into (sub-)classes; put java libs into a single \"fat\" jar; fix issue with non-daemonized threads; refactor code to start flask services\n* v0.7.2: Fix DATA_DIR config when running in Docker; fix Maven dependencies; return 'ConsumedCapacity' from DynamoDB get-item; use Queue ARN instead of URL for S3 bucket notifications\n* v0.7.1: Fix S3 API to GET bucket notifications; release Java artifacts to Maven Central; fix S3 file access from Spark; create DDB stream on UpdateTable; remove AUI dependency, optimize size of Docker image\n* v0.7.0: Support for Kinesis in CloudFormation; extend and integrate Java tests in CI; publish Docker image under new name; update READMEs and license agreements\n* v0.6.2: Major refactoring of installation process, lazy loading of dependencies\n* v0.6.1: Add CORS headers; platform compatibility fixes (remove shell commands and sh module); add CloudFormation validate-template; fix Lambda execution in Docker; basic domain handling in ES API; API Gateway authorizers\n* v0.6.0: Load services as plugins; fix service default ports; fix SQS->SNS and MD5 of message attributes; fix Host header for S3\n* v0.5.5: Enable SSL encryption for all service endpoints (`USE_SSL` config); create Docker base image; fix issue with DATA_DIR\n* v0.5.4: Remove hardcoded /tmp/ for Windows-compat.; update CLI and docs; fix S3/SNS notifications; disable Elasticsearch compression\n* v0.5.3: Add CloudFormation support for serverless / API Gateway deployments; fix installation via pypi; minor fix for Java (passing of environment variables)\n* v0.5.0: Extend DynamoDB Streams API; fix keep-alive connection for S3; fix deadlock in nested Lambda executions; add integration SNS->Lambda; CloudFormation serverless example; replace dynalite with DynamoDBLocal; support Lambda execution in remote Docker container; fix CloudWatch metrics for Lambda invocation errors\n* v0.4.3: Initial support for CloudWatch metrics (for Lambda functions); HTTP forwards for API Gateway; fix S3 message body signatures; download Lambda archive from S3 bucket; fix/extend ES tests\n* v0.4.2: Initial support for Java Lambda functions; CloudFormation deployments; API Gateway tests\n* v0.4.1: Python 3 compatibility; data persistence; add seq. numbers in Kinesis events; limit Elasticsearch memory\n* v0.4.0: Execute Lambda functions in Docker containers; CORS headers for S3\n* v0.3.11: Add Route53, SES, CloudFormation; DynamoDB fault injection; UI tweaks; refactor config\n* v0.3.10: Add initial support for S3 bucket notifications; fix subprocess32 installation\n* v0.3.9: Make services/ports configurable via $SERVICES; add tests for Firehose+S3\n* v0.3.8: Fix Elasticsearch via local bind and proxy; refactoring; improve error logging\n* v0.3.5: Fix lambda handler name; fix host name for S3 API; install web libs on pip install\n* v0.3.4: Fix file permissions in build; fix and add UI to Docker image; add stub of ES API\n* v0.3.3: Add version tags to Docker images\n* v0.3.2: Add support for Redshift API; code refactoring\n* v0.3.1: Add Dockerfile and push image to Docker Hub\n* v0.3.0: Add simple integration for JUnit; improve process signal handling\n* v0.2.11: Refactored the AWS assume role function\n* v0.2.10: Added AWS assume role functionality.\n* v0.2.9: Kinesis error response formatting\n* v0.2.7: Throw Kinesis errors randomly\n* v0.2.6: Decouple SNS/SQS: intercept SNS calls and forward to subscribed SQS queues\n* v0.2.5: Return error response from Kinesis if flag is set\n* v0.2.4: Allow Lambdas to use __file__ (import from file instead of exec'ing)\n* v0.2.3: Improve Kinesis/KCL auto-checkpointing (leases in DDB)\n* v0.2.0: Speed up installation time by lazy loading libraries\n* v0.1.19: Pass shard_id in records sent from KCL process\n* v0.1.16: Minor restructuring and refactoring (create separate kinesis_util.py)\n* v0.1.14: Fix AWS tokens when creating Elasticsearch client\n* v0.1.11: Add startup/initialization notification for KCL process\n* v0.1.10: Bump version of amazon_kclpy to 1.4.1\n* v0.1.9: Add initial support for SQS/SNS\n* v0.1.8: Fix installation of JARs in amazon_kclpy if localstack is installed transitively\n* v0.1.7: Bump version of amazon_kclpy to 1.4.0\n* v0.1.6: Add travis-ci and coveralls configuration\n* v0.1.5: Refactor Elasticsearch utils; fix bug in method to delete all ES indexes\n* v0.1.4: Enhance logging; extend java KCL credentials provider (support STS assumed roles)\n* v0.1.2: Add configurable KCL log output\n* v0.1.0: Initial release\n\n## Contributing\n\nWe welcome feedback, bug reports, and pull requests!\n\nFor pull requests, please stick to the following guidelines:\n\n* Add tests for any new features and bug fixes. Ideally, each PR should increase the test coverage.\n* Follow the existing code style (e.g., indents). A PEP8 code linting target is included in the Makefile.\n* Put a reasonable amount of comments into the code.\n* Separate unrelated changes into multiple pull requests.\n* 1 commit per PR: Please squash/rebase multiple commits into one single commit (to keep the history clean).\n\nPlease note that by contributing any code or documentation to this repository (by\nraising pull requests, or otherwise) you explicitly agree to\nthe [**Contributor License Agreement**](doc/contributor_license_agreement).\n\n## Contributors\n\nThis project exists thanks to all the people who contribute.\n<a href=\"https://github.com/localstack/localstack/graphs/contributors\"><img src=\"https://opencollective.com/localstack/contributors.svg?width=890\" /></a>\n\n\n## Backers\n\nThank you to all our backers! \ud83d\ude4f [[Become a backer](https://opencollective.com/localstack#backer)]\n\n<a href=\"https://opencollective.com/localstack#backers\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/backers.svg?width=890\"></a>\n\n\n## Sponsors\n\nSupport this project by becoming a sponsor. Your logo will show up here with a link to your website. [[Become a sponsor](https://opencollective.com/localstack#sponsor)]\n\n<a href=\"https://opencollective.com/localstack/sponsor/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/localstack/sponsor/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/localstack/sponsor/9/avatar.svg\"></a>\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/localstack/localstack.svg)](https://starchart.cc/localstack/localstack)\n\n## License\n\nCopyright (c) 2017-2019 LocalStack maintainers and contributors.\n\nCopyright (c) 2016 Atlassian and others.\n\nThis version of LocalStack is released under the Apache License, Version 2.0 (see LICENSE.txt).\nBy downloading and using this software you agree to the\n[End-User License Agreement (EULA)](doc/end_user_license_agreement).\n\nWe build on a number of third-party software tools, including the following:\n\nThird-Party software      | \tLicense\n--------------------------|-----------------------\n**Python/pip modules:**   |\nairspeed                  | BSD License\namazon_kclpy              | Amazon Software License\nboto3                     | Apache License 2.0\ncoverage                  | Apache License 2.0\ndocopt                    | MIT License\nelasticsearch             | Apache License 2.0\nflask                     | BSD License\nflask_swagger             | MIT License\njsonpath-rw               | Apache License 2.0\nmoto                      | Apache License 2.0\nrequests                  | Apache License 2.0\nsubprocess32              | PSF License\n**Node.js/npm modules:**  |\nkinesalite                | MIT License\n**Other tools:**          |\nElasticsearch             | Apache License 2.0\nlocal-kms                 | MIT License\n"}, {"repo": "fxsjy/jieba", "language": "Python", "readme_contents": "jieba\n========\n\u201c\u7ed3\u5df4\u201d\u4e2d\u6587\u5206\u8bcd\uff1a\u505a\u6700\u597d\u7684 Python \u4e2d\u6587\u5206\u8bcd\u7ec4\u4ef6\n\n\"Jieba\" (Chinese for \"to stutter\") Chinese text segmentation: built to be the best Python Chinese word segmentation module.\n\n- _Scroll down for English documentation._\n\n\n\u7279\u70b9\n========\n* \u652f\u6301\u4e09\u79cd\u5206\u8bcd\u6a21\u5f0f\uff1a\n    * \u7cbe\u786e\u6a21\u5f0f\uff0c\u8bd5\u56fe\u5c06\u53e5\u5b50\u6700\u7cbe\u786e\u5730\u5207\u5f00\uff0c\u9002\u5408\u6587\u672c\u5206\u6790\uff1b\n    * \u5168\u6a21\u5f0f\uff0c\u628a\u53e5\u5b50\u4e2d\u6240\u6709\u7684\u53ef\u4ee5\u6210\u8bcd\u7684\u8bcd\u8bed\u90fd\u626b\u63cf\u51fa\u6765, \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u4f46\u662f\u4e0d\u80fd\u89e3\u51b3\u6b67\u4e49\uff1b\n    * \u641c\u7d22\u5f15\u64ce\u6a21\u5f0f\uff0c\u5728\u7cbe\u786e\u6a21\u5f0f\u7684\u57fa\u7840\u4e0a\uff0c\u5bf9\u957f\u8bcd\u518d\u6b21\u5207\u5206\uff0c\u63d0\u9ad8\u53ec\u56de\u7387\uff0c\u9002\u5408\u7528\u4e8e\u641c\u7d22\u5f15\u64ce\u5206\u8bcd\u3002\n\n* \u652f\u6301\u7e41\u4f53\u5206\u8bcd\n* \u652f\u6301\u81ea\u5b9a\u4e49\u8bcd\u5178\n* MIT \u6388\u6743\u534f\u8bae\n\n\u53cb\u60c5\u94fe\u63a5\n=========\n* https://github.com/baidu/lac   \u767e\u5ea6\u4e2d\u6587\u8bcd\u6cd5\u5206\u6790\uff08\u5206\u8bcd+\u8bcd\u6027+\u4e13\u540d\uff09\u7cfb\u7edf\n* https://github.com/baidu/AnyQ  \u767e\u5ea6FAQ\u81ea\u52a8\u95ee\u7b54\u7cfb\u7edf\n* https://github.com/baidu/Senta \u767e\u5ea6\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\n\n\u5b89\u88c5\u8bf4\u660e\n=======\n\n\u4ee3\u7801\u5bf9 Python 2/3 \u5747\u517c\u5bb9\n\n* \u5168\u81ea\u52a8\u5b89\u88c5\uff1a`easy_install jieba` \u6216\u8005 `pip install jieba` / `pip3 install jieba`\n* \u534a\u81ea\u52a8\u5b89\u88c5\uff1a\u5148\u4e0b\u8f7d http://pypi.python.org/pypi/jieba/ \uff0c\u89e3\u538b\u540e\u8fd0\u884c `python setup.py install`\n* \u624b\u52a8\u5b89\u88c5\uff1a\u5c06 jieba \u76ee\u5f55\u653e\u7f6e\u4e8e\u5f53\u524d\u76ee\u5f55\u6216\u8005 site-packages \u76ee\u5f55\n* \u901a\u8fc7 `import jieba` \u6765\u5f15\u7528\n\n\u7b97\u6cd5\n========\n* \u57fa\u4e8e\u524d\u7f00\u8bcd\u5178\u5b9e\u73b0\u9ad8\u6548\u7684\u8bcd\u56fe\u626b\u63cf\uff0c\u751f\u6210\u53e5\u5b50\u4e2d\u6c49\u5b57\u6240\u6709\u53ef\u80fd\u6210\u8bcd\u60c5\u51b5\u6240\u6784\u6210\u7684\u6709\u5411\u65e0\u73af\u56fe (DAG)\n* \u91c7\u7528\u4e86\u52a8\u6001\u89c4\u5212\u67e5\u627e\u6700\u5927\u6982\u7387\u8def\u5f84, \u627e\u51fa\u57fa\u4e8e\u8bcd\u9891\u7684\u6700\u5927\u5207\u5206\u7ec4\u5408\n* \u5bf9\u4e8e\u672a\u767b\u5f55\u8bcd\uff0c\u91c7\u7528\u4e86\u57fa\u4e8e\u6c49\u5b57\u6210\u8bcd\u80fd\u529b\u7684 HMM \u6a21\u578b\uff0c\u4f7f\u7528\u4e86 Viterbi \u7b97\u6cd5\n\n\u4e3b\u8981\u529f\u80fd\n=======\n1. \u5206\u8bcd\n--------\n* `jieba.cut` \u65b9\u6cd5\u63a5\u53d7\u4e09\u4e2a\u8f93\u5165\u53c2\u6570: \u9700\u8981\u5206\u8bcd\u7684\u5b57\u7b26\u4e32\uff1bcut_all \u53c2\u6570\u7528\u6765\u63a7\u5236\u662f\u5426\u91c7\u7528\u5168\u6a21\u5f0f\uff1bHMM \u53c2\u6570\u7528\u6765\u63a7\u5236\u662f\u5426\u4f7f\u7528 HMM \u6a21\u578b\n* `jieba.cut_for_search` \u65b9\u6cd5\u63a5\u53d7\u4e24\u4e2a\u53c2\u6570\uff1a\u9700\u8981\u5206\u8bcd\u7684\u5b57\u7b26\u4e32\uff1b\u662f\u5426\u4f7f\u7528 HMM \u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u9002\u5408\u7528\u4e8e\u641c\u7d22\u5f15\u64ce\u6784\u5efa\u5012\u6392\u7d22\u5f15\u7684\u5206\u8bcd\uff0c\u7c92\u5ea6\u6bd4\u8f83\u7ec6\n* \u5f85\u5206\u8bcd\u7684\u5b57\u7b26\u4e32\u53ef\u4ee5\u662f unicode \u6216 UTF-8 \u5b57\u7b26\u4e32\u3001GBK \u5b57\u7b26\u4e32\u3002\u6ce8\u610f\uff1a\u4e0d\u5efa\u8bae\u76f4\u63a5\u8f93\u5165 GBK \u5b57\u7b26\u4e32\uff0c\u53ef\u80fd\u65e0\u6cd5\u9884\u6599\u5730\u9519\u8bef\u89e3\u7801\u6210 UTF-8\n* `jieba.cut` \u4ee5\u53ca `jieba.cut_for_search` \u8fd4\u56de\u7684\u7ed3\u6784\u90fd\u662f\u4e00\u4e2a\u53ef\u8fed\u4ee3\u7684 generator\uff0c\u53ef\u4ee5\u4f7f\u7528 for \u5faa\u73af\u6765\u83b7\u5f97\u5206\u8bcd\u540e\u5f97\u5230\u7684\u6bcf\u4e00\u4e2a\u8bcd\u8bed(unicode)\uff0c\u6216\u8005\u7528\n* `jieba.lcut` \u4ee5\u53ca `jieba.lcut_for_search` \u76f4\u63a5\u8fd4\u56de list\n* `jieba.Tokenizer(dictionary=DEFAULT_DICT)` \u65b0\u5efa\u81ea\u5b9a\u4e49\u5206\u8bcd\u5668\uff0c\u53ef\u7528\u4e8e\u540c\u65f6\u4f7f\u7528\u4e0d\u540c\u8bcd\u5178\u3002`jieba.dt` \u4e3a\u9ed8\u8ba4\u5206\u8bcd\u5668\uff0c\u6240\u6709\u5168\u5c40\u5206\u8bcd\u76f8\u5173\u51fd\u6570\u90fd\u662f\u8be5\u5206\u8bcd\u5668\u7684\u6620\u5c04\u3002\n\n\u4ee3\u7801\u793a\u4f8b\n\n```python\n# encoding=utf-8\nimport jieba\n\nseg_list = jieba.cut(\"\u6211\u6765\u5230\u5317\u4eac\u6e05\u534e\u5927\u5b66\", cut_all=True)\nprint(\"Full Mode: \" + \"/ \".join(seg_list))  # \u5168\u6a21\u5f0f\n\nseg_list = jieba.cut(\"\u6211\u6765\u5230\u5317\u4eac\u6e05\u534e\u5927\u5b66\", cut_all=False)\nprint(\"Default Mode: \" + \"/ \".join(seg_list))  # \u7cbe\u786e\u6a21\u5f0f\n\nseg_list = jieba.cut(\"\u4ed6\u6765\u5230\u4e86\u7f51\u6613\u676d\u7814\u5927\u53a6\")  # \u9ed8\u8ba4\u662f\u7cbe\u786e\u6a21\u5f0f\nprint(\", \".join(seg_list))\n\nseg_list = jieba.cut_for_search(\"\u5c0f\u660e\u7855\u58eb\u6bd5\u4e1a\u4e8e\u4e2d\u56fd\u79d1\u5b66\u9662\u8ba1\u7b97\u6240\uff0c\u540e\u5728\u65e5\u672c\u4eac\u90fd\u5927\u5b66\u6df1\u9020\")  # \u641c\u7d22\u5f15\u64ce\u6a21\u5f0f\nprint(\", \".join(seg_list))\n```\n\n\u8f93\u51fa:\n\n    \u3010\u5168\u6a21\u5f0f\u3011: \u6211/ \u6765\u5230/ \u5317\u4eac/ \u6e05\u534e/ \u6e05\u534e\u5927\u5b66/ \u534e\u5927/ \u5927\u5b66\n\n    \u3010\u7cbe\u786e\u6a21\u5f0f\u3011: \u6211/ \u6765\u5230/ \u5317\u4eac/ \u6e05\u534e\u5927\u5b66\n\n    \u3010\u65b0\u8bcd\u8bc6\u522b\u3011\uff1a\u4ed6, \u6765\u5230, \u4e86, \u7f51\u6613, \u676d\u7814, \u5927\u53a6    (\u6b64\u5904\uff0c\u201c\u676d\u7814\u201d\u5e76\u6ca1\u6709\u5728\u8bcd\u5178\u4e2d\uff0c\u4f46\u662f\u4e5f\u88abViterbi\u7b97\u6cd5\u8bc6\u522b\u51fa\u6765\u4e86)\n\n    \u3010\u641c\u7d22\u5f15\u64ce\u6a21\u5f0f\u3011\uff1a \u5c0f\u660e, \u7855\u58eb, \u6bd5\u4e1a, \u4e8e, \u4e2d\u56fd, \u79d1\u5b66, \u5b66\u9662, \u79d1\u5b66\u9662, \u4e2d\u56fd\u79d1\u5b66\u9662, \u8ba1\u7b97, \u8ba1\u7b97\u6240, \u540e, \u5728, \u65e5\u672c, \u4eac\u90fd, \u5927\u5b66, \u65e5\u672c\u4eac\u90fd\u5927\u5b66, \u6df1\u9020\n\n2. \u6dfb\u52a0\u81ea\u5b9a\u4e49\u8bcd\u5178\n----------------\n\n### \u8f7d\u5165\u8bcd\u5178\n\n* \u5f00\u53d1\u8005\u53ef\u4ee5\u6307\u5b9a\u81ea\u5df1\u81ea\u5b9a\u4e49\u7684\u8bcd\u5178\uff0c\u4ee5\u4fbf\u5305\u542b jieba \u8bcd\u5e93\u91cc\u6ca1\u6709\u7684\u8bcd\u3002\u867d\u7136 jieba \u6709\u65b0\u8bcd\u8bc6\u522b\u80fd\u529b\uff0c\u4f46\u662f\u81ea\u884c\u6dfb\u52a0\u65b0\u8bcd\u53ef\u4ee5\u4fdd\u8bc1\u66f4\u9ad8\u7684\u6b63\u786e\u7387\n* \u7528\u6cd5\uff1a jieba.load_userdict(file_name) # file_name \u4e3a\u6587\u4ef6\u7c7b\u5bf9\u8c61\u6216\u81ea\u5b9a\u4e49\u8bcd\u5178\u7684\u8def\u5f84\n* \u8bcd\u5178\u683c\u5f0f\u548c `dict.txt` \u4e00\u6837\uff0c\u4e00\u4e2a\u8bcd\u5360\u4e00\u884c\uff1b\u6bcf\u4e00\u884c\u5206\u4e09\u90e8\u5206\uff1a\u8bcd\u8bed\u3001\u8bcd\u9891\uff08\u53ef\u7701\u7565\uff09\u3001\u8bcd\u6027\uff08\u53ef\u7701\u7565\uff09\uff0c\u7528\u7a7a\u683c\u9694\u5f00\uff0c\u987a\u5e8f\u4e0d\u53ef\u98a0\u5012\u3002`file_name` \u82e5\u4e3a\u8def\u5f84\u6216\u4e8c\u8fdb\u5236\u65b9\u5f0f\u6253\u5f00\u7684\u6587\u4ef6\uff0c\u5219\u6587\u4ef6\u5fc5\u987b\u4e3a UTF-8 \u7f16\u7801\u3002\n* \u8bcd\u9891\u7701\u7565\u65f6\u4f7f\u7528\u81ea\u52a8\u8ba1\u7b97\u7684\u80fd\u4fdd\u8bc1\u5206\u51fa\u8be5\u8bcd\u7684\u8bcd\u9891\u3002\n\n**\u4f8b\u5982\uff1a**\n\n```\n\u521b\u65b0\u529e 3 i\n\u4e91\u8ba1\u7b97 5\n\u51f1\u7279\u7433 nz\n\u53f0\u4e2d\n```\n\n* \u66f4\u6539\u5206\u8bcd\u5668\uff08\u9ed8\u8ba4\u4e3a `jieba.dt`\uff09\u7684 `tmp_dir` \u548c `cache_file` \u5c5e\u6027\uff0c\u53ef\u5206\u522b\u6307\u5b9a\u7f13\u5b58\u6587\u4ef6\u6240\u5728\u7684\u6587\u4ef6\u5939\u53ca\u5176\u6587\u4ef6\u540d\uff0c\u7528\u4e8e\u53d7\u9650\u7684\u6587\u4ef6\u7cfb\u7edf\u3002\n\n* \u8303\u4f8b\uff1a\n\n    * \u81ea\u5b9a\u4e49\u8bcd\u5178\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/userdict.txt\n\n    * \u7528\u6cd5\u793a\u4f8b\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/test_userdict.py\n\n\n        * \u4e4b\u524d\uff1a \u674e\u5c0f\u798f / \u662f / \u521b\u65b0 / \u529e / \u4e3b\u4efb / \u4e5f / \u662f / \u4e91 / \u8ba1\u7b97 / \u65b9\u9762 / \u7684 / \u4e13\u5bb6 /\n\n        * \u52a0\u8f7d\u81ea\u5b9a\u4e49\u8bcd\u5e93\u540e\uff1a\u3000\u674e\u5c0f\u798f / \u662f / \u521b\u65b0\u529e / \u4e3b\u4efb / \u4e5f / \u662f / \u4e91\u8ba1\u7b97 / \u65b9\u9762 / \u7684 / \u4e13\u5bb6 /\n\n### \u8c03\u6574\u8bcd\u5178\n\n* \u4f7f\u7528 `add_word(word, freq=None, tag=None)` \u548c `del_word(word)` \u53ef\u5728\u7a0b\u5e8f\u4e2d\u52a8\u6001\u4fee\u6539\u8bcd\u5178\u3002\n* \u4f7f\u7528 `suggest_freq(segment, tune=True)` \u53ef\u8c03\u8282\u5355\u4e2a\u8bcd\u8bed\u7684\u8bcd\u9891\uff0c\u4f7f\u5176\u80fd\uff08\u6216\u4e0d\u80fd\uff09\u88ab\u5206\u51fa\u6765\u3002\n\n* \u6ce8\u610f\uff1a\u81ea\u52a8\u8ba1\u7b97\u7684\u8bcd\u9891\u5728\u4f7f\u7528 HMM \u65b0\u8bcd\u53d1\u73b0\u529f\u80fd\u65f6\u53ef\u80fd\u65e0\u6548\u3002\n\n\u4ee3\u7801\u793a\u4f8b\uff1a\n\n```pycon\n>>> print('/'.join(jieba.cut('\u5982\u679c\u653e\u5230post\u4e2d\u5c06\u51fa\u9519\u3002', HMM=False)))\n\u5982\u679c/\u653e\u5230/post/\u4e2d\u5c06/\u51fa\u9519/\u3002\n>>> jieba.suggest_freq(('\u4e2d', '\u5c06'), True)\n494\n>>> print('/'.join(jieba.cut('\u5982\u679c\u653e\u5230post\u4e2d\u5c06\u51fa\u9519\u3002', HMM=False)))\n\u5982\u679c/\u653e\u5230/post/\u4e2d/\u5c06/\u51fa\u9519/\u3002\n>>> print('/'.join(jieba.cut('\u300c\u53f0\u4e2d\u300d\u6b63\u786e\u5e94\u8be5\u4e0d\u4f1a\u88ab\u5207\u5f00', HMM=False)))\n\u300c/\u53f0/\u4e2d/\u300d/\u6b63\u786e/\u5e94\u8be5/\u4e0d\u4f1a/\u88ab/\u5207\u5f00\n>>> jieba.suggest_freq('\u53f0\u4e2d', True)\n69\n>>> print('/'.join(jieba.cut('\u300c\u53f0\u4e2d\u300d\u6b63\u786e\u5e94\u8be5\u4e0d\u4f1a\u88ab\u5207\u5f00', HMM=False)))\n\u300c/\u53f0\u4e2d/\u300d/\u6b63\u786e/\u5e94\u8be5/\u4e0d\u4f1a/\u88ab/\u5207\u5f00\n```\n\n* \"\u901a\u8fc7\u7528\u6237\u81ea\u5b9a\u4e49\u8bcd\u5178\u6765\u589e\u5f3a\u6b67\u4e49\u7ea0\u9519\u80fd\u529b\" --- https://github.com/fxsjy/jieba/issues/14\n\n3. \u5173\u952e\u8bcd\u63d0\u53d6\n-------------\n### \u57fa\u4e8e TF-IDF \u7b97\u6cd5\u7684\u5173\u952e\u8bcd\u62bd\u53d6\n\n`import jieba.analyse`\n\n* jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n  * sentence \u4e3a\u5f85\u63d0\u53d6\u7684\u6587\u672c\n  * topK \u4e3a\u8fd4\u56de\u51e0\u4e2a TF/IDF \u6743\u91cd\u6700\u5927\u7684\u5173\u952e\u8bcd\uff0c\u9ed8\u8ba4\u503c\u4e3a 20\n  * withWeight \u4e3a\u662f\u5426\u4e00\u5e76\u8fd4\u56de\u5173\u952e\u8bcd\u6743\u91cd\u503c\uff0c\u9ed8\u8ba4\u503c\u4e3a False\n  * allowPOS \u4ec5\u5305\u62ec\u6307\u5b9a\u8bcd\u6027\u7684\u8bcd\uff0c\u9ed8\u8ba4\u503c\u4e3a\u7a7a\uff0c\u5373\u4e0d\u7b5b\u9009\n* jieba.analyse.TFIDF(idf_path=None) \u65b0\u5efa TFIDF \u5b9e\u4f8b\uff0cidf_path \u4e3a IDF \u9891\u7387\u6587\u4ef6\n\n\u4ee3\u7801\u793a\u4f8b \uff08\u5173\u952e\u8bcd\u63d0\u53d6\uff09\n\nhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags.py\n\n\u5173\u952e\u8bcd\u63d0\u53d6\u6240\u4f7f\u7528\u9006\u5411\u6587\u4ef6\u9891\u7387\uff08IDF\uff09\u6587\u672c\u8bed\u6599\u5e93\u53ef\u4ee5\u5207\u6362\u6210\u81ea\u5b9a\u4e49\u8bed\u6599\u5e93\u7684\u8def\u5f84\n\n* \u7528\u6cd5\uff1a jieba.analyse.set_idf_path(file_name) # file_name\u4e3a\u81ea\u5b9a\u4e49\u8bed\u6599\u5e93\u7684\u8def\u5f84\n* \u81ea\u5b9a\u4e49\u8bed\u6599\u5e93\u793a\u4f8b\uff1ahttps://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big\n* \u7528\u6cd5\u793a\u4f8b\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py\n\n\u5173\u952e\u8bcd\u63d0\u53d6\u6240\u4f7f\u7528\u505c\u6b62\u8bcd\uff08Stop Words\uff09\u6587\u672c\u8bed\u6599\u5e93\u53ef\u4ee5\u5207\u6362\u6210\u81ea\u5b9a\u4e49\u8bed\u6599\u5e93\u7684\u8def\u5f84\n\n* \u7528\u6cd5\uff1a jieba.analyse.set_stop_words(file_name) # file_name\u4e3a\u81ea\u5b9a\u4e49\u8bed\u6599\u5e93\u7684\u8def\u5f84\n* \u81ea\u5b9a\u4e49\u8bed\u6599\u5e93\u793a\u4f8b\uff1ahttps://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt\n* \u7528\u6cd5\u793a\u4f8b\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py\n\n\u5173\u952e\u8bcd\u4e00\u5e76\u8fd4\u56de\u5173\u952e\u8bcd\u6743\u91cd\u503c\u793a\u4f8b\n\n* \u7528\u6cd5\u793a\u4f8b\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py\n\n### \u57fa\u4e8e TextRank \u7b97\u6cd5\u7684\u5173\u952e\u8bcd\u62bd\u53d6\n\n* jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) \u76f4\u63a5\u4f7f\u7528\uff0c\u63a5\u53e3\u76f8\u540c\uff0c\u6ce8\u610f\u9ed8\u8ba4\u8fc7\u6ee4\u8bcd\u6027\u3002\n* jieba.analyse.TextRank() \u65b0\u5efa\u81ea\u5b9a\u4e49 TextRank \u5b9e\u4f8b\n\n\u7b97\u6cd5\u8bba\u6587\uff1a [TextRank: Bringing Order into Texts](http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)\n\n#### \u57fa\u672c\u601d\u60f3:\n\n1. \u5c06\u5f85\u62bd\u53d6\u5173\u952e\u8bcd\u7684\u6587\u672c\u8fdb\u884c\u5206\u8bcd\n2. \u4ee5\u56fa\u5b9a\u7a97\u53e3\u5927\u5c0f(\u9ed8\u8ba4\u4e3a5\uff0c\u901a\u8fc7span\u5c5e\u6027\u8c03\u6574)\uff0c\u8bcd\u4e4b\u95f4\u7684\u5171\u73b0\u5173\u7cfb\uff0c\u6784\u5efa\u56fe\n3. \u8ba1\u7b97\u56fe\u4e2d\u8282\u70b9\u7684PageRank\uff0c\u6ce8\u610f\u662f\u65e0\u5411\u5e26\u6743\u56fe\n\n#### \u4f7f\u7528\u793a\u4f8b:\n\n\u89c1 [test/demo.py](https://github.com/fxsjy/jieba/blob/master/test/demo.py)\n\n4. \u8bcd\u6027\u6807\u6ce8\n-----------\n* `jieba.posseg.POSTokenizer(tokenizer=None)` \u65b0\u5efa\u81ea\u5b9a\u4e49\u5206\u8bcd\u5668\uff0c`tokenizer` \u53c2\u6570\u53ef\u6307\u5b9a\u5185\u90e8\u4f7f\u7528\u7684 `jieba.Tokenizer` \u5206\u8bcd\u5668\u3002`jieba.posseg.dt` \u4e3a\u9ed8\u8ba4\u8bcd\u6027\u6807\u6ce8\u5206\u8bcd\u5668\u3002\n* \u6807\u6ce8\u53e5\u5b50\u5206\u8bcd\u540e\u6bcf\u4e2a\u8bcd\u7684\u8bcd\u6027\uff0c\u91c7\u7528\u548c ictclas \u517c\u5bb9\u7684\u6807\u8bb0\u6cd5\u3002\n* \u7528\u6cd5\u793a\u4f8b\n\n```pycon\n>>> import jieba.posseg as pseg\n>>> words = pseg.cut(\"\u6211\u7231\u5317\u4eac\u5929\u5b89\u95e8\")\n>>> for word, flag in words:\n...    print('%s %s' % (word, flag))\n...\n\u6211 r\n\u7231 v\n\u5317\u4eac ns\n\u5929\u5b89\u95e8 ns\n```\n\n5. \u5e76\u884c\u5206\u8bcd\n-----------\n* \u539f\u7406\uff1a\u5c06\u76ee\u6807\u6587\u672c\u6309\u884c\u5206\u9694\u540e\uff0c\u628a\u5404\u884c\u6587\u672c\u5206\u914d\u5230\u591a\u4e2a Python \u8fdb\u7a0b\u5e76\u884c\u5206\u8bcd\uff0c\u7136\u540e\u5f52\u5e76\u7ed3\u679c\uff0c\u4ece\u800c\u83b7\u5f97\u5206\u8bcd\u901f\u5ea6\u7684\u53ef\u89c2\u63d0\u5347\n* \u57fa\u4e8e python \u81ea\u5e26\u7684 multiprocessing \u6a21\u5757\uff0c\u76ee\u524d\u6682\u4e0d\u652f\u6301 Windows\n* \u7528\u6cd5\uff1a\n    * `jieba.enable_parallel(4)` # \u5f00\u542f\u5e76\u884c\u5206\u8bcd\u6a21\u5f0f\uff0c\u53c2\u6570\u4e3a\u5e76\u884c\u8fdb\u7a0b\u6570\n    * `jieba.disable_parallel()` # \u5173\u95ed\u5e76\u884c\u5206\u8bcd\u6a21\u5f0f\n\n* \u4f8b\u5b50\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py\n\n* \u5b9e\u9a8c\u7ed3\u679c\uff1a\u5728 4 \u6838 3.4GHz Linux \u673a\u5668\u4e0a\uff0c\u5bf9\u91d1\u5eb8\u5168\u96c6\u8fdb\u884c\u7cbe\u786e\u5206\u8bcd\uff0c\u83b7\u5f97\u4e86 1MB/s \u7684\u901f\u5ea6\uff0c\u662f\u5355\u8fdb\u7a0b\u7248\u7684 3.3 \u500d\u3002\n\n* **\u6ce8\u610f**\uff1a\u5e76\u884c\u5206\u8bcd\u4ec5\u652f\u6301\u9ed8\u8ba4\u5206\u8bcd\u5668 `jieba.dt` \u548c `jieba.posseg.dt`\u3002\n\n6. Tokenize\uff1a\u8fd4\u56de\u8bcd\u8bed\u5728\u539f\u6587\u7684\u8d77\u6b62\u4f4d\u7f6e\n----------------------------------\n* \u6ce8\u610f\uff0c\u8f93\u5165\u53c2\u6570\u53ea\u63a5\u53d7 unicode\n* \u9ed8\u8ba4\u6a21\u5f0f\n\n```python\nresult = jieba.tokenize(u'\u6c38\u548c\u670d\u88c5\u9970\u54c1\u6709\u9650\u516c\u53f8')\nfor tk in result:\n    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n```\n\n```\nword \u6c38\u548c                start: 0                end:2\nword \u670d\u88c5                start: 2                end:4\nword \u9970\u54c1                start: 4                end:6\nword \u6709\u9650\u516c\u53f8            start: 6                end:10\n\n```\n\n* \u641c\u7d22\u6a21\u5f0f\n\n```python\nresult = jieba.tokenize(u'\u6c38\u548c\u670d\u88c5\u9970\u54c1\u6709\u9650\u516c\u53f8', mode='search')\nfor tk in result:\n    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n```\n\n```\nword \u6c38\u548c                start: 0                end:2\nword \u670d\u88c5                start: 2                end:4\nword \u9970\u54c1                start: 4                end:6\nword \u6709\u9650                start: 6                end:8\nword \u516c\u53f8                start: 8                end:10\nword \u6709\u9650\u516c\u53f8            start: 6                end:10\n```\n\n\n7. ChineseAnalyzer for Whoosh \u641c\u7d22\u5f15\u64ce\n--------------------------------------------\n* \u5f15\u7528\uff1a `from jieba.analyse import ChineseAnalyzer`\n* \u7528\u6cd5\u793a\u4f8b\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py\n\n8. \u547d\u4ee4\u884c\u5206\u8bcd\n-------------------\n\n\u4f7f\u7528\u793a\u4f8b\uff1a`python -m jieba news.txt > cut_result.txt`\n\n\u547d\u4ee4\u884c\u9009\u9879\uff08\u7ffb\u8bd1\uff09\uff1a\n\n    \u4f7f\u7528: python -m jieba [options] filename\n\n    \u7ed3\u5df4\u547d\u4ee4\u884c\u754c\u9762\u3002\n\n    \u56fa\u5b9a\u53c2\u6570:\n      filename              \u8f93\u5165\u6587\u4ef6\n\n    \u53ef\u9009\u53c2\u6570:\n      -h, --help            \u663e\u793a\u6b64\u5e2e\u52a9\u4fe1\u606f\u5e76\u9000\u51fa\n      -d [DELIM], --delimiter [DELIM]\n                            \u4f7f\u7528 DELIM \u5206\u9694\u8bcd\u8bed\uff0c\u800c\u4e0d\u662f\u7528\u9ed8\u8ba4\u7684' / '\u3002\n                            \u82e5\u4e0d\u6307\u5b9a DELIM\uff0c\u5219\u4f7f\u7528\u4e00\u4e2a\u7a7a\u683c\u5206\u9694\u3002\n      -p [DELIM], --pos [DELIM]\n                            \u542f\u7528\u8bcd\u6027\u6807\u6ce8\uff1b\u5982\u679c\u6307\u5b9a DELIM\uff0c\u8bcd\u8bed\u548c\u8bcd\u6027\u4e4b\u95f4\n                            \u7528\u5b83\u5206\u9694\uff0c\u5426\u5219\u7528 _ \u5206\u9694\n      -D DICT, --dict DICT  \u4f7f\u7528 DICT \u4ee3\u66ff\u9ed8\u8ba4\u8bcd\u5178\n      -u USER_DICT, --user-dict USER_DICT\n                            \u4f7f\u7528 USER_DICT \u4f5c\u4e3a\u9644\u52a0\u8bcd\u5178\uff0c\u4e0e\u9ed8\u8ba4\u8bcd\u5178\u6216\u81ea\u5b9a\u4e49\u8bcd\u5178\u914d\u5408\u4f7f\u7528\n      -a, --cut-all         \u5168\u6a21\u5f0f\u5206\u8bcd\uff08\u4e0d\u652f\u6301\u8bcd\u6027\u6807\u6ce8\uff09\n      -n, --no-hmm          \u4e0d\u4f7f\u7528\u9690\u542b\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\n      -q, --quiet           \u4e0d\u8f93\u51fa\u8f7d\u5165\u4fe1\u606f\u5230 STDERR\n      -V, --version         \u663e\u793a\u7248\u672c\u4fe1\u606f\u5e76\u9000\u51fa\n\n    \u5982\u679c\u6ca1\u6709\u6307\u5b9a\u6587\u4ef6\u540d\uff0c\u5219\u4f7f\u7528\u6807\u51c6\u8f93\u5165\u3002\n\n`--help` \u9009\u9879\u8f93\u51fa\uff1a\n\n    $> python -m jieba --help\n    Jieba command line interface.\n\n    positional arguments:\n      filename              input file\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -d [DELIM], --delimiter [DELIM]\n                            use DELIM instead of ' / ' for word delimiter; or a\n                            space if it is used without DELIM\n      -p [DELIM], --pos [DELIM]\n                            enable POS tagging; if DELIM is specified, use DELIM\n                            instead of '_' for POS delimiter\n      -D DICT, --dict DICT  use DICT as dictionary\n      -u USER_DICT, --user-dict USER_DICT\n                            use USER_DICT together with the default dictionary or\n                            DICT (if specified)\n      -a, --cut-all         full pattern cutting (ignored with POS tagging)\n      -n, --no-hmm          don't use the Hidden Markov Model\n      -q, --quiet           don't print loading messages to stderr\n      -V, --version         show program's version number and exit\n\n    If no filename specified, use STDIN instead.\n\n\u5ef6\u8fdf\u52a0\u8f7d\u673a\u5236\n------------\n\njieba \u91c7\u7528\u5ef6\u8fdf\u52a0\u8f7d\uff0c`import jieba` \u548c `jieba.Tokenizer()` \u4e0d\u4f1a\u7acb\u5373\u89e6\u53d1\u8bcd\u5178\u7684\u52a0\u8f7d\uff0c\u4e00\u65e6\u6709\u5fc5\u8981\u624d\u5f00\u59cb\u52a0\u8f7d\u8bcd\u5178\u6784\u5efa\u524d\u7f00\u5b57\u5178\u3002\u5982\u679c\u4f60\u60f3\u624b\u5de5\u521d\u59cb jieba\uff0c\u4e5f\u53ef\u4ee5\u624b\u52a8\u521d\u59cb\u5316\u3002\n\n    import jieba\n    jieba.initialize()  # \u624b\u52a8\u521d\u59cb\u5316\uff08\u53ef\u9009\uff09\n\n\n\u5728 0.28 \u4e4b\u524d\u7684\u7248\u672c\u662f\u4e0d\u80fd\u6307\u5b9a\u4e3b\u8bcd\u5178\u7684\u8def\u5f84\u7684\uff0c\u6709\u4e86\u5ef6\u8fdf\u52a0\u8f7d\u673a\u5236\u540e\uff0c\u4f60\u53ef\u4ee5\u6539\u53d8\u4e3b\u8bcd\u5178\u7684\u8def\u5f84:\n\n    jieba.set_dictionary('data/dict.txt.big')\n\n\u4f8b\u5b50\uff1a https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.py\n\n\u5176\u4ed6\u8bcd\u5178\n========\n1. \u5360\u7528\u5185\u5b58\u8f83\u5c0f\u7684\u8bcd\u5178\u6587\u4ef6\nhttps://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small\n\n2. \u652f\u6301\u7e41\u4f53\u5206\u8bcd\u66f4\u597d\u7684\u8bcd\u5178\u6587\u4ef6\nhttps://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big\n\n\u4e0b\u8f7d\u4f60\u6240\u9700\u8981\u7684\u8bcd\u5178\uff0c\u7136\u540e\u8986\u76d6 jieba/dict.txt \u5373\u53ef\uff1b\u6216\u8005\u7528 `jieba.set_dictionary('data/dict.txt.big')`\n\n\u5176\u4ed6\u8bed\u8a00\u5b9e\u73b0\n==========\n\n\u7ed3\u5df4\u5206\u8bcd Java \u7248\u672c\n----------------\n\u4f5c\u8005\uff1apiaolingxue\n\u5730\u5740\uff1ahttps://github.com/huaban/jieba-analysis\n\n\u7ed3\u5df4\u5206\u8bcd C++ \u7248\u672c\n----------------\n\u4f5c\u8005\uff1ayanyiwu\n\u5730\u5740\uff1ahttps://github.com/yanyiwu/cppjieba\n\n\u7ed3\u5df4\u5206\u8bcd Rust \u7248\u672c\n----------------\n\u4f5c\u8005\uff1amessense, MnO2\n\u5730\u5740\uff1ahttps://github.com/messense/jieba-rs\n\n\u7ed3\u5df4\u5206\u8bcd Node.js \u7248\u672c\n----------------\n\u4f5c\u8005\uff1ayanyiwu\n\u5730\u5740\uff1ahttps://github.com/yanyiwu/nodejieba\n\n\u7ed3\u5df4\u5206\u8bcd Erlang \u7248\u672c\n----------------\n\u4f5c\u8005\uff1afalood\n\u5730\u5740\uff1ahttps://github.com/falood/exjieba\n\n\u7ed3\u5df4\u5206\u8bcd R \u7248\u672c\n----------------\n\u4f5c\u8005\uff1aqinwf\n\u5730\u5740\uff1ahttps://github.com/qinwf/jiebaR\n\n\u7ed3\u5df4\u5206\u8bcd iOS \u7248\u672c\n----------------\n\u4f5c\u8005\uff1ayanyiwu\n\u5730\u5740\uff1ahttps://github.com/yanyiwu/iosjieba\n\n\u7ed3\u5df4\u5206\u8bcd PHP \u7248\u672c\n----------------\n\u4f5c\u8005\uff1afukuball\n\u5730\u5740\uff1ahttps://github.com/fukuball/jieba-php\n\n\u7ed3\u5df4\u5206\u8bcd .NET(C#) \u7248\u672c\n----------------\n\u4f5c\u8005\uff1aanderscui\n\u5730\u5740\uff1ahttps://github.com/anderscui/jieba.NET/\n\n\u7ed3\u5df4\u5206\u8bcd Go \u7248\u672c\n----------------\n\n+ \u4f5c\u8005: wangbin \u5730\u5740: https://github.com/wangbin/jiebago\n+ \u4f5c\u8005: yanyiwu \u5730\u5740: https://github.com/yanyiwu/gojieba\n\n\u7ed3\u5df4\u5206\u8bcdAndroid\u7248\u672c\n------------------\n+ \u4f5c\u8005   Dongliang.W  \u5730\u5740\uff1ahttps://github.com/452896915/jieba-android\n\n\n\u7cfb\u7edf\u96c6\u6210\n========\n1. Solr: https://github.com/sing1ee/jieba-solr\n\n\u5206\u8bcd\u901f\u5ea6\n=========\n* 1.5 MB / Second in Full Mode\n* 400 KB / Second in Default Mode\n* \u6d4b\u8bd5\u73af\u5883: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz\uff1b\u300a\u56f4\u57ce\u300b.txt\n\n\u5e38\u89c1\u95ee\u9898\n=========\n\n## 1. \u6a21\u578b\u7684\u6570\u636e\u662f\u5982\u4f55\u751f\u6210\u7684\uff1f\n\n\u8be6\u89c1\uff1a https://github.com/fxsjy/jieba/issues/7\n\n## 2. \u201c\u53f0\u4e2d\u201d\u603b\u662f\u88ab\u5207\u6210\u201c\u53f0 \u4e2d\u201d\uff1f\uff08\u4ee5\u53ca\u7c7b\u4f3c\u60c5\u51b5\uff09\n\nP(\u53f0\u4e2d) \uff1c P(\u53f0)\u00d7P(\u4e2d)\uff0c\u201c\u53f0\u4e2d\u201d\u8bcd\u9891\u4e0d\u591f\u5bfc\u81f4\u5176\u6210\u8bcd\u6982\u7387\u8f83\u4f4e\n\n\u89e3\u51b3\u65b9\u6cd5\uff1a\u5f3a\u5236\u8c03\u9ad8\u8bcd\u9891\n\n`jieba.add_word('\u53f0\u4e2d')` \u6216\u8005 `jieba.suggest_freq('\u53f0\u4e2d', True)`\n\n## 3. \u201c\u4eca\u5929\u5929\u6c14 \u4e0d\u9519\u201d\u5e94\u8be5\u88ab\u5207\u6210\u201c\u4eca\u5929 \u5929\u6c14 \u4e0d\u9519\u201d\uff1f\uff08\u4ee5\u53ca\u7c7b\u4f3c\u60c5\u51b5\uff09\n\n\u89e3\u51b3\u65b9\u6cd5\uff1a\u5f3a\u5236\u8c03\u4f4e\u8bcd\u9891\n\n`jieba.suggest_freq(('\u4eca\u5929', '\u5929\u6c14'), True)`\n\n\u6216\u8005\u76f4\u63a5\u5220\u9664\u8be5\u8bcd `jieba.del_word('\u4eca\u5929\u5929\u6c14')`\n\n## 4. \u5207\u51fa\u4e86\u8bcd\u5178\u4e2d\u6ca1\u6709\u7684\u8bcd\u8bed\uff0c\u6548\u679c\u4e0d\u7406\u60f3\uff1f\n\n\u89e3\u51b3\u65b9\u6cd5\uff1a\u5173\u95ed\u65b0\u8bcd\u53d1\u73b0\n\n`jieba.cut('\u4e30\u7530\u592a\u7701\u4e86', HMM=False)`\n`jieba.cut('\u6211\u4eec\u4e2d\u51fa\u4e86\u4e00\u4e2a\u53db\u5f92', HMM=False)`\n\n**\u66f4\u591a\u95ee\u9898\u8bf7\u70b9\u51fb**\uff1ahttps://github.com/fxsjy/jieba/issues?sort=updated&state=closed\n\n\u4fee\u8ba2\u5386\u53f2\n==========\nhttps://github.com/fxsjy/jieba/blob/master/Changelog\n\n--------------------\n\njieba\n========\n\"Jieba\" (Chinese for \"to stutter\") Chinese text segmentation: built to be the best Python Chinese word segmentation module.\n\nFeatures\n========\n* Support three types of segmentation mode:\n\n1. Accurate Mode attempts to cut the sentence into the most accurate segmentations, which is suitable for text analysis.\n2. Full Mode gets all the possible words from the sentence. Fast but not accurate.\n3. Search Engine Mode, based on the Accurate Mode, attempts to cut long words into several short words, which can raise the recall rate. Suitable for search engines.\n\n* Supports Traditional Chinese\n* Supports customized dictionaries\n* MIT License\n\n\nOnline demo\n=========\nhttp://jiebademo.ap01.aws.af.cm/\n\n(Powered by Appfog)\n\nUsage\n========\n* Fully automatic installation: `easy_install jieba` or `pip install jieba`\n* Semi-automatic installation: Download http://pypi.python.org/pypi/jieba/ , run `python setup.py install` after extracting.\n* Manual installation: place the `jieba` directory in the current directory or python `site-packages` directory.\n* `import jieba`.\n\nAlgorithm\n========\n* Based on a prefix dictionary structure to achieve efficient word graph scanning. Build a directed acyclic graph (DAG) for all possible word combinations.\n* Use dynamic programming to find the most probable combination based on the word frequency.\n* For unknown words, a HMM-based model is used with the Viterbi algorithm.\n\nMain Functions\n==============\n\n1. Cut\n--------\n* The `jieba.cut` function accepts three input parameters: the first parameter is the string to be cut; the second parameter is `cut_all`, controlling the cut mode; the third parameter is to control whether to use the Hidden Markov Model.\n* `jieba.cut_for_search` accepts two parameter: the string to be cut; whether to use the Hidden Markov Model. This will cut the sentence into short words suitable for search engines.\n* The input string can be an unicode/str object, or a str/bytes object which is encoded in UTF-8 or GBK. Note that using GBK encoding is not recommended because it may be unexpectly decoded as UTF-8.\n* `jieba.cut` and `jieba.cut_for_search` returns an generator, from which you can use a `for` loop to get the segmentation result (in unicode).\n* `jieba.lcut` and `jieba.lcut_for_search` returns a list.\n* `jieba.Tokenizer(dictionary=DEFAULT_DICT)` creates a new customized Tokenizer, which enables you to use different dictionaries at the same time. `jieba.dt` is the default Tokenizer, to which almost all global functions are mapped.\n\n\n**Code example: segmentation**\n\n```python\n#encoding=utf-8\nimport jieba\n\nseg_list = jieba.cut(\"\u6211\u6765\u5230\u5317\u4eac\u6e05\u534e\u5927\u5b66\", cut_all=True)\nprint(\"Full Mode: \" + \"/ \".join(seg_list))  # \u5168\u6a21\u5f0f\n\nseg_list = jieba.cut(\"\u6211\u6765\u5230\u5317\u4eac\u6e05\u534e\u5927\u5b66\", cut_all=False)\nprint(\"Default Mode: \" + \"/ \".join(seg_list))  # \u9ed8\u8ba4\u6a21\u5f0f\n\nseg_list = jieba.cut(\"\u4ed6\u6765\u5230\u4e86\u7f51\u6613\u676d\u7814\u5927\u53a6\")\nprint(\", \".join(seg_list))\n\nseg_list = jieba.cut_for_search(\"\u5c0f\u660e\u7855\u58eb\u6bd5\u4e1a\u4e8e\u4e2d\u56fd\u79d1\u5b66\u9662\u8ba1\u7b97\u6240\uff0c\u540e\u5728\u65e5\u672c\u4eac\u90fd\u5927\u5b66\u6df1\u9020\")  # \u641c\u7d22\u5f15\u64ce\u6a21\u5f0f\nprint(\", \".join(seg_list))\n```\n\nOutput:\n\n    [Full Mode]: \u6211/ \u6765\u5230/ \u5317\u4eac/ \u6e05\u534e/ \u6e05\u534e\u5927\u5b66/ \u534e\u5927/ \u5927\u5b66\n\n    [Accurate Mode]: \u6211/ \u6765\u5230/ \u5317\u4eac/ \u6e05\u534e\u5927\u5b66\n\n    [Unknown Words Recognize] \u4ed6, \u6765\u5230, \u4e86, \u7f51\u6613, \u676d\u7814, \u5927\u53a6    (In this case, \"\u676d\u7814\" is not in the dictionary, but is identified by the Viterbi algorithm)\n\n    [Search Engine Mode]\uff1a \u5c0f\u660e, \u7855\u58eb, \u6bd5\u4e1a, \u4e8e, \u4e2d\u56fd, \u79d1\u5b66, \u5b66\u9662, \u79d1\u5b66\u9662, \u4e2d\u56fd\u79d1\u5b66\u9662, \u8ba1\u7b97, \u8ba1\u7b97\u6240, \u540e, \u5728, \u65e5\u672c, \u4eac\u90fd, \u5927\u5b66, \u65e5\u672c\u4eac\u90fd\u5927\u5b66, \u6df1\u9020\n\n\n2. Add a custom dictionary\n----------------------------\n\n### Load dictionary\n\n* Developers can specify their own custom dictionary to be included in the jieba default dictionary. Jieba is able to identify new words, but you can add your own new words can ensure a higher accuracy.\n* Usage\uff1a `jieba.load_userdict(file_name)` # file_name is a file-like object or the path of the custom dictionary\n* The dictionary format is the same as that of `dict.txt`: one word per line; each line is divided into three parts separated by a space: word, word frequency, POS tag. If `file_name` is a path or a file opened in binary mode, the dictionary must be UTF-8 encoded.\n* The word frequency and POS tag can be omitted respectively. The word frequency will be filled with a suitable value if omitted.\n\n**For example:**\n\n```\n\u521b\u65b0\u529e 3 i\n\u4e91\u8ba1\u7b97 5\n\u51f1\u7279\u7433 nz\n\u53f0\u4e2d\n```\n\n\n* Change a Tokenizer's `tmp_dir` and `cache_file` to specify the path of the cache file, for using on a restricted file system.\n\n* Example:\n\n        \u4e91\u8ba1\u7b97 5\n        \u674e\u5c0f\u798f 2\n        \u521b\u65b0\u529e 3\n\n        [Before]\uff1a \u674e\u5c0f\u798f / \u662f / \u521b\u65b0 / \u529e / \u4e3b\u4efb / \u4e5f / \u662f / \u4e91 / \u8ba1\u7b97 / \u65b9\u9762 / \u7684 / \u4e13\u5bb6 /\n\n        [After]\uff1a\u3000\u674e\u5c0f\u798f / \u662f / \u521b\u65b0\u529e / \u4e3b\u4efb / \u4e5f / \u662f / \u4e91\u8ba1\u7b97 / \u65b9\u9762 / \u7684 / \u4e13\u5bb6 /\n\n\n### Modify dictionary\n\n* Use `add_word(word, freq=None, tag=None)` and `del_word(word)` to modify the dictionary dynamically in programs.\n* Use `suggest_freq(segment, tune=True)` to adjust the frequency of a single word so that it can (or cannot) be segmented.\n\n* Note that HMM may affect the final result.\n\nExample:\n\n```pycon\n>>> print('/'.join(jieba.cut('\u5982\u679c\u653e\u5230post\u4e2d\u5c06\u51fa\u9519\u3002', HMM=False)))\n\u5982\u679c/\u653e\u5230/post/\u4e2d\u5c06/\u51fa\u9519/\u3002\n>>> jieba.suggest_freq(('\u4e2d', '\u5c06'), True)\n494\n>>> print('/'.join(jieba.cut('\u5982\u679c\u653e\u5230post\u4e2d\u5c06\u51fa\u9519\u3002', HMM=False)))\n\u5982\u679c/\u653e\u5230/post/\u4e2d/\u5c06/\u51fa\u9519/\u3002\n>>> print('/'.join(jieba.cut('\u300c\u53f0\u4e2d\u300d\u6b63\u786e\u5e94\u8be5\u4e0d\u4f1a\u88ab\u5207\u5f00', HMM=False)))\n\u300c/\u53f0/\u4e2d/\u300d/\u6b63\u786e/\u5e94\u8be5/\u4e0d\u4f1a/\u88ab/\u5207\u5f00\n>>> jieba.suggest_freq('\u53f0\u4e2d', True)\n69\n>>> print('/'.join(jieba.cut('\u300c\u53f0\u4e2d\u300d\u6b63\u786e\u5e94\u8be5\u4e0d\u4f1a\u88ab\u5207\u5f00', HMM=False)))\n\u300c/\u53f0\u4e2d/\u300d/\u6b63\u786e/\u5e94\u8be5/\u4e0d\u4f1a/\u88ab/\u5207\u5f00\n```\n\n3. Keyword Extraction\n-----------------------\n`import jieba.analyse`\n\n* `jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())`\n  * `sentence`: the text to be extracted\n  * `topK`: return how many keywords with the highest TF/IDF weights. The default value is 20\n  * `withWeight`: whether return TF/IDF weights with the keywords. The default value is False\n  * `allowPOS`: filter words with which POSs are included. Empty for no filtering.\n* `jieba.analyse.TFIDF(idf_path=None)` creates a new TFIDF instance, `idf_path` specifies IDF file path.\n\nExample (keyword extraction)\n\nhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags.py\n\nDevelopers can specify their own custom IDF corpus in jieba keyword extraction\n\n* Usage\uff1a `jieba.analyse.set_idf_path(file_name) # file_name is the path for the custom corpus`\n* Custom Corpus Sample\uff1ahttps://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big\n* Sample Code\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py\n\nDevelopers can specify their own custom stop words corpus in jieba keyword extraction\n\n* Usage\uff1a `jieba.analyse.set_stop_words(file_name) # file_name is the path for the custom corpus`\n* Custom Corpus Sample\uff1ahttps://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt\n* Sample Code\uff1ahttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py\n\nThere's also a [TextRank](http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf) implementation available.\n\nUse: `jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))`\n\nNote that it filters POS by default.\n\n`jieba.analyse.TextRank()` creates a new TextRank instance.\n\n4. Part of Speech Tagging\n-------------------------\n* `jieba.posseg.POSTokenizer(tokenizer=None)` creates a new customized Tokenizer. `tokenizer` specifies the jieba.Tokenizer to internally use. `jieba.posseg.dt` is the default POSTokenizer.\n* Tags the POS of each word after segmentation, using labels compatible with ictclas.\n* Example:\n\n```pycon\n>>> import jieba.posseg as pseg\n>>> words = pseg.cut(\"\u6211\u7231\u5317\u4eac\u5929\u5b89\u95e8\")\n>>> for w in words:\n...    print('%s %s' % (w.word, w.flag))\n...\n\u6211 r\n\u7231 v\n\u5317\u4eac ns\n\u5929\u5b89\u95e8 ns\n```\n\n5. Parallel Processing\n----------------------\n* Principle: Split target text by line, assign the lines into multiple Python processes, and then merge the results, which is considerably faster.\n* Based on the multiprocessing module of Python.\n* Usage:\n    * `jieba.enable_parallel(4)` # Enable parallel processing. The parameter is the number of processes.\n    * `jieba.disable_parallel()` # Disable parallel processing.\n\n* Example:\n    https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py\n\n* Result: On a four-core 3.4GHz Linux machine, do accurate word segmentation on Complete Works of Jin Yong, and the speed reaches 1MB/s, which is 3.3 times faster than the single-process version.\n\n* **Note** that parallel processing supports only default tokenizers, `jieba.dt` and `jieba.posseg.dt`.\n\n6. Tokenize: return words with position\n----------------------------------------\n* The input must be unicode\n* Default mode\n\n```python\nresult = jieba.tokenize(u'\u6c38\u548c\u670d\u88c5\u9970\u54c1\u6709\u9650\u516c\u53f8')\nfor tk in result:\n    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n```\n\n```\nword \u6c38\u548c                start: 0                end:2\nword \u670d\u88c5                start: 2                end:4\nword \u9970\u54c1                start: 4                end:6\nword \u6709\u9650\u516c\u53f8            start: 6                end:10\n\n```\n\n* Search mode\n\n```python\nresult = jieba.tokenize(u'\u6c38\u548c\u670d\u88c5\u9970\u54c1\u6709\u9650\u516c\u53f8',mode='search')\nfor tk in result:\n    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n```\n\n```\nword \u6c38\u548c                start: 0                end:2\nword \u670d\u88c5                start: 2                end:4\nword \u9970\u54c1                start: 4                end:6\nword \u6709\u9650                start: 6                end:8\nword \u516c\u53f8                start: 8                end:10\nword \u6709\u9650\u516c\u53f8            start: 6                end:10\n```\n\n\n7. ChineseAnalyzer for Whoosh\n-------------------------------\n* `from jieba.analyse import ChineseAnalyzer`\n* Example: https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py\n\n8. Command Line Interface\n--------------------------------\n\n    $> python -m jieba --help\n    Jieba command line interface.\n\n    positional arguments:\n      filename              input file\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -d [DELIM], --delimiter [DELIM]\n                            use DELIM instead of ' / ' for word delimiter; or a\n                            space if it is used without DELIM\n      -p [DELIM], --pos [DELIM]\n                            enable POS tagging; if DELIM is specified, use DELIM\n                            instead of '_' for POS delimiter\n      -D DICT, --dict DICT  use DICT as dictionary\n      -u USER_DICT, --user-dict USER_DICT\n                            use USER_DICT together with the default dictionary or\n                            DICT (if specified)\n      -a, --cut-all         full pattern cutting (ignored with POS tagging)\n      -n, --no-hmm          don't use the Hidden Markov Model\n      -q, --quiet           don't print loading messages to stderr\n      -V, --version         show program's version number and exit\n\n    If no filename specified, use STDIN instead.\n\nInitialization\n---------------\nBy default, Jieba don't build the prefix dictionary unless it's necessary. This takes 1-3 seconds, after which it is not initialized again. If you want to initialize Jieba manually, you can call:\n\n    import jieba\n    jieba.initialize()  # (optional)\n\nYou can also specify the dictionary (not supported before version 0.28) :\n\n    jieba.set_dictionary('data/dict.txt.big')\n\n\nUsing Other Dictionaries\n===========================\n\nIt is possible to use your own dictionary with Jieba, and there are also two dictionaries ready for download:\n\n1. A smaller dictionary for a smaller memory footprint:\nhttps://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small\n\n2. There is also a bigger dictionary that has better support for traditional Chinese (\u7e41\u9ad4):\nhttps://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big\n\nBy default, an in-between dictionary is used, called `dict.txt` and included in the distribution.\n\nIn either case, download the file you want, and then call `jieba.set_dictionary('data/dict.txt.big')` or just replace the existing `dict.txt`.\n\nSegmentation speed\n=========\n* 1.5 MB / Second in Full Mode\n* 400 KB / Second in Default Mode\n* Test Env: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz\uff1b\u300a\u56f4\u57ce\u300b.txt\n\n"}, {"repo": "521xueweihan/HelloGitHub", "language": "Python", "readme_contents": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/521xueweihan/img/master/hellogithub/logo/readme.gif\"/>\n  <br>\u4e2d\u6587 | <a href=\"README_en.md\">English</a>\n  <br><strong>HelloGitHub</strong> \u4e00\u4e2a\u5206\u4eab GitHub \u4e0a\u6709\u8da3\u3001\u5165\u95e8\u7ea7\u7684\u5f00\u6e90\u9879\u76ee\u3002<br>\u5174\u8da3\u662f\u6700\u597d\u7684\u8001\u5e08\uff0c\u8fd9\u91cc\u80fd\u591f\u5e2e\u4f60\u627e\u5230\u7f16\u7a0b\u7684\u5174\u8da3\uff01\n</p>\n\n<p align=\"center\">\n  <a href=\"https://raw.githubusercontent.com/521xueweihan/img/master/hellogithub/logo/weixin.png\"><img src=\"https://img.shields.io/badge/Talk-%E5%BE%AE%E4%BF%A1%E7%BE%A4-brightgreen.svg?style=popout-square\" alt=\"WeiXin\"></a>\n  <a href=\"https://github.com/521xueweihan/HelloGitHub/stargazers\"><img src=\"https://img.shields.io/github/stars/521xueweihan/HelloGitHub.svg?style=popout-square\" alt=\"GitHub stars\"></a>\n  <a href=\"https://github.com/521xueweihan/HelloGitHub/issues\"><img src=\"https://img.shields.io/github/issues/521xueweihan/HelloGitHub.svg?style=popout-square\" alt=\"GitHub issues\"></a>\n    <a href=\"https://weibo.com/hellogithub\"><img src=\"https://img.shields.io/badge/%E6%96%B0%E6%B5%AA-Weibo-red.svg?style=popout-square\" alt=\"Sina Weibo\"></a>\n</p>\n\n## \u7b80\u4ecb\n\u8fd9\u662f\u4e00\u4e2a\u9762\u5411\u7f16\u7a0b\u65b0\u624b\u3001\u70ed\u7231\u7f16\u7a0b\u3001\u5bf9\u5f00\u6e90\u793e\u533a\u611f\u5174\u8da3\u4eba\u7fa4\u7684\u9879\u76ee\uff0c\u5185\u5bb9**\u6bcf\u6708 28 \u53f7**\u4ee5\u6708\u520a\u7684\u5f62\u5f0f\u66f4\u65b0\u53d1\u5e03\u3002\u5185\u5bb9\u5305\u62ec\uff1a**\u6d41\u884c\u9879\u76ee**\u3001**\u5165\u95e8\u7ea7\u9879\u76ee**\u3001**\u8ba9\u751f\u6d3b\u53d8\u5f97\u66f4\u7f8e\u597d\u7684\u5de5\u5177**\u3001**\u4e66\u7c4d**\u3001**\u5b66\u4e60\u5fc3\u5f97\u7b14\u8bb0**\u3001**\u4f01\u4e1a\u7ea7\u9879\u76ee**\u7b49\uff0c\u8fd9\u4e9b\u5f00\u6e90\u9879\u76ee\u5927\u591a\u90fd\u662f\u975e\u5e38\u5bb9\u6613\u4e0a\u624b\u3001\u5f88 Cool\uff0c\u80fd\u591f\u8ba9\u4f60\u7528\u5f88\u77ed\u65f6\u95f4\u611f\u53d7\u5230\u7f16\u7a0b\u7684\u9b45\u529b\u548c\u4fbf\u6377\u3002\u4ece\u800c\u8ba9\u5927\u5bb6\u611f\u53d7\u5230\u7f16\u7a0b\u7684\u4e50\u8da3\uff0c\u52a8\u624b\u5f00\u59cb\u7f16\u7a0b\u3002\n\n\u5e0c\u671b\u901a\u8fc7\u672c\u9879\u76ee\u80fd\u591f\u6709\u66f4\u591a\u4eba\u52a0\u5165\u5230\u5f00\u6e90\u793e\u533a\u3001\u56de\u9988\u793e\u533a\u3002**\u8ba9\u6709\u8da3\u3001\u6709\u4ef7\u503c\u7684\u9879\u76ee\u88ab\u66f4\u591a\u4eba\u53d1\u73b0\u548c\u52a0\u5165**\u3002\u5728\u53c2\u4e0e\u8fd9\u4e9b\u9879\u76ee\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4f60\u5c06\u5f97\u5230\uff1a**\u70ed\u7231\u7f16\u7a0b\u7684\u5c0f\u4f19\u4f34**\ud83d\udd7a \u3001**\u66f4\u591a\u7f16\u7a0b\u77e5\u8bc6**\ud83d\udcda \u3001**\u4f18\u79c0\u7684\u7f16\u7a0b\u6280\u5de7**\ud83d\udcbb \u3001**\u627e\u5230\u7f16\u7a0b\u7684\u4e50\u8da3**\ud83c\udfae \u3002\n\n- **\u300e\u6bcf\u65e5\u7cbe\u9009\u300f** \u5173\u6ce8\u6211\u4eec\u7684[\u6700\u60e8\u5b98\u5fae](https://weibo.com/hellogithub)\u83b7\u53d6\u6bcf\u65e5\u9879\u76ee\u63a8\u8350+\u62bd\u5956\u3002\n- **\u300e\u8bb2\u89e3\u5f00\u6e90\u9879\u76ee\u300f** \u6b22\u8fce\u5f00\u6e90\u7231\u597d\u8005\u7ed9\u6211\u4eec\u6295\u7a3f[\u67e5\u770b\u521b\u4f5c\u987b\u77e5](https://github.com/HelloGitHub-Team/Article/blob/master/%E5%88%9B%E4%BD%9C%E9%A1%BB%E7%9F%A5.md)\u3002\n\n\n## \u5185\u5bb9\n\u6bcf\u6708 28 \u53f7\u53d1\u5e03[\u6700\u65b0\u4e00\u671f](/content/last.md) | [\u5b98\u7f51](https://hellogithub.com) \n\n| :squirrel: | :jack_o_lantern: | :beer: | :fish_cake: | :octocat: |\n| ------- | ----- | ------------ | ------ | --------- |\n| [\u7b2c 44 \u671f](/content/44/HelloGitHub44.md) | [\u7b2c 43 \u671f](/content/43/HelloGitHub43.md) | [\u7b2c 42 \u671f](/content/42/HelloGitHub42.md) | [\u7b2c 41 \u671f](/content/41/HelloGitHub41.md) |\n| [\u7b2c 40 \u671f](/content/40/HelloGitHub40.md) | [\u7b2c 39 \u671f](/content/39/HelloGitHub39.md) | [\u7b2c 38 \u671f](/content/38/HelloGitHub38.md) | [\u7b2c 37 \u671f](/content/37/HelloGitHub37.md) | [\u7b2c 36 \u671f](/content/36/HelloGitHub36.md) |\n| [\u7b2c 35 \u671f](/content/35/HelloGitHub35.md) | [\u7b2c 34 \u671f](/content/34/HelloGitHub34.md) | [\u7b2c 33 \u671f](/content/33/HelloGitHub33.md) | [\u7b2c 32 \u671f](/content/32/HelloGitHub32.md) | [\u7b2c 31 \u671f](/content/31/HelloGitHub31.md) |\n| [\u7b2c 30 \u671f](/content/30/HelloGitHub30.md) | [\u7b2c 29 \u671f](/content/29/HelloGitHub29.md) | [\u7b2c 28 \u671f](/content/28/HelloGitHub28.md) | [\u7b2c 27 \u671f](/content/27/HelloGitHub27.md) | [\u7b2c 26 \u671f](/content/26/HelloGitHub26.md) |\n| [\u7b2c 25 \u671f](/content/25/HelloGitHub25.md) | [\u7b2c 24 \u671f](/content/24/HelloGitHub24.md) | [\u7b2c 23 \u671f](/content/23/HelloGitHub23.md) | [\u7b2c 22 \u671f](/content/22/HelloGitHub22.md) | [\u7b2c 21 \u671f](/content/21/HelloGitHub21.md) |\n| [\u7b2c 20 \u671f](/content/20/HelloGitHub20.md) | [\u7b2c 19 \u671f](/content/19/HelloGitHub19.md) | [\u7b2c 18 \u671f](/content/18/HelloGitHub18.md) | [\u7b2c 17 \u671f](/content/17/HelloGitHub17.md) | [\u7b2c 16 \u671f](/content/16/HelloGitHub16.md) |\n| [\u7b2c 15 \u671f](/content/15/HelloGitHub15.md) | [\u7b2c 14 \u671f](/content/14/HelloGitHub14.md) | [\u7b2c 13 \u671f](/content/13/HelloGitHub13.md) | [\u7b2c 12 \u671f](/content/12/HelloGitHub12.md) | [\u7b2c 11 \u671f](/content/11/HelloGitHub11.md) |\n| [\u7b2c 10 \u671f](/content/10/HelloGitHub10.md) | [\u7b2c 09 \u671f](/content/09/HelloGitHub09.md) | [\u7b2c 08 \u671f](/content/08/HelloGitHub08.md) | [\u7b2c 07 \u671f](/content/07/HelloGitHub07.md) | [\u7b2c 06 \u671f](/content/06/HelloGitHub06.md) |\n| [\u7b2c 05 \u671f](/content/05/HelloGitHub05.md) | [\u7b2c 04 \u671f](/content/04/HelloGitHub04.md) | [\u7b2c 03 \u671f](/content/03/HelloGitHub03.md) | [\u7b2c 02 \u671f](/content/02/HelloGitHub02.md) | [\u7b2c 01 \u671f](/content/01/HelloGitHub01.md) |\n\n\u6b22\u8fce[\u63a8\u8350\u6216\u81ea\u8350\u9879\u76ee](https://github.com/521xueweihan/HelloGitHub/issues/new)\u6210\u4e3a **HelloGitHub** \u7684[\u8d21\u732e\u8005](https://github.com/521xueweihan/HelloGitHub/blob/master/content/contributors.md) \n\n## \u8d21\u732e\u8005\n<table>\n  <tbody>\n    <tr>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/521xueweihan\">\n          <img src=\"https://avatars2.githubusercontent.com/u/8255800?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>\u524a\u5fae\u5bd2</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/ming995\">\n          <img src=\"https://avatars0.githubusercontent.com/u/46031112?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>\u7cd6\u918b\u91cc\u810a</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/FrontMage\">\n          <img src=\"https://avatars0.githubusercontent.com/u/17007026?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>FrontMage</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/xibinyue\">\n          <img src=\"https://avatars0.githubusercontent.com/u/14122146?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>xibinyue</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/Eurus-Holmes\">\n          <img src=\"https://avatars3.githubusercontent.com/u/34226570?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>Feiyang Chen</sub>\n        </a><br>\n      </th>\n    </tr>\n    <tr>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/ChungZH\">\n          <img src=\"https://avatars1.githubusercontent.com/u/42088872?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>ChungZH</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/daixiang0\">\n          <img src=\"https://avatars3.githubusercontent.com/u/26538619?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>daixiang0</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/nivance\">\n          <img src=\"https://avatars3.githubusercontent.com/u/3291404?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>nivance</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/hellowHuaairen\">\n          <img src=\"https://avatars2.githubusercontent.com/u/19610305?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>hellowHuaairen</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/521xueweihan/HelloGitHub/blob/master/content/contributors.md\">\n          <img src=\"https://avatars1.githubusercontent.com/u/17665302?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>\u66f4\u591a\u8d21\u732e\u8005</sub>\n        </a><br>\n      </th>\n    </tr>\n  </tbody>\n</table>\n\n\n## \u5408\u4f5c\u7ec4\u7ec7\n\u6b22\u8fce\u5404\u79cd:octocat:\u5f00\u6e90\u7ec4\u7ec7\u5408\u4f5c[\u70b9\u51fb\u8054\u7cfb\u6211](Mailto:595666367@qq.com)\n\n<table>\n  <thead>\n    <tr>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/FGDBTKD\">\n          <img src=\"https://avatars3.githubusercontent.com/u/40509403?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>FGDBTKD</sub><br>\n          <sub>AI/ML/DL/NLP</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/d2-projects\">\n          <img src=\"https://avatars3.githubusercontent.com/u/40857578?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>D2 Projects</sub><br>\n          <sub>Vue/JavaScript</sub>\n        </a><br>\n      </th>\n      <th align=\"center\" style=\"width: 80px;\">\n        <a href=\"https://github.com/doocs\">\n          <img src=\"https://avatars1.githubusercontent.com/u/43716716?s=50&v=4\" style=\"width: 50px;\"><br>\n          <sub>Doocs</sub><br>\n          <sub>Technical Knowledge</sub>\n        </a><br>\n      </th>\n    </tr>\n  </thead>\n</table>\n                    \n## \u58f0\u660e\n<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh\"><img alt=\"\u77e5\u8bc6\u5171\u4eab\u8bb8\u53ef\u534f\u8bae\" style=\"border-width: 0\" src=\"https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png\"></a><br>\u672c\u4f5c\u54c1\u91c7\u7528 <a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh\">\u7f72\u540d-\u975e\u5546\u4e1a\u6027\u4f7f\u7528-\u7981\u6b62\u6f14\u7ece 4.0 \u56fd\u9645</a> \u8fdb\u884c\u8bb8\u53ef\u3002\n\n"}, {"repo": "0xAX/linux-insides", "language": "Python", "readme_contents": "linux-insides\n===============\n\nA book-in-progress about the linux kernel and its insides.\n\n**The goal is simple** - to share my modest knowledge about the insides of the linux kernel and help people who are interested in linux kernel insides, and other low-level subject matter. Feel free to go through the book [Start here](https://github.com/0xAX/linux-insides/blob/master/SUMMARY.md)\n\n**Questions/Suggestions**: Feel free about any questions or suggestions by pinging me at twitter [@0xAX](https://twitter.com/0xAX), adding an [issue](https://github.com/0xAX/linux-insides/issues/new) or just drop me an [email](mailto:anotherworldofworld@gmail.com).\n\n# Mailing List\n\nWe have a Google Group mailing list for learning the kernel source code. Here are some instructions about how to use it.\n\n#### Join\n\nSend an email with any subject/content to `kernelhacking+subscribe@googlegroups.com`. Then you will receive a confirmation email. Reply it with any content and then you are done.\n\n> If you have Google account, you can also open the [archive page](https://groups.google.com/forum/#!forum/kernelhacking) and click **Apply to join group**. You will be approved automatically.\n\n#### Send emails to mailing list\n\nJust send emails to `kernelhacking@googlegroups.com`. The basic usage is the same as other mailing lists powered by mailman.\n\n#### Archives\n\nhttps://groups.google.com/forum/#!forum/kernelhacking\n\nSupport\n-------\n\n**Support** If you like `linux-insides` you can support me with: \n\n[![Support with bitcoin](https://img.shields.io/badge/donate-bitcoin-green.svg)](https://www.coinbase.com/checkouts/0bfa452a41cf52c0b3f99500b4f31685) [![Join the chat at https://gitter.im/0xAX/linux-insides](https://badges.gitter.im/0xAX/linux-insides.svg)](https://gitter.im/0xAX/linux-insides?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nOn other languages\n-------------------\n\n  * [Brazilian Portuguese](https://github.com/mauri870/linux-insides)\n  * [Chinese](https://github.com/MintCN/linux-insides-zh)\n  * [Japanese](https://github.com/tkmru/linux-insides-ja)\n  * [Korean](https://github.com/junsooo/linux-insides-ko)\n  * [Russian](https://github.com/proninyaroslav/linux-insides-ru)\n  * [Spanish](https://github.com/leolas95/linux-insides)\n  * [Turkish](https://github.com/ayyucedemirbas/linux-insides_Turkish)\n\nContributions \n--------------\n\nFeel free to create issues or pull-requests if you have any problems.\n\n**Please read [CONTRIBUTING.md](https://github.com/0xAX/linux-insides/blob/master/CONTRIBUTING.md) before pushing any changes.**\n\n![linux-kernel](Assets/linux-kernel.png)\n\nAuthor\n---------------\n\n[@0xAX](https://twitter.com/0xAX)\n\nLICENSE\n-------------\n\nLicensed [BY-NC-SA Creative Commons](http://creativecommons.org/licenses/by-nc-sa/4.0/).\n"}, {"repo": "ycm-core/YouCompleteMe", "language": "Python", "readme_contents": "YouCompleteMe: a code-completion engine for Vim\n===============================================\n\n[![Gitter room](https://img.shields.io/gitter/room/Valloric/YouCompleteMe.svg)](https://gitter.im/Valloric/YouCompleteMe)\n[![Build status](https://dev.azure.com/YouCompleteMe/YCM/_apis/build/status/ycm-core.YouCompleteMe?branchName=master)](https://dev.azure.com/YouCompleteMe/YCM/_build?definitionId=3&branchName=master)\n[![Coverage status](https://img.shields.io/codecov/c/github/ycm-core/YouCompleteMe/master.svg)](https://codecov.io/gh/ycm-core/YouCompleteMe)\n\nEarly Warning: Dropping support for Python 2 in 2020\n----\n\nIn early 2020, YCM will drop support for Python 2. But we will maintain\ncriticial fixes on a branch (name TBA) of YCM for a period of 1 year.\n\nWhy?\n\nOver the past decade, YouCompleteMe has had an at times fractious, \nbut ultimately very successful relationship with Python 2. However, more\nrecently it has been carrying on a simultaneous relationship with Python 3.\nIndeed all of YCM and ycmd code is Python 3 code, with a lot of gubbins\nto make it work also on Python 2. This makes the code more complex,\nrequires double testing of everything, and restricts the developers from using\ncertain new langauge features, ultimately restricting the features we can\ndeliver to users.\n\nOn 1st January 2020, Python 2 will be officially end of life. And therefore, so\nwill its relationship with YouCompleteMe and ycmd.\n\n\nHelp, Advice, Support\n---------------------\n\nLooking for help, advice or support? Having problems getting YCM to work?\n\nFirst carefully read the [installation instructions](#installation) for your OS.\nWe recommend you use the supplied `install.py`.\n\nNext check the [User Guide](#user-guide) section on the semantic completer that\nyou are using. For C/C++/Objective-C/Objective-C++/CUDA, you  _must_ read [this\nsection](#c-family-semantic-completion).\n\nFinally, check the [FAQ](#faq).\n\nIf, after reading the installation and user guides, and checking the FAQ, you're\nstill having trouble, check the [contacts](#contact) section below for how to\nget in touch.\n\nPlease do **NOT** go to #vim on freenode for support. Please contact the\nYouCompleteMe maintainers directly using the [contact details](#contact) below.\n\nContents\n--------\n\n- [Intro](#intro)\n- [Installation](#installation)\n    - [macOS](#macos)\n    - [Linux 64-bit](#linux-64-bit)\n    - [Windows](#windows)\n    - [FreeBSD/OpenBSD](#freebsdopenbsd)\n    - [Full Installation Guide](#full-installation-guide)\n- [Quick Feature Summary](#quick-feature-summary)\n- [User Guide](#user-guide)\n    - [General Usage](#general-usage)\n    - [Client-Server Architecture](#client-server-architecture)\n    - [Completion String Ranking](#completion-string-ranking)\n    - [General Semantic Completion](#general-semantic-completion)\n    - [C-family Semantic Completion](#c-family-semantic-completion)\n    - [Java Semantic Completion](#java-semantic-completion)\n    - [Python Semantic Completion](#python-semantic-completion)\n    - [Rust Semantic Completion](#rust-semantic-completion)\n    - [Go Semantic Completion](#go-semantic-completion)\n    - [JavaScript and TypeScript Semantic Completion](#javascript-and-typescript-semantic-completion)\n    - [Semantic Completion for Other Languages](#semantic-completion-for-other-languages)\n    - [LSP Configuration](#lsp-configuration)\n    - [Writing New Semantic Completers](#writing-new-semantic-completers)\n    - [Diagnostic Display](#diagnostic-display)\n        - [Diagnostic Highlighting Groups](#diagnostic-highlighting-groups)\n- [Commands](#commands)\n    - [YcmCompleter subcommands](#ycmcompleter-subcommands)\n        - [GoTo Commands](#goto-commands)\n        - [Semantic Information Commands](#semantic-information-commands)\n        - [Refactoring Commands](#refactoring-commands)\n        - [Miscellaneous Commands](#miscellaneous-commands)\n- [Functions](#functions)\n- [Autocommands](#autocommands)\n- [Options](#options)\n- [FAQ](#faq)\n- [Contributor Code of Conduct](#contributor-code-of-conduct)\n- [Contact](#contact)\n- [License](#license)\n\n\nIntro\n-----\n\nYouCompleteMe is a fast, as-you-type, fuzzy-search code completion engine for\n[Vim][]. It has several completion engines:\n\n- an identifier-based engine that works with every programming language,\n- a [Clang][]-based engine that provides native semantic code\n  completion for C/C++/Objective-C/Objective-C++/CUDA (from now on referred to\n  as \"the C-family languages\"),\n- a powerful [clangd][]-based completion engine for the C-family languages.\n- a [Jedi][]-based completion engine for Python 2 and 3,\n- an [OmniSharp-Roslyn][]-based completion engine for C#,\n- a [Gopls][]-based completion engine for Go,\n- a [TSServer][]-based completion engine for JavaScript and TypeScript,\n- a [rls][]-based completion engine for Rust,\n- a [jdt.ls][]-based experimental completion engine for Java.\n- a [generic Language Server Protocol implementation for any language](#plugging-an-arbitrary-lsp-server)\n- and an omnifunc-based completer that uses data from Vim's omnicomplete system\n  to provide semantic completions for many other languages (Ruby, PHP etc.).\n\n![YouCompleteMe GIF demo](http://i.imgur.com/0OP4ood.gif)\n\nHere's an explanation of what happens in the short GIF demo above.\n\nFirst, realize that **no keyboard shortcuts had to be pressed** to get the list\nof completion candidates at any point in the demo. The user just types and the\nsuggestions pop up by themselves. If the user doesn't find the completion\nsuggestions relevant and/or just wants to type, they can do so; the completion\nengine will not interfere.\n\nWhen the user sees a useful completion string being offered, they press the TAB\nkey to accept it. This inserts the completion string. Repeated presses of the\nTAB key cycle through the offered completions.\n\nIf the offered completions are not relevant enough, the user can continue typing\nto further filter out unwanted completions.\n\nA critical thing to notice is that the completion **filtering is NOT based on\nthe input being a string prefix of the completion** (but that works too). The\ninput needs to be a _[subsequence][] match_ of a completion. This is a fancy way\nof saying that any input characters need to be present in a completion string in\nthe order in which they appear in the input. So `abc` is a subsequence of\n`xaybgc`, but not of `xbyxaxxc`. After the filter, a complicated sorting system\nranks the completion strings so that the most relevant ones rise to the top of\nthe menu (so you usually need to press TAB just once).\n\n**All of the above works with any programming language** because of the\nidentifier-based completion engine. It collects all of the identifiers in the\ncurrent file and other files you visit (and your tags files) and searches them\nwhen you type (identifiers are put into per-filetype groups).\n\nThe demo also shows the semantic engine in use. When the user presses `.`, `->`\nor `::` while typing in insert mode (for C++; different triggers are used for\nother languages), the semantic engine is triggered (it can also be triggered\nwith a keyboard shortcut; see the rest of the docs).\n\nThe last thing that you can see in the demo is YCM's diagnostic display features\n(the little red X that shows up in the left gutter; inspired by [Syntastic][])\nif you are editing a C-family file. As the completer engine compiles your file\nand detects warnings or errors, they will be presented in various ways. You\ndon't need to save your file or press any keyboard shortcut to trigger this, it\n\"just happens\" in the background.\n\nIn essence, YCM obsoletes the following Vim plugins because it has all of their\nfeatures plus extra:\n\n- clang_complete\n- AutoComplPop\n- Supertab\n- neocomplcache\n\n**And that's not all...**\n\nYCM also provides [semantic IDE-like features](#quick-feature-summary) in a\nnumber of languages, including:\n\n- displaying signature help (argument hints) when entering the arguments to a\n  function call\n- finding declarations, definitions, usages, etc. of identifiers,\n- displaying type information for classes, variables, functions etc.,\n- displaying documentation for methods, members, etc. in the preview window,\n- fixing common coding errors, like missing semi-colons, typos, etc.,\n- semantic renaming of variables across files,\n- formatting code,\n- removing unused imports, sorting imports, etc.\n\nFor example, here's a demo of signature help:\n\n![Signature Help Early Demo](https://user-images.githubusercontent.com/10584846/58738348-5060da80-83fd-11e9-9537-d07fdbf4554c.gif)\n\nFeatures vary by file type, so make sure to check out the [file type feature\nsummary](#quick-feature-summary) and the\n[full list of completer subcommands](#ycmcompleter-subcommands) to\nfind out what's available for your favourite languages.\n\nYou'll also find that YCM has filepath completers (try typing `./` in a file)\nand a completer that integrates with [UltiSnips][].\n\nInstallation\n------------\n\n### macOS\n\nThese instructions (using `install.py`) are the quickest way to install\nYouCompleteMe, however they may not work for everyone. If the following\ninstructions don't work for you, check out the [full installation\nguide](#full-installation-guide).\n\n[MacVim][] is required. YCM won't work with the pre-installed Vim from Apple as\nits Python support is broken. If you don't already use [MacVim][], install it\nwith [Homebrew][brew]. Install CMake as well:\n\n    brew install cmake macvim\n\nInstall YouCompleteMe with [Vundle][].\n\n**Remember:** YCM is a plugin with a compiled component. If you **update** YCM\nusing Vundle and the ycm_core library APIs have changed (happens\nrarely), YCM will notify you to recompile it. You should then rerun the install\nprocess.\n\n**NOTE:** If you want C-family completion, you MUST have the latest Xcode\ninstalled along with the latest Command Line Tools (they are installed\nautomatically when you run `clang` for the first time, or manually by running\n`xcode-select --install`)\n\nCompiling YCM **with** semantic support for C-family languages through\n**libclang**:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py --clang-completer\n\nCompiling YCM **with** semantic support for C-family languages through\n**clangd**:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py --clangd-completer\n\nNote that you can install YCM with both **libclang** and **clangd** enabled. In\nthat case **clangd** will be preferred unless you have the following in your\n`vimrc`:\n\n```viml\nlet g:ycm_use_clangd = 0\n```\n\nCompiling YCM **without** semantic support for C-family languages:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py\n\nThe following additional language support options are available:\n\n- C# support: install Mono with [Homebrew][brew] or by downloading the [Mono\n  macOS package][mono-install-macos] and add `--cs-completer` when calling\n  `install.py`.\n- Go support: install [Go][go-install] and add `--go-completer` when calling\n  `install.py`.\n- JavaScript and TypeScript support: install [Node.js and npm][npm-install] and\n  add `--ts-completer` when calling `install.py`.\n- Rust support: add `--rust-completer` when calling `install.py`.\n  - If your Python interpreter is older than 2.7.9, you will also need\n    [rustup][] in your `PATH`.\n- Java support: install [JDK8 (version 8 required)][jdk-install] and add\n  `--java-completer` when calling `install.py`.\n\nTo simply compile with everything enabled, there's a `--all` flag. Note that\nthis flag does **not** install **clangd**. You need to specify it manually by\nadding `--clangd-completer`. So, to install with all language features, ensure\n`xbuild`, `go`, `tsserver`, `node` and `npm` tools are\ninstalled and in your `PATH`, then simply run:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py --all\n\nThat's it. You're done. Refer to the _User Guide_ section on how to use YCM.\nDon't forget that if you want the C-family semantic completion engine to work,\nyou will need to provide the compilation flags for your project to YCM. It's all\nin the User Guide.\n\nYCM comes with sane defaults for its options, but you still may want to take a\nlook at what's available for configuration. There are a few interesting options\nthat are conservatively turned off by default that you may want to turn on.\n\n### Linux 64-bit\n\nThese instructions (using `install.py`) are the quickest way to install\nYouCompleteMe, however they may not work for everyone. If the following\ninstructions don't work for you, check out the [full installation\nguide](#full-installation-guide).\n\nMake sure you have Vim 7.4.1578 with Python 2 or Python 3 support. The Vim\npackage on Fedora 27 and later and the pre-installed Vim on Ubuntu 16.04 and\nlater are recent enough. You can see the version of Vim installed by running\n`vim --version`. If the version is too old, you may need to [compile Vim from\nsource][vim-build] (don't worry, it's easy).\n\n**NOTE**: For all features, such as signature help, use Vim 8.1.1875 or later.\n\nInstall YouCompleteMe with [Vundle][].\n\n**Remember:** YCM is a plugin with a compiled component. If you **update** YCM\nusing Vundle and the ycm_core library APIs have changed (happens rarely), YCM\nwill notify you to recompile it. You should then rerun the install process.\n\nInstall development tools, CMake, and Python headers:\n\n- Fedora 27 and later:\n\n      sudo dnf install cmake gcc-c++ make python3-devel\n\n- Ubuntu 14.04:\n\n      sudo apt install build-essential cmake3 python3-dev\n\n- Ubuntu 16.04 and later:\n\n      sudo apt install build-essential cmake python3-dev\n\nCompiling YCM **with** semantic support for C-family languages through\n**libclang**:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    python3 install.py --clang-completer\n\nCompiling YCM **with** semantic support for C-family languages through\n**clangd**:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    python3 install.py --clangd-completer\n\nNote that you can install YCM with both **libclang** and **clangd** enabled. In\nthat case **clangd** will be preferred unless you have the following in your\n`vimrc`:\n\n```viml\nlet g:ycm_use_clangd = 0\n```\n\nCompiling YCM **without** semantic support for C-family languages:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    python3 install.py\n\nThe following additional language support options are available:\n\n- C# support: install [Mono][mono-install-linux] and add `--cs-completer`\n  when calling `install.py`.\n- Go support: install [Go][go-install] and add `--go-completer` when calling\n  `install.py`.\n- JavaScript and TypeScript support: install [Node.js and npm][npm-install] and\n  add `--ts-completer` when calling `install.py`.\n- Rust support: add `--rust-completer` when calling `install.py`.\n  - If your Python interpreter is older than 2.7.9, you will also need\n    [rustup][] in your `PATH`.\n- Java support: install [JDK8 (version 8 required)][jdk-install] and add\n  `--java-completer` when calling `install.py`.\n\nTo simply compile with everything enabled, there's a `--all` flag. Note that\nthis flag does **not** install **clangd**. You need to specify it manually by\nadding `--clangd-completer`. So, to install with all language features, ensure\n`xbuild`, `go`, `tsserver`, `node`, `npm` and tools are\ninstalled and in your `PATH`, then simply run:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    python3 install.py --all\n\nThat's it. You're done. Refer to the _User Guide_ section on how to use YCM.\nDon't forget that if you want the C-family semantic completion engine to work,\nyou will need to provide the compilation flags for your project to YCM. It's all\nin the User Guide.\n\nYCM comes with sane defaults for its options, but you still may want to take a\nlook at what's available for configuration. There are a few interesting options\nthat are conservatively turned off by default that you may want to turn on.\n\n### Windows\n\nThese instructions (using `install.py`) are the quickest way to install\nYouCompleteMe, however they may not work for everyone. If the following\ninstructions don't work for you, check out the [full installation\nguide](#full-installation-guide).\n\n**Important:** we assume that you are using the `cmd.exe` command prompt and\nthat you know how to add an executable to the PATH environment variable.\n\nMake sure you have at least Vim 7.4.1578 with Python 2 or Python 3 support. You\ncan check the version and which Python is supported by typing `:version` inside\nVim. Look at the features included: `+python/dyn` for Python 2 and\n`+python3/dyn` for Python 3. Take note of the Vim architecture, i.e. 32 or\n64-bit. It will be important when choosing the Python installer. We recommend\nusing a 64-bit client. [Daily updated installers of 32-bit and 64-bit Vim with\nPython 2 and Python 3 support][vim-win-download] are available.\n\n**NOTE**: For all features, such as signature help, use Vim 8.1.1875 or later.\n\nAdd the line:\n\n    set encoding=utf-8\n\nto your [vimrc][] if not already present. This option is required by YCM. Note\nthat it does not prevent you from editing a file in another encoding than UTF-8.\nYou can do that by specifying [the `++enc` argument][++enc] to the `:e` command.\n\nInstall YouCompleteMe with [Vundle][].\n\n**Remember:** YCM is a plugin with a compiled component. If you **update** YCM\nusing Vundle and the ycm_core library APIs have changed (happens\nrarely), YCM will notify you to recompile it. You should then rerun the install\nprocess.\n\nDownload and install the following software:\n\n- [Python 2 or Python 3][python-win-download]. Be sure to pick the version\n  corresponding to your Vim architecture. It is _Windows x86_ for a 32-bit Vim\n  and _Windows x86-64_ for a 64-bit Vim. We recommend installing Python 3.\n  Additionally, the version of Python you install must match up exactly with\n  the version of Python that Vim is looking for. Type `:version` and look at the\n  bottom of the page at the list of compiler flags. Look for flags that look\n  similar to `-DDYNAMIC_PYTHON_DLL=\\\"python27.dll\\\"` and\n  `-DDYNAMIC_PYTHON3_DLL=\\\"python35.dll\\\"`. The former indicates that Vim is\n  looking for Python 2.7 and the latter indicates that Vim is looking for\n  Python 3.5. You'll need one or the other installed, matching the version\n  number exactly.\n- [CMake][cmake-download]. Add CMake executable to the PATH environment\n  variable.\n- [Visual Studio Build Tools 2017][visual-studio-download]. During setup,\n  select _Visual C++ build tools_ in _Workloads_.\n\nCompiling YCM **with** semantic support for C-family languages through\n**libclang**:\n\n    cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe\n    python install.py --clang-completer\n\nCompiling YCM **with** semantic support for C-family languages through\n**clangd**:\n\n    cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe\n    python install.py --clangd-completer\n\nNote that you can install YCM with both **libclang** and **clangd** enabled. In\nthat case **clangd** will be preferred unless you have the following in your\n`vimrc`:\n\n```viml\nlet g:ycm_use_clangd = 0\n```\n\nCompiling YCM **without** semantic support for C-family languages:\n\n    cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe\n    python install.py\n\nThe following additional language support options are available:\n\n- C# support: add `--cs-completer` when calling `install.py`.\n  Be sure that [the build utility `msbuild` is in your PATH][add-msbuild-to-path].\n- Go support: install [Go][go-install] and add `--go-completer` when calling\n  `install.py`.\n- JavaScript and TypeScript support: install [Node.js and npm][npm-install] and\n  add `--ts-completer` when calling `install.py`.\n- Rust support: add `--rust-completer` when calling `install.py`.\n  - If your Python interpreter is older than 2.7.9, you will also need\n    [rustup][] in your `PATH`.\n- Java support: install [JDK8 (version 8 required)][jdk-install] and add\n  `--java-completer` when calling `install.py`.\n\nTo simply compile with everything enabled, there's a `--all` flag. Note that\nthis flag does **not** install **clangd**. You need to specify it manually by\nadding `--clangd-completer`. So, to install with all language features, ensure\n`msbuild`, `go`, `tsserver`, `node` and `npm` tools are installed and\nin your `PATH`, then simply run:\n\n    cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe\n    python install.py --all\n\nYou can specify the Microsoft Visual C++ (MSVC) version using the `--msvc`\noption. YCM officially supports MSVC 14 (Visual Studio 2015) and 15 (2017).\n\nThat's it. You're done. Refer to the _User Guide_ section on how to use YCM.\nDon't forget that if you want the C-family semantic completion engine to work,\nyou will need to provide the compilation flags for your project to YCM. It's all\nin the User Guide.\n\nYCM comes with sane defaults for its options, but you still may want to take a\nlook at what's available for configuration. There are a few interesting options\nthat are conservatively turned off by default that you may want to turn on.\n\n### FreeBSD/OpenBSD\n\nThese instructions (using `install.py`) are the quickest way to install\nYouCompleteMe, however they may not work for everyone. If the following\ninstructions don't work for you, check out the [full installation\nguide](#full-installation-guide).\n\n**NOTE:** OpenBSD / FreeBSD are not officially supported platforms by YCM.\n\nMake sure you have Vim 7.4.1578 with Python 2 or Python 3 support.\n\n**NOTE**: For all features, such as signature help, use Vim 8.1.1875 or later.\n\nOpenBSD 5.5 and later have a Vim that's recent enough. You can see the version of\nVim installed by running `vim --version`.\n\nFor FreeBSD 11.x, the requirement is cmake:\n\n    pkg install cmake\n\nInstall YouCompleteMe with [Vundle][].\n\n**Remember:** YCM is a plugin with a compiled component. If you **update** YCM\nusing Vundle and the ycm_core library APIs have changed (happens\nrarely), YCM will notify you to recompile it. You should then rerun the install\nprocess.\n\nCompiling YCM **with** semantic support for C-family languages through\n**libclang**:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py --clang-completer\n\nCompiling YCM **with** semantic support for C-family languages through\n**clangd**:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py --clangd-completer\n\nNote that you can install YCM with both **libclang** and **clangd** enabled. In\nthat case **clangd** will be preferred unless you have the following in your\n`vimrc`:\n\n```viml\nlet g:ycm_use_clangd = 0\n```\n\nCompiling YCM **without** semantic support for C-family languages:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py\n\nIf the `python` executable is not present, or the default `python` is not the\none that should be compiled against, specify the python interpreter explicitly:\n\n    python3 install.py --clang-completer\n\nThe following additional language support options are available:\n\n- C# support: install Mono and add `--cs-completer` when calling\n  `./install.py`.\n- Go support: install [Go][go-install] and add `--go-completer` when calling\n  `./install.py`.\n- JavaScript and TypeScript support: install [Node.js and npm][npm-install] and\n  add `--ts-completer` when calling `install.py`.\n- Rust support: add `--rust-completer` when calling `./install.py`.\n  - If your Python interpreter is older than 2.7.9, you will also need\n    [rustup][] in your `PATH`.\n- Java support: install [JDK8 (version 8 required)][jdk-install] and add\n  `--java-completer` when calling `./install.py`.\n\nTo simply compile with everything enabled, there's a `--all` flag. Note that\nthis flag does **not** install **clangd**. You need to specify it manually by\nadding `--clangd-completer`. So, to install with all language features, ensure\n`xbuild`, `go`, `tsserver`, `node`, `npm` and tools are\ninstalled and in your `PATH`, then simply run:\n\n    cd ~/.vim/bundle/YouCompleteMe\n    ./install.py --all\n\nThat's it. You're done. Refer to the _User Guide_ section on how to use YCM.\nDon't forget that if you want the C-family semantic completion engine to work,\nyou will need to provide the compilation flags for your project to YCM. It's all\nin the User Guide.\n\nYCM comes with sane defaults for its options, but you still may want to take a\nlook at what's available for configuration. There are a few interesting options\nthat are conservatively turned off by default that you may want to turn on.\n\n### Full Installation Guide\n\nThese are the steps necessary to get YCM working on a Unix OS and on Windows.\n\n**Note to Windows users:** we assume that you are running the `cmd.exe` command\nprompt and that the needed executables are in the PATH environment variable. Do\nnot just copy the shell commands. Replace `~` by `%USERPROFILE%` in them and use\nthe right Vim home directory. It should be `vimfiles` by default instead of\n`.vim`.\n\nSee the _FAQ_ if you have any issues.\n\n**Remember:** YCM is a plugin with a compiled component. If you **update** YCM\nusing Vundle and the ycm_core library APIs have changed (happens\nrarely), YCM will notify you to recompile it. You should then rerun the install\nprocess.\n\n**Please follow the instructions carefully. Read EVERY WORD.**\n\n1.  **Ensure that your version of Vim is _at least_ 7.4.1578 _and_ that it has\n    support for Python 2 or Python 3 scripting**.\n\n    Inside Vim, type `:version`. Look at the first two to three lines of output;\n    it should say `Vi IMproved X.Y`, where X.Y is the major version of vim. If\n    your version is greater than 7.4, then you're all set. If your version is\n    7.4 then look below that where it says, `Included patches: 1-Z`, where Z\n    will be some number. That number needs to be 1578 or higher.\n\n    If your version of Vim is not recent enough, you may need to [compile Vim\n    from source][vim-build] (don't worry, it's easy).\n\n    After you have made sure that you have Vim 7.4.1578+, type the following in\n    Vim: `:echo has('python') || has('python3')`. The output should be 1. If\n    it's 0, then get a version of Vim with Python support.\n\n    **NOTE**: For all features, such as signature help, use Vim 8.1.1875 or\n    later.\n\n    On Windows, check also if your Vim architecture is 32 or 64-bit. This is\n    critical because it must match the Python and the YCM libraries\n    architectures. We recommend using a 64-bit Vim.\n\n2.  **Install YCM** with [Vundle][] (or [Pathogen][], but Vundle is a better\n    idea). With Vundle, this would mean adding a `Plugin\n    'Valloric/YouCompleteMe'` line to your [vimrc][].\n\n    If you don't install YCM with Vundle, make sure you have run\n    `git submodule update --init --recursive` after checking out the YCM\n    repository (Vundle will do this for you) to fetch YCM's dependencies.\n\n3.  *Complete this step ONLY if you care about semantic completion support for\n    C-family languages. Otherwise it's not necessary.*\n\n    **Download the latest version of `libclang`**. Clang is an open-source\n    compiler that can compile C-family languages. The `libclang` library it\n    provides is used to power the YCM semantic completion engine for those\n    languages. YCM is designed to work with libclang version 9.0.0 or higher.\n\n    In addition to `libclang`, YCM also supports a [clangd][]-based completer.\n    You can download the latest version of [clangd][] from [llvm.org\n    releases][clang-download]. Follow Step 4 to learn how to tell YCM where to\n    find clangd binary. Please note that YCM is designed to work with [clangd][]\n    version 9.0.0 or higher.\n\n    You can use the system libclang or clangd _only if you are sure it is\n    version 9.0.0 or higher_, otherwise don't. Even if it is, we recommend using\n    the [official binaries from llvm.org][clang-download] if at all possible.\n    Make sure you download the correct archive file for your OS.\n\n    We **STRONGLY recommend AGAINST use** of the system libclang or clangd\n    instead of the upstream compiled binaries. Random things may break. Save\n    yourself the hassle and use the upstream pre-built libclang or clangd.\n\n4.  **Compile the `ycm_core` library** that YCM needs. This library\n    is the C++ engine that YCM uses to get fast completions.\n\n    You will need to have `cmake` installed in order to generate the required\n    makefiles. Linux users can install cmake with their package manager (`sudo\n    apt-get install cmake` for Ubuntu) whereas other users can [download and\n    install][cmake-download] cmake from its project site. macOS users can also\n    get it through [Homebrew][brew] with `brew install cmake`.\n\n    On a Unix OS, you need to make sure you have Python headers installed. On a\n    Debian-like Linux distro, this would be `sudo apt-get install python-dev\n    python3-dev`. On macOS they should already be present.\n\n    On Windows, you need to download and install [Python 2 or\n    Python 3][python-win-download]. Pick the version corresponding to your Vim\n    architecture. You will also need Microsoft Visual C++ (MSVC) to build YCM.\n    You can obtain it by installing [Visual Studio Build\n    Tools][visual-studio-download]. MSVC 14 (Visual Studio 2015) and 15 (2017)\n    are officially supported.\n\n    Here we'll assume you installed YCM with Vundle. That means that the\n    top-level YCM directory is in `~/.vim/bundle/YouCompleteMe`.\n\n    We'll create a new folder where build files will be placed. Run the\n    following:\n\n        cd ~\n        mkdir ycm_build\n        cd ycm_build\n\n    Now we need to generate the makefiles. If you DON'T care about semantic\n    support for C-family languages or plan to use **experimental** [clangd][]\n    based completer, run the following command in the `ycm_build` directory:\n\n        cmake -G \"<generator>\" . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp\n\n    where `<generator>` is `Unix Makefiles` on Unix systems and one of the\n    following Visual Studio generators on Windows:\n\n    - `Visual Studio 14 Win64`\n    - `Visual Studio 15 Win64`\n\n    Remove the `Win64` part in these generators if your Vim architecture is\n    32-bit.\n\n    For those who want to use the system version of boost, you would pass\n    `-DUSE_SYSTEM_BOOST=ON` to cmake. This may be necessary on some systems\n    where the bundled version of boost doesn't compile out of the box.\n\n    **NOTE:** We **STRONGLY recommend AGAINST use** of the system boost instead\n    of the bundled version of boost. Random things may break. Save yourself\n    the hassle and use the bundled version of boost.\n\n    If you DO care about semantic support for C-family languages, and want to\n    use libclang as the provider instead of **experimental** [clangd][]-based\n    completer then your `cmake` call will be a bit more complicated. We'll\n    assume you downloaded a binary distribution of LLVM+Clang from llvm.org in\n    step 3 and that you extracted the archive file to folder\n    `~/ycm_temp/llvm_root_dir` (with `bin`, `lib`, `include` etc. folders right\n    inside that folder). On Windows, you can extract the files from the\n    LLVM+Clang installer using [7-zip][7z-download].\n\n    **NOTE:** This _only_ works with a _downloaded_ LLVM binary package, not a\n    custom-built LLVM! See docs below for `EXTERNAL_LIBCLANG_PATH` when using a\n    custom LLVM build.\n\n    With that in mind, run the following command in the `ycm_build` directory:\n\n        cmake -G \"<generator>\" -DPATH_TO_LLVM_ROOT=~/ycm_temp/llvm_root_dir . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp\n\n    where `<generator>` is replaced like above.\n\n    Now that configuration files have been generated, compile the libraries\n    using this command:\n\n        cmake --build . --target ycm_core --config Release\n\n    The `--config Release` part is specific to Windows and will be ignored on a\n    Unix OS.\n\n    For those who want to use the system version of libclang, you would pass\n    `-DUSE_SYSTEM_LIBCLANG=ON` to cmake _instead of_ the\n    `-DPATH_TO_LLVM_ROOT=...` flag.\n\n    **NOTE:** We **STRONGLY recommend AGAINST use** of the system libclang instead\n    of the upstream compiled binaries. Random things may break. Save yourself\n    the hassle and use the upstream pre-built libclang.\n\n    You could also force the use of a custom libclang library with\n    `-DEXTERNAL_LIBCLANG_PATH=/path/to/libclang.so` flag (the library would end\n    with `.dylib` on macOS). Again, this flag would be used _instead of_ the\n    other flags. **If you compiled LLVM from source, this is the flag you should\n    be using.**\n\n    Running the `cmake` command will also place the `libclang.[so|dylib|dll]` in\n    the `YouCompleteMe/third_party/ycmd` folder for you if you compiled with\n    clang support (it needs to be there for YCM to work).\n\n    If you DO care about semantic support for C-family languages, and want to\n    use **experimental** [clangd][]-based completer then you need to add\n    following line to your `vimrc`:\n    ```viml\n    let g:ycm_clangd_binary_path = \"/path/to/clangd\"\n    ```\n    You need to change `/path/to/clangd` with the path of binary you downloaded\n    in step 3.\n\n5.  *This step is optional.*\n\n    Build the [regex][] module for improved Unicode support and better\n    performance with regular expressions. The procedure is similar to compiling\n    the `ycm_core` library:\n\n        cd ~\n        mkdir regex_build\n        cd regex_build\n        cmake -G \"<generator>\" . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/third_party/cregex\n        cmake --build . --target _regex --config Release\n\n    where `<generator>` is the same generator used in the previous step.\n\n6.  Set up support for additional languages, as desired:\n\n    - C# support: install [Mono on non-Windows platforms][mono-install].\n      Navigate to `YouCompleteMe/third_party/ycmd/third_party/omnisharp-roslyn`.\n      Download an [Omnisharp-Roslyn release archive][roslyn-releases] and\n      extract the archive to\n      `YouCompleteMe/third_party/ycmd/third_party/omnisharp-roslyn`.\n\n      On Windows, be sure that [the build utility `msbuild` is in your\n      PATH][add-msbuild-to-path].\n\n    - Go support: install [Go][go-install] and add it to your path. Navigate to\n      `YouCompleteMe/third_party/ycmd/third_party/go/src/golang.org/x/tools/cmd/gopls`\n       and run\n\n          go build\n\n    - JavaScript and TypeScript support: install [Node.js and npm][npm-install],\n      navigate to `YouCompleteMe/third_party/ycmd` and run\n      `npm install -g --prefix third_party/tsserver typescript`.\n\n    - Rust support: install [rustup][]. Export `RUSTUP_HOME` environment\n      variable and point it to an empty temporary directory.\n      Run the following commands:\n\n          rustup toolchain install nightly\n          rustup default nightly\n          rustup component add rls rust-analysis rust-src\n\n      Ensure that `YouCompleteMe/third_party/ycmd/third_party/rls` directory\n      exists and is empty. Go into the temporary directory and then into\n      `toolchains/<toolchain>`. Finally, move everything from that directory to\n      `YouCompleteMe/third_party/ycmd/third_party/rls`.\n\n    - Java support: install [JDK8 (version 8 required)][jdk-install]. Download a\n      [binary release of eclipse.jdt.ls][jdtls-release] and extract it to\n      `YouCompleteMe/third_party/ycmd/third_party/eclipse.jdt.ls/target/repository`.\n      Note: this approach is not recommended for most users and is supported\n      only for advanced users and developers of YCM on a best-efforts basis.\n      Please use `install.py` to enable java support.\n\nThat's it. You're done. Refer to the _User Guide_ section on how to use YCM.\nDon't forget that if you want the C-family semantic completion engine to work,\nyou will need to provide the compilation flags for your project to YCM. It's all\nin the User Guide.\n\nYCM comes with sane defaults for its options, but you still may want to take a\nlook at what's available for configuration. There are a few interesting options\nthat are conservatively turned off by default that you may want to turn on.\n\nQuick Feature Summary\n-----\n\n### General (all languages)\n\n* Super-fast identifier completer including tags files and syntax elements\n* Intelligent suggestion ranking and filtering\n* File and path suggestions\n* Suggestions from Vim's OmniFunc\n* UltiSnips snippet suggestions\n\n### C-family languages (C, C++, Objective C, Objective C++, CUDA)\n\n* Semantic auto-completion with automatic fixes\n* Signature help (when [using clangd](#selecting-a-c-family-completion-engine))\n* Real-time diagnostic display\n* Go to include/declaration/definition (`GoTo`, etc.)\n* View documentation comments for identifiers (`GetDoc`)\n* Type information for identifiers (`GetType`)\n* Automatically fix certain errors (`FixIt`)\n* Reference finding (`GoToReferences`)\n* Renaming symbols (`RefactorRename <new name>`)\n* Code formatting (`Format`)\n\n### C\u266f\n\n* Semantic auto-completion\n* Real-time diagnostic display\n* Go to declaration/definition (`GoTo`, etc.)\n* Go to implementation (`GoToImplementation`)\n* View documentation comments for identifiers (`GetDoc`)\n* Type information for identifiers (`GetType`)\n* Automatically fix certain errors (`FixIt`)\n* Management of OmniSharp-Roslyn server instance\n\n### Python\n\n* Semantic auto-completion\n* Signature help\n* Go to definition (`GoTo`)\n* Reference finding (`GoToReferences`)\n* View documentation comments for identifiers (`GetDoc`)\n* Type information for identifiers (`GetType`)\n\n### Go\n\n* Semantic auto-completion\n* Signature help\n* Real-time diagnostic display\n* Go to declaration/definition (`GoTo`, etc.)\n* Go to type definition (`GoToType`)\n* Automatically fix certain errors (`FixIt`)\n* View documentation comments for identifiers (`GetDoc`)\n* Type information for identifiers (`GetType`)\n* Code formatting (`Format`)\n* Management of `gopls` server instance\n\n### JavaScript and TypeScript\n\n* Semantic auto-completion with automatic import insertion\n* Signature help\n* Real-time diagnostic display\n* Go to definition (`GoTo`, `GoToDefinition`, and `GoToDeclaration` are\n  identical)\n* Go to type definition (`GoToType`)\n* Reference finding (`GoToReferences`)\n* View documentation comments for identifiers (`GetDoc`)\n* Type information for identifiers (`GetType`)\n* Automatically fix certain errors (`FixIt`)\n* Renaming symbols (`RefactorRename <new name>`)\n* Code formatting (`Format`)\n* Organize imports (`OrganizeImports`)\n* Management of `TSServer` server instance\n\n### Rust\n\n* Semantic auto-completion\n* Real-time diagnostic display\n* Go to declaration/definition (`GoTo`, etc.)\n* Go to implementation (`GoToImplementation`)\n* Reference finding (`GoToReferences`)\n* View documentation comments for identifiers (`GetDoc`)\n* Automatically fix certain errors (`FixIt`)\n* Type information for identifiers (`GetType`)\n* Renaming symbols (`RefactorRename <new name>`)\n* Code formatting (`Format`)\n* Execute custom server command (`ExecuteCommand <args>`)\n* Management of `rls` server instance\n\n### Java\n\n* Semantic auto-completion with automatic import insertion\n* Signature help\n* Real-time diagnostic display\n* Go to definition (`GoTo`, `GoToDefinition`, and `GoToDeclaration` are\n  identical)\n* Go to type definition (`GoToType`)\n* Go to implementation (`GoToImplementation`)\n* Reference finding (`GoToReferences`)\n* View documentation comments for identifiers (`GetDoc`)\n* Type information for identifiers (`GetType`)\n* Automatically fix certain errors including code generation (`FixIt`)\n* Renaming symbols (`RefactorRename <new name>`)\n* Code formatting (`Format`)\n* Organize imports (`OrganizeImports`)\n* Detection of java projects\n* Execute custom server command (`ExecuteCommand <args>`)\n* Management of `jdt.ls` server instance\n\nUser Guide\n----------\n\n### General Usage\n\nIf the offered completions are too broad, keep typing characters; YCM will\ncontinue refining the offered completions based on your input.\n\nFiltering is \"smart-case\" and \"smart-[diacritic][]\" sensitive; if you are\ntyping only lowercase letters, then it's case-insensitive. If your input\ncontains uppercase letters, then the uppercase letters in your query must\nmatch uppercase letters in the completion strings (the lowercase letters still\nmatch both). On top of that, a letter with no diacritic marks will match that\nletter with or without marks:\n\n<table>\n<tbody>\n<tr>\n  <th>matches</th>\n  <th>foo</th>\n  <th>f\u00f4o</th>\n  <th>fOo</th>\n  <th>f\u00d4o</th>\n</tr>\n<tr>\n  <th>foo</th>\n  <td>\u2714\ufe0f</td>\n  <td>\u2714\ufe0f</td>\n  <td>\u2714\ufe0f</td>\n  <td>\u2714\ufe0f</td>\n</tr>\n<tr>\n  <th>f\u00f4o</th>\n  <td>\u274c</td>\n  <td>\u2714\ufe0f</td>\n  <td>\u274c</td>\n  <td>\u2714\ufe0f</td>\n</tr>\n<tr>\n  <th>fOo</th>\n  <td>\u274c</td>\n  <td>\u274c</td>\n  <td>\u2714\ufe0f</td>\n  <td>\u2714\ufe0f</td>\n</tr>\n<tr>\n  <th>f\u00d4o</th>\n  <td>\u274c</td>\n  <td>\u274c</td>\n  <td>\u274c</td>\n  <td>\u2714\ufe0f</td>\n</tr>\n</tbody>\n</table>\n\nUse the TAB key to accept a completion and continue pressing TAB to cycle\nthrough the completions. Use Shift-TAB to cycle backwards. Note that if you're\nusing console Vim (that is, not Gvim or MacVim) then it's likely that the\nShift-TAB binding will not work because the console will not pass it to Vim.\nYou can remap the keys; see the [Options](#options) section below.\n\nKnowing a little bit about how YCM works internally will prevent confusion. YCM\nhas several completion engines: an identifier-based completer that collects all\nof the identifiers in the current file and other files you visit (and your tags\nfiles) and searches them when you type (identifiers are put into per-filetype\ngroups).\n\nThere are also several semantic engines in YCM. There are libclang-based and\nclangd-based completers that provide semantic completion for C-family languages.\nThere's a Jedi-based completer for semantic completion for Python. There's also\nan omnifunc-based completer that uses data from Vim's omnicomplete system to\nprovide semantic completions when no native completer exists for that language\nin YCM.\n\nThere are also other completion engines, like the UltiSnips completer and the\nfilepath completer.\n\nYCM automatically detects which completion engine would be the best in any\nsituation. On occasion, it queries several of them at once, merges the\noutputs and presents the results to you.\n\n### Client-Server Architecture\n\nYCM has a client-server architecture; the Vim part of YCM is only a thin client\nthat talks to the [ycmd HTTP+JSON server][ycmd] that has the vast majority of\nYCM logic and functionality. The server is started and stopped automatically as\nyou start and stop Vim.\n\n### Completion String Ranking\n\nThe subsequence filter removes any completions that do not match the input, but\nthen the sorting system kicks in. It's actually very complicated and uses lots\nof factors, but suffice it to say that \"word boundary\" (WB) subsequence\ncharacter matches are \"worth\" more than non-WB matches. In effect, this means\ngiven an input of \"gua\", the completion \"getUserAccount\" would be ranked higher\nin the list than the \"Fooguxa\" completion (both of which are subsequence\nmatches). A word-boundary character are all capital characters, characters\npreceded by an underscore and the first letter character in the completion\nstring.\n\n### Signature Help\n\nSignature help is an **experimental** feature for which we value your feedback.\nValid signatures are displayed in a second popup menu and the current signature\nis highlighed along with the current arguemnt.\n\nSignature help is triggered in insert mode automatically when\n`g:ycm_auto_trigger` is enabled and is not supported when it is not enabled.\n\nThe signatures popup is hidden when there are no matching signatures or when you\nleave insert mode. There is no key binding to clear the popup.\n\nFor more details on this feature and a few demos, check out the\n[PR that proposed it][signature-help-pr].\n\n### General Semantic Completion\n\nYou can use Ctrl+Space to trigger the completion suggestions anywhere, even\nwithout a string prefix. This is useful to see which top-level functions are\navailable for use.\n\n### C-family Semantic Completion\n\nIn order to perform semantic analysis such as code completion, `GoTo` and\ndiagnostics, YouCompleteMe uses `libclang` or `clangd`. Both of them make use of\nclang compiler, sometimes also referred to as llvm. Like any compiler,\nclang also requires a set of compile flags in order to parse your code. Simply\nput: If clang can't parse your code, YouCompleteMe can't provide semantic\nanalysis.\n\nThere are 2 methods which can be used to provide compile flags to clang:\n\n#### Option 1: Use a [compilation database][compdb]\n\nThe easiest way to get YCM to compile your code is to use a compilation\ndatabase.  A compilation database is usually generated by your build system\n(e.g. `CMake`) and contains the compiler invocation for each compilation unit in\nyour project.\n\nFor information on how to generate a compilation database, see the [clang\ndocumentation][compdb]. In short:\n\n- If using CMake, add `-DCMAKE_EXPORT_COMPILE_COMMANDS=ON` when configuring (or\n  add `set( CMAKE_EXPORT_COMPILE_COMMANDS ON )` to `CMakeLists.txt`) and copy or\n  symlink the generated database to the root of your project.\n- If using Ninja, check out the `compdb` tool (`-t compdb`) in its\n  [docs][ninja-compdb].\n- If using GNU make, check out [compiledb][] or [Bear][].\n- For other build systems, check out\n  [`.ycm_extra_conf.py`](#option-2-provide-the-flags-manually) below.\n\nIf no [`.ycm_extra_conf.py`](#option-2-provide-the-flags-manually) is found,\nYouCompleteMe automatically tries to load a compilation database if there is\none.\n\nYCM looks for a file named `compile_commands.json` in the directory of the\nopened file or in any directory above it in the hierarchy (recursively); when\nthe file is found, it is loaded.  YouCompleteMe performs the following lookups\nwhen extracting flags for a particular file:\n\n- If the database contains an entry for the file, the flags for that file are\n  used.\n- If the file is a header file and a source file with the same root exists in\n  the database, the flags for the source file are used. For example, if the file\n  is `/home/Test/project/src/lib/something.h` and the database contains an entry\n  for `/home/Test/project/src/lib/something.cc`, then the flags for\n  `/home/Test/project/src/lib/something.cc` are used.\n- Otherwise, if any flags have been returned from the directory containing the\n  requested file, those flags are used. This heuristic is intended to provide\n  potentially working flags for newly created files.\n\nFinally, YCM converts any relative paths in the extracted flags to absolute\npaths. This ensures that compilation can be performed from any Vim working\ndirectory.\n\n#### Option 2: Provide the flags manually\n\nIf you don't have a compilation database, or aren't able to generate one,\nyou have to tell YouCompleteMe how to compile your code some other way.\n\nEvery C-family project is different. It is not possible for YCM to guess what\ncompiler flags to supply for your project. Fortunately, YCM provides a mechanism\nfor you to generate the flags for a particular file with _arbitrary complexity_.\nThis is achieved by requiring you to provide a Python module which implements a\ntrivial function which, given the file name as argument, returns a list of\ncompiler flags to use to compile that file.\n\nYCM looks for a `.ycm_extra_conf.py` file in the directory of the opened file or\nin any directory above it in the hierarchy (recursively); when the file is\nfound, it is loaded (only once!) as a Python module. YCM calls a `Settings`\nmethod in that module which should provide it with the information necessary to\ncompile the current file. You can also provide a path to a global configuration\nfile with the\n[`g:ycm_global_ycm_extra_conf`](#the-gycm_global_ycm_extra_conf-option) option,\nwhich will be used as a fallback. To prevent the execution of malicious code\nfrom a file you didn't write YCM will ask you once per `.ycm_extra_conf.py` if\nit is safe to load. This can be disabled and you can white-/blacklist files. See\nthe [`g:ycm_confirm_extra_conf`](#the-gycm_confirm_extra_conf-option) and\n[`g:ycm_extra_conf_globlist`](#the-gycm_extra_conf_globlist-option) options\nrespectively.\n\nThis system was designed this way so that the user can perform any arbitrary\nsequence of operations to produce a list of compilation flags YCM should hand\nto Clang.\n\n**NOTE**: It is highly recommended to include `-x <language>` flag to libclang.\nThis is so that the correct language is detected, particularly for header files.\nCommon values are `-x c` for C, `-x c++` for C++, `-x objc` for Objective-C, and\n`-x cuda` for CUDA.\n\nTo give you an impression, if your C++ project is trivial, and your usual\ncompilation command is: `g++ -Wall -Wextra -Werror -o FILE.o FILE.cc`, then the\nfollowing `.ycm_extra_conf.py` is enough to get semantic analysis from\nYouCompleteMe:\n\n```python\ndef Settings( **kwargs ):\n  return {\n    'flags': [ '-x', 'c++', '-Wall', '-Wextra', '-Werror' ],\n  }\n```\n\nAs you can see from the trivial example, YCM calls the `Settings` method which\nreturns a dictionary with a single element `'flags'`. This element is a `list`\nof compiler flags to pass to libclang for the current file. The absolute path of\nthat file is accessible under the `filename` key of the `kwargs` dictionary.\nThat's it! This is actually enough for most projects, but for complex projects\nit is not uncommon to integrate directly with an existing build system using the\nfull power of the Python language.\n\nFor a more elaborate example,\n[see ycmd's own `.ycm_extra_conf.py`][ycmd_flags_example]. You should be able to\nuse it _as a starting point_. **Don't** just copy/paste that file somewhere and\nexpect things to magically work; **your project needs different flags**. Hint:\njust replace the strings in the `flags` variable with compilation flags\nnecessary for your project. That should be enough for 99% of projects.\n\nYou could also consider using [YCM-Generator][ygen] to generate the\n`ycm_extra_conf.py` file.\n\n#### Errors during compilation\n\nIf Clang encounters errors when compiling the header files that your file\nincludes, then it's probably going to take a long time to get completions.  When\nthe completion menu finally appears, it's going to have a large number of\nunrelated completion strings (type/function names that are not actually\nmembers). This is because Clang fails to build a precompiled preamble for your\nfile if there are any errors in the included headers and that preamble is key to\ngetting fast completions.\n\nCall the `:YcmDiags` command to see if any errors or warnings were detected in\nyour file.\n\n\n#### Selecting a C-family completion engine\n\nCurrently YCM supports two completion engines for C-family semantic completion.\nOne libclang-based and an [clangd]-based completer. When in doubt we recommend\nusing the libclang-based engine. Here is a quick comparison of the two completer\nengines:\n\n- **Project wide indexing**: Clangd has both dynamic and static index support.\n  The dynamic index stores up-to-date symbols coming from any files you are\n  currently editing, whereas static index contains project-wide symbol\n  information. This symbol information is used for code completion and code\n  navigation. Whereas libclang is limited to the current translation unit(TU).\n- **Code navigation**: Clangd provides all the GoTo requests libclang provides and it\n  improves those using the above mentioned index information to contain\n  project-wide information rather than just the current TU.\n- **Rename**: Clangd can perform semantic rename operations on the current\n  file, whereas libclang doesn\u2019t support such functionality.\n- **Code Completion**: Clangd can perform code completions at a lower latency\n  than libclang; also, it has information about all the symbols in your\n  project so it can suggest items outside your current TU and also provides\n  proper `#include` insertions for those items.\n- **Signature help**: Clangd provides signature help so that you can see the\n  names and types of arguments when calling functions.\n- **Format Code**: Clangd provides code formatting either for the selected\n  lines or the whole file, whereas libclang doesn\u2019t have such functionality.\n- **Performance**: Clangd has faster reparse and code completion times\n  compared to libclang.\n\nTo enable:\n\n- libclang-based completer pass `--clang-completer`\n- [clangd][]-based completer pass `--clangd-completer`\n\nto `install.py` while following the [installation guide](#installation). As\nmentioned before, pass `--clang-completer` when in doubt, since the\n[clangd][]-based completer is still in heavy development.\n\n### Java Semantic Completion\n\n#### Java quick Start\n\n1. Ensure that you have enabled the Java completer. See the\n   [installation guide](#installation) for details.\n\n2. Create a project file (gradle or maven) file in the root directory of your\n   Java project, by following the instructions below.\n\n3. (Optional) [Configure the LSP server](#lsp-configuration). The [jdt.ls\n   configuration options][jdtls-preferences] can be found in their codebase.\n\n4. If you previously used Eclim or Syntastic for Java, disable them for Java.\n\n5. Edit a Java file from your project.\n\nFor the best experience, we highly recommend at least Vim 8.1.1875 when using\nJava support with YouCompleteMe.\n\n#### Java Project Files\n\nIn order to provide semantic analysis, the Java completion engine requires\nknowledge of your project structure. In particular it needs to know the class\npath to use, when compiling your code. Fortunately [jdt.ls][]\nsupports [eclipse project files][eclipse-project],\n[maven projects][mvn-project] and [gradle projects][gradle-project].\n\n**NOTE:** Our recommendation is to use either maven or gradle projects.\n\n#### Diagnostic display - Syntastic\n\nThe native support for Java includes YCM's native realtime diagnostics display.\nThis can conflict with other diagnostics plugins like Syntastic, so when\nenabling Java support, please **manually disable Syntastic Java diagnostics**.\n\nAdd the following to your `vimrc`:\n\n```viml\nlet g:syntastic_java_checkers = []\n```\n\n#### Diagnostic display - Eclim\n\nThe native support for Java includes YCM's native realtime diagnostics display.\nThis can conflict with other diagnostics plugins like Eclim, so when enabling\nJava support, please **manually disable Eclim Java diagnostics**.\n\nAdd the following to your `vimrc`:\n\n```viml\nlet g:EclimFileTypeValidate = 0\n```\n\n**NOTE**: We recommend disabling Eclim entirely when editing Java with YCM's\nnative Java support. This can be done temporarily with `:EclimDisable`.\n\n#### Eclipse Projects\n\nEclipse style projects require two files: [.project][eclipse-dot-project] and\n[.classpath][eclipse-dot-classpath].\n\nIf your project already has these files due to previously being set up within\neclipse, then no setup is required. [jdt.ls][] should load the project just\nfine (it's basically eclipse after all).\n\nHowever, if not, it is possible (easy in fact) to craft them manually, though it\nis not recommended. You're better off using gradle or maven (see below).\n\n[A simple eclipse style project example][ycmd-eclipse-project] can be found in\nthe ycmd test directory. Normally all that is required is to copy these files to\nthe root of your project and to edit the `.classpath` to add additional\nlibraries, such as:\n\n```xml\n  <classpathentry kind=\"lib\" path=\"/path/to/external/jar\" />\n  <classpathentry kind=\"lib\" path=\"/path/to/external/java/source\" />\n```\n\nIt may also be necessary to change the directory in which your source files are\nlocated (paths are relative to the .project file itself):\n\n```xml\n  <classpathentry kind=\"src\" output=\"target/classes\" path=\"path/to/src/\" />\n```\n\n**NOTE**: The eclipse project and classpath files are not a public interface\nand it is highly recommended to use Maven or Gradle project definitions if you\ndon't already use eclipse to manage your projects.\n\n#### Maven Projects\n\nMaven needs a file named [pom.xml][mvn-project] in the root of the project.\nOnce again a simple [pom.xml][ycmd-mvn-pom-xml] can be found in ycmd source.\n\nThe format of [pom.xml][mvn-project] files is way beyond the scope of this\ndocument, but we do recommend using the various tools that can generate them for\nyou, if you're not familiar with them already.\n\n#### Gradle Projects\n\nGradle projects require a [build.gradle][gradle-project]. Again, there is a\n[trivial example in ycmd's tests][ycmd-gradle-project].\n\nThe format of [build.gradle][gradle-project] files is way beyond the scope of\nthis document, but we do recommend using the various tools that can generate\nthem for you, if you're not familiar with them already.\n\n#### Troubleshooting\n\nIf you're not getting completions or diagnostics, check the server health:\n\n* The Java completion engine takes a while to start up and parse your project.\n  You should be able to see its progress in the command line, and\n  `:YcmDebugInfo`. Ensure that the following lines are present:\n\n```\n--   jdt.ls Java Language Server running\n--   jdt.ls Java Language Server Startup Status: Ready\n```\n\n* If the above lines don't appear after a few minutes, check the jdt.ls and ycmd\n  log files using [`:YcmToggleLogs` ](#the-ycmtogglelogs-command). The jdt.ls\n  log file is called `.log` (for some reason).\n\nIf you get a message about \"classpath is incomplete\", then make sure you have\ncorrectly configured the [project files](#java-project-files).\n\nIf you get messages about unresolved imports, then make sure you have\ncorrectly configured the [project files](#java-project-files), in particular\ncheck that the classpath is set correctly.\n\nFor anything else, [contact us](#contact). Java support is experimental at\npresent so we'd love to hear your feedback! Please do remember to check\n[CONTRIBUTING.md][contributing-md] for the list of diagnostics we'll need.\n\n### C# Semantic Completion\n\nYCM relies on [OmniSharp-Roslyn][] to provide completion and code navigation.\nOmniSharp-Roslyn needs a solution file for a C# project and there are two ways\nof letting YCM know about your solution files.\n\n#### Automaticly discovered solution files\n\nYCM will scan all parent directories of the file currently being edited and look\nfor file with `.sln` extension.\n\n#### Manually specified solution files\n\nIf YCM loads `.ycm_extra_conf.py` which contains `CSharpSolutionFile` function,\nYCM will try to use that to determine the solution file. This is useful when one\nwants to override the default behaviour and specify a solution file that is not\nin any of the parent directories of the currently edited file. Example:\n\n```python\ndef CSharpSolutionFile( filepath ):\n  # `filepath` is the path of the file user is editing\n  return '/path/to/solution/file' # Can be relative to the `.ycm_extra_conf.py`\n```\n\nIf the path returned by `CSharpSolutionFile` is not an actual file, YCM will\nfall back to the other way of finding the file.\n\n### Python Semantic Completion\n\nYCM relies on the [Jedi][] engine to provide completion and code navigation. By\ndefault, it will pick the version of Python running the [ycmd server][ycmd] and\nuse its `sys.path`. While this is fine for simple projects, this needs to be\nconfigurable when working with virtual environments or in a project with\nthird-party packages. The next sections explain how to do that.\n\n#### Working with virtual environments\n\nA common practice when working on a Python project is to install its\ndependencies in a virtual environment and develop the project inside that\nenvironment. To support this, YCM needs to know the interpreter path of the\nvirtual environment. You can specify it by creating a `.ycm_extra_conf.py` file\nat the root of your project with the following contents:\n\n```python\ndef Settings( **kwargs ):\n  return {\n    'interpreter_path': '/path/to/virtual/environment/python'\n  }\n```\n\nwhere `/path/to/virtual/environment/python` is the path to the Python used\nby the virtual environment you are working in. Typically, the executable can be\nfound in the `Scripts` folder of the virtual environment directory on Windows\nand in the `bin` folder on other platforms.\n\nIf you don't like having to create a `.ycm_extra_conf.py` file at the root of\nyour project and would prefer to specify the interpreter path with a Vim option,\nread the [Configuring through Vim options](#configuring-through-vim-options)\nsection.\n\n#### Working with third-party packages\n\nAnother common practice is to put the dependencies directly into the project and\nadd their paths to `sys.path` at runtime in order to import them. YCM needs to\nbe told about this path manipulation to support those dependencies. This can be\ndone by creating a `.ycm_extra_conf.py` file at the root of the project. This\nfile must define a `Settings( **kwargs )` function returning a dictionary with\nthe list of paths to prepend to `sys.path` under the `sys_path` key. For\ninstance, the following `.ycm_extra_conf.py`\n\n```python\ndef Settings( **kwargs ):\n  return {\n    'sys_path': [\n      '/path/to/some/third_party/package',\n      '/path/to/another/third_party/package'\n    ]\n  }\n```\n\nadds the paths `/path/to/some/third_party/package` and\n`/path/to/another/third_party/package` at the start of `sys.path`.\n\nIf you would rather prepend paths to `sys.path` with a Vim option, read the\n[Configuring through Vim options](#configuring-through-vim-options) section.\n\nIf you need further control on how to add paths to `sys.path`, you should define\nthe `PythonSysPath( **kwargs )` function in the `.ycm_extra_conf.py` file. Its\nkeyword arguments are `sys_path` which contains the default `sys.path`, and\n`interpreter_path` which is the path to the Python interpreter. Here's a trivial\nexample that insert the `/path/to/third_party/package` path at the second\nposition of `sys.path`:\n\n```python\ndef PythonSysPath( **kwargs ):\n  sys_path = kwargs[ 'sys_path' ]\n  sys_path.insert( 1, '/path/to/third_party/package' )\n  return sys_path\n```\n\nA more advanced example can be found in [YCM's own\n`.ycm_extra_conf.py`][ycm_flags_example].\n\n#### Configuring through Vim options\n\nYou may find inconvenient to have to create a `.ycm_extra_conf.py` file at the\nroot of each one of your projects in order to set the path to the Python\ninterpreter and/or add paths to `sys.path` and would prefer to be able to\nconfigure those through Vim options. Don't worry, this is possible by using the\n[`g:ycm_extra_conf_vim_data`](#the-gycm_extra_conf_vim_data-option) option and\ncreating a global extra configuration file. Let's take an example. Suppose that\nyou want to set the interpreter path with the `g:ycm_python_interpreter_path`\noption and prepend paths to `sys.path` with the `g:ycm_python_sys_path` option.\nSuppose also that you want to name the global extra configuration file\n`global_extra_conf.py` and that you want to put it in your HOME folder. You\nshould then add the following lines to your vimrc:\n\n```viml\nlet g:ycm_python_interpreter_path = ''\nlet g:ycm_python_sys_path = []\nlet g:ycm_extra_conf_vim_data = [\n  \\  'g:ycm_python_interpreter_path',\n  \\  'g:ycm_python_sys_path'\n  \\]\nlet g:ycm_global_ycm_extra_conf = '~/global_extra_conf.py'\n```\n\nand create the `~/global_extra_conf.py` file with the following contents:\n\n```python\ndef Settings( **kwargs ):\n  client_data = kwargs[ 'client_data' ]\n  return {\n    'interpreter_path': client_data[ 'g:ycm_python_interpreter_path' ],\n    'sys_path': client_data[ 'g:ycm_python_sys_path' ]\n  }\n```\n\nThat's it. You are done. Note that you don't need to restart the server when\nsetting one of the options. YCM will automatically pick the new values.\n\n### Rust Semantic Completion\n\nCompletions and GoTo commands within the current crate and its dependencies\nshould work out of the box with no additional configuration (provided that you\nbuilt YCM with the `--rust-completer` flag; see the [*Installation*\nsection](#installation) for details). The install script takes care of\ninstalling [the Rust source code][rust-src], so no configuration is necessary.\nIn case you are running Python 2.7.8 and older, you will need to manually\ninstall [rustup][].\n\nTo [configure RLS](#lsp-configuration) look up [rls configuration options][\nrls-preferences]\n\n### Go Semantic Completion\n\nCompletions and GoTo commands should work out of the box (provided that you\nbuilt YCM with the `--go-completer` flag; see the [*Installation*\nsection](#installation) for details). The server only works for projects with\nthe \"canonical\" layout.\n\nWhile YCM can configure [a LSP server](#lsp-configuration), currently `gopls`\ndoesn't implement [the required notification][gopls-preferences].\n\n### JavaScript and TypeScript Semantic Completion\n\n**NOTE:** YCM originally used the [Tern][] engine for JavaScript but due to\n[Tern][] not being maintained anymore by its main author and the [TSServer][]\nengine offering more features, YCM is moving to [TSServer][]. This won't affect\nyou if you were already using [Tern][] but you are encouraged to do the switch\nby deleting the `third_party/ycmd/third_party/tern_runtime/node_modules`\ndirectory in YCM folder. If you are a new user but still want to use [Tern][],\nyou should pass the `--js-completer` option to the `install.py` script during\ninstallation. Further instructions on how to setup YCM with [Tern][] are\navailable on [the wiki][tern-instructions].\n\nAll JavaScript and TypeScript features are provided by the [TSServer][] engine,\nwhich is included in the TypeScript SDK. To enable these features, install\n[Node.js and npm][npm-install] and call the `install.py` script with the\n`--ts-completer` flag.\n\n[TSServer][] relies on [the `jsconfig.json` file][jsconfig.json] for JavaScript\nand [the `tsconfig.json` file][tsconfig.json] for TypeScript to analyze your\nproject. Ensure the file exists at the root of your project.\n\nTo get diagnostics in JavaScript, set the `checkJs` option to `true` in your\n`jsconfig.json` file:\n```json\n{\n    \"compilerOptions\": {\n        \"checkJs\": true\n    }\n}\n```\n\n### Semantic Completion for Other Languages\n\nC-family, C#, Go, Java, Python, Rust, and JavaScript/TypeScript languages are\nsupported natively by YouCompleteMe using the [Clang][], [OmniSharp-Roslyn][],\n[Gopls][], [jdt.ls][], [Jedi][], [rls][], and [TSServer][] engines,\nrespectively. Check the [installation](#installation) section for instructions\nto enable these features if desired.\n\n#### Plugging an arbitrary LSP server\n\nSimilar to other LSP clients, YCM can use an arbitrary LSP server with the help\nof [`g:ycm_language_server`](#the-gycm_language_server-option) option. An\nexample of a value of this option would be:\n\n```viml\nlet g:ycm_language_server = \n  \\ [ \n  \\   {\n  \\     'name': 'yaml',\n  \\     'cmdline': [ '/path/to/yaml/server/yaml-language-server', '--stdio' ],\n  \\     'filetypes': [ 'yaml' ]\n  \\   },\n  \\   {\n  \\     'name': 'rust',\n  \\     'cmdline': [ 'ra_lsp_server' ],\n  \\     'filetypes': [ 'rust' ],\n  \\     'project_root_files': [ 'Cargo.toml' ]\n  \\   }\n  \\ ]\n```\n\n`project_root_files` is an optional key, since not all servers need it.\n\nWhen [configuring a LSP server](#lsp-configuration) the value of the `name` key\nwill be used as the `kwargs[ 'language' ]`.\n\nSee [the LSP Examples](https://github.com/ycm-core/lsp-examples) project for more\nexamples of configuring the likes of PHP, Ruby, Kotlin, and D.\n\n#### Using `omnifunc` for semantic completion\n\nYCM will use your `omnifunc` (see `:h omnifunc` in Vim) as a source for semantic\ncompletions if it does not have a native semantic completion engine for your\nfile's filetype. Vim comes with okayish omnifuncs for various languages like\nRuby, PHP, etc. It depends on the language.\n\nYou can get a stellar omnifunc for Ruby with [Eclim][]. Just make sure you have\nthe _latest_ Eclim installed and configured (this means Eclim `>= 2.2.*` and\nEclipse `>= 4.2.*`).\n\nAfter installing Eclim remember to create a new Eclipse project within your\napplication by typing `:ProjectCreate <path-to-your-project> -n ruby` inside vim\nand don't forget to have `let g:EclimCompletionMethod = 'omnifunc'` in your\nvimrc. This will make YCM and Eclim play nice; YCM will use Eclim's omnifuncs as\nthe data source for semantic completions and provide the auto-triggering and\nsubsequence-based matching (and other YCM features) on top of it.\n\n### LSP Configuration\n\nMany LSP servers allow some level of user configuration. YCM enables this with\nthe help of `.ycm_extra_conf.py` files. Here's an example of jdt.ls user\nconfiguration.\n\n```python\ndef Settings( **kwargs ):\n  if kwargs[ 'language' ] == 'java':\n    return { 'ls': { 'java.format.onType.enabled': True } }\n```\n\nThe `ls` key tells YCM that the dictionary should be passed to thet LSP server.\nFor each of the LSP server's configuration you should look up the respective\nserver's documentation.\n\n### Writing New Semantic Completers\n\nYou have two options here: writing an `omnifunc` for Vim's omnicomplete system\nthat YCM will then use through its omni-completer, or a custom completer for YCM\nusing the [Completer API][completer-api].\n\nHere are the differences between the two approaches:\n\n- You have to use VimScript to write the omnifunc, but get to use Python to\n  write for the Completer API; this by itself should make you want to use the\n  API.\n- The Completer API is a _much_ more powerful way to integrate with YCM and it\n  provides a wider set of features. For instance, you can make your Completer\n  query your semantic back-end in an asynchronous fashion, thus not blocking\n  Vim's GUI thread while your completion system is processing stuff. This is\n  impossible with VimScript. All of YCM's completers use the Completer API.\n- Performance with the Completer API is better since Python executes faster than\n  VimScript.\n\nIf you want to use the `omnifunc` system, see the relevant Vim docs with `:h\ncomplete-functions`. For the Completer API, see [the API docs][completer-api].\n\nIf you want to upstream your completer into YCM's source, you should use the\nCompleter API.\n\n### Diagnostic Display\n\nYCM will display diagnostic notifications for the C-family, C#, Go, Java,\nJavaScript, Rust and TypeScript languages. Since YCM continuously recompiles\nyour file as you type, you'll get notified of errors and warnings in your file\nas fast as possible.\n\nHere are the various pieces of the diagnostic UI:\n\n- Icons show up in the Vim gutter on lines that have a diagnostic.\n- Regions of text related to diagnostics are highlighted (by default, a red\n  wavy underline in `gvim` and a red background in `vim`).\n- Moving the cursor to a line with a diagnostic echoes the diagnostic text.\n- Vim's location list is automatically populated with diagnostic data (off by\n  default, see options).\n\nThe new diagnostics (if any) will be displayed the next time you press any key\non the keyboard. So if you stop typing and just wait for the new diagnostics to\ncome in, that _will not work_. You need to press some key for the GUI to update.\n\nHaving to press a key to get the updates is unfortunate, but cannot be changed\ndue to the way Vim internals operate; there is no way that a background task can\nupdate Vim's GUI after it has finished running.  You _have to_ press a key. This\nwill make YCM check for any pending diagnostics updates.\n\nYou _can_ force a full, blocking compilation cycle with the\n`:YcmForceCompileAndDiagnostics` command (you may want to map that command to a\nkey; try putting `nnoremap <F5> :YcmForceCompileAndDiagnostics<CR>` in your\nvimrc). Calling this command will force YCM to immediately recompile your file\nand display any new diagnostics it encounters. Do note that recompilation with\nthis command may take a while and during this time the Vim GUI _will_ be\nblocked.\n\nYCM will display a short diagnostic message when you move your cursor to the\nline with the error. You can get a detailed diagnostic message with the\n`<leader>d` key mapping (can be changed in the options) YCM provides when your\ncursor is on the line with the diagnostic.\n\nYou can also see the full diagnostic message for all the diagnostics in the\ncurrent file in Vim's `locationlist`, which can be opened with the `:lopen` and\n`:lclose` commands (make sure you have set `let\ng:ycm_always_populate_location_list = 1` in your vimrc). A good way to toggle\nthe display of the `locationlist` with a single key mapping is provided by\nanother (very small) Vim plugin called [ListToggle][] (which also makes it\npossible to change the height of the `locationlist` window), also written by\nyours truly.\n\n#### Diagnostic Highlighting Groups\n\nYou can change the styling for the highlighting groups YCM uses. For the signs\nin the Vim gutter, the relevant groups are:\n\n- `YcmErrorSign`, which falls back to group `SyntasticErrorSign` and then\n  `error` if they exist\n- `YcmWarningSign`, which falls back to group `SyntasticWarningSign` and then\n  `todo` if they exist\n\nYou can also style the line that has the warning/error with these groups:\n\n- `YcmErrorLine`, which falls back to group `SyntasticErrorLine` if it exists\n- `YcmWarningLine`, which falls back to group `SyntasticWarningLine` if it\n  exists\n\nNote that the line highlighting groups only work when the\n[`g:ycm_enable_diagnostic_signs`](#the-gycm_enable_diagnostic_signs-option)\noption is set. If you want highlighted lines but no signs in the Vim gutter,\nensure that your Vim version is 7.4.2201 or later and set the `signcolumn`\noption to `off` in your vimrc:\n\n```viml\nset signcolumn=off\n```\n\nThe syntax groups used to highlight regions of text with errors/warnings:\n- `YcmErrorSection`, which falls back to group `SyntasticError` if it exists and\n  then `SpellBad`\n- `YcmWarningSection`, which falls back to group `SyntasticWarning` if it exists\n  and then `SpellCap`\n\nHere's how you'd change the style for a group:\n\n```viml\nhighlight YcmErrorLine guibg=#3f0000\n```\n\nCommands\n--------\n\n### The `:YcmRestartServer` command\n\nIf the [ycmd completion server][ycmd] suddenly stops for some reason, you can\nrestart it with this command.\n\n### The `:YcmForceCompileAndDiagnostics` command\n\nCalling this command will force YCM to immediately recompile your file\nand display any new diagnostics it encounters. Do note that recompilation with\nthis command may take a while and during this time the Vim GUI _will_ be\nblocked.\n\nYou may want to map this command to a key; try putting `nnoremap <F5>\n:YcmForceCompileAndDiagnostics<CR>` in your vimrc.\n\n### The `:YcmDiags` command\n\nCalling this command will fill Vim's `locationlist` with errors or warnings if\nany were detected in your file and then open it. If a given error or warning can\nbe fixed by a call to `:YcmCompleter FixIt`, then ` (FixIt available)` is\nappended to the error or warning text. See the `FixIt` completer subcommand for\nmore information.\n\n**NOTE:** The absence of ` (FixIt available)` does not strictly imply a fix-it\nis not available as not all completers are able to provide this indication. For\nexample, the c-sharp completer provides many fix-its but does not add this\nadditional indication.\n\nThe `g:ycm_open_loclist_on_ycm_diags` option can be used to prevent the location\nlist from opening, but still have it filled with new diagnostic data. See the\n_Options_ section for details.\n\n### The `:YcmShowDetailedDiagnostic` command\n\nThis command shows the full diagnostic text when the user's cursor is on the\nline with the diagnostic.\n\n### The `:YcmDebugInfo` command\n\nThis will print out various debug information for the current file. Useful to\nsee what compile commands will be used for the file if you're using the semantic\ncompletion engine.\n\n### The `:YcmToggleLogs` command\n\nThis command presents the list of logfiles created by YCM, the [ycmd\nserver][ycmd], and the semantic engine server for the current filetype, if any.\nOne of these logfiles can be opened in the editor (or closed if already open) by\nentering the corresponding number or by clicking on it with the mouse.\nAdditionally, this command can take the logfile names as arguments. Use the\n`<TAB>` key (or any other key defined by the `wildchar` option) to complete the\narguments or to cycle through them (depending on the value of the `wildmode`\noption). Each logfile given as an argument is directly opened (or closed if\nalready open) in the editor. Only for debugging purposes.\n\n### The `:YcmCompleter` command\n\nThis command gives access to a number of additional [IDE-like\nfeatures](#quick-feature-summary) in YCM, for things like semantic GoTo, type\ninformation, FixIt and refactoring.\n\nThis command accepts a range that can either be specified through a selection in\none of Vim's visual modes (see `:h visual-use`) or on the command line. For\ninstance, `:2,5YcmCompleter` will apply the command from line 2 to line 5. This\nis useful for [the `Format` subcommand](#the-format-subcommand).\n\nCall `YcmCompleter` without further arguments for a list of the commands you can\ncall for the current completer.\n\nSee the [file type feature summary](#quick-feature-summary) for an overview of\nthe features available for each file type. See the _YcmCompleter subcommands_\nsection for more information on the available subcommands and their usage.\n\nYcmCompleter Subcommands\n------------------------\n\n**NOTE:** See the docs for the `YcmCompleter` command before tackling this\nsection.\n\nThe invoked subcommand is automatically routed to the currently active semantic\ncompleter, so `:YcmCompleter GoToDefinition` will invoke the `GoToDefinition`\nsubcommand on the Python semantic completer if the currently active file is a\nPython one and on the Clang completer if the currently active file is a C-family\nlanguage one.\n\nYou may also want to map the subcommands to something less verbose; for\ninstance, `nnoremap <leader>jd :YcmCompleter GoTo<CR>`\nmaps the `<leader>jd` sequence to the longer subcommand invocation.\n\n### GoTo Commands\n\nThese commands are useful for jumping around and exploring code. When moving\nthe cursor, the subcommands add entries to Vim's `jumplist` so you can use\n`CTRL-O` to jump back to where you were before invoking the command (and\n`CTRL-I` to jump forward; see `:h jumplist` for details). If there is more\nthan one destination, the quickfix list (see `:h quickfix`) is populated with\nthe available locations and opened to full width at the bottom of the screen.\nYou can change this behavior by using [the `YcmQuickFixOpened`\nautocommand](#the-ycmquickfixopened-autocommand).\n\n#### The `GoToInclude` subcommand\n\nLooks up the current line for a header and jumps to it.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda`\n\n#### The `GoToDeclaration` subcommand\n\nLooks up the symbol under the cursor and jumps to its declaration.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, cs, go, java, javascript,\npython, rust, typescript`\n\n#### The `GoToDefinition` subcommand\n\nLooks up the symbol under the cursor and jumps to its definition.\n\n**NOTE:** For C-family languages **this only works in certain situations**,\nnamely when the definition of the symbol is in the current translation unit. A\ntranslation unit consists of the file you are editing and all the files you are\nincluding with `#include` directives (directly or indirectly) in that file.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, cs, go, java, javascript,\npython, rust, typescript`\n\n#### The `GoTo` subcommand\n\nThis command tries to perform the \"most sensible\" GoTo operation it can.\nCurrently, this means that it tries to look up the symbol under the cursor and\njumps to its definition if possible; if the definition is not accessible from\nthe current translation unit, jumps to the symbol's declaration. For\nC-family languages, it first tries to look up the current line for a header and\njump to it. For C#, implementations are also considered and preferred.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, cs, go, java, javascript,\npython, rust, typescript`\n\n#### The `GoToImprecise` subcommand\n\nWARNING: This command trades correctness for speed!\n\nSame as the `GoTo` command except that it doesn't recompile the file with\nlibclang before looking up nodes in the AST. This can be very useful when you're\nediting files that take long to compile but you know that you haven't made any\nchanges since the last parse that would lead to incorrect jumps. When you're\njust browsing around your codebase, this command can spare you quite a bit of\nlatency.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda`\n\n#### The `GoToReferences` subcommand\n\nThis command attempts to find all of the references within the project to the\nidentifier under the cursor and populates the quickfix list with those\nlocations.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, java, javascript, python, typescript, rust`\n\n#### The `GoToImplementation` subcommand\n\nLooks up the symbol under the cursor and jumps to its implementation (i.e.\nnon-interface). If there are multiple implementations, instead provides a list\nof implementations to choose from.\n\nSupported in filetypes: `cs, java, rust`\n\n#### The `GoToImplementationElseDeclaration` subcommand\n\nLooks up the symbol under the cursor and jumps to its implementation if one,\nelse jump to its declaration. If there are multiple implementations, instead\nprovides a list of implementations to choose from.\n\nSupported in filetypes: `cs`\n\n#### The `GoToType` subcommand\n\nLooks up the symbol under the cursor and jumps to the definition of its type\ne.g. if the symbol is an object, go to the definition of its class.\n\nSupported in filetypes: `go, java, javascript, typescript`\n\n### Semantic Information Commands\n\nThese commands are useful for finding static information about the code, such\nas the types of variables, viewing declarations and documentation strings.\n\n#### The `GetType` subcommand\n\nEchos the type of the variable or method under the cursor, and where it differs,\nthe derived type.\n\nFor example:\n\n```c++\n    std::string s;\n```\n\nInvoking this command on `s` returns `std::string => std::basic_string<char>`\n\n**NOTE:** Causes re-parsing of the current translation unit.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, java, javascript,\ngo, python, typescript, rust`\n\n#### The `GetTypeImprecise` subcommand\n\nWARNING: This command trades correctness for speed!\n\nSame as the `GetType` command except that it doesn't recompile the file with\nlibclang before looking up nodes in the AST. This can be very useful when you're\nediting files that take long to compile but you know that you haven't made any\nchanges since the last parse that would lead to incorrect type. When you're\njust browsing around your codebase, this command can spare you quite a bit of\nlatency.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda`\n\n#### The `GetParent` subcommand\n\nEchos the semantic parent of the point under the cursor.\n\nThe semantic parent is the item that semantically contains the given position.\n\nFor example:\n\n```c++\nclass C {\n    void f();\n};\n\nvoid C::f() {\n\n}\n```\n\nIn the out-of-line definition of `C::f`, the semantic parent is the class `C`,\nof which this function is a member.\n\nIn the example above, both declarations of `C::f` have `C` as their semantic\ncontext, while the lexical context of the first `C::f` is `C` and the lexical\ncontext of the second `C::f` is the translation unit.\n\nFor global declarations, the semantic parent is the translation unit.\n\n**NOTE:** Causes re-parsing of the current translation unit.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda`\n\n#### The `GetDoc` subcommand\n\nDisplays the preview window populated with quick info about the identifier\nunder the cursor. Depending on the file type, this includes things like:\n\n* The type or declaration of identifier,\n* Doxygen/javadoc comments,\n* Python docstrings,\n* etc.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, cs, go, java, javascript,\npython, typescript, rust`\n\n#### The `GetDocImprecise` subcommand\n\nWARNING: This command trades correctness for speed!\n\nSame as the `GetDoc` command except that it doesn't recompile the file with\nlibclang before looking up nodes in the AST. This can be very useful when you're\nediting files that take long to compile but you know that you haven't made any\nchanges since the last parse that would lead to incorrect docs. When you're\njust browsing around your codebase, this command can spare you quite a bit of\nlatency.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda`\n\n### Refactoring Commands\n\nThese commands make changes to your source code in order to perform refactoring\nor code correction. YouCompleteMe does not perform any action which cannot be\nundone, and never saves or writes files to the disk.\n\n#### The `FixIt` subcommand\n\nWhere available, attempts to make changes to the buffer to correct diagnostics\non the current line. Where multiple suggestions are available (such as when\nthere are multiple ways to resolve a given warning, or where multiple\ndiagnostics are reported for the current line), the options are presented\nand one can be selected.\n\nCompleters which provide diagnostics may also provide trivial modifications to\nthe source in order to correct the diagnostic. Examples include syntax errors\nsuch as missing trailing semi-colons, spurious characters, or other errors which\nthe semantic engine can deterministically suggest corrections.\n\nIf no fix-it is available for the current line, or there is no diagnostic on the\ncurrent line, this command has no effect on the current buffer. If any\nmodifications are made, the number of changes made to the buffer is echo'd and\nthe user may use the editor's undo command to revert.\n\nWhen a diagnostic is available, and `g:ycm_echo_current_diagnostic` is set to 1,\nthen the text ` (FixIt)` is appended to the echo'd diagnostic when the\ncompleter is able to add this indication. The text ` (FixIt available)` is\nalso appended to the diagnostic text in the output of the `:YcmDiags` command\nfor any diagnostics with available fix-its (where the completer can provide this\nindication).\n\n**NOTE:** Causes re-parsing of the current translation unit.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, cs, go, java, javascript,\nrust, typescript`\n\n#### The `RefactorRename <new name>` subcommand\n\nIn supported file types, this command attempts to perform a semantic rename of\nthe identifier under the cursor. This includes renaming declarations,\ndefinitions and usages of the identifier, or any other language-appropriate\naction. The specific behavior is defined by the semantic engine in use.\n\nSimilar to `FixIt`, this command applies automatic modifications to your source\nfiles. Rename operations may involve changes to multiple files, which may or may\nnot be open in Vim buffers at the time. YouCompleteMe handles all of this for\nyou. The behavior is described in [the following section](#multi-file-refactor).\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, java, javascript, typescript, rust`\n\n#### Multi-file Refactor\n\nWhen a Refactor or FixIt command touches multiple files, YouCompleteMe attempts\nto apply those modifications to any existing open, visible buffer in the current\ntab. If no such buffer can be found, YouCompleteMe opens the file in a new\nsmall horizontal split at the top of the current window, applies the change,\nand then *hides* the window. **NOTE:** The buffer remains open, and must be\nmanually saved. A confirmation dialog is opened prior to doing this to remind\nyou that this is about to happen.\n\nOnce the modifications have been made, the quickfix list (see `:help quickfix`)\nis populated with the locations of all modifications. This can be used to review\nall automatic changes made by using `:copen`. Typically, use the `CTRL-W\n<enter>` combination to open the selected file in a new split. It is possible to\ncustomize how the quickfix window is opened by using [the `YcmQuickFixOpened`\nautocommand](#the-ycmquickfixopened-autocommand).\n\nThe buffers are *not* saved automatically. That is, you must save the modified\nbuffers manually after reviewing the changes from the quickfix list. Changes\ncan be undone using Vim's powerful undo features (see `:help undo`). Note\nthat Vim's undo is per-buffer, so to undo all changes, the undo commands must\nbe applied in each modified buffer separately.\n\n**NOTE:** While applying modifications, Vim may find files which are already\nopen and have a swap file. The command is aborted if you select Abort or Quit in\nany such prompts. This leaves the Refactor operation partially complete and must\nbe manually corrected using Vim's undo features. The quickfix list is *not*\npopulated in this case. Inspect `:buffers` or equivalent (see `:help buffers`)\nto see the buffers that were opened by the command.\n\n#### The `Format` subcommand\n\nThis command formats the whole buffer or some part of it according to the value\nof the Vim options `shiftwidth` and `expandtab` (see `:h 'sw'` and `:h et`\nrespectively). To format a specific part of your document, you can either select\nit in one of Vim's visual modes (see `:h visual-use`) and run the command or\ndirectly enter the range on the command line, e.g. `:2,5YcmCompleter Format` to\nformat it from line 2 to line 5.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, java, javascript, go, typescript, rust`\n\n#### The `OrganizeImports` subcommand\n\nThis command removes unused imports and sorts imports in the current file. It\ncan also group imports from the same module in TypeScript and resolves imports\nin Java.\n\nSupported in filetypes: `java, javascript, typescript`\n\n### Miscellaneous Commands\n\nThese commands are for general administration, rather than IDE-like features.\nThey cover things like the semantic engine server instance and compilation\nflags.\n\n#### The `ExecuteCommand <args>` subcommand\n\nSome LSP completers (currently Rust and Java completers) support executing\nserver specific commands. Consult the [rls][] and [jdt.ls][] respective\ndocumentations to find out what commands are supported and which arguments are\nexpected.\n\nThe support for `ExecuteCommand` was implemented to support plugins like\n[vimspector][] to debug java, but isn't limited to that specific use case.\n\n#### The `RestartServer` subcommand\n\nRestarts the semantic-engine-as-localhost-server for those semantic engines that\nwork as separate servers that YCM talks to.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, cs, go, java, javascript, rust, typescript`\n\n#### The `ClearCompilationFlagCache` subcommand\n\nYCM caches the flags it gets from the `Settings` function in your\n`.ycm_extra_conf.py` file unless you return them with the `do_cache` parameter\nset to `False`. It also caches the flags extracted from the compilation\ndatabase. The cache is in memory and is never invalidated (unless you restart\nthe server with the `:YcmRestartServer` command).\n\nThis command clears that cache entirely. YCM will then re-query your\n`Settings` function or your compilation database as needed in the future.\n\nSupported in filetypes: `c, cpp, objc, objcpp, cuda, rust`\n\n#### The `ReloadSolution` subcommand\n\nInstruct the Omnisharp-Roslyn server to clear its cache and reload all files\nfrom disk.  This is useful when files are added, removed, or renamed in the\nsolution, files are changed outside of Vim, or whenever Omnisharp-Roslyn cache\nis out-of-sync.\n\nSupported in filetypes: `cs`\n\nFunctions\n--------\n\n### The `youcompleteme#GetErrorCount` function\n\nGet the number of YCM Diagnostic errors. If no errors are present, this function\nreturns 0.\n\nFor example:\n```viml\n  call youcompleteme#GetErrorCount()\n```\n\nBoth this function and `youcompleteme#GetWarningCount` can be useful when\nintegrating YCM with other Vim plugins. For example, a [lightline][] user could\nadd a diagnostics section to their statusline which would display the number of\nerrors and warnings.\n\n### The `youcompleteme#GetWarningCount` function\n\nGet the number of YCM Diagnostic warnings. If no warnings are present, this\nfunction returns 0.\n\nFor example:\n```viml\n  call youcompleteme#GetWarningCount()\n```\n\nAutocommands\n------------\n\n### The `YcmLocationOpened` autocommand\n\nThis `User` autocommand is fired when YCM opens the location list window in\nresponse to the `YcmDiags` command. By default, the location list window is\nopened to the bottom of the current window and its height is set to fit all\nentries. This behavior can be overridden by using the `YcmLocationOpened`\nautocommand which is triggered while the cursor is in the location list window.\nFor instance:\n```viml\nfunction! s:CustomizeYcmLocationWindow()\n  \" Move the window to the top of the screen.\n  wincmd K\n  \" Set the window height to 5.\n  5wincmd _\n  \" Switch back to working window.\n  wincmd p\nendfunction\n\nautocmd User YcmLocationOpened call s:CustomizeYcmLocationWindow()\n```\n\n### The `YcmQuickFixOpened` autocommand\n\nThis `User` autocommand is fired when YCM opens the quickfix window in response\nto the `GoTo*` and `RefactorRename` subcommands. By default, the quickfix window\nis opened to full width at the bottom of the screen and its height is set to fit\nall entries. This behavior can be overridden by using the `YcmQuickFixOpened`\nautocommand which is triggered while the cursor is in the quickfix window. For\ninstance:\n```viml\nfunction! s:CustomizeYcmQuickFixWindow()\n  \" Move the window to the top of the screen.\n  wincmd K\n  \" Set the window height to 5.\n  5wincmd _\nendfunction\n\nautocmd User YcmQuickFixOpened call s:CustomizeYcmQuickFixWindow()\n```\n\nOptions\n-------\n\nAll options have reasonable defaults so if the plug-in works after installation\nyou don't need to change any options. These options can be configured in your\n[vimrc script][vimrc] by including a line like this:\n\n```viml\nlet g:ycm_min_num_of_chars_for_completion = 1\n```\n\nNote that after changing an option in your [vimrc script][vimrc] you have to\nrestart [ycmd][] with the `:YcmRestartServer` command for the changes to take\neffect.\n\n### The `g:ycm_min_num_of_chars_for_completion` option\n\nThis option controls the number of characters the user needs to type before\nidentifier-based completion suggestions are triggered. For example, if the\noption is set to `2`, then when the user types a second alphanumeric character\nafter a whitespace character, completion suggestions will be triggered. This\noption is NOT used for semantic completion.\n\nSetting this option to a high number like `99` effectively turns off the\nidentifier completion engine and just leaves the semantic engine.\n\nDefault: `2`\n\n```viml\nlet g:ycm_min_num_of_chars_for_completion = 2\n```\n\n### The `g:ycm_min_num_identifier_candidate_chars` option\n\nThis option controls the minimum number of characters that a completion\ncandidate coming from the identifier completer must have to be shown in the\npopup menu.\n\nA special value of `0` means there is no limit.\n\n**NOTE:** This option only applies to the identifier completer; it has no effect\non the various semantic completers.\n\nDefault: `0`\n\n```viml\nlet g:ycm_min_num_identifier_candidate_chars = 0\n```\n\n### The `g:ycm_max_num_candidates` option\n\nThis option controls the maximum number of semantic completion suggestions shown\nin the completion menu. This only applies to suggestions from semantic\ncompletion engines; see [the `g:ycm_max_identifier_candidates`\noption](#the-gycm_max_num_identifier_candidates-option) to limit the number of\nsuggestions from the identifier-based engine.\n\nA special value of `0` means there is no limit.\n\n**NOTE:** Setting this option to `0` or to a value greater than `100` is not\nrecommended as it will slow down completion when there are a very large number\nof suggestions.\n\nDefault: `50`\n\n```viml\nlet g:ycm_max_num_candidates = 50\n```\n\n### The `g:ycm_max_num_identifier_candidates` option\n\nThis option controls the maximum number of completion suggestions from the\nidentifier-based engine shown in the completion menu.\n\nA special value of `0` means there is no limit.\n\n**NOTE:** Setting this option to `0` or to a value greater than `100` is not\nrecommended as it will slow down completion when there are a very large number\nof suggestions.\n\nDefault: `10`\n\n```viml\nlet g:ycm_max_num_identifier_candidates = 10\n```\n\n### The `g:ycm_auto_trigger` option\n\nWhen set to `0`, this option turns off YCM's identifier completer (the\nas-you-type popup) _and_ the semantic triggers (the popup you'd get after typing\n`.` or `->` in say C++). You can still force semantic completion with the\n`<C-Space>` shortcut.\n\nIf you want to just turn off the identifier completer but keep the semantic\ntriggers, you should set `g:ycm_min_num_of_chars_for_completion` to a high\nnumber like `99`.\n\nDefault: `1`\n\n```viml\nlet g:ycm_auto_trigger = 1\n```\n\n### The `g:ycm_filetype_whitelist` option\n\nThis option controls for which Vim filetypes (see `:h filetype`) should YCM be\nturned on. The option value should be a Vim dictionary with keys being filetype\nstrings (like `python`, `cpp`, etc.) and values being unimportant (the\ndictionary is used like a hash set, meaning that only the keys matter).\n\nThe `*` key is special and matches all filetypes. By default, the whitelist\ncontains only this `*` key.\n\nYCM also has a `g:ycm_filetype_blacklist` option that lists filetypes for which\nYCM shouldn't be turned on. YCM will work only in filetypes that both the\nwhitelist and the blacklist allow (the blacklist \"allows\" a filetype by _not_\nhaving it as a key).\n\nFor example, let's assume you want YCM to work in files with the `cpp` filetype.\nThe filetype should then be present in the whitelist either directly (`cpp` key\nin the whitelist) or indirectly through the special `*` key. It should _not_ be\npresent in the blacklist.\n\nFiletypes that are blocked by the either of the lists will be completely ignored\nby YCM, meaning that neither the identifier-based completion engine nor the\nsemantic engine will operate in them.\n\nYou can get the filetype of the current file in Vim with `:set ft?`.\n\nDefault: `{'*': 1}`\n\n```viml\nlet g:ycm_filetype_whitelist = {'*': 1}\n```\n\n### The `g:ycm_filetype_blacklist` option\n\nThis option controls for which Vim filetypes (see `:h filetype`) should YCM be\nturned off. The option value should be a Vim dictionary with keys being filetype\nstrings (like `python`, `cpp`, etc.) and values being unimportant (the\ndictionary is used like a hash set, meaning that only the keys matter).\n\nSee the `g:ycm_filetype_whitelist` option for more details on how this works.\n\nDefault: `[see next line]`\n\n```viml\nlet g:ycm_filetype_blacklist = {\n      \\ 'tagbar': 1,\n      \\ 'notes': 1,\n      \\ 'markdown': 1,\n      \\ 'netrw': 1,\n      \\ 'unite': 1,\n      \\ 'text': 1,\n      \\ 'vimwiki': 1,\n      \\ 'pandoc': 1,\n      \\ 'infolog': 1,\n      \\ 'leaderf': 1,\n      \\ 'mail': 1\n      \\}\n```\n\n### The `g:ycm_filetype_specific_completion_to_disable` option\n\nThis option controls for which Vim filetypes (see `:h filetype`) should the YCM\nsemantic completion engine be turned off. The option value should be a Vim\ndictionary with keys being filetype strings (like `python`, `cpp`, etc.) and\nvalues being unimportant (the dictionary is used like a hash set, meaning that\nonly the keys matter). The listed filetypes will be ignored by the YCM semantic\ncompletion engine, but the identifier-based completion engine will still trigger\nin files of those filetypes.\n\nNote that even if semantic completion is not turned off for a specific filetype,\nyou will not get semantic completion if the semantic engine does not support\nthat filetype.\n\nYou can get the filetype of the current file in Vim with `:set ft?`.\n\nDefault: `[see next line]`\n\n```viml\nlet g:ycm_filetype_specific_completion_to_disable = {\n      \\ 'gitcommit': 1\n      \\}\n```\n\n### The `g:ycm_filepath_blacklist` option\n\nThis option controls for which Vim filetypes (see `:h filetype`) should filepath\ncompletion be disabled. The option value should be a Vim dictionary with keys\nbeing filetype strings (like `python`, `cpp`, etc.) and values being unimportant\n(the dictionary is used like a hash set, meaning that only the keys matter).\n\nThe `*` key is special and matches all filetypes. Use this key if you want to\ncompletely disable filepath completion:\n```viml\nlet g:ycm_filepath_blacklist = {'*': 1}\n```\n\nYou can get the filetype of the current file in Vim with `:set ft?`.\n\nDefault: `[see next line]`\n\n```viml\nlet g:ycm_filepath_blacklist = {\n      \\ 'html': 1,\n      \\ 'jsx': 1,\n      \\ 'xml': 1,\n      \\}\n```\n\n### The `g:ycm_show_diagnostics_ui` option\n\nWhen set, this option turns on YCM's diagnostic display features. See the\n_Diagnostic display_ section in the _User Manual_ for more details.\n\nSpecific parts of the diagnostics UI (like the gutter signs, text highlighting,\ndiagnostic echo and auto location list population) can be individually turned on\nor off. See the other options below for details.\n\nNote that YCM's diagnostics UI is only supported for C-family languages.\n\nWhen set, this option also makes YCM remove all Syntastic checkers set for the\n`c`, `cpp`, `objc`, `objcpp`, and `cuda` filetypes since this would conflict\nwith YCM's own diagnostics UI.\n\nIf you're using YCM's identifier completer in C-family languages but cannot use\nthe clang-based semantic completer for those languages _and_ want to use the GCC\nSyntastic checkers, unset this option.\n\nDefault: `1`\n\n```viml\nlet g:ycm_show_diagnostics_ui = 1\n```\n\n### The `g:ycm_error_symbol` option\n\nYCM will use the value of this option as the symbol for errors in the Vim\ngutter.\n\nThis option is part of the Syntastic compatibility layer; if the option is not\nset, YCM will fall back to the value of the `g:syntastic_error_symbol` option\nbefore using this option's default.\n\nDefault: `>>`\n\n```viml\nlet g:ycm_error_symbol = '>>'\n```\n\n### The `g:ycm_warning_symbol` option\n\nYCM will use the value of this option as the symbol for warnings in the Vim\ngutter.\n\nThis option is part of the Syntastic compatibility layer; if the option is not\nset, YCM will fall back to the value of the `g:syntastic_warning_symbol` option\nbefore using this option's default.\n\nDefault: `>>`\n\n```viml\nlet g:ycm_warning_symbol = '>>'\n```\n\n### The `g:ycm_enable_diagnostic_signs` option\n\nWhen this option is set, YCM will put icons in Vim's gutter on lines that have a\ndiagnostic set. Turning this off will also turn off the `YcmErrorLine` and\n`YcmWarningLine` highlighting.\n\nThis option is part of the Syntastic compatibility layer; if the option is not\nset, YCM will fall back to the value of the `g:syntastic_enable_signs` option\nbefore using this option's default.\n\nDefault: `1`\n\n```viml\nlet g:ycm_enable_diagnostic_signs = 1\n```\n\n### The `g:ycm_enable_diagnostic_highlighting` option\n\nWhen this option is set, YCM will highlight regions of text that are related to\nthe diagnostic that is present on a line, if any.\n\nThis option is part of the Syntastic compatibility layer; if the option is not\nset, YCM will fall back to the value of the `g:syntastic_enable_highlighting`\noption before using this option's default.\n\nDefault: `1`\n\n```viml\nlet g:ycm_enable_diagnostic_highlighting = 1\n```\n\n### The `g:ycm_echo_current_diagnostic` option\n\nWhen this option is set, YCM will echo the text of the diagnostic present on the\ncurrent line when you move your cursor to that line. If a `FixIt` is available\nfor the current diagnostic, then ` (FixIt)` is appended.\n\nThis option is part of the Syntastic compatibility layer; if the option is not\nset, YCM will fall back to the value of the `g:syntastic_echo_current_error`\noption before using this option's default.\n\nDefault: `1`\n\n```viml\nlet g:ycm_echo_current_diagnostic = 1\n```\n\n### The `g:ycm_filter_diagnostics` option\n\nThis option controls which diagnostics will be rendered by YCM. This option\nholds a dictionary of key-values, where the keys are Vim's filetype strings\ndelimited by commas and values are dictionaries describing the filter.\n\nA filter is a dictionary of key-values, where the keys are the type of filter,\nand the value is a list of arguments to that filter. In the case of just a\nsingle item in the list, you may omit the brackets and just provide the argument\ndirectly. If any filter matches a diagnostic, it will be dropped and YCM will\nnot render it.\n\nThe following filter types are supported:\n\n- \"regex\": Accepts a string [regular expression][python-re]. This type matches\nwhen the regex (treated as case-insensitive) is found in the diagnostic text.\n- \"level\": Accepts a string level, either \"warning\" or \"error.\" This type\nmatches when the diagnostic has the same level.\n\n**NOTE:** The regex syntax is **NOT** Vim's, it's [Python's][python-re].\n\nDefault: `{}`\n\n```viml\nlet g:ycm_filter_diagnostics = {\n  \\ \"java\": {\n  \\      \"regex\": [ \".*taco.*\", ... ],\n  \\      \"level\": \"error\",\n  \\      ...\n  \\    }\n  \\ }\n```\n\n### The `g:ycm_always_populate_location_list` option\n\nWhen this option is set, YCM will populate the location list automatically every\ntime it gets new diagnostic data. This option is off by default so as not to\ninterfere with other data you might have placed in the location list.\n\nSee `:help location-list` in Vim to learn more about the location list.\n\nThis option is part of the Syntastic compatibility layer; if the option is not\nset, YCM will fall back to the value of the\n`g:syntastic_always_populate_loc_list` option before using this option's\ndefault.\n\nDefault: `0`\n\n```viml\nlet g:ycm_always_populate_location_list = 0\n```\n\n### The `g:ycm_open_loclist_on_ycm_diags` option\n\nWhen this option is set, `:YcmDiags` will automatically open the location list\nafter forcing a compilation and filling the list with diagnostic data.\n\nSee `:help location-list` in Vim to learn more about the location list.\n\nDefault: `1`\n\n```viml\nlet g:ycm_open_loclist_on_ycm_diags = 1\n```\n\n### The `g:ycm_complete_in_comments` option\n\nWhen this option is set to `1`, YCM will show the completion menu even when\ntyping inside comments.\n\nDefault: `0`\n\n```viml\nlet g:ycm_complete_in_comments = 0\n```\n\n### The `g:ycm_complete_in_strings` option\n\nWhen this option is set to `1`, YCM will show the completion menu even when\ntyping inside strings.\n\nNote that this is turned on by default so that you can use the filename\ncompletion inside strings. This is very useful for instance in C-family files\nwhere typing `#include \"` will trigger the start of filename completion. If you\nturn off this option, you will turn off filename completion in such situations\nas well.\n\nDefault: `1`\n\n```viml\nlet g:ycm_complete_in_strings = 1\n```\n\n### The `g:ycm_collect_identifiers_from_comments_and_strings` option\n\nWhen this option is set to `1`, YCM's identifier completer will also collect\nidentifiers from strings and comments. Otherwise, the text in comments and\nstrings will be ignored.\n\nDefault: `0`\n\n```viml\nlet g:ycm_collect_identifiers_from_comments_and_strings = 0\n```\n\n### The `g:ycm_collect_identifiers_from_tags_files` option\n\nWhen this option is set to `1`, YCM's identifier completer will also collect\nidentifiers from tags files. The list of tags files to examine is retrieved from\nthe `tagfiles()` Vim function which examines the `tags` Vim option. See `:h\n'tags'` for details.\n\nYCM will re-index your tags files if it detects that they have been modified.\n\nThe only supported tag format is the [Exuberant Ctags format][ctags-format]. The\nformat from \"plain\" ctags is NOT supported. Ctags needs to be called with the\n`--fields=+l` option (that's a lowercase `L`, not a one) because YCM needs the\n`language:<lang>` field in the tags output.\n\nSee the _FAQ_ for pointers if YCM does not appear to read your tag files.\n\nThis option is off by default because it makes Vim slower if your tags are on a\nnetwork directory.\n\nDefault: `0`\n\n```viml\nlet g:ycm_collect_identifiers_from_tags_files = 0\n```\n\n### The `g:ycm_seed_identifiers_with_syntax` option\n\nWhen this option is set to `1`, YCM's identifier completer will seed its\nidentifier database with the keywords of the programming language you're\nwriting.\n\nSince the keywords are extracted from the Vim syntax file for the filetype, all\nkeywords may not be collected, depending on how the syntax file was written.\nUsually at least 95% of the keywords are successfully extracted.\n\nDefault: `0`\n\n```viml\nlet g:ycm_seed_identifiers_with_syntax = 0\n```\n\n### The `g:ycm_extra_conf_vim_data` option\n\nIf you're using semantic completion for C-family files, this option might come\nhandy; it's a way of sending data from Vim to your `Settings` function in\nyour `.ycm_extra_conf.py` file.\n\nThis option is supposed to be a list of VimScript expression strings that are\nevaluated for every request to the [ycmd server][ycmd] and then passed to your\n`Settings` function as a `client_data` keyword argument.\n\nFor instance, if you set this option to `['v:version']`, your `Settings`\nfunction will be called like this:\n\n```python\n# The '801' value is of course contingent on Vim 8.1; in 8.0 it would be '800'\nSettings( ..., client_data = { 'v:version': 801 } )\n```\n\nSo the `client_data` parameter is a dictionary mapping Vim expression strings to\ntheir values at the time of the request.\n\nThe correct way to define parameters for your `Settings` function:\n\n```python\ndef Settings( **kwargs ):\n```\n\nYou can then get to `client_data` with `kwargs['client_data']`.\n\nDefault: `[]`\n\n```viml\nlet g:ycm_extra_conf_vim_data = []\n```\n\n### The `g:ycm_server_python_interpreter` option\n\nYCM will by default search for an appropriate Python interpreter on your system.\nYou can use this option to override that behavior and force the use of a\nspecific interpreter of your choosing.\n\n**NOTE:** This interpreter is only used for the [ycmd server][ycmd]. The YCM\nclient running inside Vim always uses the Python interpreter that's embedded\ninside Vim.\n\nDefault: `''`\n\n```viml\nlet g:ycm_server_python_interpreter = ''\n```\n\n### The `g:ycm_keep_logfiles` option\n\nWhen this option is set to `1`, YCM and the [ycmd completion server][ycmd] will\nkeep the logfiles around after shutting down (they are deleted on shutdown by\ndefault).\n\nTo see where the logfiles are, call `:YcmDebugInfo`.\n\nDefault: `0`\n\n```viml\nlet g:ycm_keep_logfiles = 0\n```\n\n### The `g:ycm_log_level` option\n\nThe logging level that YCM and the [ycmd completion server][ycmd] use. Valid\nvalues are the following, from most verbose to least verbose:\n- `debug`\n- `info`\n- `warning`\n- `error`\n- `critical`\n\nNote that `debug` is _very_ verbose.\n\nDefault: `info`\n\n```viml\nlet g:ycm_log_level = 'info'\n```\n\n### The `g:ycm_auto_start_csharp_server` option\n\nWhen set to `1`, the OmniSharp-Roslyn server will be automatically started\n(once per Vim session) when you open a C# file.\n\nDefault: `1`\n\n```viml\nlet g:ycm_auto_start_csharp_server = 1\n```\n\n### The `g:ycm_auto_stop_csharp_server` option\n\nWhen set to `1`, the OmniSharp-Roslyn server will be automatically stopped upon\nclosing Vim.\n\nDefault: `1`\n\n```viml\nlet g:ycm_auto_stop_csharp_server = 1\n```\n\n### The `g:ycm_csharp_server_port` option\n\nWhen g:ycm_auto_start_csharp_server is set to `1`, specifies the port for\nthe OmniSharp-Roslyn server to listen on. When set to `0` uses an unused port provided\nby the OS.\n\nDefault: `0`\n\n```viml\nlet g:ycm_csharp_server_port = 0\n```\n\n### The `g:ycm_csharp_insert_namespace_expr` option\n\nBy default, when YCM inserts a namespace, it will insert the `using` statement\nunder the nearest `using` statement. You may prefer that the `using` statement is\ninserted somewhere, for example, to preserve sorting. If so, you can set this\noption to override this behavior.\n\nWhen this option is set, instead of inserting the `using` statement itself, YCM\nwill set the global variable `g:ycm_namespace_to_insert` to the namespace to\ninsert, and then evaluate this option's value as an expression. The option's\nexpression is responsible for inserting the namespace - the default insertion\nwill not occur.\n\nDefault: ''\n\n```viml\nlet g:ycm_csharp_insert_namespace_expr = ''\n```\n\n### The `g:ycm_add_preview_to_completeopt` option\n\nWhen this option is set to `1`, YCM will add the `preview` string to Vim's\n`completeopt` option (see `:h completeopt`). If your `completeopt` option\nalready has `preview` set, there will be no effect. You can see the current\nstate of your `completeopt` setting with `:set completeopt?` (yes, the question\nmark is important).\n\nWhen `preview` is present in `completeopt`, YCM will use the `preview` window at\nthe top of the file to store detailed information about the current completion\ncandidate (but only if the candidate came from the semantic engine). For\ninstance, it would show the full function prototype and all the function\noverloads in the window if the current completion is a function name.\n\nDefault: `0`\n\n```viml\nlet g:ycm_add_preview_to_completeopt = 0\n```\n\n### The `g:ycm_autoclose_preview_window_after_completion` option\n\nWhen this option is set to `1`, YCM will auto-close the `preview` window after\nthe user accepts the offered completion string. If there is no `preview` window\ntriggered because there is no `preview` string in `completeopt`, this option is\nirrelevant. See the `g:ycm_add_preview_to_completeopt` option for more details.\n\nDefault: `0`\n\n```viml\nlet g:ycm_autoclose_preview_window_after_completion = 0\n```\n\n### The `g:ycm_autoclose_preview_window_after_insertion` option\n\nWhen this option is set to `1`, YCM will auto-close the `preview` window after\nthe user leaves insert mode. This option is irrelevant if\n`g:ycm_autoclose_preview_window_after_completion` is set or if no `preview`\nwindow is triggered. See the `g:ycm_add_preview_to_completeopt` option for more\ndetails.\n\nDefault: `0`\n\n```viml\nlet g:ycm_autoclose_preview_window_after_insertion = 0\n```\n\n### The `g:ycm_max_diagnostics_to_display` option\n\nThis option controls the maximum number of diagnostics shown to the user when\nerrors or warnings are detected in the file. This option is only relevant for\nthe C-family, C#, Java, JavaScript, and TypeScript languages.\n\nA special value of `0` means there is no limit.\n\nDefault: `30`\n\n```viml\nlet g:ycm_max_diagnostics_to_display = 30\n```\n\n### The `g:ycm_key_list_select_completion` option\n\nThis option controls the key mappings used to select the first completion\nstring.  Invoking any of them repeatedly cycles forward through the completion\nlist.\n\nSome users like adding `<Enter>` to this list.\n\nDefault: `['<TAB>', '<Down>']`\n\n```viml\nlet g:ycm_key_list_select_completion = ['<TAB>', '<Down>']\n```\n\n### The `g:ycm_key_list_previous_completion` option\n\nThis option controls the key mappings used to select the previous completion\nstring. Invoking any of them repeatedly cycles backwards through the completion\nlist.\n\nNote that one of the defaults is `<S-TAB>` which means Shift-TAB. That mapping\nwill probably only work in GUI Vim (Gvim or MacVim) and not in plain console Vim\nbecause the terminal usually does not forward modifier key combinations to Vim.\n\nDefault: `['<S-TAB>', '<Up>']`\n\n```viml\nlet g:ycm_key_list_previous_completion = ['<S-TAB>', '<Up>']\n```\n\n### The `g:ycm_key_list_stop_completion` option\n\nThis option controls the key mappings used to close the completion menu. This is\nuseful when the menu is blocking the view, when you need to insert the `<TAB>`\ncharacter, or when you want to expand a snippet from [UltiSnips][] and navigate\nthrough it.\n\nDefault: `['<C-y>']`\n\n```viml\nlet g:ycm_key_list_stop_completion = ['<C-y>']\n```\n\n### The `g:ycm_key_invoke_completion` option\n\nThis option controls the key mapping used to invoke the completion menu for\nsemantic completion. By default, semantic completion is triggered automatically\nafter typing `.`, `->` and `::` in insert mode (if semantic completion support\nhas been compiled in). This key mapping can be used to trigger semantic\ncompletion anywhere. Useful for searching for top-level functions and classes.\n\nConsole Vim (not Gvim or MacVim) passes `<Nul>` to Vim when the user types\n`<C-Space>` so YCM will make sure that `<Nul>` is used in the map command when\nyou're editing in console Vim, and `<C-Space>` in GUI Vim. This means that you\ncan just press `<C-Space>` in both console and GUI Vim and YCM will do the right\nthing.\n\nSetting this option to an empty string will make sure no mapping is created.\n\nDefault: `<C-Space>`\n\n```viml\nlet g:ycm_key_invoke_completion = '<C-Space>'\n```\n\n### The `g:ycm_key_detailed_diagnostics` option\n\nThis option controls the key mapping used to show the full diagnostic text when\nthe user's cursor is on the line with the diagnostic. It basically calls\n`:YcmShowDetailedDiagnostic`.\n\nSetting this option to an empty string will make sure no mapping is created.\n\nDefault: `<leader>d`\n\n```viml\nlet g:ycm_key_detailed_diagnostics = '<leader>d'\n```\n\n### The `g:ycm_global_ycm_extra_conf` option\n\nNormally, YCM searches for a `.ycm_extra_conf.py` file for compilation flags\n(see the User Guide for more details on how this works). This option specifies\na fallback path to a config file which is used if no `.ycm_extra_conf.py` is\nfound.\n\nYou can place such a global file anywhere in your filesystem.\n\nDefault: `''`\n\n```viml\nlet g:ycm_global_ycm_extra_conf = ''\n```\n\n### The `g:ycm_confirm_extra_conf` option\n\nWhen this option is set to `1` YCM will ask once per `.ycm_extra_conf.py` file\nif it is safe to be loaded. This is to prevent execution of malicious code\nfrom a `.ycm_extra_conf.py` file you didn't write.\n\nTo selectively get YCM to ask/not ask about loading certain `.ycm_extra_conf.py`\nfiles, see the `g:ycm_extra_conf_globlist` option.\n\nDefault: `1`\n\n```viml\nlet g:ycm_confirm_extra_conf = 1\n```\n\n### The `g:ycm_extra_conf_globlist` option\n\nThis option is a list that may contain several globbing patterns. If a pattern\nstarts with a `!` all `.ycm_extra_conf.py` files matching that pattern will be\nblacklisted, that is they won't be loaded and no confirmation dialog will be\nshown. If a pattern does not start with a `!` all files matching that pattern\nwill be whitelisted. Note that this option is not used when confirmation is\ndisabled using `g:ycm_confirm_extra_conf` and that items earlier in the list\nwill take precedence over the later ones.\n\nRules:\n\n* `*`       matches everything\n* `?`       matches any single character\n* `[seq]`   matches any character in seq\n* `[!seq]`  matches any char not in seq\n\nExample:\n\n```viml\nlet g:ycm_extra_conf_globlist = ['~/dev/*','!~/*']\n```\n\n* The first rule will match everything contained in the `~/dev` directory so\n  `.ycm_extra_conf.py` files from there will be loaded.\n* The second rule will match everything in the home directory so a\n  `.ycm_extra_conf.py` file from there won't be loaded.\n* As the first rule takes precedence everything in the home directory excluding\n  the `~/dev` directory will be blacklisted.\n\n**NOTE:** The glob pattern is first expanded with Python's\n`os.path.expanduser()` and then resolved with `os.path.abspath()` before being\nmatched against the filename.\n\nDefault: `[]`\n\n```viml\nlet g:ycm_extra_conf_globlist = []\n```\n\n### The `g:ycm_filepath_completion_use_working_dir` option\n\nBy default, YCM's filepath completion will interpret relative paths like `../`\nas being relative to the folder of the file of the currently active buffer.\nSetting this option will force YCM to always interpret relative paths as being\nrelative to Vim's current working directory.\n\nDefault: `0`\n\n```viml\nlet g:ycm_filepath_completion_use_working_dir = 0\n```\n\n### The `g:ycm_semantic_triggers` option\n\nThis option controls the character-based triggers for the various semantic\ncompletion engines. The option holds a dictionary of key-values, where the keys\nare Vim's filetype strings delimited by commas and values are lists of strings,\nwhere the strings are the triggers.\n\nSetting key-value pairs on the dictionary _adds_ semantic triggers to the\ninternal default set (listed below). You cannot remove the default triggers,\nonly add new ones.\n\nA \"trigger\" is a sequence of one or more characters that trigger semantic\ncompletion when typed. For instance, C++ (`cpp` filetype) has `.` listed as a\ntrigger. So when the user types `foo.`, the semantic engine will trigger and\nserve `foo`'s list of member functions and variables. Since C++ also has `->`\nlisted as a trigger, the same thing would happen when the user typed `foo->`.\n\nIt's also possible to use a regular expression as a trigger. You have to prefix\nyour trigger with `re!` to signify it's a regex trigger. For instance,\n`re!\\w+\\.` would only trigger after the `\\w+\\.` regex matches.\n\n**NOTE:** The regex syntax is **NOT** Vim's, it's [Python's][python-re].\n\nDefault: `[see next line]`\n\n```viml\nlet g:ycm_semantic_triggers =  {\n  \\   'c': ['->', '.'],\n  \\   'objc': ['->', '.', 're!\\[[_a-zA-Z]+\\w*\\s', 're!^\\s*[^\\W\\d]\\w*\\s',\n  \\            're!\\[.*\\]\\s'],\n  \\   'ocaml': ['.', '#'],\n  \\   'cpp,cuda,objcpp': ['->', '.', '::'],\n  \\   'perl': ['->'],\n  \\   'php': ['->', '::'],\n  \\   'cs,d,elixir,go,groovy,java,javascript,julia,perl6,python,scala,typescript,vb': ['.'],\n  \\   'ruby,rust': ['.', '::'],\n  \\   'lua': ['.', ':'],\n  \\   'erlang': [':'],\n  \\ }\n```\n\n### The `g:ycm_cache_omnifunc` option\n\nSome omnicompletion engines do not work well with the YCM cache\u2014in particular,\nthey might not produce all possible results for a given prefix. By unsetting\nthis option you can ensure that the omnicompletion engine is re-queried on every\nkeypress. That will ensure all completions will be presented, but might cause\nstuttering and lagginess if the omnifunc is slow.\n\nDefault: `1`\n\n```viml\nlet g:ycm_cache_omnifunc = 1\n```\n\n### The `g:ycm_use_ultisnips_completer` option\n\nBy default, YCM will query the UltiSnips plugin for possible completions of\nsnippet triggers. This option can turn that behavior off.\n\nDefault: `1`\n\n```viml\nlet g:ycm_use_ultisnips_completer = 1\n```\n\n### The `g:ycm_goto_buffer_command` option\n\nDefines where `GoTo*` commands result should be opened. Can take one of the\nfollowing values: `'same-buffer'`, `'split'`, or `'split-or-existing-window'`.\nIf this option is set to the `'same-buffer'` but current buffer can not be\nswitched (when buffer is modified and `nohidden` option is set), then result\nwill be opened in a split. When the option is set to\n`'split-or-existing-window'`, if the result is already open in a window of the\ncurrent tab page (or any tab pages with the `:tab` modifier; see below), it will\njump to that window. Otherwise, the result will be opened in a split as if the\noption was set to `'split'`.\n\nTo customize the way a new window is split, prefix the `GoTo*` command with one\nof the following modifiers: `:aboveleft`, `:belowright`, `:botright`,\n`:leftabove`, `:rightbelow`, `:topleft`, and `:vertical`. For instance, to\nsplit vertically to the right of the current window, run the command:\n```viml\n:rightbelow vertical YcmCompleter GoTo\n```\n\nTo open in a new tab page, use the `:tab` modifier with the `'split'` or\n`'split-or-existing-window'` options e.g.:\n```viml\n:tab YcmCompleter GoTo\n```\n\n**NOTE:** command modifiers were added in Vim 7.4.1898. If you are using an\nolder version, you can still configure this by setting the option to one of the\ndeprecated values: `'vertical-split'`, `'new-tab'`, or `'new-or-existing-tab'`.\n\nDefault: `'same-buffer'`\n\n```viml\nlet g:ycm_goto_buffer_command = 'same-buffer'\n```\n\n### The `g:ycm_disable_for_files_larger_than_kb` option\n\nDefines the max size (in Kb) for a file to be considered for completion. If this\noption is set to 0 then no check is made on the size of the file you're opening.\n\nDefault: 1000\n\n```viml\nlet g:ycm_disable_for_files_larger_than_kb = 1000\n```\n\n### The `g:ycm_use_clangd` option\n\nThis option controls whether **clangd** should be used as completion engine for\nC-family languages. Can take one of the following values: `1`, `0`, with\nmeanings:\n\n- `1`: YCM will use clangd if clangd binary exists in third party or it was\nprovided with `ycm_clangd_binary_path` option.\n- `0`: YCM will never use clangd completer.\n\nDefault: `1`\n\n```viml\nlet g:ycm_use_clangd = 1\n```\n\n### The `g:ycm_clangd_binary_path` option\n\nWhen `ycm_use_clangd` option is set to `1`, this option sets the path to\n**clangd** binary.\n\nDefault: `''`\n\n```viml\nlet g:ycm_clangd_binary_path = ''\n```\n\n### The `g:ycm_clangd_args` option\n\nThis option controls the command line arguments passed to the clangd binary. It\nappends new options and overrides the existing ones.\n\nDefault: `[]`\n\n```viml\nlet g:ycm_clangd_args = []\n```\n\n### The `g:ycm_clangd_uses_ycmd_caching` option\n\nThis option controls which ranking and filtering algorithm to use for completion\nitems. It can take values:\n\n- `1`: Uses ycmd's caching and filtering logic.\n- `0`: Uses clangd's caching and filtering logic.\n\nDefault: `1`\n\n```viml\nlet g:ycm_clangd_uses_ycmd_caching = 1\n```\n\n### The `g:ycm_language_server` option\n\nThis option lets YCM use an arbitrary LSP server, not unlike coc.nvim and others.\nHowever, the officially supported completers are favoured over custom LSP ones,\nso overriding an existing completer means first making sure YCM won't choose\nthat existing completer in the first place.\n\nA simple working example of this option can be found in the section called\n[\"Semantic Completion for Other Languages\"](#semantic-completion-for-other-languages).\n\nDefault: `[]`\n\n```viml\nlet g:ycm_language_server = []\n```\n\n### The `g:ycm_disable_signature_help` option\n\nThis option allows you to disable all signature help for all completion engines.\nThere is no way to disable it per-completer. This option is _reserved_, meaning\nthat while signature help support remains experimental, its values and meaning\nmay change and it may be removed in a future version.\n\nDefault: `0`\n\n```viml\n\" Disable signature help\nlet g:ycm_disable_signature_help = 1\n```\n\nFAQ\n---\n\n### I used to be able to `import vim` in `.ycm_extra_conf.py`, but now can't\n\nYCM was rewritten to use a client-server architecture where most of the logic is\nin the [ycmd server][ycmd]. So the magic `vim` module you could have previously\nimported in your `.ycm_extra_conf.py` files doesn't exist anymore.\n\nTo be fair, importing the magic `vim` module in extra conf files was never\nsupported in the first place; it only ever worked by accident and was never a\npart of the extra conf API.\n\nBut fear not, you should be able to tweak your extra conf files to continue\nworking by using the `g:ycm_extra_conf_vim_data` option. See the docs on that\noption for details.\n\n### I get `ImportError` exceptions that mention `PyInit_ycm_core` or `initycm_core`\n\nThese errors are caused by building the YCM native libraries for Python 2 and\ntrying to load them into a Python 3 process (or the other way around).\n\nFor instance, if building for Python 2 but loading in Python 3:\n\n```\nImportError: dynamic module does not define init function (PyInit_ycm_core)\n```\n\nIf building for Python 3 but loading in Python 2:\n\n```\nImportError: dynamic module does not define init function (initycm_core)\n```\n\nSetting the `g:ycm_server_python_interpreter` option to force the use of a\nspecific Python interpreter for `ycmd` is usually the easiest way to solve the\nproblem. Common values for that option are `/usr/bin/python` and\n`/usr/bin/python3`.\n\n### I get a linker warning regarding `libpython` on macOS when compiling YCM\n\nIf the warning is `ld: warning: path '/usr/lib/libpython2.7.dylib' following -L\nnot a directory`, then feel free to ignore it; it's caused by a limitation of\nCMake and is not an issue. Everything should still work fine.\n\n### I get a weird window at the top of my file when I use the semantic engine\n\nThis is Vim's `preview` window. Vim uses it to show you extra information about\nsomething if such information is available. YCM provides Vim with such extra\ninformation. For instance, when you select a function in the completion list,\nthe `preview` window will hold that function's prototype and the prototypes of\nany overloads of the function. It will stay there after you select the\ncompletion so that you can use the information about the parameters and their\ntypes to write the function call.\n\nIf you would like this window to auto-close after you select a completion\nstring, set the `g:ycm_autoclose_preview_window_after_completion` option to `1`\nin your `vimrc` file. Similarly, the `g:ycm_autoclose_preview_window_after_insertion`\noption can be set to close the `preview` window after leaving insert mode.\n\nIf you don't want this window to ever show up, add `set completeopt-=preview` to\nyour `vimrc`. Also make sure that the `g:ycm_add_preview_to_completeopt` option\nis set to `0`.\n\n### It appears that YCM is not working\n\nIn Vim, run `:messages` and carefully read the output. YCM will echo messages to\nthe message log if it encounters problems. It's likely you misconfigured\nsomething and YCM is complaining about it.\n\nAlso, you may want to run the `:YcmDebugInfo` command; it will make YCM spew out\nvarious debugging information, including the YCM and [ycmd][] logfile paths and\nthe compile flags for the current file if the file is a C-family language file\nand you have compiled in Clang support. Logfiles can be opened in the editor\nusing [the `:YcmToggleLogs` command](#the-ycmtogglelogs-command).\n\n### Sometimes it takes much longer to get semantic completions than normal\n\nThis means that libclang (which YCM uses for C-family semantic completion)\nfailed to pre-compile your file's preamble. In other words, there was an error\ncompiling some of the source code you pulled in through your header files. I\nsuggest calling the `:YcmDiags` command to see what they were.\n\nBottom line, if libclang can't pre-compile your file's preamble because there\nwere errors in it, you're going to get slow completions because there's no AST\ncache.\n\n### YCM auto-inserts completion strings I don't want!\n\nIf this happens when Vim automatically wraps text then it's a Vim bug that has\nbeen fixed in version 8.0.0127. Update your Vim to this version or later.\n\nThis could also be some mappings that interfere with YCM's internal ones. Make\nsure you don't have something mapped to `<C-p>`, `<C-x>` or `<C-u>` (in insert\nmode).\n\nYCM _never_ selects something for you; it just shows you a menu and the user has\nto explicitly select something. If something is being selected automatically,\nthis means there's a bug or a misconfiguration somewhere.\n\n### I get a `E227: mapping already exists for <blah>` error when I start Vim\n\nThis means that YCM tried to set up a key mapping but failed because you already\nhad something mapped to that key combination. The `<blah>` part of the message\nwill tell you what was the key combination that failed.\n\nLook in the _Options_ section and see if any of the default mappings conflict\nwith your own. Then change that option value to something else so that the\nconflict goes away.\n\n### I get `'GLIBC_2.XX' not found (required by libclang.so)` when starting Vim\n\nYour system is too old for the precompiled binaries from llvm.org. Compile\nClang on your machine and then link against the `libclang.so` you just produced.\nSee the full installation guide for help.\n\n### I get `LONG_BIT definition appears wrong for platform` when compiling\n\nLook at the output of your CMake call. There should be a line in it like the\nfollowing (with `.dylib` in place of `.so` on macOS):\n\n```\n-- Found PythonLibs: /usr/lib/libpython2.7.so (Required is at least version \"2.5\")\n```\n\nThat would be the **correct** output. An example of **incorrect** output would\nbe the following:\n\n```\n-- Found PythonLibs: /usr/lib/libpython2.7.so (found suitable version \"2.5.1\", minimum required is \"2.5\")\n```\n\nNotice how there's an extra bit of output there, the `found suitable version\n\"<version>\"` part, where `<version>` is not the same as the version of the\ndynamic library. In the example shown, the library is version 2.7 but the second\nstring is version `2.5.1`.\n\nThis means that CMake found one version of Python headers and a different\nversion for the library. This is wrong. It can happen when you have multiple\nversions of Python installed on your machine.\n\nYou should probably add the following flags to your cmake call (again, `dylib`\ninstead of `so` on macOS):\n\n```\n-DPYTHON_INCLUDE_DIR=/usr/include/python2.7 -DPYTHON_LIBRARY=/usr/lib/libpython2.7.so\n```\n\nThis will force the paths to the Python include directory and the Python library\nto use. You may need to set these flags to something else, but you need to make\nsure you use the same version of Python that your Vim binary is built against,\nwhich is highly likely to be the system's default Python.\n\n### I get `libpython2.7.a [...] relocation R_X86_64_32` when compiling\n\nThe error is usually encountered when compiling YCM on Centos or RHEL. The full\nerror looks something like the following:\n\n```\n/usr/bin/ld: /usr/local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC\n```\n\nIt's possible to get a slightly different error that's similar to the one above.\nHere's the problem and how you solve it:\n\nYour `libpython2.7.a` was not compiled with `-fPIC` so it can't be linked into\n`ycm_core.so`.  Use the `-DPYTHON_LIBRARY=` CMake flag to point it to a `.so`\nversion of libpython on your machine (for instance,\n`-DPYTHON_LIBRARY=/usr/lib/libpython2.7.so`). Naturally, this means you'll have\nto go through the full installation guide by hand.\n\n### I see `undefined symbol: clang_getCompletionFixIt` in the server logs.\n\nThis means that the server is trying to load a version of libclang that is too\nold. You need at least libclang 9.0.0. We recommend running the `install.py`\nscript without `--system-libclang` or downloading the [latest prebuilt binaries\nfrom llvm.org][clang-download] when going through the [full installation\nguide](#full-installation-guide).\n\n### I get `Fatal Python error: PyThreadState_Get: no current thread` on startup\n\nThis is caused by linking a static version of `libpython` into ycmd's\n`ycm_core.so`.  This leads to multiple copies of the python interpreter loaded\nwhen `python` loads `ycmd_core.so` and this messes up python's global state.\nThe details aren't important.\n\nThe solution is that the version of Python linked and run against must be built\nwith either `--enable-shared` or `--enable-framework` (on OS X).\nThis is achieved as follows (**NOTE:** for macOS, replace `--enable-shared`\nwith `--enable-framework`):\n\n- When building python from source: `./configure --enable-shared {options}`\n- When building python from pyenv:\n  `PYTHON_CONFIGURE_OPTS=\"--enable-shared\" pyenv install {version}`\n\n\n### `install.py` says python must be compiled with `--enable-framework`. Wat?\n\nSee the previous answer for how to ensure your python is built to support\ndynamic modules.\n\n### YCM does not read identifiers from my tags files\n\nFirst, put `let g:ycm_collect_identifiers_from_tags_files = 1` in your vimrc.\n\nMake sure you are using [Exuberant Ctags][exuberant-ctags] to produce your tags\nfiles since the only supported tag format is the [Exuberant Ctags\nformat][ctags-format]. The format from \"plain\" ctags is NOT supported. The\noutput of `ctags --version` should list \"Exuberant Ctags\". See [Universal\nCtags][universal-ctags] for a maintained version.\n\nCtags needs to be called with the `--fields=+l` (that's a lowercase `L`, not a\none) option because YCM needs the `language:<lang>` field in the tags output.\n\n**NOTE:** [Exuberant Ctags][exuberant-ctags] by default sets language tag for\n`*.h` files as `C++`. If you have C (not C++) project, consider giving parameter\n`--langmap=c:.c.h` to ctags to see tags from `*.h` files.\n\n**NOTE:** macOS comes with \"plain\" ctags installed by default. `brew install\nctags` will get you the Exuberant Ctags version.\n\nAlso make sure that your Vim `tags` option is set correctly. See `:h 'tags'` for\ndetails. If you want to see which tag files YCM will read for a given buffer,\nrun `:echo tagfiles()` with the relevant buffer active. Note that that function\nwill only list tag files that already exist.\n\n### `CTRL-U` in insert mode does not work while the completion menu is visible\n\nYCM uses `completefunc` completion mode to show suggestions and Vim disables\n`<C-U>` in that mode as a \"feature.\" Sadly there's nothing I can do about this.\n\n### My `CTRL-R` mapping does not work while the completion menu is visible\n\nVim prevents remapping of the `<C-R>` key in all `<C-X>` completion modes\n(except the `<C-X><C-N>`/`<C-X><C-P>` mode which operates in the same mode as\n`<C-N>`/`<C-P>`) and YCM uses the `<C-X><C-U>` (`completefunc`) mode for\ncompletions. This means that adding `<C-R>` to any of the `g:ycm_key_list_*`\noptions has no effect. You need to use another key.\n\n### YCM conflicts with UltiSnips TAB key usage\n\nYCM comes with support for UltiSnips (snippet suggestions in the popup menu),\nbut you'll have to change the UltiSnips mappings. See `:h UltiSnips-triggers` in\nVim for details. You'll probably want to change some/all of the following\noptions:\n\n```viml\ng:UltiSnipsExpandTrigger\ng:UltiSnipsJumpForwardTrigger\ng:UltiSnipsJumpBackwardTrigger\n```\n\n### Snippets added with `:UltiSnipsAddFiletypes` do not appear in the popup menu\n\nFor efficiency, YCM only fetches UltiSnips snippets in specific scenarios like\nvisiting a buffer or setting its filetype. You can force YCM to retrieve them by\nmanually triggering the `FileType` autocommand:\n\n```viml\n:doautocmd FileType\n```\n\n### Why isn't YCM just written in plain VimScript, FFS?\n\nBecause of the identifier completion engine and subsequence-based filtering.\nLet's say you have _many_ dozens of files open in a single Vim instance (I often\ndo); the identifier-based engine then needs to store thousands (if not tens of\nthousands) of identifiers in its internal data-structures. When the user types,\nYCM needs to perform subsequence-based filtering on _all_ of those identifiers\n(every single one!) in less than 10 milliseconds.\n\nI'm sorry, but that level of performance is just plain impossible to achieve\nwith VimScript. I've tried, and the language is just too slow. No, you can't get\nacceptable performance even if you limit yourself to just the identifiers in the\ncurrent file and simple prefix-based filtering.\n\n### Why does YCM demand such a recent version of Vim?\n\nYCM needs a version of Vim with the timers feature to achieve full\nasynchronicity. This feature is available since Vim 7.4.1578.\n\nYCM provides powerful new functionality like signature help by using new\nfeatures in Vim such as popup windows, and new APIs such as `pum_getpos`. This\nrequires Vim 8.1.1875 and we strongly recommend using this version or later.\n\n### Nasty bugs happen if I have the `vim-autoclose` plugin installed\n\nUse the [delimitMate][] plugin instead. It does the same thing without\nconflicting with YCM.\n\n### Is there some sort of YCM mailing list? I have questions\n\nIf you have questions about the plugin or need help, please use the\n[ycm-users][] mailing list, _don't_ create issues on the tracker. The tracker is\nfor bug reports and feature requests.\n\n### I get an internal compiler error when installing\n\nThis can be a problem on virtual servers with limited memory. A possible\nsolution is to add more swap memory. A more practical solution would be to force\nthe build script to run only one compile job at a time. You can do this by\nsetting the `YCM_CORES` environment variable to `1`. Example:\n\n```\nYCM_CORES=1 ./install.py --clang-completer\n```\n\n### I get weird errors when I press `Ctrl-C` in Vim\n\n_Never_ use `Ctrl-C` in Vim.\n\nUsing `Ctrl-C` to exit insert mode in Vim is a bad idea. The main issue here is\nthat `Ctrl-C` in Vim doesn't just leave insert mode, it leaves it without\ntriggering `InsertLeave` autocommands (as per Vim docs). This is a bad idea and\nis likely to break many other things and not just YCM.\n\nBottom line, if you use `Ctrl-C` to exit insert mode in Vim, you're gonna have a\nbad time.\n\nIf pressing `<esc>` is too annoying (agreed, it is), we suggest mapping it to\nsomething more convenient. On a QWERTY keyboard, a good pick for the `<esc>` map\nis `inoremap jk <Esc>`. This is right on the home row, it's an incredibly rare\ndigraph in English and if you ever need to type those two chars in sequence in\ninsert mode, you just type `j`, then wait 500ms, then type `k`.\n\n### Why did YCM stop using Syntastic for diagnostics display?\n\nPreviously, YCM would send any diagnostics it would receive from the libclang\nsemantic engine to Syntastic for display as signs in the gutter, red squiggles\netc. Today, YCM uses its own code to do that.\n\nUsing Syntastic for this was always a kludge. Syntastic assumes its \"checker\"\nplugins behave in a certain way; those assumptions have never fit YCM. For\ninstance, YCM continuously recompiles your code in the background for C-family\nlanguages and tries to push new diagnostics to the user as fast as possible,\neven while the user types.\n\nSyntastic assumes that a checker only runs on file save (\"active\" mode) or even\nless frequently, when the user explicitly invokes it (\"passive\" mode). This\nmismatch in assumptions causes performance problems since Syntastic code isn't\noptimized for this use case of constant diagnostic refreshing.\n\nPoor support for this use case also led to crash bugs in Vim caused by\nSyntastic-Vim interactions ([issue #593][issue-593]) and other problems, like\nrandom Vim flickering. Attempts were made to resolve these issues in\nSyntastic, but ultimately some of them failed (for various reasons).\n\nImplementing diagnostic display code directly in YCM resolves all of these\nproblems. Performance also improved substantially since the relevant code is now\nwritten in Python instead of VimScript (which is very slow) and is tailored only\nfor YCM's use-cases. We were also able to introduce new features in this area\nsince we're now not limited to the Syntastic checker API.\n\nWe've tried to implement this in the most backwards-compatible way possible; YCM\noptions that control diagnostic display fall back to Syntastic options that\ncontrol the same concepts if the user has those set.\n\nStill, some Syntastic-specific configuration you might have had might not\nbe supported by the new code. Please file issues on the tracker in such\ncases; if we find the request to be reasonable, we'll find a way to address it.\n\n### Completion doesn't work with the C++ standard library headers\n\nThis is caused by an issue with libclang that only affects some operating\nsystems. Compiling with `clang` the binary will use the correct default header\nsearch paths but compiling with `libclang.so` (which YCM uses) does not.\n\nmacOS is normally affected, but there's a workaround in YCM for that specific\nOS. If you're not running that OS but still have the same problem, continue\nreading.\n\nThe workaround is to call `echo | clang -v -E -x c++ -` and look at the\npaths under the `#include <...> search starts here:` heading. You should take\nthose paths, prepend `-isystem` to each individual path and append them all to\nthe list of flags you return from your `Settings` function in your\n`.ycm_extra_conf.py` file.\n\nSee [issue #303][issue-303] for details.\n\n### When I start vim I get a runtime error saying `R6034 An application has made an attempt to load the C runtime library incorrectly.`\n\n[CMake and other things seem to screw up the PATH with their own msvcrXX.dll\nversions.][identify-R6034-cause] Add the following to the very top of your vimrc\nto remove these entries from the path.\n\n```python\npython << EOF\nimport os\nimport re\npath = os.environ['PATH'].split(';')\n\ndef contains_msvcr_lib(folder):\n    try:\n        for item in os.listdir(folder):\n            if re.match(r'msvcr\\d+\\.dll', item):\n                return True\n    except:\n        pass\n    return False\n\npath = [folder for folder in path if not contains_msvcr_lib(folder)]\nos.environ['PATH'] = ';'.join(path)\nEOF\n```\n\n### I hear that YCM only supports Python 2, is that true?\n\n**No.** Both the Vim client and the [ycmd server][ycmd] run on Python 2 or 3. If\nyou are talking about code completion in a project, you can configure the Python\nused for your project through a `.ycm_extra_conf.py` file. See [the Python\nSemantic Completion section](#python-semantic-completion) for more details.\n\n### On Windows I get `E887: Sorry, this command is disabled, the Python's site module could not be loaded`\n\nIf you are running vim on Windows with Python 2.7.11, this is likely caused by a\n[bug][vim_win-python2.7.11-bug]. Follow this\n[workaround][vim_win-python2.7.11-bug_workaround] or use a different version\n(Python 2.7.12 does not suffer from the bug).\n\n### I can't complete Python packages in a virtual environment.\n\nThis means that the Python used to run [Jedi][] is not the Python of the virtual\nenvironment you're in. To resolve this you should create a `.ycm_extra_conf.py`\nfile at the root of your project that sets the `interpreter_path` option to the\nPython of your virtual environment, e.g.\n\n```python\ndef Settings(**kwargs):\n  return {\n    'interpreter_path': '/path/to/virtual/env/bin/python'\n  }\n```\n\nSee [the Python Semantic Completion section](#python-semantic-completion) for\nmore details.\n\n### I want to defer loading of YouCompleteMe until after Vim finishes booting\n\nIn recent versions of Vim, you can install YCM in a folder under\n`~/.vim/pack/*/opt` and then load it once the user is idle via an autocommand:\n\n```viml\naugroup load_ycm\n  autocmd!\n  autocmd CursorHold, CursorHoldI * :packadd YouCompleteMe\n                                \\ | autocmd! load_ycm\naugroup END\n```\n\n### YCM does not shut down when I quit Vim\n\nYCM relies on the `VimLeave` event to shut down the [ycmd server][ycmd]. Some\nplugins prevent this event from triggering by exiting Vim through an autocommand\nwithout using the `nested` keyword (see `:h autocmd-nested`). You should\nidentify which plugin is responsible for the issue and report it to the plugin\nauthor. Note that when this happens, [ycmd][] will automatically shut itself\ndown after 30 minutes.\n\n### YCM does not work with my Anaconda Python setup\n\nAnaconda is often incompatible with the pre-built libclang used by YCM\nand therefore is not supported. The recommended way to solve this is to run\n`/path/to/real/python install.py` (for example `/usr/bin/python install.py`).\n\nIf you want completion in Anaconda projects, point the `interpreter_path` option\nin your `.ycm_extra_conf.py` file to the path of your Anaconda Python e.g.\n\n```python\ndef Settings(**kwargs):\n  return {\n    'interpreter_path': '/path/to/anaconda/python'\n  }\n```\n\nSee [the Python Semantic Completion section](#python-semantic-completion) for\nmore details.\n\n### Automatic import insertion after selecting a completion breaks undo\n\nThis is a Vim bug fixed in version 8.1.0256. Update your Vim to this version or\nlater.\n\n### `TAB` is already mapped to trigger completion in the command-line window\n\nVim automatically maps the key set by the `wildchar` option, which is `TAB` by\ndefault, to complete commands in the command-line window. If you would prefer\nusing this key to cycle through YCM's suggestions without changing the value of\n`wildchar`, add the following to your vimrc:\n\n```viml\nautocmd CmdwinEnter * inoremap <expr><buffer> <TAB>\n      \\ pumvisible() ? \"\\<C-n>\" : \"\\<TAB>\"\n```\n\nContributor Code of Conduct\n---------------------------\n\nPlease note that this project is released with a [Contributor Code of\nConduct][ccoc]. By participating in this project you agree to abide by its\nterms.\n\n\nContact\n-------\n\nIf you have questions about the plugin or need help, please join the [Gitter\nroom][gitter] or use the [ycm-users][] mailing list.\n\nIf you have bug reports or feature suggestions, please use the [issue\ntracker][tracker]. Before you do, please carefully read\n[CONTRIBUTING.md][contributing-md] as this asks for important diagnostics which\nthe team will use to help get you going.\n\nThe latest version of the plugin is available at\n<http://ycm-core.github.io/YouCompleteMe/>.\n\nThe author's homepage is <http://val.markovic.io>.\n\nPlease do **NOT** go to #vim on freenode for support. Please contact the\nYouCompleteMe maintainers directly using the [contact details](#contact).\n\nLicense\n-------\n\nThis software is licensed under the [GPL v3 license][gpl].\n\u00a9 2015-2018 YouCompleteMe contributors\n\n[ycmd]: https://github.com/Valloric/ycmd\n[Clang]: http://clang.llvm.org/\n[vundle]: https://github.com/VundleVim/Vundle.vim#about\n[pathogen]: https://github.com/tpope/vim-pathogen#pathogenvim\n[clang-download]: http://llvm.org/releases/download.html\n[brew]: http://brew.sh\n[cmake-download]: https://cmake.org/download/\n[macvim]: https://macvim-dev.github.io/macvim/\n[vimrc]: http://vimhelp.appspot.com/starting.txt.html#vimrc\n[gpl]: http://www.gnu.org/copyleft/gpl.html\n[vim]: http://www.vim.org/\n[syntastic]: https://github.com/scrooloose/syntastic\n[lightline]: https://github.com/itchyny/lightline.vim\n[ycm_flags_example]: https://github.com/Valloric/YouCompleteMe/blob/master/.ycm_extra_conf.py\n[ycmd_flags_example]: https://raw.githubusercontent.com/Valloric/ycmd/66030cd94299114ae316796f3cad181cac8a007c/.ycm_extra_conf.py\n[compdb]: http://clang.llvm.org/docs/JSONCompilationDatabase.html\n[subsequence]: https://en.wikipedia.org/wiki/Subsequence\n[listtoggle]: https://github.com/Valloric/ListToggle\n[vim-build]: https://github.com/Valloric/YouCompleteMe/wiki/Building-Vim-from-source\n[tracker]: https://github.com/Valloric/YouCompleteMe/issues?state=open\n[issue18]: https://github.com/Valloric/YouCompleteMe/issues/18\n[delimitMate]: https://github.com/Raimondi/delimitMate\n[completer-api]: https://github.com/Valloric/ycmd/blob/master/ycmd/completers/completer.py\n[eclim]: http://eclim.org/\n[jedi]: https://github.com/davidhalter/jedi\n[ultisnips]: https://github.com/SirVer/ultisnips/blob/master/doc/UltiSnips.txt\n[exuberant-ctags]: http://ctags.sourceforge.net/\n[universal-ctags]: https://github.com/universal-ctags/ctags\n[ctags-format]: http://ctags.sourceforge.net/FORMAT\n[vundle-bug]: https://github.com/VundleVim/Vundle.vim/issues/48\n[ycm-users]: https://groups.google.com/forum/?hl=en#!forum/ycm-users\n[omnisharp-roslyn]: https://github.com/OmniSharp/omnisharp-roslyn\n[issue-303]: https://github.com/Valloric/YouCompleteMe/issues/303\n[issue-593]: https://github.com/Valloric/YouCompleteMe/issues/593\n[issue-669]: https://github.com/Valloric/YouCompleteMe/issues/669\n[status-mes]: https://groups.google.com/forum/#!topic/vim_dev/WeBBjkXE8H8\n[python-re]: https://docs.python.org/2/library/re.html#regular-expression-syntax\n[Bear]: https://github.com/rizsotto/Bear\n[ygen]: https://github.com/rdnetto/YCM-Generator\n[Gopls]: https://github.com/golang/go/wiki/gopls\n[gopls-preferences]: https://github.com/golang/tools/blob/master/internal/lsp/server.go#L120\n[TSServer]: https://github.com/Microsoft/TypeScript/tree/master/src/server\n[jsconfig.json]: https://code.visualstudio.com/docs/languages/jsconfig\n[tsconfig.json]: https://www.typescriptlang.org/docs/handbook/tsconfig-json.html\n[vim-win-download]: https://github.com/vim/vim-win32-installer/releases\n[python-win-download]: https://www.python.org/downloads/windows/\n[visual-studio-download]: https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&rel=15\n[7z-download]: http://www.7-zip.org/download.html\n[mono-install-macos]: http://www.mono-project.com/docs/getting-started/install/mac/\n[mono-install-linux]: https://www.mono-project.com/download/stable/#download-lin\n[mono-install]: http://www.mono-project.com/docs/getting-started/install/\n[go-install]: https://golang.org/doc/install\n[npm-install]: https://docs.npmjs.com/getting-started/installing-node#1-install-nodejs--npm\n[tern-instructions]: https://github.com/Valloric/YouCompleteMe/wiki/JavaScript-Semantic-Completion-through-Tern\n[Tern]: http://ternjs.net\n[rls]: https://github.com/rust-lang/rls\n[rls-preferences]: https://github.com/rust-lang/rls#configuration\n[rust-src]: https://www.rust-lang.org/downloads.html\n[add-msbuild-to-path]: http://stackoverflow.com/questions/6319274/how-do-i-run-msbuild-from-the-command-line-using-windows-sdk-7-1\n[identify-R6034-cause]: http://stackoverflow.com/questions/14552348/runtime-error-r6034-in-embedded-python-application/34696022\n[ccoc]: https://github.com/Valloric/YouCompleteMe/blob/master/CODE_OF_CONDUCT.md\n[vim_win-python2.7.11-bug]: https://github.com/vim/vim/issues/717\n[vim_win-python2.7.11-bug_workaround]: https://github.com/vim/vim-win32-installer/blob/a27bbdba9bb87fa0e44c8a00d33d46be936822dd/appveyor.bat#L86-L88\n[gitter]: https://gitter.im/Valloric/YouCompleteMe\n[ninja-compdb]: https://ninja-build.org/manual.html\n[++enc]: http://vimdoc.sourceforge.net/htmldoc/editing.html#++enc\n[rustup]: https://www.rustup.rs/\n[contributing-md]: https://github.com/Valloric/YouCompleteMe/blob/master/CONTRIBUTING.md\n[jdt.ls]: https://github.com/eclipse/eclipse.jdt.ls\n[jdk-install]: http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n[mvn-project]: https://maven.apache.org/guides/getting-started/maven-in-five-minutes.html\n[eclipse-project]: https://help.eclipse.org/oxygen/index.jsp?topic=%2Forg.eclipse.platform.doc.isv%2Freference%2Fmisc%2Fproject_description_file.html\n[gradle-project]: https://docs.gradle.org/current/userguide/tutorial_java_projects.html\n[eclipse-dot-project]: https://help.eclipse.org/oxygen/index.jsp?topic=%2Forg.eclipse.platform.doc.isv%2Freference%2Fmisc%2Fproject_description_file.html\n[eclipse-dot-classpath]: https://help.eclipse.org/mars/index.jsp?topic=%2Forg.eclipse.jdt.doc.isv%2Freference%2Fapi%2Forg%2Feclipse%2Fjdt%2Fcore%2FIClasspathEntry.html\n[ycmd-eclipse-project]: https://github.com/Valloric/ycmd/tree/3602f38ef7a762fc765afd75e562aec9a134711e/ycmd/tests/java/testdata/simple_eclipse_project\n[ycmd-mvn-pom-xml]: https://github.com/Valloric/ycmd/blob/3602f38ef7a762fc765afd75e562aec9a134711e/ycmd/tests/java/testdata/simple_maven_project/pom.xml\n[ycmd-gradle-project]: https://github.com/Valloric/ycmd/tree/3602f38ef7a762fc765afd75e562aec9a134711e/ycmd/tests/java/testdata/simple_gradle_project\n[jdtls-release]: http://download.eclipse.org/jdtls/milestones\n[jdtls-preferences]: https://github.com/eclipse/eclipse.jdt.ls/blob/master/org.eclipse.jdt.ls.core/src/org/eclipse/jdt/ls/core/internal/preferences/Preferences.java\n[diacritic]: https://www.unicode.org/glossary/#diacritic\n[regex]: https://pypi.org/project/regex/\n[clangd]: https://clang.llvm.org/extra/clangd.html\n[fixedcdb]: https://clang.llvm.org/docs/JSONCompilationDatabase.html#alternatives\n[clangd-indexing]: https://clang.llvm.org/extra/clangd.html#project-wide-indexing\n[vimspector]: https://github.com/puremourning/vimspector\n[roslyn-releases]: https://github.com/OmniSharp/omnisharp-roslyn/releases\n[compiledb]: https://pypi.org/project/compiledb/\n[signature-help-pr]: https://github.com/ycm-core/ycmd/pull/1255\n"}, {"repo": "google-research/bert", "language": "Python", "readme_contents": "# BERT\n\n**\\*\\*\\*\\*\\* New May 31st, 2019: Whole Word Masking Models \\*\\*\\*\\*\\***\n\nThis is a release of several new models which were the result of an improvement\nthe pre-processing code.\n\nIn the original pre-processing code, we randomly select WordPiece tokens to\nmask. For example:\n\n`Input Text: the man jumped up , put his basket on phil ##am ##mon ' s head`\n`Original Masked Input: [MASK] man [MASK] up , put his [MASK] on phil\n[MASK] ##mon ' s head`\n\nThe new technique is called Whole Word Masking. In this case, we always mask\n*all* of the the tokens corresponding to a word at once. The overall masking\nrate remains the same.\n\n`Whole Word Masked Input: the man [MASK] up , put his basket on [MASK] [MASK]\n[MASK] ' s head`\n\nThe training is identical -- we still predict each masked WordPiece token\nindependently. The improvement comes from the fact that the original prediction\ntask was too 'easy' for words that had been split into multiple WordPieces.\n\nThis can be enabled during data generation by passing the flag\n`--do_whole_word_mask=True` to `create_pretraining_data.py`.\n\nPre-trained models with Whole Word Masking are linked below. The data and\ntraining were otherwise identical, and the models have identical structure and\nvocab to the original models. We only include BERT-Large models. When using\nthese models, please make it clear in the paper that you are using the Whole\nWord Masking variant of BERT-Large.\n\n*   **[`BERT-Large, Uncased (Whole Word Masking)`](https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip)**:\n    24-layer, 1024-hidden, 16-heads, 340M parameters\n\n*   **[`BERT-Large, Cased (Whole Word Masking)`](https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip)**:\n    24-layer, 1024-hidden, 16-heads, 340M parameters\n\nModel                                    | SQUAD 1.1 F1/EM | Multi NLI Accuracy\n---------------------------------------- | :-------------: | :----------------:\nBERT-Large, Uncased (Original)           | 91.0/84.3       | 86.05\nBERT-Large, Uncased (Whole Word Masking) | 92.8/86.7       | 87.07\nBERT-Large, Cased (Original)             | 91.5/84.8       | 86.09\nBERT-Large, Cased (Whole Word Masking)   | 92.9/86.7       | 86.46\n\n**\\*\\*\\*\\*\\* New February 7th, 2019: TfHub Module \\*\\*\\*\\*\\***\n\nBERT has been uploaded to [TensorFlow Hub](https://tfhub.dev). See\n`run_classifier_with_tfhub.py` for an example of how to use the TF Hub module,\nor run an example in the browser on\n[Colab](https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\n\n**\\*\\*\\*\\*\\* New November 23rd, 2018: Un-normalized multilingual model + Thai +\nMongolian \\*\\*\\*\\*\\***\n\nWe uploaded a new multilingual model which does *not* perform any normalization\non the input (no lower casing, accent stripping, or Unicode normalization), and\nadditionally inclues Thai and Mongolian.\n\n**It is recommended to use this version for developing multilingual models,\nespecially on languages with non-Latin alphabets.**\n\nThis does not require any code changes, and can be downloaded here:\n\n*   **[`BERT-Base, Multilingual Cased`](https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip)**:\n    104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters\n\n**\\*\\*\\*\\*\\* New November 15th, 2018: SOTA SQuAD 2.0 System \\*\\*\\*\\*\\***\n\nWe released code changes to reproduce our 83% F1 SQuAD 2.0 system, which is\ncurrently 1st place on the leaderboard by 3%. See the SQuAD 2.0 section of the\nREADME for details.\n\n**\\*\\*\\*\\*\\* New November 5th, 2018: Third-party PyTorch and Chainer versions of\nBERT available \\*\\*\\*\\*\\***\n\nNLP researchers from HuggingFace made a\n[PyTorch version of BERT available](https://github.com/huggingface/pytorch-pretrained-BERT)\nwhich is compatible with our pre-trained checkpoints and is able to reproduce\nour results. Sosuke Kobayashi also made a\n[Chainer version of BERT available](https://github.com/soskek/bert-chainer)\n(Thanks!) We were not involved in the creation or maintenance of the PyTorch\nimplementation so please direct any questions towards the authors of that\nrepository.\n\n**\\*\\*\\*\\*\\* New November 3rd, 2018: Multilingual and Chinese models available\n\\*\\*\\*\\*\\***\n\nWe have made two new BERT models available:\n\n*   **[`BERT-Base, Multilingual`](https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip)\n    (Not recommended, use `Multilingual Cased` instead)**: 102 languages,\n    12-layer, 768-hidden, 12-heads, 110M parameters\n*   **[`BERT-Base, Chinese`](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip)**:\n    Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M\n    parameters\n\nWe use character-based tokenization for Chinese, and WordPiece tokenization for\nall other languages. Both models should work out-of-the-box without any code\nchanges. We did update the implementation of `BasicTokenizer` in\n`tokenization.py` to support Chinese character tokenization, so please update if\nyou forked it. However, we did not change the tokenization API.\n\nFor more, see the\n[Multilingual README](https://github.com/google-research/bert/blob/master/multilingual.md).\n\n**\\*\\*\\*\\*\\* End new information \\*\\*\\*\\*\\***\n\n## Introduction\n\n**BERT**, or **B**idirectional **E**ncoder **R**epresentations from\n**T**ransformers, is a new method of pre-training language representations which\nobtains state-of-the-art results on a wide array of Natural Language Processing\n(NLP) tasks.\n\nOur academic paper which describes BERT in detail and provides full results on a\nnumber of tasks can be found here:\n[https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805).\n\nTo give a few numbers, here are the results on the\n[SQuAD v1.1](https://rajpurkar.github.io/SQuAD-explorer/) question answering\ntask:\n\nSQuAD v1.1 Leaderboard (Oct 8th 2018) | Test EM  | Test F1\n------------------------------------- | :------: | :------:\n1st Place Ensemble - BERT             | **87.4** | **93.2**\n2nd Place Ensemble - nlnet            | 86.0     | 91.7\n1st Place Single Model - BERT         | **85.1** | **91.8**\n2nd Place Single Model - nlnet        | 83.5     | 90.1\n\nAnd several natural language inference tasks:\n\nSystem                  | MultiNLI | Question NLI | SWAG\n----------------------- | :------: | :----------: | :------:\nBERT                    | **86.7** | **91.1**     | **86.3**\nOpenAI GPT (Prev. SOTA) | 82.2     | 88.1         | 75.0\n\nPlus many other tasks.\n\nMoreover, these results were all obtained with almost no task-specific neural\nnetwork architecture design.\n\nIf you already know what BERT is and you just want to get started, you can\n[download the pre-trained models](#pre-trained-models) and\n[run a state-of-the-art fine-tuning](#fine-tuning-with-bert) in only a few\nminutes.\n\n## What is BERT?\n\nBERT is a method of pre-training language representations, meaning that we train\na general-purpose \"language understanding\" model on a large text corpus (like\nWikipedia), and then use that model for downstream NLP tasks that we care about\n(like question answering). BERT outperforms previous methods because it is the\nfirst *unsupervised*, *deeply bidirectional* system for pre-training NLP.\n\n*Unsupervised* means that BERT was trained using only a plain text corpus, which\nis important because an enormous amount of plain text data is publicly available\non the web in many languages.\n\nPre-trained representations can also either be *context-free* or *contextual*,\nand contextual representations can further be *unidirectional* or\n*bidirectional*. Context-free models such as\n[word2vec](https://www.tensorflow.org/tutorials/representation/word2vec) or\n[GloVe](https://nlp.stanford.edu/projects/glove/) generate a single \"word\nembedding\" representation for each word in the vocabulary, so `bank` would have\nthe same representation in `bank deposit` and `river bank`. Contextual models\ninstead generate a representation of each word that is based on the other words\nin the sentence.\n\nBERT was built upon recent work in pre-training contextual representations \u2014\nincluding [Semi-supervised Sequence Learning](https://arxiv.org/abs/1511.01432),\n[Generative Pre-Training](https://blog.openai.com/language-unsupervised/),\n[ELMo](https://allennlp.org/elmo), and\n[ULMFit](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)\n\u2014 but crucially these models are all *unidirectional* or *shallowly\nbidirectional*. This means that each word is only contextualized using the words\nto its left (or right). For example, in the sentence `I made a bank deposit` the\nunidirectional representation of `bank` is only based on `I made a` but not\n`deposit`. Some previous work does combine the representations from separate\nleft-context and right-context models, but only in a \"shallow\" manner. BERT\nrepresents \"bank\" using both its left and right context \u2014 `I made a ... deposit`\n\u2014 starting from the very bottom of a deep neural network, so it is *deeply\nbidirectional*.\n\nBERT uses a simple approach for this: We mask out 15% of the words in the input,\nrun the entire sequence through a deep bidirectional\n[Transformer](https://arxiv.org/abs/1706.03762) encoder, and then predict only\nthe masked words. For example:\n\n```\nInput: the man went to the [MASK1] . he bought a [MASK2] of milk.\nLabels: [MASK1] = store; [MASK2] = gallon\n```\n\nIn order to learn relationships between sentences, we also train on a simple\ntask which can be generated from any monolingual corpus: Given two sentences `A`\nand `B`, is `B` the actual next sentence that comes after `A`, or just a random\nsentence from the corpus?\n\n```\nSentence A: the man went to the store .\nSentence B: he bought a gallon of milk .\nLabel: IsNextSentence\n```\n\n```\nSentence A: the man went to the store .\nSentence B: penguins are flightless .\nLabel: NotNextSentence\n```\n\nWe then train a large model (12-layer to 24-layer Transformer) on a large corpus\n(Wikipedia + [BookCorpus](http://yknzhu.wixsite.com/mbweb)) for a long time (1M\nupdate steps), and that's BERT.\n\nUsing BERT has two stages: *Pre-training* and *fine-tuning*.\n\n**Pre-training** is fairly expensive (four days on 4 to 16 Cloud TPUs), but is a\none-time procedure for each language (current models are English-only, but\nmultilingual models will be released in the near future). We are releasing a\nnumber of pre-trained models from the paper which were pre-trained at Google.\nMost NLP researchers will never need to pre-train their own model from scratch.\n\n**Fine-tuning** is inexpensive. All of the results in the paper can be\nreplicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU,\nstarting from the exact same pre-trained model. SQuAD, for example, can be\ntrained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of\n91.0%, which is the single system state-of-the-art.\n\nThe other important aspect of BERT is that it can be adapted to many types of\nNLP tasks very easily. In the paper, we demonstrate state-of-the-art results on\nsentence-level (e.g., SST-2), sentence-pair-level (e.g., MultiNLI), word-level\n(e.g., NER), and span-level (e.g., SQuAD) tasks with almost no task-specific\nmodifications.\n\n## What has been released in this repository?\n\nWe are releasing the following:\n\n*   TensorFlow code for the BERT model architecture (which is mostly a standard\n    [Transformer](https://arxiv.org/abs/1706.03762) architecture).\n*   Pre-trained checkpoints for both the lowercase and cased version of\n    `BERT-Base` and `BERT-Large` from the paper.\n*   TensorFlow code for push-button replication of the most important\n    fine-tuning experiments from the paper, including SQuAD, MultiNLI, and MRPC.\n\nAll of the code in this repository works out-of-the-box with CPU, GPU, and Cloud\nTPU.\n\n## Pre-trained models\n\nWe are releasing the `BERT-Base` and `BERT-Large` models from the paper.\n`Uncased` means that the text has been lowercased before WordPiece tokenization,\ne.g., `John Smith` becomes `john smith`. The `Uncased` model also strips out any\naccent markers. `Cased` means that the true case and accent markers are\npreserved. Typically, the `Uncased` model is better unless you know that case\ninformation is important for your task (e.g., Named Entity Recognition or\nPart-of-Speech tagging).\n\nThese models are all released under the same license as the source code (Apache\n2.0).\n\nFor information about the Multilingual and Chinese model, see the\n[Multilingual README](https://github.com/google-research/bert/blob/master/multilingual.md).\n\n**When using a cased model, make sure to pass `--do_lower=False` to the training\nscripts. (Or pass `do_lower_case=False` directly to `FullTokenizer` if you're\nusing your own script.)**\n\nThe links to the models are here (right-click, 'Save link as...' on the name):\n\n*   **[`BERT-Large, Uncased (Whole Word Masking)`](https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip)**:\n    24-layer, 1024-hidden, 16-heads, 340M parameters\n*   **[`BERT-Large, Cased (Whole Word Masking)`](https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip)**:\n    24-layer, 1024-hidden, 16-heads, 340M parameters\n*   **[`BERT-Base, Uncased`](https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip)**:\n    12-layer, 768-hidden, 12-heads, 110M parameters\n*   **[`BERT-Large, Uncased`](https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip)**:\n    24-layer, 1024-hidden, 16-heads, 340M parameters\n*   **[`BERT-Base, Cased`](https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip)**:\n    12-layer, 768-hidden, 12-heads , 110M parameters\n*   **[`BERT-Large, Cased`](https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip)**:\n    24-layer, 1024-hidden, 16-heads, 340M parameters\n*   **[`BERT-Base, Multilingual Cased (New, recommended)`](https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip)**:\n    104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters\n*   **[`BERT-Base, Multilingual Uncased (Orig, not recommended)`](https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip)\n    (Not recommended, use `Multilingual Cased` instead)**: 102 languages,\n    12-layer, 768-hidden, 12-heads, 110M parameters\n*   **[`BERT-Base, Chinese`](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip)**:\n    Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M\n    parameters\n\nEach .zip file contains three items:\n\n*   A TensorFlow checkpoint (`bert_model.ckpt`) containing the pre-trained\n    weights (which is actually 3 files).\n*   A vocab file (`vocab.txt`) to map WordPiece to word id.\n*   A config file (`bert_config.json`) which specifies the hyperparameters of\n    the model.\n\n## Fine-tuning with BERT\n\n**Important**: All results on the paper were fine-tuned on a single Cloud TPU,\nwhich has 64GB of RAM. It is currently not possible to re-produce most of the\n`BERT-Large` results on the paper using a GPU with 12GB - 16GB of RAM, because\nthe maximum batch size that can fit in memory is too small. We are working on\nadding code to this repository which allows for much larger effective batch size\non the GPU. See the section on [out-of-memory issues](#out-of-memory-issues) for\nmore details.\n\nThis code was tested with TensorFlow 1.11.0. It was tested with Python2 and\nPython3 (but more thoroughly with Python2, since this is what's used internally\nin Google).\n\nThe fine-tuning examples which use `BERT-Base` should be able to run on a GPU\nthat has at least 12GB of RAM using the hyperparameters given.\n\n### Fine-tuning with Cloud TPUs\n\nMost of the examples below assumes that you will be running training/evaluation\non your local machine, using a GPU like a Titan X or GTX 1080.\n\nHowever, if you have access to a Cloud TPU that you want to train on, just add\nthe following flags to `run_classifier.py` or `run_squad.py`:\n\n```\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME\n```\n\nPlease see the\n[Google Cloud TPU tutorial](https://cloud.google.com/tpu/docs/tutorials/mnist)\nfor how to use Cloud TPUs. Alternatively, you can use the Google Colab notebook\n\"[BERT FineTuning with Cloud TPUs](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\".\n\nOn Cloud TPUs, the pretrained model and the output directory will need to be on\nGoogle Cloud Storage. For example, if you have a bucket named `some_bucket`, you\nmight use the following flags instead:\n\n```\n  --output_dir=gs://some_bucket/my_output_dir/\n```\n\nThe unzipped pre-trained model files can also be found in the Google Cloud\nStorage folder `gs://bert_models/2018_10_18`. For example:\n\n```\nexport BERT_BASE_DIR=gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12\n```\n\n### Sentence (and sentence-pair) classification tasks\n\nBefore running this example you must download the\n[GLUE data](https://gluebenchmark.com/tasks) by running\n[this script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e)\nand unpack it to some directory `$GLUE_DIR`. Next, download the `BERT-Base`\ncheckpoint and unzip it to some directory `$BERT_BASE_DIR`.\n\nThis example code fine-tunes `BERT-Base` on the Microsoft Research Paraphrase\nCorpus (MRPC) corpus, which only contains 3,600 examples and can fine-tune in a\nfew minutes on most GPUs.\n\n```shell\nexport BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12\nexport GLUE_DIR=/path/to/glue\n\npython run_classifier.py \\\n  --task_name=MRPC \\\n  --do_train=true \\\n  --do_eval=true \\\n  --data_dir=$GLUE_DIR/MRPC \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  --max_seq_length=128 \\\n  --train_batch_size=32 \\\n  --learning_rate=2e-5 \\\n  --num_train_epochs=3.0 \\\n  --output_dir=/tmp/mrpc_output/\n```\n\nYou should see output like this:\n\n```\n***** Eval results *****\n  eval_accuracy = 0.845588\n  eval_loss = 0.505248\n  global_step = 343\n  loss = 0.505248\n```\n\nThis means that the Dev set accuracy was 84.55%. Small sets like MRPC have a\nhigh variance in the Dev set accuracy, even when starting from the same\npre-training checkpoint. If you re-run multiple times (making sure to point to\ndifferent `output_dir`), you should see results between 84% and 88%.\n\nA few other pre-trained models are implemented off-the-shelf in\n`run_classifier.py`, so it should be straightforward to follow those examples to\nuse BERT for any single-sentence or sentence-pair classification task.\n\nNote: You might see a message `Running train on CPU`. This really just means\nthat it's running on something other than a Cloud TPU, which includes a GPU.\n\n#### Prediction from classifier\n\nOnce you have trained your classifier you can use it in inference mode by using\nthe --do_predict=true command. You need to have a file named test.tsv in the\ninput folder. Output will be created in file called test_results.tsv in the\noutput folder. Each line will contain output for each sample, columns are the\nclass probabilities.\n\n```shell\nexport BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12\nexport GLUE_DIR=/path/to/glue\nexport TRAINED_CLASSIFIER=/path/to/fine/tuned/classifier\n\npython run_classifier.py \\\n  --task_name=MRPC \\\n  --do_predict=true \\\n  --data_dir=$GLUE_DIR/MRPC \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$TRAINED_CLASSIFIER \\\n  --max_seq_length=128 \\\n  --output_dir=/tmp/mrpc_output/\n```\n\n### SQuAD 1.1\n\nThe Stanford Question Answering Dataset (SQuAD) is a popular question answering\nbenchmark dataset. BERT (at the time of the release) obtains state-of-the-art\nresults on SQuAD with almost no task-specific network architecture modifications\nor data augmentation. However, it does require semi-complex data pre-processing\nand post-processing to deal with (a) the variable-length nature of SQuAD context\nparagraphs, and (b) the character-level answer annotations which are used for\nSQuAD training. This processing is implemented and documented in `run_squad.py`.\n\nTo run on SQuAD, you will first need to download the dataset. The\n[SQuAD website](https://rajpurkar.github.io/SQuAD-explorer/) does not seem to\nlink to the v1.1 datasets any longer, but the necessary files can be found here:\n\n*   [train-v1.1.json](https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json)\n*   [dev-v1.1.json](https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json)\n*   [evaluate-v1.1.py](https://github.com/allenai/bi-att-flow/blob/master/squad/evaluate-v1.1.py)\n\nDownload these to some directory `$SQUAD_DIR`.\n\nThe state-of-the-art SQuAD results from the paper currently cannot be reproduced\non a 12GB-16GB GPU due to memory constraints (in fact, even batch size 1 does\nnot seem to fit on a 12GB GPU using `BERT-Large`). However, a reasonably strong\n`BERT-Base` model can be trained on the GPU with these hyperparameters:\n\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  --do_train=True \\\n  --train_file=$SQUAD_DIR/train-v1.1.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v1.1.json \\\n  --train_batch_size=12 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=/tmp/squad_base/\n```\n\nThe dev set predictions will be saved into a file called `predictions.json` in\nthe `output_dir`:\n\n```shell\npython $SQUAD_DIR/evaluate-v1.1.py $SQUAD_DIR/dev-v1.1.json ./squad/predictions.json\n```\n\nWhich should produce an output like this:\n\n```shell\n{\"f1\": 88.41249612335034, \"exact_match\": 81.2488174077578}\n```\n\nYou should see a result similar to the 88.5% reported in the paper for\n`BERT-Base`.\n\nIf you have access to a Cloud TPU, you can train with `BERT-Large`. Here is a\nset of hyperparameters (slightly different than the paper) which consistently\nobtain around 90.5%-91.0% F1 single-system trained only on SQuAD:\n\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\\n  --do_train=True \\\n  --train_file=$SQUAD_DIR/train-v1.1.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v1.1.json \\\n  --train_batch_size=24 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=gs://some_bucket/squad_large/ \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME\n```\n\nFor example, one random run with these parameters produces the following Dev\nscores:\n\n```shell\n{\"f1\": 90.87081895814865, \"exact_match\": 84.38978240302744}\n```\n\nIf you fine-tune for one epoch on\n[TriviaQA](http://nlp.cs.washington.edu/triviaqa/) before this the results will\nbe even better, but you will need to convert TriviaQA into the SQuAD json\nformat.\n\n### SQuAD 2.0\n\nThis model is also implemented and documented in `run_squad.py`.\n\nTo run on SQuAD 2.0, you will first need to download the dataset. The necessary\nfiles can be found here:\n\n*   [train-v2.0.json](https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json)\n*   [dev-v2.0.json](https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json)\n*   [evaluate-v2.0.py](https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/)\n\nDownload these to some directory `$SQUAD_DIR`.\n\nOn Cloud TPU you can run with BERT-Large as follows:\n\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\\n  --do_train=True \\\n  --train_file=$SQUAD_DIR/train-v2.0.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v2.0.json \\\n  --train_batch_size=24 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=gs://some_bucket/squad_large/ \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME \\\n  --version_2_with_negative=True\n```\n\nWe assume you have copied everything from the output directory to a local\ndirectory called ./squad/. The initial dev set predictions will be at\n./squad/predictions.json and the differences between the score of no answer (\"\")\nand the best non-null answer for each question will be in the file\n./squad/null_odds.json\n\nRun this script to tune a threshold for predicting null versus non-null answers:\n\npython $SQUAD_DIR/evaluate-v2.0.py $SQUAD_DIR/dev-v2.0.json\n./squad/predictions.json --na-prob-file ./squad/null_odds.json\n\nAssume the script outputs \"best_f1_thresh\" THRESH. (Typical values are between\n-1.0 and -5.0). You can now re-run the model to generate predictions with the\nderived threshold or alternatively you can extract the appropriate answers from\n./squad/nbest_predictions.json.\n\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\\n  --do_train=False \\\n  --train_file=$SQUAD_DIR/train-v2.0.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v2.0.json \\\n  --train_batch_size=24 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=gs://some_bucket/squad_large/ \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME \\\n  --version_2_with_negative=True \\\n  --null_score_diff_threshold=$THRESH\n```\n\n### Out-of-memory issues\n\nAll experiments in the paper were fine-tuned on a Cloud TPU, which has 64GB of\ndevice RAM. Therefore, when using a GPU with 12GB - 16GB of RAM, you are likely\nto encounter out-of-memory issues if you use the same hyperparameters described\nin the paper.\n\nThe factors that affect memory usage are:\n\n*   **`max_seq_length`**: The released models were trained with sequence lengths\n    up to 512, but you can fine-tune with a shorter max sequence length to save\n    substantial memory. This is controlled by the `max_seq_length` flag in our\n    example code.\n\n*   **`train_batch_size`**: The memory usage is also directly proportional to\n    the batch size.\n\n*   **Model type, `BERT-Base` vs. `BERT-Large`**: The `BERT-Large` model\n    requires significantly more memory than `BERT-Base`.\n\n*   **Optimizer**: The default optimizer for BERT is Adam, which requires a lot\n    of extra memory to store the `m` and `v` vectors. Switching to a more memory\n    efficient optimizer can reduce memory usage, but can also affect the\n    results. We have not experimented with other optimizers for fine-tuning.\n\nUsing the default training scripts (`run_classifier.py` and `run_squad.py`), we\nbenchmarked the maximum batch size on single Titan X GPU (12GB RAM) with\nTensorFlow 1.11.0:\n\nSystem       | Seq Length | Max Batch Size\n------------ | ---------- | --------------\n`BERT-Base`  | 64         | 64\n...          | 128        | 32\n...          | 256        | 16\n...          | 320        | 14\n...          | 384        | 12\n...          | 512        | 6\n`BERT-Large` | 64         | 12\n...          | 128        | 6\n...          | 256        | 2\n...          | 320        | 1\n...          | 384        | 0\n...          | 512        | 0\n\nUnfortunately, these max batch sizes for `BERT-Large` are so small that they\nwill actually harm the model accuracy, regardless of the learning rate used. We\nare working on adding code to this repository which will allow much larger\neffective batch sizes to be used on the GPU. The code will be based on one (or\nboth) of the following techniques:\n\n*   **Gradient accumulation**: The samples in a minibatch are typically\n    independent with respect to gradient computation (excluding batch\n    normalization, which is not used here). This means that the gradients of\n    multiple smaller minibatches can be accumulated before performing the weight\n    update, and this will be exactly equivalent to a single larger update.\n\n*   [**Gradient checkpointing**](https://github.com/openai/gradient-checkpointing):\n    The major use of GPU/TPU memory during DNN training is caching the\n    intermediate activations in the forward pass that are necessary for\n    efficient computation in the backward pass. \"Gradient checkpointing\" trades\n    memory for compute time by re-computing the activations in an intelligent\n    way.\n\n**However, this is not implemented in the current release.**\n\n## Using BERT to extract fixed feature vectors (like ELMo)\n\nIn certain cases, rather than fine-tuning the entire pre-trained model\nend-to-end, it can be beneficial to obtained *pre-trained contextual\nembeddings*, which are fixed contextual representations of each input token\ngenerated from the hidden layers of the pre-trained model. This should also\nmitigate most of the out-of-memory issues.\n\nAs an example, we include the script `extract_features.py` which can be used\nlike this:\n\n```shell\n# Sentence A and Sentence B are separated by the ||| delimiter for sentence\n# pair tasks like question answering and entailment.\n# For single sentence inputs, put one sentence per line and DON'T use the\n# delimiter.\necho 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > /tmp/input.txt\n\npython extract_features.py \\\n  --input_file=/tmp/input.txt \\\n  --output_file=/tmp/output.jsonl \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  --layers=-1,-2,-3,-4 \\\n  --max_seq_length=128 \\\n  --batch_size=8\n```\n\nThis will create a JSON file (one line per line of input) containing the BERT\nactivations from each Transformer layer specified by `layers` (-1 is the final\nhidden layer of the Transformer, etc.)\n\nNote that this script will produce very large output files (by default, around\n15kb for every input token).\n\nIf you need to maintain alignment between the original and tokenized words (for\nprojecting training labels), see the [Tokenization](#tokenization) section\nbelow.\n\n**Note:** You may see a message like `Could not find trained model in model_dir:\n/tmp/tmpuB5g5c, running initialization to predict.` This message is expected, it\njust means that we are using the `init_from_checkpoint()` API rather than the\nsaved model API. If you don't specify a checkpoint or specify an invalid\ncheckpoint, this script will complain.\n\n## Tokenization\n\nFor sentence-level tasks (or sentence-pair) tasks, tokenization is very simple.\nJust follow the example code in `run_classifier.py` and `extract_features.py`.\nThe basic procedure for sentence-level tasks is:\n\n1.  Instantiate an instance of `tokenizer = tokenization.FullTokenizer`\n\n2.  Tokenize the raw text with `tokens = tokenizer.tokenize(raw_text)`.\n\n3.  Truncate to the maximum sequence length. (You can use up to 512, but you\n    probably want to use shorter if possible for memory and speed reasons.)\n\n4.  Add the `[CLS]` and `[SEP]` tokens in the right place.\n\nWord-level and span-level tasks (e.g., SQuAD and NER) are more complex, since\nyou need to maintain alignment between your input text and output text so that\nyou can project your training labels. SQuAD is a particularly complex example\nbecause the input labels are *character*-based, and SQuAD paragraphs are often\nlonger than our maximum sequence length. See the code in `run_squad.py` to show\nhow we handle this.\n\nBefore we describe the general recipe for handling word-level tasks, it's\nimportant to understand what exactly our tokenizer is doing. It has three main\nsteps:\n\n1.  **Text normalization**: Convert all whitespace characters to spaces, and\n    (for the `Uncased` model) lowercase the input and strip out accent markers.\n    E.g., `John Johanson's, \u2192 john johanson's,`.\n\n2.  **Punctuation splitting**: Split *all* punctuation characters on both sides\n    (i.e., add whitespace around all punctuation characters). Punctuation\n    characters are defined as (a) Anything with a `P*` Unicode class, (b) any\n    non-letter/number/space ASCII character (e.g., characters like `$` which are\n    technically not punctuation). E.g., `john johanson's, \u2192 john johanson ' s ,`\n\n3.  **WordPiece tokenization**: Apply whitespace tokenization to the output of\n    the above procedure, and apply\n    [WordPiece](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder.py)\n    tokenization to each token separately. (Our implementation is directly based\n    on the one from `tensor2tensor`, which is linked). E.g., `john johanson ' s\n    , \u2192 john johan ##son ' s ,`\n\nThe advantage of this scheme is that it is \"compatible\" with most existing\nEnglish tokenizers. For example, imagine that you have a part-of-speech tagging\ntask which looks like this:\n\n```\nInput:  John Johanson 's   house\nLabels: NNP  NNP      POS NN\n```\n\nThe tokenized output will look like this:\n\n```\nTokens: john johan ##son ' s house\n```\n\nCrucially, this would be the same output as if the raw text were `John\nJohanson's house` (with no space before the `'s`).\n\nIf you have a pre-tokenized representation with word-level annotations, you can\nsimply tokenize each input word independently, and deterministically maintain an\noriginal-to-tokenized alignment:\n\n```python\n### Input\norig_tokens = [\"John\", \"Johanson\", \"'s\",  \"house\"]\nlabels      = [\"NNP\",  \"NNP\",      \"POS\", \"NN\"]\n\n### Output\nbert_tokens = []\n\n# Token map will be an int -> int mapping between the `orig_tokens` index and\n# the `bert_tokens` index.\norig_to_tok_map = []\n\ntokenizer = tokenization.FullTokenizer(\n    vocab_file=vocab_file, do_lower_case=True)\n\nbert_tokens.append(\"[CLS]\")\nfor orig_token in orig_tokens:\n  orig_to_tok_map.append(len(bert_tokens))\n  bert_tokens.extend(tokenizer.tokenize(orig_token))\nbert_tokens.append(\"[SEP]\")\n\n# bert_tokens == [\"[CLS]\", \"john\", \"johan\", \"##son\", \"'\", \"s\", \"house\", \"[SEP]\"]\n# orig_to_tok_map == [1, 2, 4, 6]\n```\n\nNow `orig_to_tok_map` can be used to project `labels` to the tokenized\nrepresentation.\n\nThere are common English tokenization schemes which will cause a slight mismatch\nbetween how BERT was pre-trained. For example, if your input tokenization splits\noff contractions like `do n't`, this will cause a mismatch. If it is possible to\ndo so, you should pre-process your data to convert these back to raw-looking\ntext, but if it's not possible, this mismatch is likely not a big deal.\n\n## Pre-training with BERT\n\nWe are releasing code to do \"masked LM\" and \"next sentence prediction\" on an\narbitrary text corpus. Note that this is *not* the exact code that was used for\nthe paper (the original code was written in C++, and had some additional\ncomplexity), but this code does generate pre-training data as described in the\npaper.\n\nHere's how to run the data generation. The input is a plain text file, with one\nsentence per line. (It is important that these be actual sentences for the \"next\nsentence prediction\" task). Documents are delimited by empty lines. The output\nis a set of `tf.train.Example`s serialized into `TFRecord` file format.\n\nYou can perform sentence segmentation with an off-the-shelf NLP toolkit such as\n[spaCy](https://spacy.io/). The `create_pretraining_data.py` script will\nconcatenate segments until they reach the maximum sequence length to minimize\ncomputational waste from padding (see the script for more details). However, you\nmay want to intentionally add a slight amount of noise to your input data (e.g.,\nrandomly truncate 2% of input segments) to make it more robust to non-sentential\ninput during fine-tuning.\n\nThis script stores all of the examples for the entire input file in memory, so\nfor large data files you should shard the input file and call the script\nmultiple times. (You can pass in a file glob to `run_pretraining.py`, e.g.,\n`tf_examples.tf_record*`.)\n\nThe `max_predictions_per_seq` is the maximum number of masked LM predictions per\nsequence. You should set this to around `max_seq_length` * `masked_lm_prob` (the\nscript doesn't do that automatically because the exact value needs to be passed\nto both scripts).\n\n```shell\npython create_pretraining_data.py \\\n  --input_file=./sample_text.txt \\\n  --output_file=/tmp/tf_examples.tfrecord \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --do_lower_case=True \\\n  --max_seq_length=128 \\\n  --max_predictions_per_seq=20 \\\n  --masked_lm_prob=0.15 \\\n  --random_seed=12345 \\\n  --dupe_factor=5\n```\n\nHere's how to run the pre-training. Do not include `init_checkpoint` if you are\npre-training from scratch. The model configuration (including vocab size) is\nspecified in `bert_config_file`. This demo code only pre-trains for a small\nnumber of steps (20), but in practice you will probably want to set\n`num_train_steps` to 10000 steps or more. The `max_seq_length` and\n`max_predictions_per_seq` parameters passed to `run_pretraining.py` must be the\nsame as `create_pretraining_data.py`.\n\n```shell\npython run_pretraining.py \\\n  --input_file=/tmp/tf_examples.tfrecord \\\n  --output_dir=/tmp/pretraining_output \\\n  --do_train=True \\\n  --do_eval=True \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  --train_batch_size=32 \\\n  --max_seq_length=128 \\\n  --max_predictions_per_seq=20 \\\n  --num_train_steps=20 \\\n  --num_warmup_steps=10 \\\n  --learning_rate=2e-5\n```\n\nThis will produce an output like this:\n\n```\n***** Eval results *****\n  global_step = 20\n  loss = 0.0979674\n  masked_lm_accuracy = 0.985479\n  masked_lm_loss = 0.0979328\n  next_sentence_accuracy = 1.0\n  next_sentence_loss = 3.45724e-05\n```\n\nNote that since our `sample_text.txt` file is very small, this example training\nwill overfit that data in only a few steps and produce unrealistically high\naccuracy numbers.\n\n### Pre-training tips and caveats\n\n*   **If using your own vocabulary, make sure to change `vocab_size` in\n    `bert_config.json`. If you use a larger vocabulary without changing this,\n    you will likely get NaNs when training on GPU or TPU due to unchecked\n    out-of-bounds access.**\n*   If your task has a large domain-specific corpus available (e.g., \"movie\n    reviews\" or \"scientific papers\"), it will likely be beneficial to run\n    additional steps of pre-training on your corpus, starting from the BERT\n    checkpoint.\n*   The learning rate we used in the paper was 1e-4. However, if you are doing\n    additional steps of pre-training starting from an existing BERT checkpoint,\n    you should use a smaller learning rate (e.g., 2e-5).\n*   Current BERT models are English-only, but we do plan to release a\n    multilingual model which has been pre-trained on a lot of languages in the\n    near future (hopefully by the end of November 2018).\n*   Longer sequences are disproportionately expensive because attention is\n    quadratic to the sequence length. In other words, a batch of 64 sequences of\n    length 512 is much more expensive than a batch of 256 sequences of\n    length 128. The fully-connected/convolutional cost is the same, but the\n    attention cost is far greater for the 512-length sequences. Therefore, one\n    good recipe is to pre-train for, say, 90,000 steps with a sequence length of\n    128 and then for 10,000 additional steps with a sequence length of 512. The\n    very long sequences are mostly needed to learn positional embeddings, which\n    can be learned fairly quickly. Note that this does require generating the\n    data twice with different values of `max_seq_length`.\n*   If you are pre-training from scratch, be prepared that pre-training is\n    computationally expensive, especially on GPUs. If you are pre-training from\n    scratch, our recommended recipe is to pre-train a `BERT-Base` on a single\n    [preemptible Cloud TPU v2](https://cloud.google.com/tpu/docs/pricing), which\n    takes about 2 weeks at a cost of about $500 USD (based on the pricing in\n    October 2018). You will have to scale down the batch size when only training\n    on a single Cloud TPU, compared to what was used in the paper. It is\n    recommended to use the largest batch size that fits into TPU memory.\n\n### Pre-training data\n\nWe will **not** be able to release the pre-processed datasets used in the paper.\nFor Wikipedia, the recommended pre-processing is to download\n[the latest dump](https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2),\nextract the text with\n[`WikiExtractor.py`](https://github.com/attardi/wikiextractor), and then apply\nany necessary cleanup to convert it into plain text.\n\nUnfortunately the researchers who collected the\n[BookCorpus](http://yknzhu.wixsite.com/mbweb) no longer have it available for\npublic download. The\n[Project Guttenberg Dataset](https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html)\nis a somewhat smaller (200M word) collection of older books that are public\ndomain.\n\n[Common Crawl](http://commoncrawl.org/) is another very large collection of\ntext, but you will likely have to do substantial pre-processing and cleanup to\nextract a usable corpus for pre-training BERT.\n\n### Learning a new WordPiece vocabulary\n\nThis repository does not include code for *learning* a new WordPiece vocabulary.\nThe reason is that the code used in the paper was implemented in C++ with\ndependencies on Google's internal libraries. For English, it is almost always\nbetter to just start with our vocabulary and pre-trained models. For learning\nvocabularies of other languages, there are a number of open source options\navailable. However, keep in mind that these are not compatible with our\n`tokenization.py` library:\n\n*   [Google's SentencePiece library](https://github.com/google/sentencepiece)\n\n*   [tensor2tensor's WordPiece generation script](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder_build_subword.py)\n\n*   [Rico Sennrich's Byte Pair Encoding library](https://github.com/rsennrich/subword-nmt)\n\n## Using BERT in Colab\n\nIf you want to use BERT with [Colab](https://colab.research.google.com), you can\nget started with the notebook\n\"[BERT FineTuning with Cloud TPUs](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\".\n**At the time of this writing (October 31st, 2018), Colab users can access a\nCloud TPU completely for free.** Note: One per user, availability limited,\nrequires a Google Cloud Platform account with storage (although storage may be\npurchased with free credit for signing up with GCP), and this capability may not\nlonger be available in the future. Click on the BERT Colab that was just linked\nfor more information.\n\n## FAQ\n\n#### Is this code compatible with Cloud TPUs? What about GPUs?\n\nYes, all of the code in this repository works out-of-the-box with CPU, GPU, and\nCloud TPU. However, GPU training is single-GPU only.\n\n#### I am getting out-of-memory errors, what is wrong?\n\nSee the section on [out-of-memory issues](#out-of-memory-issues) for more\ninformation.\n\n#### Is there a PyTorch version available?\n\nThere is no official PyTorch implementation. However, NLP researchers from\nHuggingFace made a\n[PyTorch version of BERT available](https://github.com/huggingface/pytorch-pretrained-BERT)\nwhich is compatible with our pre-trained checkpoints and is able to reproduce\nour results. We were not involved in the creation or maintenance of the PyTorch\nimplementation so please direct any questions towards the authors of that\nrepository.\n\n#### Is there a Chainer version available?\n\nThere is no official Chainer implementation. However, Sosuke Kobayashi made a\n[Chainer version of BERT available](https://github.com/soskek/bert-chainer)\nwhich is compatible with our pre-trained checkpoints and is able to reproduce\nour results. We were not involved in the creation or maintenance of the Chainer\nimplementation so please direct any questions towards the authors of that\nrepository.\n\n#### Will models in other languages be released?\n\nYes, we plan to release a multi-lingual BERT model in the near future. We cannot\nmake promises about exactly which languages will be included, but it will likely\nbe a single model which includes *most* of the languages which have a\nsignificantly-sized Wikipedia.\n\n#### Will models larger than `BERT-Large` be released?\n\nSo far we have not attempted to train anything larger than `BERT-Large`. It is\npossible that we will release larger models if we are able to obtain significant\nimprovements.\n\n#### What license is this library released under?\n\nAll code *and* models are released under the Apache 2.0 license. See the\n`LICENSE` file for more information.\n\n#### How do I cite BERT?\n\nFor now, cite [the Arxiv paper](https://arxiv.org/abs/1810.04805):\n\n```\n@article{devlin2018bert,\n  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  journal={arXiv preprint arXiv:1810.04805},\n  year={2018}\n}\n```\n\nIf we submit the paper to a conference or journal, we will update the BibTeX.\n\n## Disclaimer\n\nThis is not an official Google product.\n\n## Contact information\n\nFor help or issues using BERT, please submit a GitHub issue.\n\nFor personal communication related to BERT, please contact Jacob Devlin\n(`jacobdevlin@google.com`), Ming-Wei Chang (`mingweichang@google.com`), or\nKenton Lee (`kentonl@google.com`).\n"}, {"repo": "littlecodersh/ItChat", "language": "Python", "readme_contents": "# itchat\n\n[![Gitter][gitter-picture]][gitter] ![py27][py27] ![py35][py35] [English version][english-version]\n\nitchat\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u5fae\u4fe1\u4e2a\u4eba\u53f7\u63a5\u53e3\uff0c\u4f7f\u7528python\u8c03\u7528\u5fae\u4fe1\u4ece\u672a\u5982\u6b64\u7b80\u5355\u3002\n\n\u4f7f\u7528\u4e0d\u5230\u4e09\u5341\u884c\u7684\u4ee3\u7801\uff0c\u4f60\u5c31\u53ef\u4ee5\u5b8c\u6210\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u6240\u6709\u4fe1\u606f\u7684\u5fae\u4fe1\u673a\u5668\u4eba\u3002\n\n\u5f53\u7136\uff0c\u8be5api\u7684\u4f7f\u7528\u8fdc\u4e0d\u6b62\u4e00\u4e2a\u673a\u5668\u4eba\uff0c\u66f4\u591a\u7684\u529f\u80fd\u7b49\u7740\u4f60\u6765\u53d1\u73b0\uff0c\u6bd4\u5982[\u8fd9\u4e9b][tutorial2]\u3002\n\n\u8be5\u63a5\u53e3\u4e0e\u516c\u4f17\u53f7\u63a5\u53e3[itchatmp][itchatmp]\u5171\u4eab\u7c7b\u4f3c\u7684\u64cd\u4f5c\u65b9\u5f0f\uff0c\u5b66\u4e60\u4e00\u6b21\u638c\u63e1\u4e24\u4e2a\u5de5\u5177\u3002\n\n\u5982\u4eca\u5fae\u4fe1\u5df2\u7ecf\u6210\u4e3a\u4e86\u4e2a\u4eba\u793e\u4ea4\u7684\u5f88\u5927\u4e00\u90e8\u5206\uff0c\u5e0c\u671b\u8fd9\u4e2a\u9879\u76ee\u80fd\u591f\u5e2e\u52a9\u4f60\u6269\u5c55\u4f60\u7684\u4e2a\u4eba\u7684\u5fae\u4fe1\u53f7\u3001\u65b9\u4fbf\u81ea\u5df1\u7684\u751f\u6d3b\u3002\n\n## \u5b89\u88c5\n\n\u53ef\u4ee5\u901a\u8fc7\u672c\u547d\u4ee4\u5b89\u88c5itchat\uff1a\n\n```python\npip install itchat\n```\n\n## \u7b80\u5355\u5165\u95e8\u5b9e\u4f8b\n\n\u6709\u4e86itchat\uff0c\u5982\u679c\u4f60\u60f3\u8981\u7ed9\u6587\u4ef6\u4f20\u8f93\u52a9\u624b\u53d1\u4e00\u6761\u4fe1\u606f\uff0c\u53ea\u9700\u8981\u8fd9\u6837\uff1a\n\n```python\nimport itchat\n\nitchat.auto_login()\n\nitchat.send('Hello, filehelper', toUserName='filehelper')\n```\n\n\u5982\u679c\u4f60\u60f3\u8981\u56de\u590d\u53d1\u7ed9\u81ea\u5df1\u7684\u6587\u672c\u6d88\u606f\uff0c\u53ea\u9700\u8981\u8fd9\u6837\uff1a\n\n```python\nimport itchat\n\n@itchat.msg_register(itchat.content.TEXT)\ndef text_reply(msg):\n    return msg.text\n\nitchat.auto_login()\nitchat.run()\n```\n\n\u4e00\u4e9b\u8fdb\u9636\u5e94\u7528\u53ef\u4ee5\u5728\u4e0b\u9762\u7684\u5f00\u6e90\u673a\u5668\u4eba\u7684\u6e90\u7801\u548c\u8fdb\u9636\u5e94\u7528\u4e2d\u770b\u5230\uff0c\u6216\u8005\u4f60\u4e5f\u53ef\u4ee5\u9605\u89c8[\u6587\u6863][document]\u3002\n\n## \u8bd5\u4e00\u8bd5\n\n\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u8fd9\u4e00\u9879\u76ee\u7684[\u5f00\u6e90\u5c0f\u673a\u5668\u4eba][robot-source-code]\uff0c\u767e\u95fb\u4e0d\u5982\u4e00\u89c1\uff0c\u6709\u5174\u8da3\u53ef\u4ee5\u5c1d\u8bd5\u4e00\u4e0b\u3002\n\n\u7531\u4e8e\u597d\u53cb\u6570\u91cf\u5b9e\u5728\u589e\u957f\u8fc7\u5feb\uff0c\u81ea\u52a8\u901a\u8fc7\u597d\u53cb\u9a8c\u8bc1\u7684\u529f\u80fd\u6f14\u793a\u6682\u65f6\u5173\u95ed\u3002\n\n![QRCode][robot-qr]\n\n## \u622a\u5c4f\n\n![file-autoreply][robot-demo-file] ![login-page][robot-demo-login]\n\n## \u8fdb\u9636\u5e94\u7528\n\n### \u7279\u6b8a\u7684\u5b57\u5178\u4f7f\u7528\u65b9\u5f0f\n\n\u901a\u8fc7\u6253\u5370itchat\u7684\u7528\u6237\u4ee5\u53ca\u6ce8\u518c\u6d88\u606f\u7684\u53c2\u6570\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd9\u4e9b\u503c\u90fd\u662f\u5b57\u5178\u3002\n\n\u4f46\u5b9e\u9645\u4e0aitchat\u7cbe\u5fc3\u6784\u9020\u4e86\u76f8\u5e94\u7684\u6d88\u606f\u3001\u7528\u6237\u3001\u7fa4\u804a\u3001\u516c\u4f17\u53f7\u7c7b\u3002\n\n\u5176\u6240\u6709\u7684\u952e\u503c\u90fd\u53ef\u4ee5\u901a\u8fc7\u8fd9\u4e00\u65b9\u5f0f\u8bbf\u95ee\uff1a\n\n```python\n@itchat.msg_register(TEXT)\ndef _(msg):\n    # equals to print(msg['FromUserName'])\n    print(msg.fromUserName)\n```\n\n\u5c5e\u6027\u540d\u4e3a\u952e\u503c\u9996\u5b57\u6bcd\u5c0f\u5199\u540e\u7684\u5185\u5bb9\u3002\n\n```python\nauthor = itchat.search_friends(nickName='LittleCoder')[0]\nauthor.send('greeting, littlecoder!')\n```\n\n### \u5404\u7c7b\u578b\u6d88\u606f\u7684\u6ce8\u518c\n\n\u901a\u8fc7\u5982\u4e0b\u4ee3\u7801\uff0c\u5fae\u4fe1\u5df2\u7ecf\u53ef\u4ee5\u5c31\u65e5\u5e38\u7684\u5404\u79cd\u4fe1\u606f\u8fdb\u884c\u83b7\u53d6\u4e0e\u56de\u590d\u3002\n\n```python\nimport itchat, time\nfrom itchat.content import *\n\n@itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING])\ndef text_reply(msg):\n    msg.user.send('%s: %s' % (msg.type, msg.text))\n\n@itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO])\ndef download_files(msg):\n    msg.download(msg.fileName)\n    typeSymbol = {\n        PICTURE: 'img',\n        VIDEO: 'vid', }.get(msg.type, 'fil')\n    return '@%s@%s' % (typeSymbol, msg.fileName)\n\n@itchat.msg_register(FRIENDS)\ndef add_friend(msg):\n    msg.user.verify()\n    msg.user.send('Nice to meet you!')\n\n@itchat.msg_register(TEXT, isGroupChat=True)\ndef text_reply(msg):\n    if msg.isAt:\n        msg.user.send(u'@%s\\u2005I received: %s' % (\n            msg.actualNickName, msg.text))\n\nitchat.auto_login(True)\nitchat.run(True)\n```\n\n### \u547d\u4ee4\u884c\u4e8c\u7ef4\u7801\n\n\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u53ef\u4ee5\u5728\u767b\u9646\u7684\u65f6\u5019\u4f7f\u7528\u547d\u4ee4\u884c\u663e\u793a\u4e8c\u7ef4\u7801\uff1a\n\n```python\nitchat.auto_login(enableCmdQR=True)\n```\n\n\u90e8\u5206\u7cfb\u7edf\u53ef\u80fd\u5b57\u5e45\u5bbd\u5ea6\u6709\u51fa\u5165\uff0c\u53ef\u4ee5\u901a\u8fc7\u5c06enableCmdQR\u8d4b\u503c\u4e3a\u7279\u5b9a\u7684\u500d\u6570\u8fdb\u884c\u8c03\u6574\uff1a\n\n```python\n# \u5982\u90e8\u5206\u7684linux\u7cfb\u7edf\uff0c\u5757\u5b57\u7b26\u7684\u5bbd\u5ea6\u4e3a\u4e00\u4e2a\u5b57\u7b26\uff08\u6b63\u5e38\u5e94\u4e3a\u4e24\u5b57\u7b26\uff09\uff0c\u6545\u8d4b\u503c\u4e3a2\nitchat.auto_login(enableCmdQR=2)\n```\n\n\u9ed8\u8ba4\u63a7\u5236\u53f0\u80cc\u666f\u8272\u4e3a\u6697\u8272\uff08\u9ed1\u8272\uff09\uff0c\u82e5\u80cc\u666f\u8272\u4e3a\u6d45\u8272\uff08\u767d\u8272\uff09\uff0c\u53ef\u4ee5\u5c06enableCmdQR\u8d4b\u503c\u4e3a\u8d1f\u503c\uff1a\n\n```python\nitchat.auto_login(enableCmdQR=-1)\n```\n\n### \u9000\u51fa\u7a0b\u5e8f\u540e\u6682\u5b58\u767b\u9646\u72b6\u6001\n\n\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u767b\u9646\uff0c\u5373\u4f7f\u7a0b\u5e8f\u5173\u95ed\uff0c\u4e00\u5b9a\u65f6\u95f4\u5185\u91cd\u65b0\u5f00\u542f\u4e5f\u53ef\u4ee5\u4e0d\u7528\u91cd\u65b0\u626b\u7801\u3002\n\n```python\nitchat.auto_login(hotReload=True)\n```\n\n### \u7528\u6237\u641c\u7d22\n\n\u4f7f\u7528`search_friends`\u65b9\u6cd5\u53ef\u4ee5\u641c\u7d22\u7528\u6237\uff0c\u6709\u56db\u79cd\u641c\u7d22\u65b9\u5f0f\uff1a\n1. \u4ec5\u83b7\u53d6\u81ea\u5df1\u7684\u7528\u6237\u4fe1\u606f\n2. \u83b7\u53d6\u7279\u5b9a`UserName`\u7684\u7528\u6237\u4fe1\u606f\n3. \u83b7\u53d6\u5907\u6ce8\u3001\u5fae\u4fe1\u53f7\u3001\u6635\u79f0\u4e2d\u7684\u4efb\u4f55\u4e00\u9879\u7b49\u4e8e`name`\u952e\u503c\u7684\u7528\u6237\n4. \u83b7\u53d6\u5907\u6ce8\u3001\u5fae\u4fe1\u53f7\u3001\u6635\u79f0\u5206\u522b\u7b49\u4e8e\u76f8\u5e94\u952e\u503c\u7684\u7528\u6237\n\n\u5176\u4e2d\u4e09\u3001\u56db\u9879\u53ef\u4ee5\u4e00\u540c\u4f7f\u7528\uff0c\u4e0b\u9762\u662f\u793a\u4f8b\u7a0b\u5e8f\uff1a\n\n```python\n# \u83b7\u53d6\u81ea\u5df1\u7684\u7528\u6237\u4fe1\u606f\uff0c\u8fd4\u56de\u81ea\u5df1\u7684\u5c5e\u6027\u5b57\u5178\nitchat.search_friends()\n# \u83b7\u53d6\u7279\u5b9aUserName\u7684\u7528\u6237\u4fe1\u606f\nitchat.search_friends(userName='@abcdefg1234567')\n# \u83b7\u53d6\u4efb\u4f55\u4e00\u9879\u7b49\u4e8ename\u952e\u503c\u7684\u7528\u6237\nitchat.search_friends(name='littlecodersh')\n# \u83b7\u53d6\u5206\u522b\u5bf9\u5e94\u76f8\u5e94\u952e\u503c\u7684\u7528\u6237\nitchat.search_friends(wechatAccount='littlecodersh')\n# \u4e09\u3001\u56db\u9879\u529f\u80fd\u53ef\u4ee5\u4e00\u540c\u4f7f\u7528\nitchat.search_friends(name='LittleCoder\u673a\u5668\u4eba', wechatAccount='littlecodersh')\n```\n\n\u5173\u4e8e\u516c\u4f17\u53f7\u3001\u7fa4\u804a\u7684\u83b7\u53d6\u4e0e\u641c\u7d22\u5728\u6587\u6863\u4e2d\u6709\u66f4\u52a0\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002\n\n### \u9644\u4ef6\u7684\u4e0b\u8f7d\u4e0e\u53d1\u9001\n\nitchat\u7684\u9644\u4ef6\u4e0b\u8f7d\u65b9\u6cd5\u5b58\u50a8\u5728msg\u7684Text\u952e\u4e2d\u3002\n\n\u53d1\u9001\u7684\u6587\u4ef6\u7684\u6587\u4ef6\u540d\uff08\u56fe\u7247\u7ed9\u51fa\u7684\u9ed8\u8ba4\u6587\u4ef6\u540d\uff09\u90fd\u5b58\u50a8\u5728msg\u7684FileName\u952e\u4e2d\u3002\n\n\u4e0b\u8f7d\u65b9\u6cd5\u63a5\u53d7\u4e00\u4e2a\u53ef\u7528\u7684\u4f4d\u7f6e\u53c2\u6570\uff08\u5305\u62ec\u6587\u4ef6\u540d\uff09\uff0c\u5e76\u5c06\u6587\u4ef6\u76f8\u5e94\u7684\u5b58\u50a8\u3002\n\n```python\n@itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO])\ndef download_files(msg):\n    msg.download(msg.fileName)\n    itchat.send('@%s@%s' % (\n        'img' if msg['Type'] == 'Picture' else 'fil', msg['FileName']),\n        msg['FromUserName'])\n    return '%s received' % msg['Type']\n```\n\n\u5982\u679c\u4f60\u4e0d\u9700\u8981\u4e0b\u8f7d\u5230\u672c\u5730\uff0c\u4ec5\u60f3\u8981\u8bfb\u53d6\u4e8c\u8fdb\u5236\u4e32\u8fdb\u884c\u8fdb\u4e00\u6b65\u5904\u7406\u53ef\u4ee5\u4e0d\u4f20\u5165\u53c2\u6570\uff0c\u65b9\u6cd5\u5c06\u4f1a\u8fd4\u56de\u56fe\u7247\u7684\u4e8c\u8fdb\u5236\u4e32\u3002\n\n```python\n@itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO])\ndef download_files(msg):\n    with open(msg.fileName, 'wb') as f:\n        f.write(msg.download())\n```\n\n### \u7528\u6237\u591a\u5f00\n\n\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u53ef\u4ee5\u5b8c\u6210\u591a\u5f00\u7684\u64cd\u4f5c\uff1a\n\n```python\nimport itchat\n\nnewInstance = itchat.new_instance()\nnewInstance.auto_login(hotReload=True, statusStorageDir='newInstance.pkl')\n\n@newInstance.msg_register(itchat.content.TEXT)\ndef reply(msg):\n    return msg.text\n\nnewInstance.run()\n```\n\n### \u9000\u51fa\u53ca\u767b\u9646\u5b8c\u6210\u540e\u8c03\u7528\u7279\u5b9a\u65b9\u6cd5\n\n\u767b\u9646\u5b8c\u6210\u540e\u7684\u65b9\u6cd5\u9700\u8981\u8d4b\u503c\u5728`loginCallback`\u4e2d\u3002\n\n\u800c\u9000\u51fa\u540e\u7684\u65b9\u6cd5\u9700\u8981\u8d4b\u503c\u5728`exitCallback`\u4e2d\u3002\n\n```python\nimport time\n\nimport itchat\n\ndef lc():\n    print('finish login')\ndef ec():\n    print('exit')\n\nitchat.auto_login(loginCallback=lc, exitCallback=ec)\ntime.sleep(3)\nitchat.logout()\n```\n\n\u82e5\u4e0d\u8bbe\u7f6eloginCallback\u7684\u503c\uff0c\u5219\u5c06\u4f1a\u81ea\u52a8\u5220\u9664\u4e8c\u7ef4\u7801\u56fe\u7247\u5e76\u6e05\u7a7a\u547d\u4ee4\u884c\u663e\u793a\u3002\n\n## \u5e38\u89c1\u95ee\u9898\u4e0e\u89e3\u7b54\n\nQ: \u5982\u4f55\u901a\u8fc7\u8fd9\u4e2a\u5305\u5c06\u81ea\u5df1\u7684\u5fae\u4fe1\u53f7\u53d8\u4e3a\u63a7\u5236\u5668\uff1f\n\nA: \u6709\u4e24\u79cd\u65b9\u5f0f\uff1a\u53d1\u9001\u3001\u63a5\u53d7\u81ea\u5df1UserName\u7684\u6d88\u606f\uff1b\u53d1\u9001\u63a5\u6536\u6587\u4ef6\u4f20\u8f93\u52a9\u624b\uff08filehelper\uff09\u7684\u6d88\u606f\n\nQ: \u4e3a\u4ec0\u4e48\u6211\u53d1\u9001\u4fe1\u606f\u7684\u65f6\u5019\u90e8\u5206\u4fe1\u606f\u6ca1\u6709\u6210\u529f\u53d1\u51fa\u6765\uff1f\n\nA: \u6709\u4e9b\u8d26\u53f7\u662f\u5929\u751f\u65e0\u6cd5\u7ed9\u81ea\u5df1\u7684\u8d26\u53f7\u53d1\u9001\u4fe1\u606f\u7684\uff0c\u5efa\u8bae\u4f7f\u7528`filehelper`\u4ee3\u66ff\u3002\n\n## \u4f5c\u8005\n\n[LittleCoder][littlecodersh]: \u6784\u67b6\u53ca\u7ef4\u62a4Python2 Python3\u7248\u672c\u3002\n\n[tempdban][tempdban]: \u534f\u8bae\u3001\u6784\u67b6\u53ca\u65e5\u5e38\u7ef4\u62a4\u3002\n\n[Chyroc][Chyroc]: \u5b8c\u6210\u7b2c\u4e00\u7248\u672c\u7684Python3\u6784\u67b6\u3002\n\n## \u7c7b\u4f3c\u9879\u76ee\n\n[youfou/wxpy][youfou-wxpy]: \u4f18\u79c0\u7684api\u5305\u88c5\u548c\u914d\u5957\u63d2\u4ef6\uff0c\u5fae\u4fe1\u673a\u5668\u4eba/\u4f18\u96c5\u7684\u5fae\u4fe1\u4e2a\u4eba\u53f7API\n\n[liuwons/wxBot][liuwons-wxBot]: \u7c7b\u4f3c\u7684\u57fa\u4e8ePython\u7684\u5fae\u4fe1\u673a\u5668\u4eba\n\n[zixia/wechaty][zixia-wechaty]: \u57fa\u4e8eJavascript(ES6)\u7684\u5fae\u4fe1\u4e2a\u4eba\u8d26\u53f7\u673a\u5668\u4ebaNodeJS\u6846\u67b6/\u5e93\n\n[sjdy521/Mojo-Weixin][Mojo-Weixin]: \u4f7f\u7528Perl\u8bed\u8a00\u7f16\u5199\u7684\u5fae\u4fe1\u5ba2\u6237\u7aef\u6846\u67b6\uff0c\u53ef\u901a\u8fc7\u63d2\u4ef6\u63d0\u4f9b\u57fa\u4e8eHTTP\u534f\u8bae\u7684api\u63a5\u53e3\u4f9b\u5176\u4ed6\u8bed\u8a00\u8c03\u7528\n\n[HanSon/vbot][HanSon-vbot]: \u57fa\u4e8ePHP7\u7684\u5fae\u4fe1\u4e2a\u4eba\u53f7\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u5b9e\u73b0\u533f\u540d\u51fd\u6570\u53ef\u4ee5\u65b9\u4fbf\u5730\u5b9e\u73b0\u5404\u79cd\u81ea\u5b9a\u4e49\u7684\u529f\u80fd\n\n[yaphone/itchat4j][yaphone-itchat4j]: \u7528Java\u6269\u5c55\u4e2a\u4eba\u5fae\u4fe1\u53f7\u7684\u80fd\u529b\n\n[kanjielu/jeeves][kanjielu-jeeves]: \u4f7f\u7528springboot\u5f00\u53d1\u7684\u5fae\u4fe1\u673a\u5668\u4eba\n\n## \u95ee\u9898\u548c\u5efa\u8bae\n\n\u5982\u679c\u6709\u4ec0\u4e48\u95ee\u9898\u6216\u8005\u5efa\u8bae\u90fd\u53ef\u4ee5\u5728\u8fd9\u4e2a[Issue][issue#1]\u548c\u6211\u8ba8\u8bba\n\n\u6216\u8005\u4e5f\u53ef\u4ee5\u5728gitter\u4e0a\u4ea4\u6d41\uff1a[![Gitter][gitter-picture]][gitter]\n\n\u5f53\u7136\u4e5f\u53ef\u4ee5\u52a0\u5165\u6211\u4eec\u65b0\u5efa\u7684QQ\u7fa4\u8ba8\u8bba\uff1a549762872, 205872856\n\n[gitter-picture]: https://badges.gitter.im/littlecodersh/ItChat.svg\n[gitter]: https://gitter.im/littlecodersh/ItChat?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge\n[py27]: https://img.shields.io/badge/python-2.7-ff69b4.svg\n[py35]: https://img.shields.io/badge/python-3.5-red.svg\n[english-version]: https://github.com/littlecodersh/ItChat/blob/master/README_EN.md\n[itchatmp]: https://github.com/littlecodersh/itchatmp\n[document]: https://itchat.readthedocs.org/zh/latest/\n[tutorial2]: http://python.jobbole.com/86532/\n[robot-source-code]: https://gist.github.com/littlecodersh/ec8ddab12364323c97d4e36459174f0d\n[robot-qr]: http://7xrip4.com1.z0.glb.clouddn.com/ItChat%2FQRCode2.jpg?imageView/2/w/400/\n[robot-demo-file]: http://7xrip4.com1.z0.glb.clouddn.com/ItChat%2FScreenshots%2F%E5%BE%AE%E4%BF%A1%E8%8E%B7%E5%8F%96%E6%96%87%E4%BB%B6%E5%9B%BE%E7%89%87.png?imageView/2/w/300/\n[robot-demo-login]: http://7xrip4.com1.z0.glb.clouddn.com/ItChat%2FScreenshots%2F%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2%E6%88%AA%E5%9B%BE.jpg?imageView/2/w/450/\n[littlecodersh]: https://github.com/littlecodersh\n[tempdban]: https://github.com/tempdban\n[Chyroc]: https://github.com/Chyroc\n[youfou-wxpy]: https://github.com/youfou/wxpy\n[liuwons-wxBot]: https://github.com/liuwons/wxBot\n[zixia-wechaty]: https://github.com/zixia/wechaty\n[Mojo-Weixin]: https://github.com/sjdy521/Mojo-Weixin\n[HanSon-vbot]: https://github.com/hanson/vbot\n[yaphone-itchat4j]: https://github.com/yaphone/itchat4j\n[kanjielu-jeeves]: https://github.com/kanjielu/jeeves\n[issue#1]: https://github.com/littlecodersh/ItChat/issues/1\n"}, {"repo": "openai/gym", "language": "Python", "readme_contents": "**Status:** Maintenance (expect bug fixes and minor updates)\n\nOpenAI Gym\n**********\n\n**OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms.** This is the ``gym`` open-source library, which gives you access to a standardized set of environments.\n\n.. image:: https://travis-ci.org/openai/gym.svg?branch=master\n    :target: https://travis-ci.org/openai/gym\n\n`See What's New section below <#what-s-new>`_\n\n``gym`` makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano. You can use it from Python code, and soon from other languages.\n\nIf you're not sure where to start, we recommend beginning with the\n`docs <https://gym.openai.com/docs>`_ on our site. See also the `FAQ <https://github.com/openai/gym/wiki/FAQ>`_.\n\nA whitepaper for OpenAI Gym is available at http://arxiv.org/abs/1606.01540, and here's a BibTeX entry that you can use to cite it in a publication::\n\n  @misc{1606.01540,\n    Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},\n    Title = {OpenAI Gym},\n    Year = {2016},\n    Eprint = {arXiv:1606.01540},\n  }\n\n.. contents:: **Contents of this document**\n   :depth: 2\n\nBasics\n======\n\nThere are two basic concepts in reinforcement learning: the\nenvironment (namely, the outside world) and the agent (namely, the\nalgorithm you are writing). The agent sends `actions` to the\nenvironment, and the environment replies with `observations` and\n`rewards` (that is, a score).\n\nThe core `gym` interface is `Env <https://github.com/openai/gym/blob/master/gym/core.py>`_, which is\nthe unified environment interface. There is no interface for agents;\nthat part is left to you. The following are the ``Env`` methods you\nshould know:\n\n- `reset(self)`: Reset the environment's state. Returns `observation`.\n- `step(self, action)`: Step the environment by one timestep. Returns `observation`, `reward`, `done`, `info`.\n- `render(self, mode='human')`: Render one frame of the environment. The default mode will do something human friendly, such as pop up a window. \n\nSupported systems\n-----------------\n\nWe currently support Linux and OS X running Python 2.7 or 3.5 -- 3.7. \nWindows support is experimental - algorithmic, toy_text, classic_control and atari *should* work on Windows (see next section for installation instructions); nevertheless, proceed at your own risk.\n\nInstallation\n============\n\nYou can perform a minimal install of ``gym`` with:\n\n.. code:: shell\n\n    git clone https://github.com/openai/gym.git\n    cd gym\n    pip install -e .\n\nIf you prefer, you can do a minimal install of the packaged version directly from PyPI:\n\n.. code:: shell\n\n    pip install gym\n\nYou'll be able to run a few environments right away:\n\n- algorithmic\n- toy_text\n- classic_control (you'll need ``pyglet`` to render though)\n\nWe recommend playing with those environments at first, and then later\ninstalling the dependencies for the remaining environments.\n\nInstalling everything\n---------------------\n\nTo install the full set of environments, you'll need to have some system\npackages installed. We'll build out the list here over time; please let us know\nwhat you end up installing on your platform. Also, take a look at the docker files (py.Dockerfile) to\nsee the composition of our CI-tested images.\n\nOn Ubuntu 16.04 and 18.04:\n\n.. code:: shell\n    apt-get install -y libglu1-mesa-dev libgl1-mesa-dev libosmesa6-dev xvfb ffmpeg curl patchelf libglfw3 libglfw3-dev\n\n\nMuJoCo has a proprietary dependency we can't set up for you. Follow\nthe\n`instructions <https://github.com/openai/mujoco-py#obtaining-the-binaries-and-license-key>`_\nin the ``mujoco-py`` package for help.  As an alternative to ``mujoco-py``, consider `PyBullet <https://github.com/openai/gym/blob/master/docs/environments.md#pybullet-robotics-environments>`_ which uses the open source Bullet physics engine and has no license requirement.\n\nOnce you're ready to install everything, run ``pip install -e '.[all]'`` (or ``pip install 'gym[all]'``).\n\nPip version\n-----------\n\nTo run ``pip install -e '.[all]'``, you'll need a semi-recent pip.\nPlease make sure your pip is at least at version ``1.5.0``. You can\nupgrade using the following: ``pip install --ignore-installed\npip``. Alternatively, you can open `setup.py\n<https://github.com/openai/gym/blob/master/setup.py>`_ and\ninstall the dependencies by hand.\n\nRendering on a server\n---------------------\n\nIf you're trying to render video on a server, you'll need to connect a\nfake display. The easiest way to do this is by running under\n``xvfb-run`` (on Ubuntu, install the ``xvfb`` package):\n\n.. code:: shell\n\n     xvfb-run -s \"-screen 0 1400x900x24\" bash\n\nInstalling dependencies for specific environments\n-------------------------------------------------\n\nIf you'd like to install the dependencies for only specific\nenvironments, see `setup.py\n<https://github.com/openai/gym/blob/master/setup.py>`_. We\nmaintain the lists of dependencies on a per-environment group basis.\n\nEnvironments\n============\n\nSee `List of Environments <docs/environments.md>`_ and the `gym site <http://gym.openai.com/envs/>`_.\n\nFor information on creating your own environments, see `Creating your own Environments <docs/creating-environments.md>`_.\n\nExamples\n========\n\nSee the ``examples`` directory.\n\n- Run `examples/agents/random_agent.py <https://github.com/openai/gym/blob/master/examples/agents/random_agent.py>`_ to run a simple random agent.\n- Run `examples/agents/cem.py <https://github.com/openai/gym/blob/master/examples/agents/cem.py>`_ to run an actual learning agent (using the cross-entropy method).\n- Run `examples/scripts/list_envs <https://github.com/openai/gym/blob/master/examples/scripts/list_envs>`_ to generate a list of all environments.\n\nTesting\n=======\n\nWe are using `pytest <http://doc.pytest.org>`_ for tests. You can run them via:\n\n.. code:: shell\n\n    pytest\n\n\n.. _See What's New section below:\n\nWhat's new\n==========\n- 2019-11-08 (v0.15.4)\n    + Added multiple env wrappers (thanks @zuoxingdong and @hartikainen!)\n    - Removed mujoco >= 2.0 support due to lack of tests\n\n- 2019-10-09 (v0.15.3)\n    + VectorEnv modifications - unified the VectorEnv api (added reset_async, reset_wait, step_async, step_wait methods to SyncVectorEnv); more flexibility in AsyncVectorEnv workers\n\n- 2019-08-23 (v0.15.2)\n    + More Wrappers - AtariPreprocessing, FrameStack, GrayScaleObservation, FilterObservation,  FlattenDictObservationsWrapper, PixelObservationWrapper, TransformReward (thanks @zuoxingdong, @hartikainen)\n    + Remove rgb_rendering_tracking logic from mujoco environments (default behavior stays the same for the -v3 environments, rgb rendering returns a view from tracking camera)\n    + Velocity goal constraint for MountainCar (thanks @abhinavsagar)\n    + Taxi-v2 -> Taxi-v3 (add missing wall in the map to replicate env as describe in the original paper, thanks @kobotics)\n    \n- 2019-07-26 (v0.14.0)\n    + Wrapper cleanup\n    + Spec-related bug fixes\n    + VectorEnv fixes\n\n- 2019-06-21 (v0.13.1)\n    + Bug fix for ALE 0.6 difficulty modes\n    + Use narrow range for pyglet versions\n\n- 2019-06-21 (v0.13.0)\n    + Upgrade to ALE 0.6 (atari-py 0.2.0) (thanks @JesseFarebro!)\n\n- 2019-06-21 (v0.12.6)\n    + Added vectorized environments (thanks @tristandeleu!). Vectorized environment runs multiple copies of an environment in parallel. To create a vectorized version of an environment, use `gym.vector.make(env_id, num_envs, **kwargs)`, for instance, `gym.vector.make('Pong-v4',16)`.\n\n- 2019-05-28 (v0.12.5)\n    + fixed Fetch-slide environment to be solvable.\n\n- 2019-05-24 (v0.12.4)\n    + remove pyopengl dependency and use more narrow atari-py and box2d-py versions\n\n- 2019-03-25 (v0.12.1)\n    + rgb rendering in MuJoCo locomotion `-v3` environments now comes from tracking camera (so that agent does not run away from the field of view). The old behaviour can be restored by passing rgb_rendering_tracking=False kwarg. Also, a potentially breaking change!!! Wrapper class now forwards methods and attributes to wrapped env.\n\n- 2019-02-26 (v0.12.0)\n    + release mujoco environments v3 with support for gym.make kwargs such as `xml_file`, `ctrl_cost_weight`, `reset_noise_scale` etc\n\n- 2019-02-06 (v0.11.0)\n    + remove gym.spaces.np_random common PRNG; use per-instance PRNG instead.\n    + support for kwargs in gym.make\n    + lots of bugfixes\n\n- 2018-02-28: Release of a set of new robotics environments.\n- 2018-01-25: Made some aesthetic improvements and removed unmaintained parts of gym. This may seem like a downgrade in functionality, but it is actually a long-needed cleanup in preparation for some great new things that will be released in the next month.\n\n    + Now your `Env` and `Wrapper` subclasses should define `step`, `reset`, `render`, `close`, `seed` rather than underscored method names.\n    + Removed the `board_game`, `debugging`, `safety`, `parameter_tuning` environments since they're not being maintained by us at OpenAI. We encourage authors and users to create new repositories for these environments.\n    + Changed `MultiDiscrete` action space to range from `[0, ..., n-1]` rather than `[a, ..., b-1]`.\n    + No more `render(close=True)`, use env-specific methods to close the rendering.\n    + Removed `scoreboard` directory, since site doesn't exist anymore.\n    + Moved `gym/monitoring` to `gym/wrappers/monitoring`\n    + Add `dtype` to `Space`.\n    + Not using python's built-in module anymore, using `gym.logger`\n\n- 2018-01-24: All continuous control environments now use mujoco_py >= 1.50.\n  Versions have been updated accordingly to -v2, e.g. HalfCheetah-v2. Performance\n  should be similar (see https://github.com/openai/gym/pull/834) but there are likely\n  some differences due to changes in MuJoCo.\n- 2017-06-16: Make env.spec into a property to fix a bug that occurs\n  when you try to print out an unregistered Env.\n- 2017-05-13: BACKWARDS INCOMPATIBILITY: The Atari environments are now at\n  *v4*. To keep using the old v3 environments, keep gym <= 0.8.2 and atari-py\n  <= 0.0.21. Note that the v4 environments will not give identical results to\n  existing v3 results, although differences are minor. The v4 environments\n  incorporate the latest Arcade Learning Environment (ALE), including several\n  ROM fixes, and now handle loading and saving of the emulator state. While\n  seeds still ensure determinism, the effect of any given seed is not preserved\n  across this upgrade because the random number generator in ALE has changed.\n  The `*NoFrameSkip-v4` environments should be considered the canonical Atari\n  environments from now on.\n- 2017-03-05: BACKWARDS INCOMPATIBILITY: The `configure` method has been removed\n  from `Env`. `configure` was not used by `gym`, but was used by some dependent\n  libraries including `universe`. These libraries will migrate away from the\n  configure method by using wrappers instead. This change is on master and will be released with 0.8.0.\n- 2016-12-27: BACKWARDS INCOMPATIBILITY: The gym monitor is now a\n  wrapper. Rather than starting monitoring as\n  `env.monitor.start(directory)`, envs are now wrapped as follows:\n  `env = wrappers.Monitor(env, directory)`. This change is on master\n  and will be released with 0.7.0.\n- 2016-11-1: Several experimental changes to how a running monitor interacts\n  with environments. The monitor will now raise an error if reset() is called\n  when the env has not returned done=True. The monitor will only record complete\n  episodes where done=True. Finally, the monitor no longer calls seed() on the\n  underlying env, nor does it record or upload seed information.\n- 2016-10-31: We're experimentally expanding the environment ID format\n  to include an optional username.\n- 2016-09-21: Switch the Gym automated logger setup to configure the\n  root logger rather than just the 'gym' logger.\n- 2016-08-17: Calling `close` on an env will also close the monitor\n  and any rendering windows.\n- 2016-08-17: The monitor will no longer write manifest files in\n  real-time, unless `write_upon_reset=True` is passed.\n- 2016-05-28: For controlled reproducibility, envs now support seeding\n  (cf #91 and #135). The monitor records which seeds are used. We will\n  soon add seed information to the display on the scoreboard.\n"}, {"repo": "pypa/pipenv", "language": "Python", "readme_contents": "Pipenv: Python Development Workflow for Humans\n==============================================\n\n[![image](https://img.shields.io/pypi/v/pipenv.svg)](https://python.org/pypi/pipenv)\n[![image](https://img.shields.io/pypi/l/pipenv.svg)](https://python.org/pypi/pipenv)\n[![Azure Pipelines Build Status](https://dev.azure.com/pypa/pipenv/_apis/build/status/Pipenv%20CI?branchName=master)](https://dev.azure.com/pypa/pipenv/_build/latest?definitionId=16&branchName=master)\n[![image](https://img.shields.io/pypi/pyversions/pipenv.svg)](https://python.org/pypi/pipenv)\n[![image](https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg)](https://saythanks.io/to/kennethreitz)\n\n------------------------------------------------------------------------\n\n**Pipenv** is a tool that aims to bring the best of all packaging worlds\n(bundler, composer, npm, cargo, yarn, etc.) to the Python world.\n*Windows is a first-class citizen, in our world.*\n\nIt automatically creates and manages a virtualenv for your projects, as\nwell as adds/removes packages from your `Pipfile` as you\ninstall/uninstall packages. It also generates the ever-important\n`Pipfile.lock`, which is used to produce deterministic builds.\n\n![GIF demonstrating Pipenv's usage](https://gist.githubusercontent.com/jlusk/855d611bbcfa2b159839db73d07f6ce9/raw/7f5743401809f7e630ee8ff458faa980e19924a0/pipenv.gif)\n\nThe problems that Pipenv seeks to solve are multi-faceted:\n\n-   You no longer need to use `pip` and `virtualenv` separately. They\n    work together.\n-   Managing a `requirements.txt` file [can be\n    problematic](https://www.kennethreitz.org/essays/a-better-pip-workflow),\n    so Pipenv uses the upcoming `Pipfile` and `Pipfile.lock` instead,\n    which is superior for basic use cases.\n-   Hashes are used everywhere, always. Security. Automatically expose\n    security vulnerabilities.\n-   Give you insight into your dependency graph (e.g. `$ pipenv graph`).\n-   Streamline development workflow by loading `.env` files.\n\nYou can quickly play with Pipenv right in your browser:\n\n[![Try in browser](https://cdn.rawgit.com/rootnroll/library/assets/try.svg)](https://rootnroll.com/d/pipenv/)\n\nInstallation\n------------\n\nIf you\\'re on MacOS, you can install Pipenv easily with Homebrew:\n\n    $ brew install pipenv\n\nOr, if you\\'re using Debian Buster+:\n\n    $ sudo apt install pipenv\n\nOr, if you\\'re using Fedora:\n\n    $ sudo dnf install pipenv\n    \nOr, if you\\'re using FreeBSD:\n\n    # pkg install py36-pipenv\n\nOtherwise, refer to the [documentation](https://pipenv.kennethreitz.org/en/latest/#install-pipenv-today) for instructions.\n\n\u2728\ud83c\udf70\u2728\n\n\u2624 User Testimonials\n-------------------\n\n**Jannis Leidel**, former pip maintainer---\n\n:   *Pipenv is the porcelain I always wanted to build for pip. It fits\n    my brain and mostly replaces virtualenvwrapper and manual pip calls\n    for me. Use it.*\n\n**David Gang**---\n\n:   *This package manager is really awesome. For the first time I know\n    exactly what my dependencies are which I installed and what the\n    transitive dependencies are. Combined with the fact that installs\n    are deterministic, makes this package manager first class, like\n    cargo*.\n\n**Justin Myles Holmes**---\n\n:   *Pipenv is finally an abstraction meant to engage the mind instead\n    of merely the filesystem.*\n\n\u2624 Features\n----------\n\n-   Enables truly *deterministic builds*, while easily specifying *only\n    what you want*.\n-   Generates and checks file hashes for locked dependencies.\n-   Automatically install required Pythons, if `pyenv` is available.\n-   Automatically finds your project home, recursively, by looking for a\n    `Pipfile`.\n-   Automatically generates a `Pipfile`, if one doesn\\'t exist.\n-   Automatically creates a virtualenv in a standard location.\n-   Automatically adds/removes packages to a `Pipfile` when they are\n    un/installed.\n-   Automatically loads `.env` files, if they exist.\n\nThe main commands are `install`, `uninstall`, and `lock`, which\ngenerates a `Pipfile.lock`. These are intended to replace\n`$ pip install` usage, as well as manual virtualenv management (to\nactivate a virtualenv, run `$ pipenv shell`).\n\n### Basic Concepts\n\n-   A virtualenv will automatically be created, when one doesn\\'t exist.\n-   When no parameters are passed to `install`, all packages\n    `[packages]` specified will be installed.\n-   To initialize a Python 3 virtual environment, run\n    `$ pipenv --three`.\n-   To initialize a Python 2 virtual environment, run `$ pipenv --two`.\n-   Otherwise, whatever virtualenv defaults to will be the default.\n\n### Other Commands\n\n-   `shell` will spawn a shell with the virtualenv activated.\n-   `run` will run a given command from the virtualenv, with any\n    arguments forwarded (e.g. `$ pipenv run python`).\n-   `check` asserts that PEP 508 requirements are being met by the\n    current environment.\n-   `graph` will print a pretty graph of all your installed\n    dependencies.\n\n### Shell Completion\n\nFor example, with fish, put this in your\n`~/.config/fish/completions/pipenv.fish`:\n\n    eval (pipenv --completion)\n\nAlternatively, with bash, put this in your `.bashrc` or `.bash_profile`:\n\n    eval \"$(pipenv --completion)\"\n\nMagic shell completions are now enabled! There is also a [fish\nplugin](https://github.com/fisherman/pipenv), which will automatically\nactivate your subshells for you!\n\nFish is the best shell. You should use it.\n\n\u2624 Usage\n-------\n\n    $ pipenv\n    Usage: pipenv [OPTIONS] COMMAND [ARGS]...\n\n    Options:\n      --where          Output project home information.\n      --venv           Output virtualenv information.\n      --py             Output Python interpreter information.\n      --envs           Output Environment Variable options.\n      --rm             Remove the virtualenv.\n      --bare           Minimal output.\n      --completion     Output completion (to be eval'd).\n      --man            Display manpage.\n      --three / --two  Use Python 3/2 when creating virtualenv.\n      --python TEXT    Specify which version of Python virtualenv should use.\n      --site-packages  Enable site-packages for the virtualenv.\n      --version        Show the version and exit.\n      -h, --help       Show this message and exit.\n\n\n    Usage Examples:\n       Create a new project using Python 3.7, specifically:\n       $ pipenv --python 3.7\n\n       Remove project virtualenv (inferred from current directory):\n       $ pipenv --rm\n\n       Install all dependencies for a project (including dev):\n       $ pipenv install --dev\n\n       Create a lockfile containing pre-releases:\n       $ pipenv lock --pre\n\n       Show a graph of your installed dependencies:\n       $ pipenv graph\n\n       Check your installed dependencies for security vulnerabilities:\n       $ pipenv check\n\n       Install a local setup.py into your virtual environment/Pipfile:\n       $ pipenv install -e .\n\n       Use a lower-level pip command:\n       $ pipenv run pip freeze\n\n    Commands:\n      check      Checks for security vulnerabilities and against PEP 508 markers\n                 provided in Pipfile.\n      clean      Uninstalls all packages not specified in Pipfile.lock.\n      graph      Displays currently\u2013installed dependency graph information.\n      install    Installs provided packages and adds them to Pipfile, or (if no\n                 packages are given), installs all packages from Pipfile.\n      lock       Generates Pipfile.lock.\n      open       View a given module in your editor.\n      run        Spawns a command installed into the virtualenv.\n      shell      Spawns a shell within the virtualenv.\n      sync       Installs all packages specified in Pipfile.lock.\n      uninstall  Un-installs a provided package and removes it from Pipfile.\n\nLocate the project:\n\n    $ pipenv --where\n    /Users/kennethreitz/Library/Mobile Documents/com~apple~CloudDocs/repos/kr/pipenv/test\n\nLocate the virtualenv:\n\n    $ pipenv --venv\n    /Users/kennethreitz/.local/share/virtualenvs/test-Skyy4vre\n\nLocate the Python interpreter:\n\n    $ pipenv --py\n    /Users/kennethreitz/.local/share/virtualenvs/test-Skyy4vre/bin/python\n\nInstall packages:\n\n    $ pipenv install\n    Creating a virtualenv for this project...\n    ...\n    No package provided, installing all dependencies.\n    Virtualenv location: /Users/kennethreitz/.local/share/virtualenvs/test-EJkjoYts\n    Installing dependencies from Pipfile.lock...\n    ...\n\n    To activate this project's virtualenv, run the following:\n    $ pipenv shell\n\nInstalling from git:\n\nYou can install packages with pipenv from git and other version control systems using URLs formatted according to the following rule:\n\n    <vcs_type>+<scheme>://<location>/<user_or_organization>/<repository>@<branch_or_tag>#<package_name>\n\nThe only optional section is the `@<branch_or_tag>` section.  When using git over SSH, you may use the shorthand vcs and scheme alias `git+git@<location>:<user_or_organization>/<repository>@<branch_or_tag>#<package_name>`. Note that this is translated to `git+ssh://git@<location>` when parsed.\n\nValid values for `<vcs_type>` include `git`, `bzr`, `svn`, and `hg`.  Valid values for `<scheme>` include `http,`, `https`, `ssh`, and `file`.  In specific cases you also have access to other schemes: `svn` may be combined with `svn` as a scheme, and `bzr` can be combined with `sftp` and `lp`.\n\nNote that it is **strongly recommended** that you install any version-controlled dependencies in editable mode, using `pipenv install -e`, in order to ensure that dependency resolution can be performed with an up to date copy of the repository each time it is performed, and that it includes all known dependencies.\n\nBelow is an example usage which installs the git repository located at `https://github.com/requests/requests.git` from tag `v2.19.1` as package name `requests`:\n\n    $ pipenv install -e git+https://github.com/requests/requests.git@v2.19#egg=requests\n    Creating a Pipfile for this project...\n    Installing -e git+https://github.com/requests/requests.git@v2.19.1#egg=requests...\n    [...snipped...]\n    Adding -e git+https://github.com/requests/requests.git@v2.19.1#egg=requests to Pipfile's [packages]...\n    [...]\n\nYou can read more about [pip's implementation of vcs support here](https://pip.pypa.io/en/stable/reference/pip_install/#vcs-support).\n\nInstall a dev dependency:\n\n    $ pipenv install pytest --dev\n    Installing pytest...\n    ...\n    Adding pytest to Pipfile's [dev-packages]...\n\nShow a dependency graph:\n\n    $ pipenv graph\n    requests==2.18.4\n      - certifi [required: >=2017.4.17, installed: 2017.7.27.1]\n      - chardet [required: >=3.0.2,<3.1.0, installed: 3.0.4]\n      - idna [required: >=2.5,<2.7, installed: 2.6]\n      - urllib3 [required: <1.23,>=1.21.1, installed: 1.22]\n\nGenerate a lockfile:\n\n    $ pipenv lock\n    Assuring all dependencies from Pipfile are installed...\n    Locking [dev-packages] dependencies...\n    Locking [packages] dependencies...\n    Note: your project now has only default [packages] installed.\n    To install [dev-packages], run: $ pipenv install --dev\n\nInstall all dev dependencies:\n\n    $ pipenv install --dev\n    Pipfile found at /Users/kennethreitz/repos/kr/pip2/test/Pipfile. Considering this to be the project home.\n    Pipfile.lock out of date, updating...\n    Assuring all dependencies from Pipfile are installed...\n    Locking [dev-packages] dependencies...\n    Locking [packages] dependencies...\n\nUninstall everything:\n\n    $ pipenv uninstall --all\n    No package provided, un-installing all dependencies.\n    Found 25 installed package(s), purging...\n    ...\n    Environment now purged and fresh!\n\nUse the shell:\n\n    $ pipenv shell\n    Loading .env environment variables\u2026\n    Launching subshell in virtual environment. Type 'exit' or 'Ctrl+D' to return.\n    $ \u25af\n\n\u2624 Documentation\n---------------\n\nDocumentation resides over at [pipenv.org](https://pipenv.kennethreitz.org/en/latest/).\n"}, {"repo": "donnemartin/interactive-coding-challenges", "language": "Python", "readme_contents": "<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/cover_challenge.gif\">\n</p>\n\ninteractive-coding-challenges\n============\n\n**120+ continually updated, interactive, and test-driven coding challenges**, with [Anki flashcards](#anki-flashcards-coding-and-design).\n\nChallenges focus on **algorithms** and **data structures** found in **coding interviews**.\n\nEach challenge has one or more reference solutions that are:\n\n* Fully functional\n* Unit tested\n* Easy-to-understand\n\nChallenges will soon provide on-demand [incremental hints](https://github.com/donnemartin/interactive-coding-challenges/issues/22) to help you arrive at the optimal solution.\n\nNotebooks also detail:\n\n* Constraints\n* Test cases\n* Algorithms\n* Big-O time and space complexities\n\nAlso included are **unit tested reference implementations** of various [data structures](#reference-implementations-data-structures) and [algorithms](#reference-implementations-algorithms).\n\n## Challenge Solutions\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/cover_solution.gif\">\n</p>\n<br/>\n\n## Anki Flashcards: Coding and Design\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/b4YtAEN.png\">\n  <br/>\n</p>\n\nThe provided [Anki flashcard deck](https://apps.ankiweb.net/) uses spaced repetition to help you retain key concepts.\n\n* [Coding deck](anki_cards/Coding.apkg)\n\nGreat for use while on-the-go.\n\n### Design Resource: The System Design Primer\n\nLooking for resources to help you prep for the **System Design** and **Object-Oriented Design interviews**?\n\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/zdCAkB3.png\">\n  <br/>\n</p>\n\nCheck out the sister repo [The System Design Primer](https://github.com/donnemartin/system-design-primer), which contains additional Anki decks:\n\n* [System design deck](https://github.com/donnemartin/system-design-primer/blob/master/resources/flash_cards/System%20Design.apkg)\n* [System design exercises deck](https://github.com/donnemartin/system-design-primer/blob/master/resources/flash_cards/System%20Design%20Exercises.apkg)\n* [Object oriented design exercises deck](https://github.com/donnemartin/system-design-primer/blob/master/resources/flash_cards/OO%20Design.apkg)\n\n![](https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67)\n\n## Notebook Structure\n\nEach challenge has two notebooks, a **challenge notebook** with unit tests for you to solve and a **solution notebook** for reference.\n\n### Problem Statement\n\n* States the problem to solve.\n\n### Constraints\n\n* Describes any constraints or assumptions.\n\n### Test Cases\n\n* Describes the general and edge test cases that will be evaluated in the unit test.\n\n### Algorithm\n\n* [Challenge Notebook] Empty, refer to the solution notebook algorithm section if you need a hint.\n* [Solution Notebook] One or more algorithm solution discussions, with Big-O time and space complexities.\n\n### Hints\n\n* [Challenge Notebook] Provides on-demand [incremental hints](https://github.com/donnemartin/interactive-coding-challenges/issues/22) to help you arrive at the optimal solution.  Coming soon!\n\n### Code (Challenge: Implement Me!)\n\n* [Challenge Notebook] Skeleton code for you to implement.\n* [Solution Notebook] One or more reference solutions.\n\n### Unit Test\n\n* [Challenge Notebook] Unit test for your code.  Expected to fail until you solve the challenge.\n* [Solution Notebook] Unit test for the reference solution(s).\n\n## Index\n\n### Challenges Categories\n\n**Format**: Challenge Category - Number of Challenges\n\n* [Arrays and Strings](#arrays-and-strings) - 10\n* [Linked Lists](#linked-lists) - 8\n* [Stacks and Queues](#stacks-and-queues) - 8\n* [Graphs and Trees](#graphs-and-trees) - 21\n* [Sorting](#sorting) - 10\n* [Recursion and Dynamic Programming](#recursion-and-dynamic-programming) - 17\n* [Mathematics and Probability](#mathematics-and-probability) - 6\n* [Bit Manipulation](#bit-manipulation) - 8\n* [Online Judges](#online-judges) - 16\n* [System Design](https://github.com/donnemartin/system-design-primer#system-design-interview-questions-with-solutions) - 8\n* [Object Oriented Design](https://github.com/donnemartin/system-design-primer#object-oriented-design-interview-questions-with-solutions) - 8\n\n**Total number of challenges: 120**\n\n### Reference Implementations: Data Structures\n\nUnit tested, fully functional implementations of the following data structures:\n\n* [Linked List](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/linked_list/linked_list_solution.ipynb)\n* [Stack](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/stack/stack_solution.ipynb)\n* [Queue](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/queue_list/queue_list_solution.ipynb)\n* [Binary Search Tree](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst/bst_solution.ipynb)\n* [Graph](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph/graph_solution.ipynb)\n* [Min Heap](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/min_heap/min_heap_solution.ipynb)\n* [Trie](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/trie/trie_solution.ipynb)\n* [Priority Queue](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/priority_queue/priority_queue_solution.ipynb)\n* [Hash Map](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/hash_map/hash_map_solution.ipynb)\n\n### Reference Implementations: Algorithms\n\nUnit tested, fully functional implementations of the following algorithms:\n\n* [Selection Sort](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/selection_sort/selection_sort_solution.ipynb)\n* [Insertion Sort](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/insertion_sort/insertion_sort_solution.ipynb)\n* [Quick Sort](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/quick_sort/quick_sort_solution.ipynb)\n* [Merge Sort](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/merge_sort/merge_sort_solution.ipynb)\n* [Radix Sort](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/radix_sort/radix_sort_solution.ipynb)\n* [Topological Sort](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_build_order/build_order_solution.ipynb)\n* [Tree Depth-First Search (Pre-, In-, Post-Order)](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_dfs/dfs_solution.ipynb)\n* [Tree Breadth-First Search](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_bfs/bfs_solution.ipynb)\n* [Graph Depth-First Search](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_dfs/dfs_solution.ipynb)\n* [Graph Breadth-First Search](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_bfs/bfs_solution.ipynb)\n* [Dijkstra's Shortest Path](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_shortest_path/graph_shortest_path_solution.ipynb)\n* [Unweighted Graph Shortest Path](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_shortest_path_unweighted/shortest_path_solution.ipynb)\n* [Knapsack 0/1](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/knapsack_01/knapsack_solution.ipynb)\n* [Knapsack Unbounded](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/knapsack_unbounded/knapsack_unbounded_solution.ipynb)\n* [Sieve of Eratosthenes](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/generate_primes/check_prime_solution.ipynb)\n\n### Reference Implementations: TODO\n\n* [A*](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Bellman-Ford](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Bloom Filter](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Convex Hull](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Fisher-Yates Shuffle](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Kruskal's](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Max Flow](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Prim's](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Rabin-Karp](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Traveling Salesman](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Union Find](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n\n### Installing and Running Challenges\n\n* [Repo Structure](#repo-structure)\n* [Notebook Installation](#notebook-installation)\n    * [Nose Installation](#nose-installation)\n* [Running Challenges](#running-challenges)\n\n### Misc\n\n* [Contributing](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\n* [Credits](#credits)\n* [Contact Info](#contact-info)\n* [License](#license)\n\n## Challenges\n\n[Image Credits](#credits)\n\n<br/>\n<p>\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/arrays_nltk.png\">\n</p>\n<br/>\n\n### Arrays and Strings\n\n| Challenge | Static Notebook |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Determine if a string contains unique characters | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/unique_chars/unique_chars_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/unique_chars/unique_chars_solution.ipynb) |\n| Determine if a string is a permutation of another | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/permutation/permutation_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/permutation/permutation_solution.ipynb) |\n| Determine if a string is a rotation of another | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/rotation/rotation_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/rotation/rotation_solution.ipynb) |\n| Compress a string | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/compress/compress_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/compress/compress_solution.ipynb) |\n| Reverse characters in a string | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/reverse_string/reverse_string_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/reverse_string/reverse_string_solution.ipynb) |\n| Given two strings, find the single different char | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/str_diff/str_diff_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/str_diff/str_diff_solution.ipynb) |\n| Find two indices that sum to a specific value | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/two_sum/two_sum_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/two_sum/two_sum_solution.ipynb) |\n| Implement a hash table | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/hash_map/hash_map_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/hash_map/hash_map_solution.ipynb) |\n| Implement fizz buzz | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/fizz_buzz/fizz_buzz_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/fizz_buzz/fizz_buzz_solution.ipynb) |\n| Find the first non-repeated character in a string | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Remove specified characters in a string | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Reverse words in a string | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Convert a string to an integer | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Convert an integer to a string | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/linked_lists_wikipedia.png\">\n</p>\n<br/>\n\n### Linked Lists\n\n| Challenge | Static Notebook |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Remove duplicates from a linked list | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/remove_duplicates/remove_duplicates_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/remove_duplicates/remove_duplicates_solution.ipynb) |\n| Find the kth to last element of a linked list | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/kth_to_last_elem/kth_to_last_elem_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/kth_to_last_elem/kth_to_last_elem_solution.ipynb) |\n| Delete a node in the middle of a linked list | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/delete_mid/delete_mid_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/delete_mid/delete_mid_solution.ipynb) |\n| Partition a linked list around a given value | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/partition/partition_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/partition/partition_solution.ipynb) |\n| Add two numbers whose digits are stored in a linked list | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/add_reverse/add_reverse_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/add_reverse/add_reverse_solution.ipynb) |\n| Find the start of a linked list loop | [Challenge](http://nbviewer.jupyter.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/find_loop_start/find_loop_start_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/find_loop_start/find_loop_start_solution.ipynb) |\n| Determine if a linked list is a palindrome | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/palindrome/palindrome_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/palindrome/palindrome_solution.ipynb) |\n| Implement a linked list | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/linked_list/linked_list_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/linked_lists/linked_list/linked_list_solution.ipynb) |\n| Determine if a list is cyclic or acyclic | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/stack_queue_wikipedia.png\">\n</p>\n<br/>\n\n### Stacks and Queues\n\n| Challenge | Static Notebook |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Implement n stacks using a single array | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/n_stacks/n_stacks_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/n_stacks/n_stacks_solution.ipynb) |\n| Implement a stack that keeps track of its minimum element | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/stack_min/stack_min_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/stack_min/stack_min_solution.ipynb) |\n| Implement a set of stacks class that wraps a list of capacity-bounded stacks | [Challenge](http://nbviewer.jupyter.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/set_of_stacks/set_of_stacks_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/set_of_stacks/set_of_stacks_solution.ipynb) |\n| Implement a queue using two stacks | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/queue_from_stacks/queue_from_stacks_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/queue_from_stacks/queue_from_stacks_solution.ipynb) |\n| Sort a stack using another stack as a buffer | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/sort_stack/sort_stack_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/sort_stack/sort_stack_solution.ipynb) |\n| Implement a stack | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/stack/stack_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/stack/stack_solution.ipynb) |\n| Implement a queue | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/queue_list/queue_list_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/stacks_queues/queue_list/queue_list_solution.ipynb) |\n| Implement a priority queue backed by an array | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/priority_queue/priority_queue_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/arrays_strings/priority_queue/priority_queue_solution.ipynb) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/binary_tree_wikipedia.png\">\n</p>\n<br/>\n\n### Graphs and Trees\n\n| Challenge | Static Notebooks |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Implement depth-first search (pre-, in-, post-order) on a tree |  [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_dfs/dfs_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_dfs/dfs_solution.ipynb) |\n| Implement breadth-first search on a tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_bfs/bfs_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_bfs/bfs_solution.ipynb) |\n| Determine the height of a tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_height/height_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_height/height_solution.ipynb) |\n| Create a binary search tree with minimal height from a sorted array | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_min/bst_min_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_min/bst_min_solution.ipynb) |\n| Create a linked list for each level of a binary tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_level_lists/tree_level_lists_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_level_lists/tree_level_lists_solution.ipynb) |\n| Check if a binary tree is balanced | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/check_balance/check_balance_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/check_balance/check_balance_solution.ipynb) |\n| Determine if a tree is a valid binary search tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_validate/bst_validate_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_validate/bst_validate_solution.ipynb) |\n| Find the in-order successor of a given node in a binary search tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_successor/bst_successor_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_successor/bst_successor_solution.ipynb) |\n| Find the second largest node in a binary search tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_second_largest/bst_second_largest_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst_second_largest/bst_second_largest_solution.ipynb) |\n| Find the lowest common ancestor | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_lca/tree_lca_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/tree_lca/tree_lca_solution.ipynb) |\n| Invert a binary tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/invert_tree/invert_tree_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/invert_tree/invert_tree_solution.ipynb) |\n| Implement a binary search tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst/bst_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/bst/bst_solution.ipynb) |\n| Implement a min heap | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/min_heap/min_heap_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/min_heap/min_heap_solution.ipynb) |\n| Implement a trie | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/trie/trie_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/trie/trie_solution.ipynb) |\n| Implement depth-first search on a graph |  [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_dfs/dfs_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_dfs/dfs_solution.ipynb) |\n| Implement breadth-first search on a graph | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_bfs/bfs_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_bfs/bfs_solution.ipynb) |\n| Determine if there is a path between two nodes in a graph | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_path_exists/path_exists_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_path_exists/path_exists_solution.ipynb) |\n| Implement a graph | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph/graph_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph/graph_solution.ipynb) |\n| Find a build order given a list of projects and dependencies. |  [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_build_order/build_order_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_build_order/build_order_solution.ipynb) |\n| Find the shortest path in a weighted graph. |  [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_shortest_path/graph_shortest_path_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_shortest_path/graph_shortest_path_solution.ipynb) |\n| Find the shortest path in an unweighted graph. |  [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_shortest_path_unweighted/shortest_path_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/graphs_trees/graph_shortest_path_unweighted/shortest_path_solution.ipynb) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6a/Sorting_quicksort_anim.gif\">\n</p>\n<br/>\n\n### Sorting\n\n| Challenge | Static Notebooks |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Implement selection sort | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/selection_sort/selection_sort_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/selection_sort/selection_sort_solution.ipynb) |\n| Implement insertion sort | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/insertion_sort/insertion_sort_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/insertion_sort/insertion_sort_solution.ipynb) |\n| Implement quick sort | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/quick_sort/quick_sort_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/quick_sort/quick_sort_solution.ipynb) |\n| Implement merge sort | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/merge_sort/merge_sort_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/merge_sort/merge_sort_solution.ipynb) |\n| Implement radix sort | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/radix_sort/radix_sort_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/radix_sort/radix_sort_solution.ipynb) |\n| Sort an array of strings so all anagrams are next to each other | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/anagrams/anagrams_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/anagrams/anagrams_solution.ipynb) |\n| Find an item in a sorted, rotated array | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/rotated_array_search/rotated_array_search_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/rotated_array_search/rotated_array_search_solution.ipynb) |\n| Search a sorted matrix for an item | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/search_sorted_matrix/search_sorted_matrix_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/search_sorted_matrix/search_sorted_matrix_solution.ipynb) |\n| Find an int not in an input of n integers | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/new_int/new_int_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/new_int/new_int_solution.ipynb) |\n|  Given sorted arrays A, B, merge B into A in sorted order | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/merge_into/merge_into_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/sorting_searching/merge_into/merge_into_solution.ipynb) |\n| Implement a stable selection sort | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Make an unstable sort stable | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Implement an efficient, in-place version of quicksort | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Given two sorted arrays, merge one into the other in sorted order | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Find an element in a rotated and sorted array of integers | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/fibonacci_wikipedia.png\">\n</p>\n<br/>\n\n### Recursion and Dynamic Programming\n\n| Challenge | Static Notebooks |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Implement fibonacci recursively, dynamically, and iteratively | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/fibonacci/fibonacci_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/fibonacci/fibonacci_solution.ipynb) |\n| Maximize items placed in a knapsack | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/knapsack_01/knapsack_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/knapsack_01/knapsack_solution.ipynb) |\n| Maximize unbounded items placed in a knapsack | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/knapsack_unbounded/knapsack_unbounded_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/knapsack_unbounded/knapsack_unbounded_solution.ipynb) |\n| Find the longest common subsequence | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/longest_common_subsequence/longest_common_subseq_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/longest_common_subsequence/longest_common_subseq_solution.ipynb) |\n| Find the longest increasing subsequence | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/longest_inc_subseq/longest_inc_subseq_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/longest_inc_subseq/longest_inc_subseq_solution.ipynb) |\n| Minimize the cost of matrix multiplication | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/matrix_mult/find_min_cost_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/matrix_mult/find_min_cost_solution.ipynb) |\n| Maximize stock prices given k transactions | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/max_profit_k/max_profit_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/max_profit_k/max_profit_solution.ipynb) |\n| Find the minimum number of ways to represent n cents given an array of coins | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/coin_change_min/coin_change_min_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/coin_change_min/coin_change_min_solution.ipynb) |\n| Find the unique number of ways to represent n cents given an array of coins | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/coin_change/coin_change_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/coin_change/coin_change_solution.ipynb) |\n| Print all valid combinations of n-pairs of parentheses | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/n_pairs_parentheses/n_pairs_parentheses_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/n_pairs_parentheses/n_pairs_parentheses_solution.ipynb) |\n| Navigate a maze | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/grid_path/grid_path_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/grid_path/grid_path_solution.ipynb) |\n| Print all subsets of a set | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/power_set/power_set_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/power_set/power_set_solution.ipynb) |\n| Print all permutations of a string | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/permutations/permutations_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/permutations/permutations_solution.ipynb) |\n| Find the magic index in an array | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/magic_index/magic_index_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/magic_index/magic_index_solution.ipynb) |\n| Find the number of ways to run up n steps | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/steps/steps_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/steps/steps_solution.ipynb) |\n| Implement the Towers of Hanoi with 3 towers and N disks | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/hanoi/hanoi_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/recursion_dynamic/hanoi/hanoi_solution.ipynb) |\n| Implement factorial recursively, dynamically, and iteratively | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Perform a binary search on a sorted array of integers | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Print all combinations of a string | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Implement a paint fill function | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Find all permutations to represent n cents, given 1, 5, 10, 25 cent coins | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/probability_distribution_wikipedia.png\">\n</p>\n<br/>\n\n### Mathematics and Probability\n\n| Challenge | Static Notebooks |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Generate a list of primes | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/generate_primes/check_prime_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/generate_primes/check_prime_solution.ipynb) |\n| Find the digital root | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/add_digits/add_digits_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/add_digits/add_digits_solution.ipynb) |\n| Create a class supporting insert, max, min, mean, mode in O(1) | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/math_ops/math_ops_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/math_ops/math_ops_solution.ipynb) |\n| Determine if a number is a power of two | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/power_two/power_two_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/power_two/power_two_solution.ipynb) |\n| Add two numbers without the + or - sign | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/sum_two/sum_two_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/sum_two/sum_two_solution.ipynb) |\n| Subtract two numbers without the + or - sign | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/sub_two/sub_two_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/math_probability/sub_two/sub_two_solution.ipynb) |\n| Check if a number is prime | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Determine if two lines on a Cartesian plane intersect | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Using only add, implement multiply, subtract, and divide for ints | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Find the kth number such that the only prime factors are 3, 5, and 7 | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/bit_manipulation_wikipedia.png\">\n</p>\n<br/>\n\n### Bit Manipulation\n\n| Challenge | Static Notebooks |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Implement common bit manipulation operations | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/bit/bit_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/bit/bit_solution.ipynb) |\n| Determine number of bits to flip to convert a into b | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/bits_to_flip/bits_to_flip_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/bits_to_flip/bits_to_flip_solution.ipynb) |\n| Draw a line on a screen | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/draw_line/draw_line_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/draw_line/draw_line_solution.ipynb) |\n| Flip a bit to maximize the longest sequence of 1s | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/flip_bit/flip_bit_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/flip_bit/flip_bit_solution.ipynb) |\n| Get the next largest and next smallest numbers | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/get_next/get_next_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/get_next/get_next_solution.ipynb) |\n| Merge two binary numbers | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/insert_m_into_n/insert_m_into_n_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/insert_m_into_n/insert_m_into_n_solution.ipynb) |\n| Swap odd and even bits in an integer | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/pairwise_swap/pairwise_swap_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/pairwise_swap/pairwise_swap_solution.ipynb) |\n| Print the binary representation of a number between 0 and 1 | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/print_binary/print_binary_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/bit_manipulation/print_binary/print_binary_solution.ipynb) |\n| Determine the number of 1s in the binary representation of a given integer | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/interactive-coding-challenges/master/images/logo_topcoder.png\">\n</p>\n<br/>\n\n### Online Judges\n\n| Challenge | Static Notebooks |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| Find the longest substring with at most k distinct chars | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/longest_substr_k_distinct/longest_substr_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/longest_substr_k_distinct/longest_substr_solution.ipynb) |\n| Find the highest product of three numbers | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/prod_three/prod_three_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/prod_three/prod_three_solution.ipynb) |\n| Maximize stocks profit from 1 buy and 1 sell | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/max_profit/max_profit_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/max_profit/max_profit_solution.ipynb) |\n| Move all zeroes in a list to the end | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/move_zeroes/move_zeroes_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/move_zeroes/move_zeroes_solution.ipynb) |\n| Find the products of every other int | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/mult_other_numbers/mult_other_numbers_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/mult_other_numbers/mult_other_numbers_solution.ipynb) |\n| Given a list of entries and exits, find the busiest period | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/busiest_period/busiest_period_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/busiest_period/busiest_period_solution.ipynb) |\n| Determine an island's perimeter | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/island_perimeter/island_perimeter_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/island_perimeter/island_perimeter_solution.ipynb) |\n| Format license keys | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/license_key/format_license_key_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/license_key/format_license_key_solution.ipynb) |\n| Find the longest absolute file path | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/longest_abs_file_path/longest_path_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/longest_abs_file_path/longest_path_solution.ipynb) |\n| Merge tuple ranges | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/merge_ranges/merge_ranges_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/merge_ranges/merge_ranges_solution.ipynb) |\n| Assign cookies | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/assign_cookies/assign_cookies_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/assign_cookies/assign_cookies_solution.ipynb) |\n| Determine if you can win in Nim | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/nim/nim_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/nim/nim_solution.ipynb) |\n| Check if a magazine could have been used to create a ransom note | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/ransom_note/ransom_note_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/ransom_note/ransom_note_solution.ipynb) |\n| Find the number of times a sentence can fit on a screen | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/sentence_screen_fit/sentence_screen_fit_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/sentence_screen_fit/sentence_screen_fit_solution.ipynb) |\n| Utopian tree | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/utopian_tree/utopian_tree_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/utopian_tree/utopian_tree_solution.ipynb) |\n| Maximizing xor | [Challenge](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/maximizing_xor/maximizing_xor_challenge.ipynb)\u2502[Solution](http://nbviewer.ipython.org/github/donnemartin/interactive-coding-challenges/blob/master/online_judges/maximizing_xor/maximizing_xor_solution.ipynb) |\n| Add a challenge | [Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md)\u2502[Contribute](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) |\n\n## Repo Structure\n\n```\ninteractive-coding-challenges        # Repo\n\u251c\u2500 arrays_strings                    # Category of challenges\n\u2502  \u251c\u2500 rotation                       # Challenge folder\n\u2502  \u2502  \u251c\u2500 rotation_challenge.ipynb    # Challenge notebook\n\u2502  \u2502  \u251c\u2500 rotation_solution.ipynb     # Solution notebook\n\u2502  \u2502  \u251c\u2500 test_rotation.py            # Unit test*\n\u2502  \u251c\u2500 compress\n\u2502  \u2502  \u251c\u2500 compress_challenge.ipynb\n\u2502  \u2502  \u251c\u2500 compress_solution.ipynb\n\u2502  \u2502  \u251c\u2500 test_compress.py\n\u2502  \u251c\u2500 ...\n\u251c\u2500 linked_lists\n\u2502  \u251c\u2500 palindrome\n\u2502  \u2502  \u2514\u2500 ...\n\u2502  \u251c\u2500 ...\n\u251c\u2500 ...\n```\n\n<i>\\*The notebooks (.ipynb) read/write the associated unit test (.py) file.</i>\n\n\n## Notebook Installation\n\n### Jupyter Notebook\n\nRun:\n\n```\npip install jupyter\n```\n\nFor detailed instructions, scripts, and tools to more optimally set up your development environment, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.\n\nFor more details on notebook installation, follow the directions [here](http://ipython.org/install.html).\n\nMore information on IPython/Jupyter Notebooks can be found [here](http://ipython.org/notebook.html).\n\n### Nose Tests\n\nInstall nose using setuptools/distribute:\n\n```\neasy_install nose\n```\n\nor\n\n```\npip install nose\n```\n\nMore information on Nose can be found [here](https://nose.readthedocs.org/en/latest/).\n\n## Running Challenges\n\n### Notebooks\n\nChallenges are provided in the form of **IPython/Jupyter Notebooks** and have been **tested with Python 2.7 and Python 3.x**.\n\n*If you need to install IPython/Jupyter Notebook, see the [Notebook Installation](#notebook-installation) section.*\n\n* This README contains links to [nbviewer](http://nbviewer.ipython.org), which hosts **static notebooks** of the repo's contents\n* To interact with or to modify elements within the **dynamic notebooks**, refer to the instructions below\n\nRun the notebook of challenges:\n\n```\n$ git clone https://github.com/donnemartin/interactive-coding-challenges.git\n$ cd interactive-coding-challenges\n$ jupyter notebook\n```\n\nThis will launch your web browser with the list of challenge categories:\n\n* Navigate to the **Challenge Notebook** you wish to solve\n* Run the cells within the challenge notebook (Cell->Run All)\n    * This will result in an expected unit test error\n* Solve the challenge and verify it passes the unit test\n* Check out the accompanying **Solution Notebook** for further discussion\n\nTo **debug** your solution with pdb, refer to the following [ticket](https://github.com/donnemartin/interactive-coding-challenges/issues/11).\n\nNote: If your solution is different from those listed in the Solution Notebook, consider submitting a pull request so others can benefit from your work.  Review the [Contributing Guidelines](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) for details.\n\n## Future Development\n\nChallenges, solutions, and unit tests are presented in the form of **IPython/Jupyter Notebooks**.\n\n* Notebooks currently contain mostly Python solutions (tested on both Python 2.7 and Python 3.x), but can be extended to include [40+ supported languages](https://github.com/ipython/ipython/wiki/IPython-kernels-for-other-languages)\n* Repo will be **continually updated** with new solutions and challenges\n* [Contributions](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) are welcome!\n\n## Contributing\n\nContributions are welcome!\n\nReview the [Contributing Guidelines](https://github.com/donnemartin/interactive-coding-challenges/blob/master/CONTRIBUTING.md) for details on how to:\n\n* Submit issues\n* Add solutions to existing challenges\n* Add new challenges\n\n## Credits\n\n### Resources\n\n* [Cracking the Coding Interview](http://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/098478280X) | [GitHub Solutions](https://github.com/gaylemcd/ctci)\n* [Programming Interviews Exposed](http://www.amazon.com/gp/product/1118261364/)\n* [The Algorithm Design Manual](http://www.amazon.com/Algorithm-Design-Manual-Steve-Skiena/dp/0387948600) | [Solutions](http://www.algorithm.cs.sunysb.edu/algowiki/index.php/The_Algorithms_Design_Manual_(Second_Edition))\n* [CareerCup](http://www.careercup.com/)\n* [Quora](http://www.quora.com/)\n* [HackerRank](https://www.hackerrank.com)\n* [LeetCode](https://leetcode.com/)\n\n### Images\n\n* [Arrays and Strings: nltk.org](http://www.nltk.org/images/string-slicing.png)\n* [Linked Lists: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/6/6d/Singly-linked-list.svg)\n* [Stacks: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/2/29/Data_stack.svg)\n* [Queues: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/5/52/Data_Queue.svg)\n* [Sorting: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/6/6a/Sorting_quicksort_anim.gif)\n* [Recursion and Dynamic Programming: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/b/bf/PascalTriangleFibanacci.svg)\n* [Graphs and Trees: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/f/f7/Binary_tree.svg)\n* [Mathematics and Probability: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/d/d2/Gaussian_distribution_2.jpg)\n* [Bit Manipulation: wikipedia.org](https://upload.wikimedia.org/wikipedia/commons/5/5c/Rotate_left_logically.svg)\n* [Online Judges: topcoder.com](https://www.topcoder.com/wp-content/uploads/2014/05/topcoder_logo_home_sm.png)\n\n## Contact Info\n\nFeel free to contact me to discuss any issues, questions, or comments.\n\nMy contact info can be found on my [GitHub page](https://github.com/donnemartin).\n\n## License\n\n*I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).*\n\n    Copyright 2015 Donne Martin\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n"}, {"repo": "tornadoweb/tornado", "language": "Python", "readme_contents": "Tornado Web Server\n==================\n\n.. image:: https://badges.gitter.im/Join%20Chat.svg\n   :alt: Join the chat at https://gitter.im/tornadoweb/tornado\n   :target: https://gitter.im/tornadoweb/tornado?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\n`Tornado <http://www.tornadoweb.org>`_ is a Python web framework and\nasynchronous networking library, originally developed at `FriendFeed\n<http://friendfeed.com>`_.  By using non-blocking network I/O, Tornado\ncan scale to tens of thousands of open connections, making it ideal for\n`long polling <http://en.wikipedia.org/wiki/Push_technology#Long_Polling>`_,\n`WebSockets <http://en.wikipedia.org/wiki/WebSocket>`_, and other\napplications that require a long-lived connection to each user.\n\nHello, world\n------------\n\nHere is a simple \"Hello, world\" example web app for Tornado:\n\n.. code-block:: python\n\n    import tornado.ioloop\n    import tornado.web\n\n    class MainHandler(tornado.web.RequestHandler):\n        def get(self):\n            self.write(\"Hello, world\")\n\n    def make_app():\n        return tornado.web.Application([\n            (r\"/\", MainHandler),\n        ])\n\n    if __name__ == \"__main__\":\n        app = make_app()\n        app.listen(8888)\n        tornado.ioloop.IOLoop.current().start()\n\nThis example does not use any of Tornado's asynchronous features; for\nthat see this `simple chat room\n<https://github.com/tornadoweb/tornado/tree/stable/demos/chat>`_.\n\nDocumentation\n-------------\n\nDocumentation and links to additional resources are available at\nhttps://www.tornadoweb.org\n"}, {"repo": "huggingface/transformers", "language": "Python", "readme_contents": "<p align=\"center\">\n    <br>\n    <img src=\"https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png\" width=\"400\"/>\n    <br>\n<p>\n<p align=\"center\">\n    <a href=\"https://circleci.com/gh/huggingface/transformers\">\n        <img alt=\"Build\" src=\"https://img.shields.io/circleci/build/github/huggingface/transformers/master\">\n    </a>\n    <a href=\"https://github.com/huggingface/transformers/blob/master/LICENSE\">\n        <img alt=\"GitHub\" src=\"https://img.shields.io/github/license/huggingface/transformers.svg?color=blue\">\n    </a>\n    <a href=\"https://huggingface.co/transformers/index.html\">\n        <img alt=\"Documentation\" src=\"https://img.shields.io/website/http/huggingface.co/transformers/index.html.svg?down_color=red&down_message=offline&up_message=online\">\n    </a>\n    <a href=\"https://github.com/huggingface/transformers/releases\">\n        <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/huggingface/transformers.svg\">\n    </a>\n</p>\n\n<h3 align=\"center\">\n<p>State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n</h3>\n\n\ud83e\udd17 Transformers (formerly known as `pytorch-transformers` and `pytorch-pretrained-bert`) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.\n\n### Features\n\n- As easy to use as pytorch-transformers\n- As powerful and concise as Keras\n- High performance on NLU and NLG tasks\n- Low barrier to entry for educators and practitioners\n\nState-of-the-art NLP for everyone\n- Deep learning researchers\n- Hands-on practitioners\n- AI/ML/NLP teachers and educators\n\nLower compute costs, smaller carbon footprint\n- Researchers can share trained models instead of always retraining\n- Practitioners can reduce compute time and production costs\n- 10 architectures with over 30 pretrained models, some in more than 100 languages\n\nChoose the right framework for every part of a model's lifetime\n- Train state-of-the-art models in 3 lines of code\n- Deep interoperability between TensorFlow 2.0 and PyTorch models\n- Move a single model between TF2.0/PyTorch frameworks at will\n- Seamlessly pick the right framework for training, evaluation, production\n\n\n| Section | Description |\n|-|-|\n| [Installation](#installation) | How to install the package |\n| [Model architectures](#model-architectures) | Architectures (with pretrained weights) |\n| [Online demo](#online-demo) | Experimenting with this repo\u2019s text generation capabilities |\n| [Quick tour: Usage](#quick-tour) | Tokenizers & models usage: Bert and GPT-2 |\n| [Quick tour: TF 2.0 and PyTorch ](#Quick-tour-TF-20-training-and-PyTorch-interoperability) | Train a TF 2.0 model in 10 lines of code, load it in PyTorch |\n| [Quick tour: Fine-tuning/usage scripts](#quick-tour-of-the-fine-tuningusage-scripts) | Using provided scripts: GLUE, SQuAD and Text generation |\n| [Migrating from pytorch-transformers to transformers](#Migrating-from-pytorch-transformers-to-transformers) | Migrating your code from pytorch-transformers to transformers |\n| [Migrating from pytorch-pretrained-bert to pytorch-transformers](#Migrating-from-pytorch-pretrained-bert-to-transformers) | Migrating your code from pytorch-pretrained-bert to transformers |\n| [Documentation][(v2.2.0/v2.2.1)](https://huggingface.co/transformers/v2.2.0) [(v2.1.1)](https://huggingface.co/transformers/v2.1.1) [(v2.0.0)](https://huggingface.co/transformers/v2.0.0) [(v1.2.0)](https://huggingface.co/transformers/v1.2.0) [(v1.1.0)](https://huggingface.co/transformers/v1.1.0) [(v1.0.0)](https://huggingface.co/transformers/v1.0.0) [(master)](https://huggingface.co/transformers) | Full API documentation and more |\n\n## Installation\n\nThis repo is tested on Python 2.7 and 3.5+ (examples are tested only on python 3.5+), PyTorch 1.0.0+ and TensorFlow 2.0.0-rc1\n\n### With pip\n\nFirst you need to install one of, or both, TensorFlow 2.0 and PyTorch.\nPlease refer to [TensorFlow installation page](https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available) and/or [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) regarding the specific install command for your platform.\n\nWhen TensorFlow 2.0 and/or PyTorch has been installed, \ud83e\udd17 Transformers can be installed using pip as follows:\n\n```bash\npip install transformers\n```\n\n### From source\n\nHere also, you first need to install one of, or both, TensorFlow 2.0 and PyTorch.\nPlease refer to [TensorFlow installation page](https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available) and/or [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) regarding the specific install command for your platform.\n\nWhen TensorFlow 2.0 and/or PyTorch has been installed, you can install from source by cloning the repository and running:\n\n```bash\npip install [--editable] .\n```\n\n### Run the examples\n\nExamples are included in the repository but are not shipped with the library.\nTherefore, in order to run the latest versions of the examples you also need to install from source. To do so, create a new virtual environment and follow these steps:\n\n```bash\ngit clone https://github.com/huggingface/transformers\ncd transformers\npip install [--editable] .\n```\n\n### Tests\n\nA series of tests are included for the library and the example scripts. Library tests can be found in the [tests folder](https://github.com/huggingface/transformers/tree/master/transformers/tests) and examples tests in the [examples folder](https://github.com/huggingface/transformers/tree/master/examples).\n\nThese tests can be run using `unittest` or `pytest` (install pytest if needed with `pip install pytest`).\n\nDepending on which framework is installed (TensorFlow 2.0 and/or PyTorch), the irrelevant tests will be skipped. Ensure that both frameworks are installed if you want to execute all tests.\n\nYou can run the tests from the root of the cloned repository with the commands:\n\n```bash\npython -m unittest discover -s transformers/tests -p \"*test.py\" -t .\npython -m unittest discover -s examples -p \"*test.py\" -t examples\n```\n\nor\n\n```bash\npython -m pytest -sv ./transformers/tests/\npython -m pytest -sv ./examples/\n```\n\nBy default, slow tests are skipped. Set the `RUN_SLOW` environment variable to `yes` to run them.\n\n### Do you want to run a Transformer model on a mobile device?\n\nYou should check out our [`swift-coreml-transformers`](https://github.com/huggingface/swift-coreml-transformers) repo.\n\nIt contains a set of tools to convert PyTorch or TensorFlow 2.0 trained Transformer models (currently contains `GPT-2`, `DistilGPT-2`, `BERT`, and `DistilBERT`) to CoreML models that run on iOS devices.\n\nAt some point in the future, you'll be able to seamlessly move from pre-training or fine-tuning models to productizing them in CoreML, or prototype a model or an app in CoreML then research its hyperparameters or architecture from TensorFlow 2.0 and/or PyTorch. Super exciting!\n\n## Model architectures\n\n\ud83e\udd17 Transformers currently provides 10 NLU/NLG architectures:\n\n1. **[BERT](https://github.com/google-research/bert)** (from Google) released with the paper [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.\n2. **[GPT](https://github.com/openai/finetune-transformer-lm)** (from OpenAI) released with the paper [Improving Language Understanding by Generative Pre-Training](https://blog.openai.com/language-unsupervised/) by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.\n3. **[GPT-2](https://blog.openai.com/better-language-models/)** (from OpenAI) released with the paper [Language Models are Unsupervised Multitask Learners](https://blog.openai.com/better-language-models/) by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.\n4. **[Transformer-XL](https://github.com/kimiyoung/transformer-xl)** (from Google/CMU) released with the paper [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860) by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.\n5. **[XLNet](https://github.com/zihangdai/xlnet/)** (from Google/CMU) released with the paper [\u200bXLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.\n6. **[XLM](https://github.com/facebookresearch/XLM/)** (from Facebook) released together with the paper [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291) by Guillaume Lample and Alexis Conneau.\n7. **[RoBERTa](https://github.com/pytorch/fairseq/tree/master/examples/roberta)** (from Facebook), released together with the paper a [Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.\n8. **[DistilBERT](https://github.com/huggingface/transformers/tree/master/examples/distillation)** (from HuggingFace), released together with the paper [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108) by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into [DistilGPT2](https://github.com/huggingface/transformers/tree/master/examples/distillation), RoBERTa into [DistilRoBERTa](https://github.com/huggingface/transformers/tree/master/examples/distillation), Multilingual BERT into [DistilmBERT](https://github.com/huggingface/transformers/tree/master/examples/distillation) and a German version of DistilBERT.\n9. **[CTRL](https://github.com/salesforce/ctrl/)** (from Salesforce) released with the paper [CTRL: A Conditional Transformer Language Model for Controllable Generation](https://arxiv.org/abs/1909.05858) by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.\n10. **[CamemBERT](https://camembert-model.fr)** (from Inria/Facebook/Sorbonne) released with the paper [CamemBERT: a Tasty French Language Model](https://arxiv.org/abs/1911.03894) by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Su\u00e1rez*, Yoann Dupont, Laurent Romary, \u00c9ric Villemonte de la Clergerie, Djam\u00e9 Seddah and Beno\u00eet Sagot.\n11. **[ALBERT](https://github.com/google-research/ALBERT)** (from Google Research and the Toyota Technological Institute at Chicago) released with the paper [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942), by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.\n11. Want to contribute a new model? We have added a **detailed guide and templates** to guide you in the process of adding a new model. You can find them in the [`templates`](./templates) folder of the repository. Be sure to check the [contributing guidelines](./CONTRIBUTING.md) and contact the maintainers or open an issue to collect feedbacks before starting your PR.\n\nThese implementations have been tested on several datasets (see the example scripts) and should match the performances of the original implementations (e.g. ~93 F1 on SQuAD for BERT Whole-Word-Masking, ~88 F1 on RocStories for OpenAI GPT, ~18.3 perplexity on WikiText 103 for Transformer-XL, ~0.916 Peason R coefficient on STS-B for XLNet). You can find more details on the performances in the Examples section of the [documentation](https://huggingface.co/transformers/examples.html).\n\n## Online demo\n\n**[Write With Transformer](https://transformer.huggingface.co)**, built by the Hugging Face team at transformer.huggingface.co, is the official demo of this repo\u2019s text generation capabilities.\nYou can use it to experiment with completions generated by `GPT2Model`, `TransfoXLModel`, and `XLNetModel`.\n\n> \u201c\ud83e\udd84 Write with transformer is to writing what calculators are to calculus.\u201d\n\n![write_with_transformer](https://transformer.huggingface.co/front/assets/thumbnail-large.png)\n\n## Quick tour\n\nLet's do a very quick overview of the model architectures in \ud83e\udd17 Transformers. Detailed examples for each model architecture (Bert, GPT, GPT-2, Transformer-XL, XLNet and XLM) can be found in the [full documentation](https://huggingface.co/transformers/).\n\n```python\nimport torch\nfrom transformers import *\n\n# Transformers has a unified API\n# for 8 transformer architectures and 30 pretrained weights.\n#          Model          | Tokenizer          | Pretrained weights shortcut\nMODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n          (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n          (CTRLModel,       CTRLTokenizer,       'ctrl'),\n          (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n          (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n          (DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased'),\n          (RobertaModel,    RobertaTokenizer,    'roberta-base')]\n\n# To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`\n\n# Let's encode some text in a sequence of hidden-states using each model:\nfor model_class, tokenizer_class, pretrained_weights in MODELS:\n    # Load pretrained model/tokenizer\n    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n    model = model_class.from_pretrained(pretrained_weights)\n\n    # Encode text\n    input_ids = torch.tensor([tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n    with torch.no_grad():\n        last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n\n# Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\nBERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]\n\n# All the classes for an architecture can be initiated from pretrained weights for this architecture\n# Note that additional weights added for fine-tuning are only initialized\n# and need to be trained on the down-stream task\npretrained_weights = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(pretrained_weights)\nfor model_class in BERT_MODEL_CLASSES:\n    # Load pretrained model/tokenizer\n    model = model_class.from_pretrained(pretrained_weights)\n\n    # Models can return full list of hidden-states & attentions weights at each layer\n    model = model_class.from_pretrained(pretrained_weights,\n                                        output_hidden_states=True,\n                                        output_attentions=True)\n    input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n    all_hidden_states, all_attentions = model(input_ids)[-2:]\n\n    # Models are compatible with Torchscript\n    model = model_class.from_pretrained(pretrained_weights, torchscript=True)\n    traced_model = torch.jit.trace(model, (input_ids,))\n\n    # Simple serialization for models and tokenizers\n    model.save_pretrained('./directory/to/save/')  # save\n    model = model_class.from_pretrained('./directory/to/save/')  # re-load\n    tokenizer.save_pretrained('./directory/to/save/')  # save\n    tokenizer = BertTokenizer.from_pretrained('./directory/to/save/')  # re-load\n\n    # SOTA examples for GLUE, SQUAD, text generation...\n```\n\n## Quick tour TF 2.0 training and PyTorch interoperability\n\nLet's do a quick example of how a TensorFlow 2.0 model can be trained in 12 lines of code with \ud83e\udd17 Transformers and then loaded in PyTorch for fast inspection/tests.\n\n```python\nimport tensorflow as tf\nimport tensorflow_datasets\nfrom transformers import *\n\n# Load dataset, tokenizer, model from pretrained model/vocabulary\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-cased')\ndata = tensorflow_datasets.load('glue/mrpc')\n\n# Prepare dataset for GLUE as a tf.data.Dataset instance\ntrain_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\nvalid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\ntrain_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\nvalid_dataset = valid_dataset.batch(64)\n\n# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\nmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n\n# Train and evaluate using tf.keras.Model.fit()\nhistory = model.fit(train_dataset, epochs=2, steps_per_epoch=115,\n                    validation_data=valid_dataset, validation_steps=7)\n\n# Load the TensorFlow model in PyTorch for inspection\nmodel.save_pretrained('./save/')\npytorch_model = BertForSequenceClassification.from_pretrained('./save/', from_tf=True)\n\n# Quickly test a few predictions - MRPC is a paraphrasing task, let's see if our model learned the task\nsentence_0 = \"This research was consistent with his findings.\"\nsentence_1 = \"His findings were compatible with this research.\"\nsentence_2 = \"His findings were not compatible with this research.\"\ninputs_1 = tokenizer.encode_plus(sentence_0, sentence_1, add_special_tokens=True, return_tensors='pt')\ninputs_2 = tokenizer.encode_plus(sentence_0, sentence_2, add_special_tokens=True, return_tensors='pt')\n\npred_1 = pytorch_model(inputs_1['input_ids'], token_type_ids=inputs_1['token_type_ids'])[0].argmax().item()\npred_2 = pytorch_model(inputs_2['input_ids'], token_type_ids=inputs_2['token_type_ids'])[0].argmax().item()\n\nprint(\"sentence_1 is\", \"a paraphrase\" if pred_1 else \"not a paraphrase\", \"of sentence_0\")\nprint(\"sentence_2 is\", \"a paraphrase\" if pred_2 else \"not a paraphrase\", \"of sentence_0\")\n```\n\n## Quick tour of the fine-tuning/usage scripts\n\n**Important**  \nBefore running the fine-tuning scripts, please read the\n[instructions](#run-the-examples) on how to\nsetup your environment to run the examples.\n\nThe library comprises several example scripts with SOTA performances for NLU and NLG tasks:\n\n- `run_glue.py`: an example fine-tuning Bert, XLNet and XLM on nine different GLUE tasks (*sequence-level classification*)\n- `run_squad.py`: an example fine-tuning Bert, XLNet and XLM on the question answering dataset SQuAD 2.0 (*token-level classification*)\n- `run_generation.py`: an example using GPT, GPT-2, CTRL, Transformer-XL and XLNet for conditional language generation\n- other model-specific examples (see the documentation).\n\nHere are three quick usage examples for these scripts:\n\n### `run_glue.py`: Fine-tuning on GLUE tasks for sequence classification\n\nThe [General Language Understanding Evaluation (GLUE) benchmark](https://gluebenchmark.com/) is a collection of nine sentence- or sentence-pair language understanding tasks for evaluating and analyzing natural language understanding systems.\n\nBefore running anyone of these GLUE tasks you should download the\n[GLUE data](https://gluebenchmark.com/tasks) by running\n[this script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e)\nand unpack it to some directory `$GLUE_DIR`.\n\nYou should also install the additional packages required by the examples:\n\n```shell\npip install -r ./examples/requirements.txt\n```\n\n```shell\nexport GLUE_DIR=/path/to/glue\nexport TASK_NAME=MRPC\n\npython ./examples/run_glue.py \\\n    --model_type bert \\\n    --model_name_or_path bert-base-uncased \\\n    --task_name $TASK_NAME \\\n    --do_train \\\n    --do_eval \\\n    --do_lower_case \\\n    --data_dir $GLUE_DIR/$TASK_NAME \\\n    --max_seq_length 128 \\\n    --per_gpu_eval_batch_size=8   \\\n    --per_gpu_train_batch_size=8   \\\n    --learning_rate 2e-5 \\\n    --num_train_epochs 3.0 \\\n    --output_dir /tmp/$TASK_NAME/\n```\n\nwhere task name can be one of CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, RTE, WNLI.\n\nThe dev set results will be present within the text file 'eval_results.txt' in the specified output_dir. In case of MNLI, since there are two separate dev sets, matched and mismatched, there will be a separate output folder called '/tmp/MNLI-MM/' in addition to '/tmp/MNLI/'.\n\n#### Fine-tuning XLNet model on the STS-B regression task\n\nThis example code fine-tunes XLNet on the STS-B corpus using parallel training on a server with 4 V100 GPUs.\nParallel training is a simple way to use several GPUs (but is slower and less flexible than distributed training, see below).\n\n```shell\nexport GLUE_DIR=/path/to/glue\n\npython ./examples/run_glue.py \\\n    --model_type xlnet \\\n    --model_name_or_path xlnet-large-cased \\\n    --do_train  \\\n    --do_eval   \\\n    --task_name=sts-b     \\\n    --data_dir=${GLUE_DIR}/STS-B  \\\n    --output_dir=./proc_data/sts-b-110   \\\n    --max_seq_length=128   \\\n    --per_gpu_eval_batch_size=8   \\\n    --per_gpu_train_batch_size=8   \\\n    --gradient_accumulation_steps=1 \\\n    --max_steps=1200  \\\n    --model_name=xlnet-large-cased   \\\n    --overwrite_output_dir   \\\n    --overwrite_cache \\\n    --warmup_steps=120\n```\n\nOn this machine we thus have a batch size of 32, please increase `gradient_accumulation_steps` to reach the same batch size if you have a smaller machine. These hyper-parameters should result in a Pearson correlation coefficient of `+0.917` on the development set.\n\n#### Fine-tuning Bert model on the MRPC classification task\n\nThis example code fine-tunes the Bert Whole Word Masking model on the Microsoft Research Paraphrase Corpus (MRPC) corpus using distributed training on 8 V100 GPUs to reach a F1 > 92.\n\n```bash\npython -m torch.distributed.launch --nproc_per_node 8 ./examples/run_glue.py   \\\n    --model_type bert \\\n    --model_name_or_path bert-large-uncased-whole-word-masking \\\n    --task_name MRPC \\\n    --do_train   \\\n    --do_eval   \\\n    --do_lower_case   \\\n    --data_dir $GLUE_DIR/MRPC/   \\\n    --max_seq_length 128   \\\n    --per_gpu_eval_batch_size=8   \\\n    --per_gpu_train_batch_size=8   \\\n    --learning_rate 2e-5   \\\n    --num_train_epochs 3.0  \\\n    --output_dir /tmp/mrpc_output/ \\\n    --overwrite_output_dir   \\\n    --overwrite_cache \\\n```\n\nTraining with these hyper-parameters gave us the following results:\n\n```bash\n  acc = 0.8823529411764706\n  acc_and_f1 = 0.901702786377709\n  eval_loss = 0.3418912578906332\n  f1 = 0.9210526315789473\n  global_step = 174\n  loss = 0.07231863956341798\n```\n\n### `run_squad.py`: Fine-tuning on SQuAD for question-answering\n\nThis example code fine-tunes BERT on the SQuAD dataset using distributed training on 8 V100 GPUs and Bert Whole Word Masking uncased model to reach a F1 > 93 on SQuAD:\n\n```bash\npython -m torch.distributed.launch --nproc_per_node=8 ./examples/run_squad.py \\\n    --model_type bert \\\n    --model_name_or_path bert-large-uncased-whole-word-masking \\\n    --do_train \\\n    --do_eval \\\n    --do_lower_case \\\n    --train_file $SQUAD_DIR/train-v1.1.json \\\n    --predict_file $SQUAD_DIR/dev-v1.1.json \\\n    --learning_rate 3e-5 \\\n    --num_train_epochs 2 \\\n    --max_seq_length 384 \\\n    --doc_stride 128 \\\n    --output_dir ../models/wwm_uncased_finetuned_squad/ \\\n    --per_gpu_eval_batch_size=3   \\\n    --per_gpu_train_batch_size=3   \\\n```\n\nTraining with these hyper-parameters gave us the following results:\n\n```bash\npython $SQUAD_DIR/evaluate-v1.1.py $SQUAD_DIR/dev-v1.1.json ../models/wwm_uncased_finetuned_squad/predictions.json\n{\"exact_match\": 86.91579943235573, \"f1\": 93.1532499015869}\n```\n\nThis is the model provided as `bert-large-uncased-whole-word-masking-finetuned-squad`.\n\n### `run_generation.py`: Text generation with GPT, GPT-2, CTRL, Transformer-XL and XLNet\n\nA conditional generation script is also included to generate text from a prompt.\nThe generation script includes the [tricks](https://github.com/rusiaaman/XLNet-gen#methodology) proposed by Aman Rusia to get high-quality generation with memory models like Transformer-XL and XLNet (include a predefined text to make short inputs longer).\n\nHere is how to run the script with the small version of OpenAI GPT-2 model:\n\n```shell\npython ./examples/run_generation.py \\\n    --model_type=gpt2 \\\n    --length=20 \\\n    --model_name_or_path=gpt2 \\\n```\n\nand from the Salesforce CTRL model: \n```shell\npython ./examples/run_generation.py \\\n    --model_type=ctrl \\\n    --length=20 \\\n    --model_name_or_path=ctrl \\\n    --temperature=0 \\\n    --repetition_penalty=1.2 \\\n```\n\n## Migrating from pytorch-transformers to transformers\n\nHere is a quick summary of what you should take care of when migrating from `pytorch-transformers` to `transformers`.\n\n### Positional order of some models' keywords inputs (`attention_mask`, `token_type_ids`...) changed\n\nTo be able to use Torchscript (see #1010, #1204 and #1195) the specific order of some models **keywords inputs** (`attention_mask`, `token_type_ids`...) has been changed.\n\nIf you used to call the models with keyword names for keyword arguments, e.g. `model(inputs_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)`, this should not cause any change.\n\nIf you used to call the models with positional inputs for keyword arguments, e.g. `model(inputs_ids, attention_mask, token_type_ids)`, you may have to double check the exact order of input arguments.\n\n\n## Migrating from pytorch-pretrained-bert to transformers\n\nHere is a quick summary of what you should take care of when migrating from `pytorch-pretrained-bert` to `transformers`.\n\n### Models always output `tuples`\n\nThe main breaking change when migrating from `pytorch-pretrained-bert` to `transformers` is that every model's forward method always outputs a `tuple` with various elements depending on the model and the configuration parameters.\n\nThe exact content of the tuples for each model is detailed in the models' docstrings and the [documentation](https://huggingface.co/transformers/).\n\nIn pretty much every case, you will be fine by taking the first element of the output as the output you previously used in `pytorch-pretrained-bert`.\n\nHere is a `pytorch-pretrained-bert` to `transformers` conversion example for a `BertForSequenceClassification` classification model:\n\n```python\n# Let's load our model\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n\n# If you used to have this line in pytorch-pretrained-bert:\nloss = model(input_ids, labels=labels)\n\n# Now just use this line in transformers to extract the loss from the output tuple:\noutputs = model(input_ids, labels=labels)\nloss = outputs[0]\n\n# In transformers you can also have access to the logits:\nloss, logits = outputs[:2]\n\n# And even the attention weights if you configure the model to output them (and other outputs too, see the docstrings and documentation)\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', output_attentions=True)\noutputs = model(input_ids, labels=labels)\nloss, logits, attentions = outputs\n```\n\n### Using hidden states\n\nBy enabling the configuration option `output_hidden_states`, it was possible to retrieve the last hidden states of the encoder. In `pytorch-transformers` as well as `transformers` the return value has changed slightly: `all_hidden_states` now also includes the hidden state of the embeddings in addition to those of the encoding layers. This allows users to easily access the embeddings final state.\n\n### Serialization\n\nBreaking change in the `from_pretrained()` method:\n\n1. Models are now set in evaluation mode by default when instantiated with the `from_pretrained()` method. To train them, don't forget to set them back in training mode (`model.train()`) to activate the dropout modules.\n\n2. The additional `*input` and `**kwargs` arguments supplied to the `from_pretrained()` method used to be directly passed to the underlying model's class `__init__()` method. They are now used to update the model configuration attribute instead, which can break derived model classes built based on the previous `BertForSequenceClassification` examples. We are working on a way to mitigate this breaking change in [#866](https://github.com/huggingface/transformers/pull/866) by forwarding the the model's `__init__()` method (i) the provided positional arguments and (ii) the keyword arguments which do not match any configuration class attributes.\n\nAlso, while not a breaking change, the serialization methods have been standardized and you probably should switch to the new method `save_pretrained(save_directory)` if you were using any other serialization method before.\n\nHere is an example:\n\n```python\n### Let's load a model and tokenizer\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n### Do some stuff to our model and tokenizer\n# Ex: add new tokens to the vocabulary and embeddings of our model\ntokenizer.add_tokens(['[SPECIAL_TOKEN_1]', '[SPECIAL_TOKEN_2]'])\nmodel.resize_token_embeddings(len(tokenizer))\n# Train our model\ntrain(model)\n\n### Now let's save our model and tokenizer to a directory\nmodel.save_pretrained('./my_saved_model_directory/')\ntokenizer.save_pretrained('./my_saved_model_directory/')\n\n### Reload the model and the tokenizer\nmodel = BertForSequenceClassification.from_pretrained('./my_saved_model_directory/')\ntokenizer = BertTokenizer.from_pretrained('./my_saved_model_directory/')\n```\n\n### Optimizers: BertAdam & OpenAIAdam are now AdamW, schedules are standard PyTorch schedules\n\nThe two optimizers previously included, `BertAdam` and `OpenAIAdam`, have been replaced by a single `AdamW` optimizer which has a few differences:\n\n- it only implements weights decay correction,\n- schedules are now externals (see below),\n- gradient clipping is now also external (see below).\n\nThe new optimizer `AdamW` matches PyTorch `Adam` optimizer API and let you use standard PyTorch or apex methods for the schedule and clipping.\n\nThe schedules are now standard [PyTorch learning rate schedulers](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) and not part of the optimizer anymore.\n\nHere is a conversion examples from `BertAdam` with a linear warmup and decay schedule to `AdamW` and the same schedule:\n\n```python\n# Parameters:\nlr = 1e-3\nmax_grad_norm = 1.0\nnum_training_steps = 1000\nnum_warmup_steps = 100\nwarmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n\n### Previously BertAdam optimizer was instantiated like this:\noptimizer = BertAdam(model.parameters(), lr=lr, schedule='warmup_linear', warmup=warmup_proportion, t_total=num_training_steps)\n### and used like this:\nfor batch in train_data:\n    loss = model(batch)\n    loss.backward()\n    optimizer.step()\n\n### In Transformers, optimizer and schedules are splitted and instantiated like this:\noptimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n### and used like this:\nfor batch in train_data:\n    model.train()\n    loss = model(batch)\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n```\n\n## Citation\n\nWe now have a paper you can cite for the \ud83e\udd17 Transformers library:\n```\n@article{Wolf2019HuggingFacesTS,\n  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},\n  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},\n  journal={ArXiv},\n  year={2019},\n  volume={abs/1910.03771}\n}\n```\n"}, {"repo": "testerSunshine/12306", "language": "Python", "readme_contents": "### 12306 \u8d2d\u7968\u5c0f\u52a9\u624b\n#### python\u7248\u672c\n  - [ ] 2.7.10 - 2.7.15\n  - [x] 3.6 - 3.7.4\n  - [ ] 2.7.9\n\n#### \u5df2\u6709\u529f\u80fd\n  - [x] \u81ea\u52a8\u6253\u7801\n  - [x] \u81ea\u52a8\u767b\u5f55\n  - [x] \u51c6\u70b9\u9884\u552e\u548c\u6361\u6f0f\n  - [x] \u667a\u80fd\u5019\u8865\n  - [x] \u90ae\u4ef6\u901a\u77e5\n  - [x] server\u9171\u901a\u77e5\n\n#### \u4f9d\u8d56\u5e93\n  - \u9a8c\u8bc1\u7801\u76ee\u524d\u53ef\u4ee5\u672c\u5730\u8bc6\u522b\uff0c\u9700\u8981\u4e0b\u8f7d\u6a21\u578b\uff0c\u653e\u4e8e\u9879\u76ee\u6839\u76ee\u5f55\uff0c\u5168\u90e8\u4ee3\u7801\u6765\u6e90\u4e8e\u6b64\u9879\u76ee [\u4f20\u9001\u95e8](https://github.com/zhaipro/easy12306)\uff0c\u8868\u793a\u611f\u8c22\n    ```\n      PS: \n      1. \u6a21\u578b\u4e0b\u8f7d\u94fe\u63a5:https://pan.baidu.com/s/1rS155VjweWVWIJogakechA  \u5bc6\u7801:bmlm\n         \u7fa4\u91cc\u9762\u4e5f\u53ef\u4ee5\u4e0b\u8f7d\n      2. git\u4ed3\u5e93\u4e0b\u8f7d\uff1ahttps://github.com/testerSunshine/12306model.git\n    ```\n  - \u81ea\u6258\u7ba1\u4e91\u6253\u7801\u670d\u52a1\u5668\u642d\u5efa\uff1a[12306_code_server](https://github.com/YinAoXiong/12306_code_server)\n    - \u5982\u679c\u5927\u5bb6\u6709\u7a7a\u95f2\u7684\u670d\u52a1\u5668\uff0c\u53ef\u642d\u5efa\u4e4b\u540e\u518d\u8fd9\u4e2a [issues](https://github.com/testerSunshine/12306/issues/446) \u91cc\u9762\u586b\u5165\u81ea\u5df1\u7684\u670d\u52a1\u5668(\u8bf7\u6ce8\u610f\u670d\u52a1\u5668\u5b89\u5168\uff01)\n  - \u9879\u76ee\u4f9d\u8d56\u5305\u67e5\u770b [requirements.txt](requirements.txt)\n  - \u5b89\u88c5\u65b9\u6cd5x:\n      - root\u7528\u6237(\u907f\u514d\u591apython\u73af\u5883\u4ea7\u751f\u95ee\u9898): `pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt`\n      - \u975eroot\u7528\u6237\uff08\u907f\u514d\u5b89\u88c5\u548c\u8fd0\u884c\u65f6\u4f7f\u7528\u4e86\u4e0d\u540c\u73af\u5883\uff09: `pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt`\n\n#### \u9879\u76ee\u4f7f\u7528\u8bf4\u660e\n\n  - \u670d\u52a1\u5668\u542f\u52a8:\n      - \u4fee\u6539[\u914d\u7f6e](TickerConfig.py)\u6587\u4ef6\n        - \u53ef\u4ee5\u914d\u7f6e\u90ae\u7bb1,\u914d\u7f6e\u90ae\u7bb1\u7684\u683c\u5f0f\u5728[\u914d\u7f6e](TickerConfig.py)\u91cc\u9762\u53ef\u4ee5\u770b\u5230ex\n        - \u53ef\u4ee5\u914d\u7f6eserver\u9171\u63d0\u9192\uff08\u63a8\u8350\uff09[\u914d\u7f6e\u6559\u7a0b](https://www.jianshu.com/p/8d10b5b9c4e3)\n        - \u914d\u7f6e[\u914d\u7f6e](TickerConfig.py)\u6587\u4ef6\u7684\u65f6\u5019\uff0c\u9700\u6ce8\u610f\u7a7a\u683c\u548c\u9075\u5faapython\u8bed\u6cd5\u683c\u5f0f\n      - \u8fd0\u884c\u6839\u76ee\u5f55`sudo python run.py`\uff0c\u5373\u53ef\u5f00\u59cb\n  - \u5982\u679c\u4f60\u7684\u670d\u52a1\u5668\u5b89\u88c5\u4e86docker\u4e0edocker-compose, \u90a3\u4e48\u5c31\u53ef\u4ee5\u901a\u8fc7`docker-compose`\u8fdb\u884c\u542f\u52a8,`docker.sh`\u811a\u672c\u5bf9\u6b64\u8fdb\u884c\u4e86\u5c01\u88c5\uff0c\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u8fdb\u884c\u542f\u52a8\n      - 1\u3001`sudo ./docker.sh run` #\u521b\u5efa\u4e00\u4e2a\u955c\u50cf\u5e76\u542f\u52a8\u5bb9\u5668\uff0c\u5982\u679c\u955c\u50cf\u5df2\u7ecf\u521b\u5efa\u8fc7\u4e86\u4f1a\u76f4\u63a5\u542f\u52a8\u5bb9\u5668\u3002\n      - 2\u3001`sudo ./docker.sh restart` #\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u540e\uff0c\u901a\u8fc7\u6b64\u540d\u547d\u4ee4\u53ef\u91cd\u65b0\u52a0\u8f7d\u5bb9\u5668\u8fd0\u884c\n      - 3\u3001`sudo ./docker.sh rm` #\u5220\u9664\u5bb9\u5668\n      - 4\u3001`sudo ./docker.sh drun` #\u540e\u53f0\u8fd0\u884c\u5bb9\u5668\n      - 5\u3001`sudo ./docker.sh logs` #\u5728\u540e\u53f0\u8fd0\u884c\u65f6\uff0c\u901a\u8fc7\u6b64\u547d\u4ee4\u67e5\u770b\u8fd0\u884c\u7684\u5185\u5bb9\n      - \u6ce8: \u9488\u5bf9\u6ca1\u6709docker\u73af\u5883\u7684\u540c\u5b66\u63d0\u4f9b\u4e86docker\u5b89\u88c5\u811a\u672c(**<font color=\"red\">centos7</font>**)\n            - `sudo ./docker_install_centos.sh`\n      - ~~\u6ce8: \u82e5\u53ea\u6709docker\u6ca1\u6709docker-compose. \u53ef\u901a\u8fc7`pip install docker-compose`\u8fdb\u884c\u4e0b\u8f7d~~\n\n#### \u76ee\u5f55\u5bf9\u5e94\u8bf4\u660e\n  - agency - cdn\u4ee3\u7406\n  - config - \u9879\u76ee\u914d\u7f6e\n  - verify - \u81ea\u52a8\u6253\u7801\n  - init - \u9879\u76ee\u4e3b\u8fd0\u884c\u76ee\u5f55\n  - inter - \u63a5\u53e3\n  - myException - \u5f02\u5e38\n  - myUrllib  request\u7f51\u7edc\u8bf7\u6c42\u5e93\n\n#### \u601d\u8def\u56fe\n- ![image](uml/uml.png)\n\n#### \u9879\u76ee\u58f0\u660e\uff1a\n  - \u672c\u8f6f\u4ef6\u53ea\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\uff0c\u52ff\u4f5c\u4e3a\u5546\u4e1a\u7528\u9014\uff0c\u4ea4\u6d41\u7fa4\u53f7\n    - 1\u7fa4\uff1a286271084(\u5df2\u6ee1)\n    - 2\u7fa4\uff1a649992274(\u5df2\u6ee1)\n    - 3\u7fa4\uff1a632501142(\u5df2\u6ee1)\n    - 4\u7fa4: 606340519(\u5df2\u6ee1)\n    - 5\u7fa4: 948526733(\u5df2\u6ee1)\n    - 7\u7fa4: 660689659(\u5df2\u6ee1)\n    - 8\u7fa4: 620629239(\u5df2\u6ee1)\n    - 6\u7fa4: 608792930(\u672a\u6ee1)\n    - 9\u7fa4: 693035807(\u672a\u6ee1)\n  - \u8bf7\u4e0d\u8981\u91cd\u590d\u52a0\u7fa4\uff0c\u4e00\u4e2a\u7fa4\u5c31\u53ef\u4ee5\u4e86\uff0c\u628a\u673a\u4f1a\u7559\u7ed9\u66f4\u591a\u4eba\n  - **\u8fdb\u7fa4\u5148\u770b\u516c\u544a\uff01\uff01\uff01\u8fdb\u7fa4\u5148\u770b\u516c\u544a\uff01\uff01\uff01\u8fdb\u7fa4\u5148\u770b\u516c\u544a\uff01\uff01\uff01 \u91cd\u8981\u7684\u4e8b\u60c5\u8bf4\u4e09\u904d**\n  - \u80fd\u4e3a\u4f60\u62a2\u5230\u4e00\u5f20\u56de\u5bb6\u7684\u7968\uff0c\u662f\u6211\u6700\u5927\u7684\u5fc3\u613f\n\n#### \u65e5\u5fd7\u5217\u5b50\n   - \u6210\u529flog\uff0c\u5982\u679c\u662f\u8d2d\u7968\u5931\u8d25\u7684\uff0c\u8bf7\u5e26\u4e0a\u5931\u8d25\u7684log\u7ed9\u6211\uff0c\u6211\u5c3d\u529b\u5e2e\u4f60\u8c03\uff0c\u4e5f\u53ef\u52a0\u7fa4\u4e00\u8d77\u4ea4\u6d41\uff0c\u7a0b\u5e8f\u53ea\u662f\u52a0\u901f\u4e70\u7968\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e0d\u4e00\u5b9a\u80fd\u4e70\u5230\u7968\n        ```\n        \u6b63\u5728\u7b2c355\u6b21\u67e5\u8be2  \u4e58\u8f66\u65e5\u671f: 2018-02-12  \u8f66\u6b21G4741,G2365,G1371,G1377,G1329 \u67e5\u8be2\u65e0\u7968  \u4ee3\u7406\u8bbe\u7f6e \u65e0  \u603b\u8017\u65f6429ms\n        \u8f66\u6b21: G4741 \u59cb\u53d1\u8f66\u7ad9: \u4e0a\u6d77 \u7ec8\u70b9\u7ad9: \u90b5\u9633 \u4e8c\u7b49\u5ea7:\u6709\n        \u6b63\u5728\u5c1d\u8bd5\u63d0\u4ea4\u8ba2\u7968...\n        \u5c1d\u8bd5\u63d0\u4ea4\u8ba2\u5355...\n        \u51fa\u7968\u6210\u529f\n        \u6392\u961f\u6210\u529f, \u5f53\u524d\u4f59\u7968\u8fd8\u5269\u4f59: 359 \u5f20\n        \u6b63\u5728\u4f7f\u7528\u81ea\u52a8\u8bc6\u522b\u9a8c\u8bc1\u7801\u529f\u80fd\n        \u9a8c\u8bc1\u7801\u901a\u8fc7,\u6b63\u5728\u63d0\u4ea4\u8ba2\u5355\n        \u63d0\u4ea4\u8ba2\u5355\u6210\u529f\uff01\n        \u6392\u961f\u7b49\u5f85\u65f6\u95f4\u9884\u8ba1\u8fd8\u5269 -12 ms\n        \u6392\u961f\u7b49\u5f85\u65f6\u95f4\u9884\u8ba1\u8fd8\u5269 -6 ms\n        \u6392\u961f\u7b49\u5f85\u65f6\u95f4\u9884\u8ba1\u8fd8\u5269 -7 ms\n        \u6392\u961f\u7b49\u5f85\u65f6\u95f4\u9884\u8ba1\u8fd8\u5269 -4 ms\n        \u6392\u961f\u7b49\u5f85\u65f6\u95f4\u9884\u8ba1\u8fd8\u5269 -4 ms\n        \u606d\u559c\u60a8\u8ba2\u7968\u6210\u529f\uff0c\u8ba2\u5355\u53f7\u4e3a\uff1aEB52743573, \u8bf7\u7acb\u5373\u6253\u5f00\u6d4f\u89c8\u5668\u767b\u5f5512306\uff0c\u8bbf\u95ee\u2018\u672a\u5b8c\u6210\u8ba2\u5355\u2019\uff0c\u572830\u5206\u949f\u5185\u5b8c\u6210\u652f\u4ed8\uff01\n        ```\n#### \u4f7f\u7528\u5e2e\u52a9(\u4e00\u4e9b\u5b89\u88c5\u95ee\u9898\u548c\u4f7f\u7528\u53cd\u9988\u8f83\u591a\u7684\u95ee\u9898)\uff1a\n   - \u6d4b\u8bd5\u90ae\u7bb1\u662f\u5426\u53ef\u7528 [\u90ae\u7bb1\u914d\u7f6e\u95ee\u9898\u770bissues](https://github.com/testerSunshine/12306/issues/107)\n   - \u5b66\u751f\u7968issues [\u5b66\u751f\u7968\u4fee\u6539](https://github.com/testerSunshine/12306/issues/47)\n   - \u4f9d\u8d56\u5b89\u88c5\u4e0d\u5bf9\u7684\u95ee\u9898\uff08ImportError\uff09[requirements.txt\u95ee\u9898](https://github.com/testerSunshine/12306/issues/91)\n   - \u82e5\u5feb\u8c46\u5b50\u7591\u95ee [\u70b9\u6211](https://github.com/testerSunshine/12306/issues/67)\n   - IOError: \u3010Errno 0\u3011 Error \u95ee\u9898 [\u70b9\u6211](https://github.com/testerSunshine/12306/issues/159)\n    \n   - \u6d4b\u8bd5\u4e0b\u5355\u63a5\u53e3\u662f\u5426\u53ef\u7528\uff0c\u6709\u4e24\u4e2a\u4e0b\u5355\u63a5\u53e3\uff0c\u968f\u4fbf\u7528\u54ea\u4e2a\u90fdok\n   - \u5982\u679c\u4e0b\u8f7d\u9a8c\u8bc1\u7801\u8fc7\u671f\u6216\u8005\u4e0b\u8f7d\u5931\u8d25\u7684\u95ee\u9898\uff0c\u5e94\u8be5\u662f12306\u5c01ip\u7684\u7b56\u7565\uff0c\u591a\u91cd\u8bd5\u51e0\u6b21\uff0c12306\u73b0\u5728\u5c01\u670d\u52a1\u5668(\u963f\u91cc\u4e91\u548c\u817e\u8baf\u4e91)ip\u6bd4\u8f83\u4e25\u91cd\uff0c\u5c3d\u91cf\u4e0d\u8981\u653e\u5728\u670d\u52a1\u5668\u91cc\u9762\n   - \u76ee\u524d12306\u5bf9\u670d\u52a1\u5668ip\u6bd4\u8f83\u654f\u611f\uff0c\u5927\u5bb6\u8fd8\u662f\u5728\u81ea\u5df1\u5bb6\u91cc\u6302\u7740\u5427\n   - \u81ea\u52a8\u66f4\u6362ip\u8f6f\u4ef6\u76ee\u524d\u5df2\u652f\u6301TPLINK\u548c\u5c0f\u7c73\u8def\u7531\u5668\uff0c\u53ea\u9650\u5bb6\u5ead\u7f51\u7edc[\u70b9\u6211\u8df3\u8f6c](https://github.com/testerSunshine/AutoRouterIP)\n\n\n#### \u611f\u8c22\u4e00\u4e0b\u5c0f\u4f19\u4f34\u5bf9\u672c\u9879\u76ee\u63d0\u4f9b\u7684\u5e2e\u52a9\n   - @sun7127@126.com\n   - @ \u624d\n   - @[MonsterTan](https://github.com/MonsterTan)\n   - \u4ee5\u53ca\u6240\u6709\u4e3a\u6b64\u9879\u76ee\u63d0\u4f9bpr\u7684\u540c\u5b66\n#### \u66f4\u65b0\u65e5\u5fd7\n   - [\u66f4\u65b0\u65e5\u5fd7](Update.md)\n"}, {"repo": "apache/incubator-mxnet", "language": "Python", "readme_contents": "<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n<!--- or more contributor license agreements.  See the NOTICE file -->\n<!--- distributed with this work for additional information -->\n<!--- regarding copyright ownership.  The ASF licenses this file -->\n<!--- to you under the Apache License, Version 2.0 (the -->\n<!--- \"License\"); you may not use this file except in compliance -->\n<!--- with the License.  You may obtain a copy of the License at -->\n\n<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n\n<!--- Unless required by applicable law or agreed to in writing, -->\n<!--- software distributed under the License is distributed on an -->\n<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n<!--- KIND, either express or implied.  See the License for the -->\n<!--- specific language governing permissions and limitations -->\n<!--- under the License. -->\n\n<div align=\"center\">\n  <a href=\"https://mxnet.apache.org/\"><img src=\"https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet_logo_2.png\"></a><br>\n</div>\n\nApache MXNet (incubating) for Deep Learning\n=====\n| Master         | Docs          | License  |\n| :-------------:|:-------------:|:--------:|\n[![CentOS CPU Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/centos-cpu/job/master/badge/icon?subject=build%20centos%20cpu)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/centos-cpu/job/master/) [![CentOS GPU Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/centos-gpu/job/master/badge/icon?subject=build%20centos%20gpu)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/centos-gpu/job/master/) [![Clang Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/clang/job/master/badge/icon?subject=build%20clang)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/clang/job/master/) <br> [![Edge Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/edge/job/master/badge/icon?subject=build%20edge)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/edge/job/master/) [![Miscellaneous Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/miscellaneous/job/master/badge/icon?subject=build%20miscellaneous)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/miscellaneous/job/master/) [![Sanity Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/sanity/job/master/badge/icon?subject=build%20sanity)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/sanity/job/master/) <br> [![Unix CPU Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/unix-cpu/job/master/badge/icon?subject=build%20unix%20cpu)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/unix-cpu/job/master/) [![Unix GPU Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/unix-gpu/job/master/badge/icon?subject=build%20unix%20gpu)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/unix-gpu/job/master/) [![Website Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/website/job/master/badge/icon?subject=build%20website)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/website/job/master/) <br> [![Windows CPU Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/windows-cpu/job/master/badge/icon?subject=build%20windows%20cpu)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/windows-cpu/job/master/) [![Windows GPU Build Status](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/windows-gpu/job/master/badge/icon?subject=build%20windows%20gpu)](http://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/windows-gpu/job/master/) | [![Documentation Status](http://jenkins.mxnet-ci.amazon-ml.com/job/restricted-website-build/badge/icon)](https://mxnet.apache.org/) | [![GitHub license](http://dmlc.github.io/img/apache2.svg)](./LICENSE) |\n\n![banner](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/banner.png)\n\nApache MXNet (incubating) is a deep learning framework designed for both *efficiency* and *flexibility*.\nIt allows you to ***mix*** [symbolic and imperative programming](https://mxnet.apache.org/api/architecture/program_model)\nto ***maximize*** efficiency and productivity.\nAt its core, MXNet contains a dynamic dependency scheduler that automatically parallelizes both symbolic and imperative operations on the fly.\nA graph optimization layer on top of that makes symbolic execution fast and memory efficient.\nMXNet is portable and lightweight, scaling effectively to multiple GPUs and multiple machines.\n\nMXNet is more than a deep learning project. It is a collection of\n[blue prints and guidelines](https://mxnet.apache.org/api/architecture/overview) for building\ndeep learning systems, and interesting insights of DL systems for hackers.\n\nAsk Questions\n-------------\n* Please use [discuss.mxnet.io](https://discuss.mxnet.io/) for asking questions.\n* Please use [mxnet/issues](https://github.com/apache/incubator-mxnet/issues) for reporting bugs.\n* [Frequent Asked Questions](https://mxnet.apache.org/faq/faq.html)\n\nHow to Contribute\n-----------------\n* [Contribute to MXNet](https://mxnet.apache.org/community/contribute.html)\n\nWhat's New\n----------\n* [Version 1.5.1 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.5.1) - MXNet 1.5.1 Patch Release.\n* [Version 1.5.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.5.0) - MXNet 1.5.0 Release.\n* [Version 1.4.1 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.4.1) - MXNet 1.4.1 Patch Release.\n* [Version 1.4.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.4.0) - MXNet 1.4.0 Release.\n* [Version 1.3.1 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.3.1) - MXNet 1.3.1 Patch Release.\n* [Version 1.3.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.3.0) - MXNet 1.3.0 Release.\n* [Version 1.2.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.2.0) - MXNet 1.2.0 Release.\n* [Version 1.1.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.1.0) - MXNet 1.1.0 Release.\n* [Version 1.0.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/1.0.0) - MXNet 1.0.0 Release.\n* [Version 0.12.1 Release](https://github.com/apache/incubator-mxnet/releases/tag/0.12.1) - MXNet 0.12.1 Patch Release.\n* [Version 0.12.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/0.12.0) - MXNet 0.12.0 Release.\n* [Version 0.11.0 Release](https://github.com/apache/incubator-mxnet/releases/tag/0.11.0) - MXNet 0.11.0 Release.\n* [Apache Incubator](http://incubator.apache.org/projects/mxnet.html) - We are now an Apache Incubator project.\n* [Version 0.10.0 Release](https://github.com/dmlc/mxnet/releases/tag/v0.10.0) - MXNet 0.10.0 Release.\n* [Version 0.9.3 Release](./docs/architecture/release_note_0_9.md) - First 0.9 official release.\n* [Version 0.9.1 Release (NNVM refactor)](./docs/architecture/release_note_0_9.md) - NNVM branch is merged into master now. An official release will be made soon.\n* [Version 0.8.0 Release](https://github.com/dmlc/mxnet/releases/tag/v0.8.0)\n* [Updated Image Classification with new Pre-trained Models](./example/image-classification)\n* [Notebooks How to Use MXNet](https://github.com/d2l-ai/d2l-en)\n* [MKLDNN for Faster CPU Performance](docs/python_docs/python/tutorials/performance/backend/mkldnn/mkldnn_readme.md)\n* [MXNet Memory Monger, Training Deeper Nets with Sublinear Memory Cost](https://github.com/dmlc/mxnet-memonger)\n* [Tutorial for NVidia GTC 2016](https://github.com/dmlc/mxnet-gtc-tutorial)\n* [MXNet.js: Javascript Package for Deep Learning in Browser (without server)](https://github.com/dmlc/mxnet.js/)\n* [Guide to Creating New Operators (Layers)](https://mxnet.apache.org/api/faq/new_op)\n* [Go binding for inference](https://github.com/songtianyi/go-mxnet-predictor)\n* [Amalgamation and Go Binding for Predictors](https://github.com/jdeng/gomxnet/) - Outdated\n* [Large Scale Image Classification](https://github.com/apache/incubator-mxnet/tree/master/example/image-classification)\n\nContents\n--------\n* [Website](https://mxnet.apache.org)\n* [Documentation](https://mxnet.apache.org/api)\n* [Blog](https://mxnet.apache.org/blog)\n* [Code Examples](https://github.com/apache/incubator-mxnet/tree/master/example)\n* [Installation](https://mxnet.apache.org/get_started)\n* [Features](https://mxnet.apache.org/features)\n* [Ecosystem](https://mxnet.apache.org/ecosystem)\n\nFeatures\n--------\n* Design notes providing useful insights that can re-used by other DL projects\n* Flexible configuration for arbitrary computation graph\n* Mix and match imperative and symbolic programming to maximize flexibility and efficiency\n* Lightweight, memory efficient and portable to smart devices\n* Scales up to multi GPUs and distributed setting with auto parallelism\n* Support for [Python](https://mxnet.apache.org/api/python), [Scala](https://mxnet.apache.org/api/scala), [C++](https://mxnet.apache.org/api/cpp), [Java](https://mxnet.apache.org/api/java), [Clojure](https://mxnet.apache.org/api/clojure), [R](https://mxnet.apache.org/api/r), [Go](https://github.com/jdeng/gomxnet/), [Javascript](https://github.com/dmlc/mxnet.js/), [Perl](https://mxnet.apache.org/api/perl), [Matlab](https://github.com/apache/incubator-mxnet/tree/master/matlab), and [Julia](https://mxnet.apache.org/api/julia)\n* Cloud-friendly and directly compatible with AWS S3, AWS Deep Learning AMI, AWS SageMaker, HDFS, and Azure\n\nLicense\n-------\nLicensed under an [Apache-2.0](https://github.com/apache/incubator-mxnet/blob/master/LICENSE) license.\n\nReference Paper\n---------------\n\nTianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao,\nBing Xu, Chiyuan Zhang, and Zheng Zhang.\n[MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems](https://github.com/dmlc/web-data/raw/master/mxnet/paper/mxnet-learningsys.pdf).\nIn Neural Information Processing Systems, Workshop on Machine Learning Systems, 2015\n\nHistory\n-------\nMXNet emerged from a collaboration by the authors of [cxxnet](https://github.com/dmlc/cxxnet), [minerva](https://github.com/dmlc/minerva), and [purine2](https://github.com/purine/purine2). The project reflects what we have learned from the past projects. MXNet combines aspects of each of these projects to achieve flexibility, speed, and memory efficiency.\n"}, {"repo": "docker/compose", "language": "Python", "readme_contents": "Docker Compose\n==============\n![Docker Compose](logo.png?raw=true \"Docker Compose Logo\")\n\n## :exclamation: The docker-compose project announces that as Python 2 reaches it's EOL, versions 1.25.x will be the last to support it. For more information, please refer to this [issue](https://github.com/docker/compose/issues/6890).\n\nCompose is a tool for defining and running multi-container Docker applications.\nWith Compose, you use a Compose file to configure your application's services.\nThen, using a single command, you create and start all the services\nfrom your configuration. To learn more about all the features of Compose\nsee [the list of features](https://github.com/docker/docker.github.io/blob/master/compose/index.md#features).\n\nCompose is great for development, testing, and staging environments, as well as\nCI workflows. You can learn more about each case in\n[Common Use Cases](https://github.com/docker/docker.github.io/blob/master/compose/index.md#common-use-cases).\n\nUsing Compose is basically a three-step process.\n\n1. Define your app's environment with a `Dockerfile` so it can be\nreproduced anywhere.\n2. Define the services that make up your app in `docker-compose.yml` so\nthey can be run together in an isolated environment.\n3. Lastly, run `docker-compose up` and Compose will start and run your entire app.\n\nA `docker-compose.yml` looks like this:\n\n    version: '2'\n\n    services:\n      web:\n        build: .\n        ports:\n         - \"5000:5000\"\n        volumes:\n         - .:/code\n      redis:\n        image: redis\n\nFor more information about the Compose file, see the\n[Compose file reference](https://github.com/docker/docker.github.io/blob/master/compose/compose-file/compose-versioning.md).\n\nCompose has commands for managing the whole lifecycle of your application:\n\n * Start, stop and rebuild services\n * View the status of running services\n * Stream the log output of running services\n * Run a one-off command on a service\n\nInstallation and documentation\n------------------------------\n\n- Full documentation is available on [Docker's website](https://docs.docker.com/compose/).\n- Code repository for Compose is on [GitHub](https://github.com/docker/compose).\n- If you find any problems please fill out an [issue](https://github.com/docker/compose/issues/new/choose). Thank you!\n\nContributing\n------------\n\n[![Build Status](https://jenkins.dockerproject.org/buildStatus/icon?job=docker/compose/master)](https://jenkins.dockerproject.org/job/docker/job/compose/job/master/)\n\nWant to help build Compose? Check out our [contributing documentation](https://github.com/docker/compose/blob/master/CONTRIBUTING.md).\n\nReleasing\n---------\n\nReleases are built by maintainers, following an outline of the [release process](https://github.com/docker/compose/blob/master/project/RELEASE-PROCESS.md).\n"}, {"repo": "chubin/cheat.sh", "language": "Python", "readme_contents": "\n![cheat.sh logo](http://cheat.sh/files/big-logo-v2-fixed.png)\n\nUnified access to the best community driven cheat sheets repositories of the world.\n\nLet's imagine for a moment that there is such a thing as an ideal cheat sheet.\nWhat should it look like?\nWhat features should it have?\n\n* **Concise** \u2014 It should only contain the things you need, and nothing else.\n* **Fast** \u2014 It should be possible to use it instantly.\n* **Comprehensive** \u2014 It should contain answers for every possible question.\n* **Universal** \u2014 It should be available everywhere, anytime, without any preparations.\n* **Unobtrusive** \u2014 It should not distract you from your main task.\n* **Tutoring** \u2014 It should help you to learn the subject.\n* **Inconspicuous** \u2014 It should be possible to use it completely unnoticed.\n\nSuch a thing exists.\n\n[![Build Status](https://travis-ci.org/chubin/cheat.sh.svg?branch=master)](https://travis-ci.org/chubin/cheat.sh)\n\n## Features\n\n**cheat.sh**\n\n* Has a simple curl/browser interface.\n* Covers 56 programming languages, several DBMSes, and more than 1000 most important UNIX/Linux commands.\n* Provides access to the best community driven cheat sheets repositories in the world, on par with StackOverflow.\n* Available everywhere, no installation needed.\n* Ultrafast, returns answers within 100 ms, as a rule.\n* Has a convenient command line client, `cht.sh`, that is very advantageous and helpful, though not mandatory.\n* Can be used directly from code editors, without opening a browser and not switching your mental context.\n* Supports a special stealth mode where it can be used fully invisibly without ever touching a key and and making sounds.\n\n<p align=\"center\">\n  <img src='https://cheat.sh/files/demo-curl.gif'/>\n</p>\n\n## Contents\n\n* [Features](#features)\n* [Usage](#usage)\n* [Command line client, cht.sh](#command-line-client-chtsh)\n  * [Installation](#installation)\n  * [Client usage](#client-usage)\n  * [Tab-completion](#tab-completion)\n  * [Stealth mode](#stealth-mode)\n* [Self-Hosting](#self-hosting)\n  * [Docker](#docker)\n* [Editors integration](#editors-integration)\n  * [Vim](#vim)\n  * [Emacs](#emacs)\n  * [Visual Studio Code](#visual-studio-code)\n  * [Sublime](#sublime)\n  * [IntelliJ IDEA](#intellij-idea)\n* [Special pages](#special-pages)\n* [Search](#search)\n* [Programming languages cheat sheets](#programming-languages-cheat-sheets)\n* [Cheat sheets sources](#cheat-sheets-sources)\n* [How to contribute](#how-to-contribute)\n  * [How to edit a cheat sheet](#how-to-edit-a-cheat-sheet)\n  * [How to add a cheat sheet](#how-to-add-a-cheat-sheet)\n  * [How to add a cheat sheet repository](#how-to-add-a-cheat-sheet-repository)\n\n## Usage\n\nTo get a cheat sheet for a UNIX/Linux command from a command line, query the service using `curl` or any other HTTP/HTTPS client\nspecifying the name of the command in the query:\n\n```\n    curl cheat.sh/tar\n    curl cht.sh/curl\n    curl https://cheat.sh/rsync\n    curl https://cht.sh/tr\n```\nAs you can see, you can use both HTTPS and HTTP to access the service, and both the long (cheat.sh) and the short (cht.sh) service names.\n\nHere `tar`, `curl`, `rsync`, and `tr` are names of the UNIX/Linux commands you want to get cheat sheets for.\n\nIf you don't know the name of the command you need, you can search for it using the `~KEYWORD` notation.\nFor example, to see how you can make `snapshots` of a filesystem/volume/something else:\n```\n    curl cht.sh/~snapshot\n```\n\n<p align=\"center\">\n  <img src='https://cheat.sh/files/cht.sh-url-structure.png'/>\n</p>\n\nThe programming language cheat sheets are located in special namespaces dedicated to them.\n\n```\n    curl cht.sh/go/Pointers\n    curl cht.sh/scala/Functions\n    curl cht.sh/python/lambda\n```\n\nTo get the list of available programming language cheat sheets, use the special query `:list`:\n\n```\n    curl cht.sh/go/:list\n```\n\nAlmost each programming language has a special page named `:learn`\nthat describes the language basics (that's a direct mapping from the *\"Learn X in Y\"* project).\nIt could be a good starting point if you've just started learning a language.\n\nIf there is no cheat sheet for a programming language query (and it is almost always the case),\nit is generated on the fly, based on available cheat sheets and answers on StackOverflow.\nOf course, there is no guarantee that the returned cheat sheet will be a 100% hit, but it is almost always exactly what you are looking for.\n\nTry these (and your own) queries to get the impression of that, what the answers look like:\n```\n    curl cht.sh/go/reverse+a+list\n    curl cht.sh/python/random+list+elements\n    curl cht.sh/js/parse+json\n    curl cht.sh/lua/merge+tables\n    curl cht.sh/clojure/variadic+function\n```\n\nIf you don't like an answer for your queries, you can pick another one. For that, repeat the query with an additional parameter `/1`, `/2` etc. appended:\n\n```\n    curl cht.sh/python/random+string\n    curl cht.sh/python/random+string/1\n    curl cht.sh/python/random+string/2\n```\n\nCheat sheets are formatted as code of the queried programming language (at least we are trying our best to do so)\nso they can be pasted into a program in this language directly. Text comments, if there are any, are formatted according to the language syntax.\n\n```lua\n    $ curl cht.sh/lua/table+keys\n    -- lua: retrieve list of keys in a table\n\n    local keyset={}\n    local n=0\n\n    for k,v in pairs(tab) do\n      n=n+1\n      keyset[n]=k\n    end\n\n    --[[\n       [ Note that you cannot guarantee any order in keyset. If you want the\n       [ keys in sorted order, then sort keyset with table.sort(keyset).\n       [ \n       [ [lhf] [so/q/12674345] [cc by-sa 3.0]\n       ]]\n\n```\n\nIf you don't need text comments in the answer, you can eliminate them\nusing a special option `?Q`:\n```lua\n    $ curl cht.sh/lua/table+keys?Q\n    local keyset={}\n    local n=0\n\n    for k,v in pairs(tab) do\n      n=n+1\n      keyset[n]=k\n    end\n```\n\nAnd if you don't need syntax highlighting, switch it off using `?T`.\nYou can combine the options together:\n\n```\n    curl cht.sh/go/reverse+a+list?Q\n    curl cht.sh/python/random+list+elements?Q\n    curl cht.sh/js/parse+json?Q\n    curl cht.sh/lua/merge+tables?QT\n    curl cht.sh/clojure/variadic+function?QT\n```\n\nFull list of all options described below and in `/:help`.\n\nTry your own queries. Follow these rules:\n\n1. Try to be more specific (`/python/append+file` is better than `/python/file` and `/python/append`).\n2. Ask practical question if possible (yet theoretical question are possible too).\n3. Ask programming language questions only; specify the name of the programming language as the section name.\n4. Separate words with `+` instead of spaces.\n5. Do not use special characters, they are ignored anyway.\n6. If you want to eliminate cheat sheets containing some word, add it to the query with `+-`: `python/multiply+matrices+-numpy`\n\nRead more about the programming languages queries below.\n\n## Command line client, cht.sh\n\nThe cheat.sh service has its own command line client (`cht.sh`) that\nhas several useful features compared to querying the service directly with `curl`:\n\n* Special shell mode with a persistent queries context and readline support.\n* Queries history.\n* Clipboard integration.\n* Tab completion support for shells (bash, fish, zsh).\n* Stealth mode.\n\n### Installation\n\nTo install the client:\n\n```\n    mkdir -p ~/bin/\n    curl https://cht.sh/:cht.sh > ~/bin/cht.sh\n    chmod +x ~/bin/cht.sh\n```\n\nor to install it globally (for all users):\n\n```\n    curl https://cht.sh/:cht.sh | sudo tee /usr/local/bin/cht.sh\n    chmod +x /usr/local/bin/cht.sh\n```\n\nNote: The package \"rlwrap\" is a required dependency to run in shell mode. Install this using `sudo apt install rlwrap`\n\n### Client usage\n\nNow, you can use `cht.sh` instead of `curl`, and write your queries in more natural way,\nwith spaces instead of `+`:\n\n```\n    $ cht.sh go reverse a list\n    $ cht.sh python random list elements\n    $ cht.sh js parse json\n```\n\nIt is even more convenient to start the client in a special shell mode:\n```\n    $ cht.sh --shell\n    cht.sh> go reverse a list\n```\n\nIf all your queries are about the same language, you can change the context\nand spare repeating the programming language name:\n```\n    $ cht.sh --shell\n    cht.sh> cd go\n    cht.sh/go> reverse a list\n```\nor even start the client in this context:\n```\n    $ cht.sh --shell go\n    cht.sh/go> reverse a list\n    ...\n    cht.sh/go> join a list\n    ...\n```\n\nIf you want to change the context, you can do it with the `cd` command,\nor if you want do a single query for some other language, just prepend it with `/`:\n\n```\n    $ cht.sh --shell go\n    ...\n    cht.sh/go> /python dictionary comprehension\n    ...\n```\n\nIf you want to copy the last answer into the clipboard, you can\nuse the `c` (`copy`) command, or `C` (`ccopy`, without comments).\n\n```\n    cht.sh/python> append file\n    #  python - How do you append to a file?\n\n    with open(\"test.txt\", \"a\") as myfile:\n        myfile.write(\"appended text\")\n    cht.sh/python> C\n    copy: 2 lines copied to the selection\n```\n\nType `help` for other internal `cht.sh` commands.\n\n```\n\tcht.sh> help\n\thelp    - show this help\n\thush    - do not show the 'help' string at start anymore\n\tcd LANG - change the language context\n\tcopy    - copy the last answer in the clipboard (aliases: yank, y, c)\n\tccopy   - copy the last answer w/o comments (cut comments; aliases: cc, Y, C)\n\texit    - exit the cheat shell (aliases: quit, ^D)\n\tid [ID] - set/show an unique session id (\"reset\" to reset, \"remove\" to remove)\n\tstealth - stealth mode (automatic queries for selected text)\n\tupdate  - self update (only if the scriptfile is writeable)\n\tversion - show current cht.sh version\n\t/:help  - service help\n\tQUERY   - space separated query staring (examples are below)\n\t\t\t\t  cht.sh> python zip list\n\t\t\t\t  cht.sh/python> zip list\n\t\t\t\t  cht.sh/go> /python zip list\n```\n\nThe `cht.sh` client has its configuration file which is located at `~/.cht.sh/cht.sh.conf`\n(location of the file can be overriden by the environment variable `CHTSH_CONF`).\nUse it to specify query options that you would use with each query.\nFor example, to switch syntax highlighting off create the file with the following\ncontent:\n\n```\nCHTSH_QUERY_OPTIONS=\"T\"\n```\n\nOr if you want to use a special syntax highlighting theme:\n\n```\nCHTSH_QUERY_OPTIONS=\"style=native\"\n```\n\n(`curl cht.sh/:styles-demo` to see all supported styles).\n\nOther cht.sh configuration parameters:\n\n```\nCHTSH_CURL_OPTIONS=\"-A curl\"        # curl options used for cht.sh queries\nCHTSH_URL=https://cht.sh            # URL of the cheat.sh server\n```\n\n### Tab completion\n\n\n#### Bash Tab completion\n\nTo activate tab completion support for `cht.sh`, add the `:bash_completion` script to your `~/.bashrc`:\n\n```\n    $ curl https://cheat.sh/:bash_completion > ~/.bash.d/cht.sh\n    $ . ~/.bash.d/cht.sh\n    $ # and add . ~/.bash.d/cht.sh to ~/.bashrc\n```\n\n#### ZSH Tab completion\n\nTo activate tab completion support for `cht.sh`, add the `:zsh` script to the *fpath* in your `~/.zshrc`:\n\n```\n    $ curl https://cheat.sh/:zsh > ~/.zsh.d/_cht\n    $ echo 'fpath=(~/.zsh.d/ $fpath)' >> ~/.zshrc\n    $ # Open a new shell to load the plugin\n```\n\n### Stealth mode\n\nBeing used fully unnoticed is one of the most important property of any cheat sheet.\n\ncheat.sh can be used completely unnoticed too. The cheat.sh client, `cht.sh`, has\na special mode, called **stealth mode**. Using that, you don't even need to touch your\nkeyboard to open a cheat sheet.\n\nIn this mode, as soon as you select some text with the mouse (and thus adding it\ninto the selection buffer of X Window System or into the clipboard) it's used\nas a query string for cheat.sh, and the correspondent cheat sheet is automatically shown.\n\nLet's imagine, that you are having an online interview, where your interviewer asks you\nsome questions using a shared document (say Google Docs) and you are supposed\nto write your coding answers there (it's possible too that you'll type in the questions\non your own, just to show to the interviewer that you've heard it right).\n\nWhen using the stealth mode of `cht.sh`, the only thing you need to do in order to see\na cheat sheet for some question, is to select the question using the mouse.\nIf you don't want any text in the answers and the only thing you need is code,\nuse the `Q` option when starting the stealth mode.\n\n<p align=\"center\">\n  <img src='https://cheat.sh/files/stealth-mode.gif'/>\n</p>\n\n```\nYou: Hi!                                            | $ cht.sh --shell python\nShe: Hi!                                            | cht.sh/python> stealth Q\nShe: Are you ready for a small interview?           | stealth: you are in the stealth mode; select any text\nShe: Just a couple of questions                     | stealth: selections longer than 5 words are ignored\nShe: We will talk about python                      | stealth: query arguments: ?Q\nShe: Let's start from something simple.             | stealth: use ^C to leave this mode\nShe: Do you know how to reverse a list in python?   |\nYou: Sure                                           |\nYou: (selecting \"reverse a list\")                   | stealth: reverse a list\n                                                    | reverse_lst = lst[::-1]\nYou: lst[::-1]?                                     |\nShe: Good.                                          |\nShe: Do you know how to chain a list of lists?      |\nYou: (selecting \"chain a list of lists\")            | stealth: chain a list of lists\n                                                    | import itertools\n                                                    | a = [[\"a\",\"b\"], [\"c\"]]\n                                                    | print list(itertools.chain.from_iterable(a))\nYou: May I use external modules?                    |\nShe: What module do you want to use?                |\nYou: itertools                                      |\nShe: Yes, you may use it                            |\nYou: Ok, then:                                      |\nYou: itertools.chain.from_iterable(a)               |\nShe: Good. Let's try something harder.              |\nShe: What about quicksort implementation?           |\nYou: (selecting \"quicksort implementation\")         | stealth: quicksort implementation\nYou: Let me think about it.                         | (some big and clumsy lowlevel implementation shown)\nYou: Well...(starting typing it in)                 | def sort(array=[12,4,5,6,7,3,1,15]):\n                                                    |     less = []\nShe: (seeing your ugly pascal style)                |     equal = []\nShe: Could you write it more concise?               |     greater = []\n                                                    |     if len(array) > 1:\nYou: What do you mean?                              |         pivot = array[0]\n                                                    |         for x in array:\nShe: I mean,                                        |             if x < pivot: less.append(x)\nShe: do you really need all these ifs and fors?     |             if x == pivot: equal.append(x)\nShe: Could you maybe just use filter instead?       |             if x > pivot: greater.append(x)\n                                                    |         return sort(less)+equal+sort(greater)\nYou: quicksort with filter?                         |     else:\n                                                    |         return array\nShe: Yes                                            |\nYou: (selecting \"quicksort with filter\")            | stealth: quicksort with filter\nYou: Ok, I will try.                                | return qsort(filter(lt, L[1:]))+[pivot] \\\nYou: Something like this?                           |     +qsort(filter(ge, L[1:]))\nYou: qsort(filter(lt, L[1:]))+[pivot] \\             |\n       + qsort(filter(ge, L[1:]))                   |\n                                                    |\nShe: Yes! Perfect! Exactly what I wanted to see!    |\n                                                    |\n\n```\n\nOf course, this is just for fun, and you should never cheat in your coding interviews,\nbecause you know what happens when you do.\n\n![when you lie in your interview](http://cheat.sh/files/when-you-lie-katze.png)\n\n### Windows command line client\n\nYou can access cheat.sh from Windows command line too.\n\nUse cheat.sh command line client for that: [`cht.exe`](https://github.com/tpanj/cht.exe).\nIt supports:\n\n* output colorization;\n* command line options;\n* its own configuration file.\n\nYou can also use [`scoop`](https://github.com/lukesampson/scoop) command-line installer for Windows to get it:\n```batch\nscoop install cht\n```\n\n## Self-Hosting\n\n### Docker\n\nCurrently, the easiest way to get a self-hosted instance running is by using the docker-compose.yml file provided in the extra/docker folder.\nThis pulls down the latest image with baked in cheatsheets and starts the app and a Redis instance to back it, making the service available on port 8002 of the local host. This is currently an early implementation and should probably not be used for anything outside of internal/dev/personal use right now.\n\n## Editors integration\n\nYou can use *cheat.sh* directly from the editor\n(*Emacs*, *Sublime*, *Vim*, and *Visual Studio Code* are currently supported;\nnot all features are supported by all plugins though; see below).\nInstead of opening your browser, googling, browsing Stack Overflow\nand eventually copying the code snippets you need into the clipboard\nand later pasting them into the editor,\nyou can achieve the same instantly and without leaving the editor at all!\n\nHere is what it looks like in Vim:\n\n1. If you have a question while editing a program, you can just type\nyour question directly in the buffer and press `<leader>KK`. You will get\nthe answer to your question in pager. (with `<leader>KB` you'll get the answer\nin a separate buffer).\n\n2. If you like the answer, you can manually paste it from the buffer or\nthe pager, or if you are lazy you can use `<leader>KP` to paste it below/under\nyour question (or replace you question using `<leader>KR`). If you want the\nanswer without the comments, `<leader>KC` replays the last query\ntoggling them.\n\nIf you use some static analysis plugin such as *syntastic* (for Vim), you can use\nits warning and error messages as cheat.sh queries: place the cursor on the problem line\nand press `<leader>KE`: explanation for the warning will be opened in a new buffer.\n\nFeatures supported by cheat.sh plugins for different editors:\n\n|Feature            |Emacs|Sublime|Vim|VSCode|IDEA|\n|-------------------|-----|-------|---|------|----|\n|Command queries    |\u2713    |\u2713      |\u2713  |\u2713     |\u2713   |\n|Queries from buffer|     |       |\u2713  |\u2713     |    |\n|Toggle comments    |     |       |\u2713  |\u2713     |\u2713   |\n|Prev/next answer   |     |       |\u2713  |\u2713     |\u2713   |\n|Multiple answers   |     |\u2713      |   |      |\u2713   |\n|Warnings as queries|     |       |\u2713  |      |    |\n|Queries history    |     |       |\u2713  |\u2713     |    |\n|Session id         |     |       |\u2713  |      |    |\n|Configurable server|\u2713    |       |\u2713  |\u2713     |    |\n\n### Vim\n\n* [cheat.sh-vim](https://github.com/dbeniamine/cheat.sh-vim) \u2014 Vim support\n\nHere is Vim configuration example:\n\n```vim\n\" some configuration above ...\n\nlet mapleader=\" \"\n\ncall vundle#begin()\nBundle 'gmarik/vundle'\nBundle 'scrooloose/syntastic'\nBundle 'dbeniamine/cheat.sh-vim'\ncall vundle#end()\n\nlet g:syntastic_javascript_checkers = [ 'jshint' ]\nlet g:syntastic_ocaml_checkers = ['merlin']\nlet g:syntastic_python_checkers = ['pylint']\nlet g:syntastic_shell_checkers = ['shellcheck']\n\n\" some configuration below ...\n```\n\nIn this example, several Vim plugins are used:\n\n* [gmarik/vundle](https://github.com/VundleVim/Vundle.vim) \u2014 Vim plugin manager\n* [scrooloose/syntastic](https://github.com/vim-syntastic/syntastic) \u2014 Syntax checking plugin\n* [cheat.sh-vim](https://github.com/dbeniamine/cheat.sh-vim) \u2014 Vim support\n\nSyntastic shows warnings and errors (found by code analysis tools: `jshint`, `merlin`, `pylint`, `shellcheckt etc.),\nand `cheat.sh-vim` shows you explanations for the errors and warnings\nand answers on programming languages queries written in the editor.\n\nWatch a demo, where the most important features of the cheat.sh Vim plugin are shown (5 Min):\n\n<p align=\"center\">\n  <img src='https://cheat.sh/files/vim-demo.gif'/>\n</p>\n\nOr, if you want to scroll and/or pause, the same on YouTube:\n\n<p align=\"center\">\n  <a href=\"http://www.youtube.com/watch?feature=player_embedded&v=xyf6MJ0y-z8\n  \" target=\"_blank\"><img src=\"http://img.youtube.com/vi/xyf6MJ0y-z8/0.jpg\" \n  alt=\"cheat.sh-vim: Using cheat.sh from vim\" width=\"700\" height=\"490\" border=\"10\" /></a>\n</p>\n\n<!-- [![asciicast](https://asciinema.org/a/c6QRIhus7np2OOQzmQ2RNXzRZ.png)](https://asciinema.org/a/c6QRIhus7np2OOQzmQ2RNXzRZ) -->\n\n### Emacs\n\n* [cheat-sh.el](https://github.com/davep/cheat-sh.el) \u2014 Emacs support (available also at cheat.sh/:emacs)\n* cheat.sh/:emacs-ivy \u2014 Emacs support for ivy users\n\n[![asciicast](https://asciinema.org/a/3xvqwrsu9g4taj5w526sb2t35.png)](https://asciinema.org/a/3xvqwrsu9g4taj5w526sb2t35)\n\n\n### Visual Studio Code\n\n* [vscode-snippet](https://github.com/mre/vscode-snippet)\n* Install it from [VSCode Marketplace](https://marketplace.visualstudio.com/items?itemName=vscode-snippet.Snippet)\n\nUsage: \n\n1. Hit <kbd>\u2318 Command</kbd> + <kbd>\u21e7 Shift</kbd> + <kbd>p</kbd>\n2. Run `Snippet: Find`.\n3. Type your query and hit enter.\n\n[![vscode-snippet](https://cheat.sh/files/vscode-snippet-demo.gif)](https://github.com/mre/vscode-snippet)\n\n*(GIF courtesy: Matthias Endler, @mre)*\n\n### Sublime\n\n* [cheat.sh-sublime-plugin](https://github.com/gauravk-in/cheat.sh-sublime-plugin/)\n\nUsage:\n\n1.  Write your query string.\n2.  Select the query string.\n3.  Press <kbd>Cmd</kbd> + <kbd>\u21e7 Shift</kbd> + <kbd>B</kbd> to replace the selected query string by the answer generated from `cht.sh`.\n\n[![cheat.sh-sublime-plugin-demo](https://cheat.sh/files/demo-sublime.gif)](https://github.com/gauravk-in/cheat.sh-sublime-plugin)\n\n*(GIF courtesy: Gaurav Kukreja, @gauravk-in)*\n\n### IntelliJ IDEA \n\n* [idea-cheatsh-plugin](https://github.com/szymonprz/idea-cheatsh-plugin)\n* Install from [idea plugins marketplace](https://plugins.jetbrains.com/plugin/11942-cheat-sh-code-snippets) \n\nUsage: \n\n1. Write query string\n2. Select the query string\n3. Press keyboard shortcut <kbd>Alt</kbd> + <kbd>C</kbd> , <kbd>S</kbd> to replace the selected query string by the answer\n\n[![idea-cheatsh-plugin](https://cheat.sh/files/idea-demo.gif)](https://github.com/szymonprz/idea-cheatsh-plugin)\n\n*(GIF courtesy: Szymon Przebierowski, @szymonprz)*\n\n## Special pages\n\nThere are several special pages that are not cheat sheets.\nTheir names start with colon and have special meaning.\n\n\nGetting started:\n\n```\n    :help               description of all special pages and options\n    :intro              cheat.sh introduction, covering the most important usage questions\n    :list               list all cheat sheets (can be used in a subsection too: /go/:list)\n```\n\nCommand line client `cht.sh` and shells support:\n```\n    :cht.sh             code of the cht.sh client\n    :bash_completion    bash function for tab completion\n    :bash               bash function and tab completion setup\n    :fish               fish function and tab completion setup\n    :zsh                zsh function and tab completion setup\n```\n\nEditors support:\n\n```\n    :vim                cheat.sh support for Vim\n    :emacs              cheat.sh function for Emacs\n    :emacs-ivy          cheat.sh function for Emacs (uses ivy)\n```\n\nOther pages:\n\n```\n    :post               how to post new cheat sheet\n    :styles             list of color styles\n    :styles-demo        show color styles usage examples\n```\n\n## Search\n\nTo search for a keyword, use the query:\n\n```\n    /~keyword\n```\n\nIn this case search is not recursive \u2014 it is conducted only in a page of the specified level.\nFor example:\n\n```\n    /~snapshot          look for snapshot in the first level cheat sheets\n    /scala/~currying     look for currying in scala cheat sheets\n```\n\nFor a recursive search in all cheat sheets, use double slash:\n\n```\n    /~snapshot/r         look for snapshot in all cheat sheets\n```\n\nYou can use special search options after the closing slash:\n\n```\n    /~shot/bi           case insensitive (i), word boundaries (b)\n```\n\nList of search options:\n\n```\n    i   case insensitive search\n    b   word boundaries\n    r   recursive search\n```\n\n## Programming languages cheat sheets\n\nCheat sheets related to programming languages\nare organized in namespaces (subdirectories), that are named according\nto the programming language.\n\nFor each supported programming language\nthere are several special cheat sheets: its own sheet, `hello`, `:list` and `:learn`.\nSay for lua it will look like:\n\n```\n    lua\n    lua/hello\n    lua/:list\n    lua/:learn\n```\n\nSome languages has the one-liners-cheat sheet, `1line`:\n\n```\n    perl/1line\n```\n* `hello` describes how you can start with the language \u2014 install it if needed, build and run its programs, and it shows the \"Hello world\" program written in the language;\n* `:list` shows all topics related to the language\n* `:learn` shows a learn-x-in-minutes language cheat sheet perfect for getting started with the language.\n* `1line` is a collection of one-liners in this language\n* `weirdness` is a collection of examples of weird things in this language\n\n![cheat.sh usage](http://cheat.sh/files/supported-languages-c++.png)\n\nAt the moment, cheat.sh covers the 58 following programming languages (alphabetically sorted):\n\n|Prefix     |Language  |Basics|One-liners|Weirdness|StackOverflow|\n|-----------|----------|------|----------|---------|-------------|\n|`arduino/` |Arduino   |      |          |         |\u2713            |\n|`assembly/`|Assembly  |      |          |         |\u2713            |\n|`awk/`     |AWK       |\u2713     |          |         |\u2713            |\n|`bash/`    |Bash      |\u2713     |          |         |\u2713            |\n|`basic/`   |BASIC     |      |          |         |\u2713            |\n|`bf/`      |Brainfuck |\u2713     |          |         |\u2713            |\n|`c/`       |C         |\u2713     |          |         |\u2713            |\n|`chapel/`  |Chapel    |\u2713     |          |         |\u2713            |\n|`clean/`   |Clean     |      |          |         |\u2713            |\n|`clojure/` |Clojure   |\u2713     |          |         |\u2713            |\n|`coffee/`  |CoffeeScript|\u2713   |          |         |\u2713            |\n|`cpp/`     |C++       |\u2713     |          |         |\u2713            |\n|`csharp/`  |C#        |\u2713     |          |         |\u2713            |\n|`d/`       |D         |\u2713     |          |         |\u2713            |\n|`dart/`    |Dart      |\u2713     |          |         |\u2713            |\n|`delphi/`  |Dephi     |      |          |         |\u2713            |\n|`dylan/`   |Dylan     |\u2713     |          |         |\u2713            |\n|`eiffel/`  |Eiffel    |      |          |         |\u2713            |\n|`elixir/`  |Elixir    |\u2713     |          |         |\u2713            |\n|`elisp/`   |ELisp     |\u2713     |          |         |\u2713            |\n|`elm/`     |Elm       |\u2713     |          |         |\u2713            |\n|`erlang/`  |Erlang    |\u2713     |          |         |\u2713            |\n|`factor/`  |Factor    |\u2713     |          |         |\u2713            |\n|`fortran/` |Fortran   |\u2713     |          |         |\u2713            |\n|`forth/`   |Forth     |\u2713     |          |         |\u2713            |\n|`fsharp/`  |F#        |\u2713     |          |         |\u2713            |\n|`go/`      |Go        |\u2713     |          |         |\u2713            |\n|`groovy/`  |Groovy    |\u2713     |          |         |\u2713            |\n|`haskell/` |Haskell   |\u2713     |          |         |\u2713            |\n|`java/`    |Java      |\u2713     |          |         |\u2713            |\n|`js/`      |JavaScript|\u2713     |\u2713         |\u2713        |\u2713            |\n|`julia/`   |Julia     |\u2713     |          |         |\u2713            |\n|`kotlin/`  |Kotlin    |\u2713     |          |         |\u2713            |\n|`latex/`   |LaTeX     |\u2713     |          |         |\u2713            |\n|`lisp/`    |Lisp      |\u2713     |          |         |\u2713            |\n|`lua/`     |Lua       |\u2713     |          |         |\u2713            |\n|`matlab/`  |MATLAB    |\u2713     |          |         |\u2713            |\n|`nim/`     |Nim       |\u2713     |          |         |\u2713            |\n|`ocaml/`   |OCaml     |\u2713     |          |         |\u2713            |\n|`octave/`  |Octave    |\u2713     |          |         |\u2713            |\n|`perl/`    |Perl      |\u2713     |\u2713         |         |\u2713            |\n|`perl6/`   |Perl 6    |\u2713     |\u2713         |         |\u2713            |\n|`php/`     |PHP       |\u2713     |          |         |\u2713            |\n|`pike/`    |Pike      |      |          |         |\u2713            |\n|`python/`  |Python    |\u2713     |\u2713         |         |\u2713            |\n|`python3/` |Python 3  |\u2713     |          |         |\u2713            |\n|`r/`       |R         |\u2713     |          |         |\u2713            |\n|`racket/`  |Racket    |\u2713     |          |         |\u2713            |\n|`ruby/`    |Ruby      |\u2713     |          |         |\u2713            |\n|`rust/`    |Rust      |\u2713     |          |         |\u2713            |\n|`scala/`   |Scala     |\u2713     |          |         |\u2713            |\n|`scheme/`  |Scheme    |\u2713     |          |         |\u2713            |\n|`solidity/`|Solidity  |\u2713     |          |         |\u2713            |\n|`swift/`   |Swift     |\u2713     |          |         |\u2713            |\n|`tcsh/`    |Tcsh      |\u2713     |          |         |\u2713            |\n|`tcl/`     |Tcl       |\u2713     |          |         |\u2713            |\n|`objective-c/`|Objective-C|\u2713 |          |         |\u2713            |\n|`vb/`      |VisualBasic|\u2713    |          |         |\u2713            |\n|`vbnet/`   |VB.Net    |\u2713     |          |         |\u2713            |\n\nAnd several other topics, that are though related to programming,\nare not programming languages:\n\n|Prefix     |Topic     |Basics|StackOverflow|\n|-----------|----------|------|-------------|\n|`cmake/`   |CMake     |\u2713     |\u2713            |\n|`django/`  |Django    |      |\u2713            |\n|`flask/`   |Flask     |      |\u2713            |\n|`git/`     |Git       |\u2713     |\u2713            |\n\n## Cheat sheets sources\n\nInstead of creating yet another mediocre cheat sheet repository,\nwe are concentrating our efforts on creation of a unified\nmechanism to access selected existing well developed and good maintained\ncheat sheet repositories covering topics of our interest:\nprogramming and operating systems usage.\n\n*cheat.sh* uses selected community driven cheat sheet repositories\nand information sources, maintained by thousands of users, developers and authors\nall over the world\n(in the *Users* column number of contributors/number of stars is shown):\n\n|Cheat sheets           |Repository                                            | Users | Creation Date |\n|-----------------------|------------------------------------------------------|------------|---------------|\n|UNIX/Linux, programming|[cheat.sheets](https://github.com/chubin/cheat.sheets)| 38/223       | May 1, 2017   |\n|UNIX/Linux commands    |[tldr-pages/tldr](https://github.com/tldr-pages/tldr) | 760/23158  | Dec 8, 2013   |\n|UNIX/Linux commands    |[chrisallenlane/cheat](https://github.com/chrisallenlane/cheat)|131/5240|Jul 28, 2013|\n|Programming languages  |[adambard/learnxinyminutes-docs](https://github.com/adambard/learnxinyminutes-docs)|1246/6748|Jun 23, 2013|\n|Go                     |[a8m/go-lang-cheat-sheet](https://github.com/a8m/go-lang-cheat-sheet)|31/4039|Feb 9, 2014|\n|Perl                   |[pkrumnis/perl1line.txt](https://github.com/pkrumins/perl1line.txt)|5/190|Nov 4, 2011|\n|Programming languages  |[StackOverflow](https://stackoverflow.com)|9M |Sep 15, 2008|\n\nPie diagram reflecting cheat sheets sources distribution (by number of cheat sheets on cheat.sh originating from a repository):\n\n![cheat.sh cheat sheets repositories](http://cheat.sh/files/stat-2017-06-05.png)\n\n## How to contribute\n\n### How to edit a cheat sheet\n\nIf you want to edit a cheat.sh cheat sheet, you should edit it in the upstream repository.\nYou will find the name of the source repository in a browser when you open a cheat sheet.\nThere are two github buttons at the bottom of the page: the second one is the button\nof the repository, which belongs the current cheat sheet.\n\nYou can edit the cheat sheet directly in your browser (you need a github account for it).\nThere is an edit button in the top right corner. If you click on it, an editor will be open.\nThere you will change the cheat sheet (under the hood: the upstrem repository is forked, your changes are\ncommitted in the forked repository, a pull request to the upstream repository owner is sent).\n\n![cheat.sh cheat sheets repositories](http://cheat.sh/files/edit-cheat-sheet.png)\n\n### How to add a cheat sheet\n\nIf you want to add a cheat sheet, you have one of the following\nways:\n\n* Add it to one of the external cheat sheets repositories; you should decide on your own what is the best repository for your cheat sheet;\n* Add it to the local cheat.sh repository ([cheat.sheets](https://github.com/chubin/cheat.sheets)) on github (fork, commit, pull request);\n* Post it on cheat.sh using curl or a web browser ([cheat.sh/:post](http://cheat.sh/:post)).\n\nIf you want to change an existing cheat sheet,\nyou have to find the original repository (when you open a cheat sheet in a browser,\nyou see the repository's github button in the bottom of the cheat sheet),\nthe cheat sheet is coming from, and change it there.\nAfter some time the changes will be synchronized on cheat.sh.\n\n### How to add a cheat sheet repository\n\nIf you want to add a cheat sheet repository to cheat.sh, please open an issue:\n\n* [Add a new repository](https://github.com/chubin/cheat.sh/issues/new)\n\nPlease specify the name of the repository, and give its short description.\n"}, {"repo": "donnemartin/data-science-ipython-notebooks", "language": "Python", "readme_contents": "<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif\">\n</p>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png\">\n  <br/>\n</p>\n\n# data-science-ipython-notebooks\n\n## Index\n\n* [deep-learning](#deep-learning)\n    * [tensorflow](#tensor-flow-tutorials)\n    * [theano](#theano-tutorials)\n    * [keras](#keras-tutorials)\n    * [caffe](#deep-learning-misc)\n* [scikit-learn](#scikit-learn)\n* [statistical-inference-scipy](#statistical-inference-scipy)\n* [pandas](#pandas)\n* [matplotlib](#matplotlib)\n* [numpy](#numpy)\n* [python-data](#python-data)\n* [kaggle-and-business-analyses](#kaggle-and-business-analyses)\n* [spark](#spark)\n* [mapreduce-python](#mapreduce-python)\n* [amazon web services](#aws)\n* [command lines](#commands)\n* [misc](#misc)\n* [notebook-installation](#notebook-installation)\n* [credits](#credits)\n* [contributing](#contributing)\n* [contact-info](#contact-info)\n* [license](#license)\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/ZhKXrKZ.png\">\n</p>\n\n## deep-learning\n\nIPython Notebook(s) demonstrating deep learning functionality.\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://avatars0.githubusercontent.com/u/15658638?v=3&s=100\">\n</p>\n\n### tensor-flow-tutorials\n\nAdditional TensorFlow tutorials:\n\n* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)\n* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)\n* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)\n* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)\n* [tuanavu/tensorflow-basic-tutorials](https://github.com/tuanavu/tensorflow-basic-tutorials)\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-basics](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |\n| [tsf-linear](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |\n| [tsf-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |\n| [tsf-nn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |\n| [tsf-alex](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |\n| [tsf-cnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |\n| [tsf-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |\n| [tsf-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |\n| [tsf-gpu](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |\n| [tsf-gviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |\n| [tsf-lviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |\n\n### tensor-flow-exercises\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-not-mnist](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |\n| [tsf-fully-connected](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |\n| [tsf-regularization](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |\n| [tsf-convolutions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |\n| [tsf-word2vec](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |\n| [tsf-lstm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png\">\n</p>\n\n### theano-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [theano-intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |\n| [theano-scan](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |\n| [theano-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |\n| [theano-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |\n| [theano-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/L45Q8c2.jpg\">\n</p>\n\n### keras-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |\n| [setup](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/0.%20Preamble.ipynb) | Learn about the tutorial goals and how to set up your Keras environment. |\n| [intro-deep-learning-ann](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |\n| [theano](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |\n| [keras-otto](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |\n| [ann-mnist](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.4%20%28Extra%29%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |\n| [conv-nets](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |\n| [conv-net-1](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |\n| [conv-net-2](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |\n| [keras-models](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |\n| [auto-encoders](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.1%20Unsupervised%20Learning%20-%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |\n| [rnn-lstm](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.2%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |\n| [lstm-sentence-gen](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.3%20%28Extra%29%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |\n\n### deep-learning-misc\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [deep-dream](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png\">\n</p>\n\n## scikit-learn\n\nIPython Notebook(s) demonstrating scikit-learn functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [knn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |\n| [linear-reg](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |\n| [svm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |\n| [random-forest](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |\n| [k-means](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |\n| [pca](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |\n| [gmm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |\n| [validation](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png\">\n</p>\n\n## statistical-inference-scipy\n\nIPython Notebook(s) demonstrating statistical inference with SciPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |\n| [effect-size](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |\n| [sampling](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |\n| [hypothesis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png\">\n</p>\n\n## pandas\n\nIPython Notebook(s) demonstrating pandas functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [pandas](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |\n| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |\n| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |\n| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |\n| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |\n| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |\n| [Missing-Values](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |\n| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |\n| [Concat-And-Append](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |\n| [Merge-and-Join](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |\n| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |\n| [Pivot-Tables](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |\n| [Working-With-Strings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |\n| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |\n| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png\">\n</p>\n\n## matplotlib\n\nIPython Notebook(s) demonstrating matplotlib functionality.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [matplotlib](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |\n| [matplotlib-applied](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |\n| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |\n| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |\n| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |\n| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |\n| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |\n| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |\n| [Customizing-Legends](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |\n| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |\n| [Multiple-Subplots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |\n| [Text-and-Annotation](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |\n| [Customizing-Ticks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |\n| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |\n| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |\n| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |\n| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png\">\n</p>\n\n## numpy\n\nIPython Notebook(s) demonstrating NumPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [numpy](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |\n| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |\n| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |\n| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |\n| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |\n| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |\n| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |\n| [Fancy-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |\n| [Sorting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |\n| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png\">\n</p>\n\n## python-data\n\nIPython Notebook(s) demonstrating Python functionality geared towards data analysis.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n| [data structures](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |\n| [data structure utilities](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |\n| [functions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |\n| [datetime](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |\n| [logging](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |\n| [pdb](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |\n| [unit tests](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png\">\n</p>\n\n## kaggle-and-business-analyses\n\nIPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.\n\n| Notebook | Description |\n|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n| [titanic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |\n| [churn-analysis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png\">\n</p>\n\n## spark\n\nIPython Notebook(s) demonstrating spark and HDFS functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [spark](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |\n| [hdfs](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png\">\n</p>\n\n## mapreduce-python\n\nIPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [mapreduce-python](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|\n\n<br/>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png\">\n</p>\n\n## aws\n\nIPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.\n\n\nAlso check out:\n\n* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).\n* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.\n\n| Notebook | Description |\n|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [boto](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |\n| [s3cmd](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |\n| [s3distcp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |\n| [s3-parallel-put](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |\n| [redshift](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |\n| [kinesis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |\n| [lambda](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png\">\n</p>\n\n## commands\n\nIPython Notebook(s) demonstrating various command lines for Linux, Git, etc.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [linux](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|\n| [anaconda](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |\n| [ipython notebook](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |\n| [git](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |\n| [ruby](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |\n| [jekyll](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |\n| [pelican](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |\n| [django](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).\n\n## misc\n\nIPython Notebook(s) demonstrating miscellaneous functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [regex](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|\n[algorithmia](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|\n\n## notebook-installation\n\n### anaconda\n\nAnaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.\n\nFollow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).\n\n### dev-setup\n\nFor detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.\n\n### running-notebooks\n\nTo view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)\n\n    $ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git\n    $ cd data-science-ipython-notebooks\n    $ jupyter notebook\n\nNotebooks tested with Python 2.7.x.\n\n## credits\n\n* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney\n* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas\n* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas\n* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel\n* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey\n* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien\n* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital\n* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz\n* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen\n* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla\n* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem\n* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio\n* [Kaggle](https://www.kaggle.com/)\n* [Yhat Blog](http://blog.yhat.com/)\n\n## contributing\n\nContributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/donnemartin/data-science-ipython-notebooks/issues).\n\n## contact-info\n\nFeel free to contact me to discuss any issues, questions, or comments.\n\n* Email: [donne.martin@gmail.com](mailto:donne.martin@gmail.com)\n* Twitter: [@donne_martin](https://twitter.com/donne_martin)\n* GitHub: [donnemartin](https://github.com/donnemartin)\n* LinkedIn: [donnemartin](https://www.linkedin.com/in/donnemartin)\n* Website: [donnemartin.com](http://donnemartin.com)\n\n## license\n\nThis repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties.\n\nThe content developed by Donne Martin is distributed under the following license:\n\n*I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).*\n\n    Copyright 2015 Donne Martin\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n"}, {"repo": "mitmproxy/mitmproxy", "language": "Python", "readme_contents": "mitmproxy\n^^^^^^^^^\n\n|ci_status| |coverage| |latest_release| |python_versions|\n\nThis repository contains the **mitmproxy** and **pathod** projects.\n\n``mitmproxy`` is an interactive, SSL/TLS-capable intercepting proxy with a console\ninterface for HTTP/1, HTTP/2, and WebSockets.\n\n``mitmdump`` is the command-line version of mitmproxy. Think tcpdump for HTTP.\n\n``mitmweb`` is a web-based interface for mitmproxy.\n\n``pathoc`` and ``pathod`` are perverse HTTP client and server applications\ndesigned to let you craft almost any conceivable HTTP request, including ones\nthat creatively violate the standards.\n\n\nDocumentation & Help\n--------------------\n\n\nGeneral information, tutorials, and precompiled binaries can be found on the mitmproxy website.\n\n|mitmproxy_site|\n\nThe documentation for mitmproxy is available on our website:\n\n|mitmproxy_docs_stable| |mitmproxy_docs_master|\n\nIf you have questions on how to use mitmproxy, please\nask them on StackOverflow!\n\n|mitmproxy_stackoverflow|\n\nJoin our developer chat on Slack if you would like to contribute to mitmproxy itself.\n\n|slack|\n\n\nInstallation\n------------\n\nThe installation instructions are `here <https://docs.mitmproxy.org/stable/overview-installation>`__.\nIf you want to contribute changes, keep on reading.\n\nContributing\n------------\n\nAs an open source project, mitmproxy welcomes contributions of all forms. If you would like to bring the project forward,\nplease consider contributing in the following areas:\n\n- **Maintenance:** We are *incredibly* thankful for individuals who are stepping up and helping with maintenance. This includes (but is not limited to) triaging issues, reviewing pull requests and picking up stale ones, helping out other users on StackOverflow_, creating minimal, complete and verifiable examples or test cases for existing bug reports, updating documentation, or fixing minor bugs that have recently been reported.\n- **Code Contributions:** We actively mark issues that we consider are `good first contributions`_. If you intend to work on a larger contribution to the project, please come talk to us first.\n\nDevelopment Setup\n-----------------\n\nTo get started hacking on mitmproxy, please install a recent version of Python (we require at least 3.6).\nThe following commands should work on your system:\n\n.. code-block:: bash\n\n    python3 --version\n    python3 -m pip --help\n    python3 -m venv --help\n\nIf all of this run successfully, do the following:\n\n.. code-block:: bash\n\n    git clone https://github.com/mitmproxy/mitmproxy.git\n    cd mitmproxy\n    ./dev.sh  # \"powershell .\\dev.ps1\" on Windows\n\n\nThe *dev* script will create a `virtualenv`_ environment in a directory called \"venv\"\nand install all mandatory and optional dependencies into it. The primary\nmitmproxy components - mitmproxy and pathod - are installed as\n\"editable\", so any changes to the source in the repository will be reflected\nlive in the virtualenv.\n\nThe main executables for the project - ``mitmdump``, ``mitmproxy``,\n``mitmweb``, ``pathod``, and ``pathoc`` - are all created within the\nvirtualenv. After activating the virtualenv, they will be on your $PATH, and\nyou can run them like any other command:\n\n.. code-block:: bash\n\n    . venv/bin/activate  # \"venv\\Scripts\\activate\" on Windows\n    mitmdump --version\n\nTesting\n-------\n\nIf you've followed the procedure above, you already have all the development\nrequirements installed, and you can run the full test suite with tox_:\n\n.. code-block:: bash\n\n    tox -e py    # runs Python tests\n    tox -e lint  # checks code style\n\nFor speedier testing, we recommend you run `pytest`_ directly on individual test files or folders:\n\n.. code-block:: bash\n\n    cd test/mitmproxy/addons\n    pytest --cov mitmproxy.addons.anticache --cov-report term-missing --looponfail test_anticache.py\n\nPytest does not check the code style, so you want to run ``tox -e lint`` again before committing.\n\nPlease ensure that all patches are accompanied by matching changes in the test\nsuite. The project tries to maintain 100% test coverage and enforces this strictly for some parts of the codebase.\n\nDocumentation\n-------------\n\nThe following tools are required to build the mitmproxy docs:\n\n- Hugo_\n- modd_\n- yarn_\n\n.. code-block:: bash\n\n    cd docs\n    yarn\n    modd\n\n\nCode Style\n----------\n\nKeeping to a consistent code style throughout the project makes it easier to\ncontribute and collaborate. Please stick to the guidelines in\n`PEP8`_ and the `Google Style Guide`_ unless there's a very\ngood reason not to.\n\nThis is automatically enforced on every PR. If we detect a linting error, the\nPR checks will fail and block merging. You can run our lint checks yourself\nwith the following command:\n\n.. code-block:: bash\n\n    tox -e lint\n\n\n.. |mitmproxy_site| image:: https://shields.mitmproxy.org/badge/https%3A%2F%2F-mitmproxy.org-blue.svg\n    :target: https://mitmproxy.org/\n    :alt: mitmproxy.org\n\n.. |mitmproxy_docs_stable| image:: https://shields.mitmproxy.org/badge/docs-stable-brightgreen.svg\n    :target: https://docs.mitmproxy.org/stable/\n    :alt: mitmproxy documentation stable\n\n.. |mitmproxy_docs_master| image:: https://shields.mitmproxy.org/badge/docs-master-brightgreen.svg\n    :target: https://docs.mitmproxy.org/master/\n    :alt: mitmproxy documentation master\n\n.. |mitmproxy_stackoverflow| image:: https://shields.mitmproxy.org/stackexchange/stackoverflow/t/mitmproxy?color=orange&label=stackoverflow%20questions\n    :target: https://stackoverflow.com/questions/tagged/mitmproxy\n    :alt: StackOverflow: mitmproxy\n\n.. |slack| image:: http://slack.mitmproxy.org/badge.svg\n    :target: http://slack.mitmproxy.org/\n    :alt: Slack Developer Chat\n\n.. |ci_status| image:: https://github.com/mitmproxy/mitmproxy/workflows/CI/badge.svg?branch=master\n    :target: https://github.com/mitmproxy/mitmproxy/actions?query=branch%3Amaster\n    :alt: Continuous Integration Status\n\n.. |coverage| image:: https://shields.mitmproxy.org/codecov/c/github/mitmproxy/mitmproxy/master.svg?label=codecov\n    :target: https://codecov.io/gh/mitmproxy/mitmproxy\n    :alt: Coverage Status\n\n.. |latest_release| image:: https://shields.mitmproxy.org/pypi/v/mitmproxy.svg\n    :target: https://pypi.python.org/pypi/mitmproxy\n    :alt: Latest Version\n\n.. |python_versions| image:: https://shields.mitmproxy.org/pypi/pyversions/mitmproxy.svg\n    :target: https://pypi.python.org/pypi/mitmproxy\n    :alt: Supported Python versions\n\n.. _virtualenv: https://virtualenv.pypa.io/\n.. _`pytest`: http://pytest.org/\n.. _tox: https://tox.readthedocs.io/\n.. _Hugo: https://gohugo.io/\n.. _modd: https://github.com/cortesi/modd\n.. _yarn: https://yarnpkg.com/en/\n.. _PEP8: https://www.python.org/dev/peps/pep-0008\n.. _`Google Style Guide`: https://google.github.io/styleguide/pyguide.html\n.. _StackOverflow: https://stackoverflow.com/questions/tagged/mitmproxy\n.. _`good first contributions`: https://github.com/mitmproxy/mitmproxy/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22\n"}, {"repo": "keon/algorithms", "language": "Python", "readme_contents": "[![PyPI version](https://badge.fury.io/py/algorithms.svg)](https://badge.fury.io/py/algorithms)\n[![Open Source Helpers](https://www.codetriage.com/keon/algorithms/badges/users.svg)](https://www.codetriage.com/keon/algorithms)\n[![Build Status](https://travis-ci.org/keon/algorithms.svg?branch=master)](https://travis-ci.org/keon/algorithms)\n[![Coverage Status](https://coveralls.io/repos/github/keon/algorithms/badge.svg?branch=master)](https://coveralls.io/github/keon/algorithms?branch=master)\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/keon/algorithms/master/docs/source/_static/logo/logotype1blue.png\"></p>\n\nPythonic Data Structures and Algorithms\n=========================================\n\nMinimal and clean example implementations of data structures and algorithms in Python 3.\n\n## Contributing\nThanks for your interest in contributing! There are many ways to contribute to this project. [Get started here](CONTRIBUTING.md)\n\n## Tests\n\n### Use unittest\nFor running all tests write down:\n\n    $ python3 -m unittest discover tests\n\nFor running some specific tests you can do this as following (Ex: sort):\n\n    $ python3 -m unittest tests.test_sort\n\n### Use pytest\nFor running all tests write down:\n\n    $ python3 -m pytest tests\n\n## Install\nIf you want to use the API algorithms in your code, it is as simple as:\n\n    $ pip3 install algorithms\n\nYou can test by creating a python file: (Ex: use `merge_sort` in `sort`)\n\n```python3\nfrom algorithms.sort import merge_sort\n\nif __name__ == \"__main__\":\n    my_list = [1, 8, 3, 5, 6]\n    my_list = merge_sort(my_list)\n    print(my_list)\n```\n\n## Uninstall\nIf you want to uninstall algorithms, it is as simple as:\n\n    $ pip3 uninstall -y algorithms\n\n## List of Implementations\n\n- [arrays](algorithms/arrays)\n    - [delete_nth](algorithms/arrays/delete_nth.py)\n    - [flatten](algorithms/arrays/flatten.py)\n    - [garage](algorithms/arrays/garage.py)\n    - [josephus_problem](algorithms/arrays/josephus.py)\n    - [limit](algorithms/arrays/limit.py)\n    - [longest_non_repeat](algorithms/arrays/longest_non_repeat.py/)\n    - [max_ones_index](algorithms/arrays/max_ones_index.py)\n    - [merge_intervals](algorithms/arrays/merge_intervals.py)\n    - [missing_ranges](algorithms/arrays/missing_ranges.py)\n    - [plus_one](algorithms/arrays/plus_one.py)\n    - [rotate](algorithms/arrays/rotate.py)\n    - [summarize_ranges](algorithms/arrays/summarize_ranges.py)\n    - [three_sum](algorithms/arrays/three_sum.py)\n    - [trimmean](algorithms/arrays/trimmean.py)\n    - [top_1](algorithms/arrays/top_1.py)\n    - [two_sum](algorithms/arrays/two_sum.py)\n    - [move_zeros](algorithms/arrays/move_zeros.py)\n    - [n_sum](algorithms/arrays/n_sum.py)\n- [backtrack](algorithms/backtrack)\n    - [general_solution.md](algorithms/backtrack/)\n    - [add_operators](algorithms/backtrack/add_operators.py)\n    - [anagram](algorithms/backtrack/anagram.py)\n    - [array_sum_combinations](algorithms/backtrack/array_sum_combinations.py)\n    - [combination_sum](algorithms/backtrack/combination_sum.py)\n    - [factor_combinations](algorithms/backtrack/factor_combinations.py)\n    - [generate_abbreviations](algorithms/backtrack/generate_abbreviations.py)\n    - [generate_parenthesis](algorithms/backtrack/generate_parenthesis.py)\n    - [letter_combination](algorithms/backtrack/letter_combination.py)\n    - [palindrome_partitioning](algorithms/backtrack/palindrome_partitioning.py)\n    - [pattern_match](algorithms/backtrack/pattern_match.py)\n    - [permute](algorithms/backtrack/permute.py)\n    - [permute_unique](algorithms/backtrack/permute_unique.py)\n    - [subsets](algorithms/backtrack/subsets.py)\n    - [subsets_unique](algorithms/backtrack/subsets_unique.py)\n- [bfs](algorithms/bfs)\n    - [maze_search](algorithms/bfs/maze_search.py)\n    - [shortest_distance_from_all_buildings](algorithms/bfs/shortest_distance_from_all_buildings.py)\n    - [word_ladder](algorithms/bfs/word_ladder.py)\n- [bit](algorithms/bit)\n    - [add_bitwise_operator](algorithms/bit/add_bitwise_operator.py)\n    - [bit_operation](algorithms/bit/bit_operation.py)\n    - [bytes_int_conversion](algorithms/bit/bytes_int_conversion.py)\n    - [count_flips_to_convert](algorithms/bit/count_flips_to_convert.py)\n    - [count_ones](algorithms/bit/count_ones.py)\n    - [find_difference](algorithms/bit/find_difference.py)\n    - [find_missing_number](algorithms/bit/find_missing_number.py)\n    - [flip_bit_longest_sequence](algorithms/bit/flip_bit_longest_sequence.py)\n    - [power_of_two](algorithms/bit/power_of_two.py)\n    - [reverse_bits](algorithms/bit/reverse_bits.py)\n    - [single_number](algorithms/bit/single_number.py)\n    - [single_number2](algorithms/bit/single_number2.py)\n    - [single_number3](algorithms/bit/single_number3.py)\n    - [subsets](algorithms/bit/subsets.py)\n    - [swap_pair](algorithms/bit/swap_pair.py)\n    - [has_alternative_bit](algorithms/bit/has_alternative_bit.py)\n    - [insert_bit](algorithms/bit/insert_bit.py)\n    - [remove_bit](algorithms/bit/remove_bit.py)\n    - [binary_gap](algorithms/bit/binary_gap.py)\n- [calculator](algorithms/calculator)\n    - [math_parser](algorithms/calculator/math_parser.py)\n- [compression](algorithms/compression)\n    - [huffman_coding](algorithms/compression/huffman_coding.py)\n    - [rle_compression](algorithms/compression/rle_compression.py)\n    - [elias](algorithms/compression/elias.py)\n- [dfs](algorithms/dfs)\n    - [all_factors](algorithms/dfs/all_factors.py)\n    - [count_islands](algorithms/dfs/count_islands.py)\n    - [pacific_atlantic](algorithms/dfs/pacific_atlantic.py)\n    - [sudoku_solver](algorithms/dfs/sudoku_solver.py)\n    - [walls_and_gates](algorithms/dfs/walls_and_gates.py)\n- [distribution](algorithms/distribution)\n    - [histogram](algorithms/distribution/histogram.py)\n- [dp](algorithms/dp)\n    - [buy_sell_stock](algorithms/dp/buy_sell_stock.py)\n    - [climbing_stairs](algorithms/dp/climbing_stairs.py)\n    - [coin_change](algorithms/dp/coin_change.py)\n    - [combination_sum](algorithms/dp/combination_sum.py)\n    - [egg_drop](algorithms/dp/egg_drop.py)\n    - [house_robber](algorithms/dp/house_robber.py)\n    - [int_divide](algorithms/dp/int_divide.py)\n    - [job_scheduling](algorithms/dp/job_scheduling.py)\n    - [knapsack](algorithms/dp/knapsack.py)\n    - [longest_increasing](algorithms/dp/longest_increasing.py)\n    - [matrix_chain_order](algorithms/dp/matrix_chain_order.py)\n    - [max_product_subarray](algorithms/dp/max_product_subarray.py)\n    - [max_subarray](algorithms/dp/max_subarray.py)\n    - [min_cost_path](algorithms/dp/min_cost_path.py)\n    - [num_decodings](algorithms/dp/num_decodings.py)\n    - [regex_matching](algorithms/dp/regex_matching.py)\n    - [rod_cut](algorithms/dp/rod_cut.py)\n    - [word_break](algorithms/dp/word_break.py)\n    - [fibonacci](algorithms/dp/fib.py)\n\t- [hosoya triangle](algorithms/dp/hosoya_triangle.py)\n- [graph](algorithms/graph)\n    - [check_bipartite](algorithms/graph/check_bipartite.py)\n    - [strongly_connected](algorithms/graph/check_digraph_strongly_connected.py)\n    - [clone_graph](algorithms/graph/clone_graph.py)\n    - [cycle_detection](algorithms/graph/cycle_detection.py)\n    - [find_all_cliques](algorithms/graph/find_all_cliques.py)\n    - [find_path](algorithms/graph/find_path.py)\n    - [graph](algorithms/graph/graph.py)\n    - [dijkstra](algorithms/graph/dijkstra.py)\n    - [markov_chain](algorithms/graph/markov_chain.py)\n    - [minimum_spanning_tree](algorithms/graph/minimum_spanning_tree.py)\n    - [satisfiability](algorithms/graph/satisfiability.py)\n    - [tarjan](algorithms/graph/tarjan.py)\n    - [traversal](algorithms/graph/traversal.py)\n    - [bellman_ford](algorithms/graph/bellman_ford.py)\n- [heap](algorithms/heap)\n    - [merge_sorted_k_lists](algorithms/heap/merge_sorted_k_lists.py)\n    - [skyline](algorithms/heap/skyline.py)\n    - [sliding_window_max](algorithms/heap/sliding_window_max.py)\n    - [binary_heap](algorithms/heap/binary_heap.py)\n- [iterables](algorithms/iterables)\n    - [convolved](algorithms/iterables/convolved.py)\n    - [k_closest_points](algorithms/heap/k_closest_points.py)\n- [linkedlist](algorithms/linkedlist)\n    - [add_two_numbers](algorithms/linkedlist/add_two_numbers.py)\n    - [copy_random_pointer](algorithms/linkedlist/copy_random_pointer.py)\n    - [delete_node](algorithms/linkedlist/delete_node.py)\n    - [first_cyclic_node](algorithms/linkedlist/first_cyclic_node.py)\n    - [is_cyclic](algorithms/linkedlist/is_cyclic.py)\n    - [is_palindrome](algorithms/linkedlist/is_palindrome.py)\n    - [kth_to_last](algorithms/linkedlist/kth_to_last.py)\n    - [linkedlist](algorithms/linkedlist/linkedlist.py)\n    - [remove_duplicates](algorithms/linkedlist/remove_duplicates.py)\n    - [reverse](algorithms/linkedlist/reverse.py)\n    - [rotate_list](algorithms/linkedlist/rotate_list.py)\n    - [swap_in_pairs](algorithms/linkedlist/swap_in_pairs.py)\n    - [is_sorted](algorithms/linkedlist/is_sorted.py)\n    - [remove_range](algorithms/linkedlist/remove_range.py)\n- [map](algorithms/map)\n    - [hashtable](algorithms/map/hashtable.py)\n    - [separate_chaining_hashtable](algorithms/map/separate_chaining_hashtable.py)\n    - [longest_common_subsequence](algorithms/map/longest_common_subsequence.py)\n    - [randomized_set](algorithms/map/randomized_set.py)\n    - [valid_sudoku](algorithms/map/valid_sudoku.py)\n    - [word_pattern](algorithms/map/word_pattern.py)\n    - [is_isomorphic](algorithms/map/is_isomorphic.py)\n    - [is_anagram](algorithms/map/is_anagram.py)    \n- [maths](algorithms/maths)\n    - [base_conversion](algorithms/maths/base_conversion.py)\n    - [combination](algorithms/maths/combination.py)\n    - [cosine_similarity](algorithms/maths/cosine_similarity.py)\n    - [decimal_to_binary_ip](algorithms/maths/decimal_to_binary_ip.py)\n    - [euler_totient](algorithms/maths/euler_totient.py)\n    - [extended_gcd](algorithms/maths/extended_gcd.py)\n    - [factorial](algorithms/maths/factorial.py)    \n    - [gcd/lcm](algorithms/maths/gcd.py)\n    - [generate_strobogrammtic](algorithms/maths/generate_strobogrammtic.py)\n    - [is_strobogrammatic](algorithms/maths/is_strobogrammatic.py)\n    - [modular_exponential](algorithms/maths/modular_exponential.py)\n    - [next_bigger](algorithms/maths/next_bigger.py)\n    - [next_perfect_square](algorithms/maths/next_perfect_square.py)\n    - [nth_digit](algorithms/maths/nth_digit.py)\n    - [prime_check](algorithms/maths/prime_check.py)\n    - [primes_sieve_of_eratosthenes](algorithms/maths/primes_sieve_of_eratosthenes.py)\n    - [pythagoras](algorithms/maths/pythagoras.py)\n    - [rabin_miller](algorithms/maths/rabin_miller.py)\n    - [rsa](algorithms/maths/rsa.py)\n    - [sqrt_precision_factor](algorithms/maths/sqrt_precision_factor.py)\n    - [summing_digits](algorithms/maths/summing_digits.py)\n    - [hailstone](algorithms/maths/hailstone.py)\n\t  - [find_order](algorithms/maths/find_order_simple.py)\n\t  - [find_primitive_root](algorithms/maths/find_primitive_root_simple.py)\n- [matrix](algorithms/matrix)\n    - [sudoku_validator](algorithms/matrix/sudoku_validator.py)\n    - [bomb_enemy](algorithms/matrix/bomb_enemy.py)\n    - [copy_transform](algorithms/matrix/copy_transform.py)\n    - [count_paths](algorithms/matrix/count_paths.py)\n    - [matrix_rotation.txt](algorithms/matrix/matrix_rotation.txt)\n    - [matrix_multiplication](algorithms/matrix/multiply.py)\n    - [rotate_image](algorithms/matrix/rotate_image.py)\n    - [search_in_sorted_matrix](algorithms/matrix/search_in_sorted_matrix.py)\n    - [sparse_dot_vector](algorithms/matrix/sparse_dot_vector.py)\n    - [sparse_mul](algorithms/matrix/sparse_mul.py)\n    - [spiral_traversal](algorithms/matrix/spiral_traversal.py)\n\t- [crout_matrix_decomposition](algorithms/matrix/crout_matrix_decomposition.py)\n\t- [cholesky_matrix_decomposition](algorithms/matrix/cholesky_matrix_decomposition.py)\n- [queues](algorithms/queues)\n    - [max_sliding_window](algorithms/queues/max_sliding_window.py)\n    - [moving_average](algorithms/queues/moving_average.py)\n    - [queue](algorithms/queues/queue.py)\n    - [reconstruct_queue](algorithms/queues/reconstruct_queue.py)\n    - [zigzagiterator](algorithms/queues/zigzagiterator.py)\n- [search](algorithms/search)\n    - [binary_search](algorithms/search/binary_search.py)\n    - [first_occurrence](algorithms/search/first_occurrence.py)\n    - [last_occurrence](algorithms/search/last_occurrence.py)\n    - [linear_search](algorithms/search/linear_search.py)\n    - [search_insert](algorithms/search/search_insert.py)\n    - [two_sum](algorithms/search/two_sum.py)\n    - [search_range](algorithms/search/search_range.py)\n    - [find_min_rotate](algorithms/search/find_min_rotate.py)\n    - [search_rotate](algorithms/search/search_rotate.py)\n    - [jump_search](algorithms/search/jump_search.py)\n    - [next_greatest_letter](algorithms/search/next_greatest_letter.py)\n- [set](algorithms/set)\n    - [randomized_set](algorithms/set/randomized_set.py)\n    - [set_covering](algorithms/set/set_covering.py)\n    - [find_keyboard_row](algorithms/set/find_keyboard_row.py)\n- [sort](algorithms/sort)\n    - [bitonic_sort](algorithms/sort/bitonic_sort.py)\n    - [bogo_sort](algorithms/sort/bogo_sort.py)\n    - [bubble_sort](algorithms/sort/bubble_sort.py)\n    - [bucket_sort](algorithms/sort/bucket_sort.py)\n    - [cocktail_shaker_sort](algorithms/sort/cocktail_shaker_sort.py)\n    - [comb_sort](algorithms/sort/comb_sort.py)\n    - [counting_sort](algorithms/sort/counting_sort.py)\n    - [cycle_sort](algorithms/sort/cycle_sort.py)\n    - [gnome_sort](algorithms/sort/gnome_sort.py)\n    - [heap_sort](algorithms/sort/heap_sort.py)\n    - [insertion_sort](algorithms/sort/insertion_sort.py)\n    - [meeting_rooms](algorithms/sort/meeting_rooms.py)\n    - [merge_sort](algorithms/sort/merge_sort.py)\n    - [pancake_sort](algorithms/sort/pancake_sort.py)\n    - [quick_sort](algorithms/sort/quick_sort.py)\n    - [radix_sort](algorithms/sort/radix_sort.py)\n    - [selection_sort](algorithms/sort/selection_sort.py)\n    - [shell_sort](algorithms/sort/shell_sort.py)\n    - [sort_colors](algorithms/sort/sort_colors.py)\n    - [top_sort](algorithms/sort/top_sort.py)\n    - [wiggle_sort](algorithms/sort/wiggle_sort.py)\n- [stack](algorithms/stack)\n    - [longest_abs_path](algorithms/stack/longest_abs_path.py)\n    - [simplify_path](algorithms/stack/simplify_path.py)\n    - [stack](algorithms/stack/stack.py)\n    - [valid_parenthesis](algorithms/stack/valid_parenthesis.py)\n    - [stutter](algorithms/stack/stutter.py)\n    - [switch_pairs](algorithms/stack/switch_pairs.py)\n    - [is_consecutive](algorithms/stack/is_consecutive.py)\n    - [remove_min](algorithms/stack/remove_min.py)\n    - [is_sorted](algorithms/stack/is_sorted.py)\n- [strings](algorithms/strings)\n    - [fizzbuzz](algorithms/strings/fizzbuzz.py)\n    - [delete_reoccurring](algorithms/strings/delete_reoccurring.py)\n    - [strip_url_params](algorithms/strings/strip_url_params.py)\n    - [validate_coordinates](algorithms/strings/validate_coordinates.py)\n    - [domain_extractor](algorithms/strings/domain_extractor.py)\n    - [merge_string_checker](algorithms/strings/merge_string_checker.py)\n    - [add_binary](algorithms/strings/add_binary.py)\n    - [breaking_bad](algorithms/strings/breaking_bad.py)\n    - [decode_string](algorithms/strings/decode_string.py)\n    - [encode_decode](algorithms/strings/encode_decode.py)\n    - [group_anagrams](algorithms/strings/group_anagrams.py)\n    - [int_to_roman](algorithms/strings/int_to_roman.py)\n    - [is_palindrome](algorithms/strings/is_palindrome.py)\n    - [license_number](algorithms/strings/license_number.py)\n    - [make_sentence](algorithms/strings/make_sentence.py)\n    - [multiply_strings](algorithms/strings/multiply_strings.py)\n    - [one_edit_distance](algorithms/strings/one_edit_distance.py)\n    - [rabin_karp](algorithms/strings/rabin_karp.py)\n    - [reverse_string](algorithms/strings/reverse_string.py)\n    - [reverse_vowel](algorithms/strings/reverse_vowel.py)\n    - [reverse_words](algorithms/strings/reverse_words.py)\n    - [roman_to_int](algorithms/strings/roman_to_int.py)\n    - [word_squares](algorithms/strings/word_squares.py)\n    - [unique_morse](algorithms/strings/unique_morse.py)\n    - [judge_circle](algorithms/strings/judge_circle.py)\n    - [strong_password](algorithms/strings/strong_password.py)\n    - [caesar_cipher](algorithms/strings/caesar_cipher.py)\n    - [contain_string](algorithms/strings/contain_string.py)\n    - [count_binary_substring](algorithms/strings/count_binary_substring.py)\n    - [repeat_string](algorithms/strings/repeat_string.py)\n    - [min_distance](algorithms/strings/min_distance.py)\n    - [longest_common_prefix](algorithms/strings/longest_common_prefix.py)\n    - [rotate](algorithms/strings/rotate.py)\n    - [first_unique_char](algorithms/strings/first_unique_char.py)\n    - [repeat_substring](algorithms/strings/repeat_substring.py)     \n\t- [atbash_cipher](algorithms/strings/atbash_cipher.py)\n- [tree](algorithms/tree)\n    - [bst](algorithms/tree/bst)\n        - [array_to_bst](algorithms/tree/bst/array_to_bst.py)\n        - [bst_closest_value](algorithms/tree/bst/bst_closest_value.py)\n        - [BSTIterator](algorithms/tree/bst/BSTIterator.py)\n        - [delete_node](algorithms/tree/bst/delete_node.py)\n        - [is_bst](algorithms/tree/bst/is_bst.py)\n        - [kth_smallest](algorithms/tree/bst/kth_smallest.py)\n        - [lowest_common_ancestor](algorithms/tree/bst/lowest_common_ancestor.py)\n        - [predecessor](algorithms/tree/bst/predecessor.py)\n        - [serialize_deserialize](algorithms/tree/bst/serialize_deserialize.py)\n        - [successor](algorithms/tree/bst/successor.py)\n        - [unique_bst](algorithms/tree/bst/unique_bst.py)\n        - [depth_sum](algorithms/tree/bst/depth_sum.py)\n        - [count_left_node](algorithms/tree/bst/count_left_node.py)\n        - [num_empty](algorithms/tree/bst/num_empty.py)\n        - [height](algorithms/tree/bst/height.py)\n    - [red_black_tree](algorithms/tree/red_black_tree)\n        - [red_black_tree](algorithms/tree/red_black_tree/red_black_tree.py)\n    - [segment_tree](algorithms/tree/segment_tree)\n        - [segment_tree](algorithms/tree/segment_tree/segment_tree.py)\n        - [iterative_segment_tree](algorithms/tree/segment_tree/iterative_segment_tree.py)\n    - [traversal](algorithms/tree/traversal)\n        - [inorder](algorithms/tree/traversal/inorder.py)\n        - [level_order](algorithms/tree/traversal/level_order.py)\n        - [postorder](algorithms/tree/traversal/postorder.py)\n        - [preorder](algorithms/tree/traversal/preorder.py)\n        - [zigzag](algorithms/tree/traversal/zigzag.py)\n    - [trie](algorithms/tree/trie)\n        - [add_and_search](algorithms/tree/trie/add_and_search.py)\n        - [trie](algorithms/tree/trie/trie.py)\n    - [b_tree](algorithms/tree/b_tree.py)\n    - [binary_tree_paths](algorithms/tree/binary_tree_paths.py)\n    - [bin_tree_to_list](algorithms/tree/bin_tree_to_list.py)\n    - [deepest_left](algorithms/tree/deepest_left.py)\n    - [invert_tree](algorithms/tree/invert_tree.py)\n    - [is_balanced](algorithms/tree/is_balanced.py)\n    - [is_subtree](algorithms/tree/is_subtree.py)\n    - [is_symmetric](algorithms/tree/is_symmetric.py)\n    - [longest_consecutive](algorithms/tree/longest_consecutive.py)\n    - [lowest_common_ancestor](algorithms/tree/lowest_common_ancestor.py)\n    - [max_height](algorithms/tree/max_height.py)\n    - [max_path_sum](algorithms/tree/max_path_sum.py)\n    - [min_height](algorithms/tree/min_height.py)\n    - [path_sum](algorithms/tree/path_sum.py)\n    - [path_sum2](algorithms/tree/path_sum2.py)\n    - [pretty_print](algorithms/tree/pretty_print.py)\n    - [same_tree](algorithms/tree/same_tree.py)\n    - [tree](algorithms/tree/tree.py)\n- [unix](algorithms/unix)\n    - [path](algorithms/unix/path/)\n        - [join_with_slash](algorithms/unix/path/join_with_slash.py)\n        - [full_path](algorithms/unix/path/full_path.py)\n        - [split](algorithms/unix/path/split.py)\n        - [simplify_path](algorithms/unix/path/simplify_path.py)\n- [union-find](algorithms/union-find)\n    - [count_islands](algorithms/union-find/count_islands.py)\n\n\n## Contributors\n\nThanks to [all the contributors](https://github.com/keon/algorithms/graphs/contributors)\nwho helped in building the repo.\n"}, {"repo": "satwikkansal/wtfpython", "language": "Python", "readme_contents": "<p align=\"center\"><img src=\"/images/logo.png\" alt=\"\"></p>\n<h1 align=\"center\">What the f*ck Python! \ud83d\udc0d</h1>\n<p align=\"center\">An interesting collection of surprising snippets and lesser-known Python features.</p>\n\n[![WTFPL 2.0][license-image]][license-url]\n\nTranslations: [Chinese \u4e2d\u6587](https://github.com/leisurelicht/wtfpython-cn)\n\nPython, being a beautifully designed high-level and interpreter-based programming language, provides us with many features for the programmer's comfort. But sometimes, the outcomes of a Python snippet may not seem obvious to a regular user at first sight.\n\nHere is a fun project to collect such tricky & counter-intuitive examples and lesser-known features in Python, attempting to discuss what exactly is happening under the hood!\n\nWhile some of the examples you see below may not be WTFs in the truest sense, but they'll reveal some of the interesting parts of Python that you might be unaware of. I find it a nice way to learn the internals of a programming language, and I think you'll find them interesting as well!\n\nIf you're an experienced Python programmer, you can take it as a challenge to get most of them right in first attempt. You may be already familiar with some of these examples, and I might be able to revive sweet old memories of yours being bitten by these gotchas :sweat_smile:\n\nPS: If you're a returning reader, you can learn about the new modifications [here](https://github.com/satwikkansal/wtfpython/releases/).\n\nSo, here we go...\n\n# Table of Contents\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n\n\n- [Structure of the Examples](#structure-of-the-examples)\n- [Usage](#usage)\n- [\ud83d\udc40 Examples](#-examples)\n  - [Section: Strain your brain!](#section-strain-your-brain)\n    - [\u25b6 Strings can be tricky sometimes *](#-strings-can-be-tricky-sometimes-)\n    - [\u25b6 Time for some hash brownies!](#-time-for-some-hash-brownies)\n    - [\u25b6 Return return everywhere!](#-return-return-everywhere)\n    - [\u25b6 Deep down, we're all the same. *](#-deep-down-were-all-the-same-)\n    - [\u25b6 For what?](#-for-what)\n    - [\u25b6 Evaluation time discrepancy](#-evaluation-time-discrepancy)\n    - [\u25b6 `is` is not what it is!](#-is-is-not-what-it-is)\n    - [\u25b6 A tic-tac-toe where X wins in the first attempt!](#-a-tic-tac-toe-where-x-wins-in-the-first-attempt)\n    - [\u25b6 The sticky output function](#-the-sticky-output-function)\n    - [\u25b6 `is not ...` is not `is (not ...)`](#-is-not--is-not-is-not-)\n    - [\u25b6 The surprising comma](#-the-surprising-comma)\n    - [\u25b6 Backslashes at the end of string](#-backslashes-at-the-end-of-string)\n    - [\u25b6 not knot!](#-not-knot)\n    - [\u25b6 Half triple-quoted strings](#-half-triple-quoted-strings)\n    - [\u25b6 Midnight time doesn't exist?](#-midnight-time-doesnt-exist)\n    - [\u25b6 What's wrong with booleans?](#-whats-wrong-with-booleans)\n    - [\u25b6 Class attributes and instance attributes](#-class-attributes-and-instance-attributes)\n    - [\u25b6 yielding None](#-yielding-none)\n    - [\u25b6 Mutating the immutable!](#-mutating-the-immutable)\n    - [\u25b6 The disappearing variable from outer scope](#-the-disappearing-variable-from-outer-scope)\n    - [\u25b6 When True is actually False](#-when-true-is-actually-false)\n    - [\u25b6 From filled to None in one instruction...](#-from-filled-to-none-in-one-instruction)\n    - [\u25b6 Subclass relationships *](#-subclass-relationships-)\n    - [\u25b6 The mysterious key type conversion *](#-the-mysterious-key-type-conversion-)\n    - [\u25b6 Let's see if you can guess this?](#-lets-see-if-you-can-guess-this)\n  - [Section: Appearances are deceptive!](#section-appearances-are-deceptive)\n    - [\u25b6 Skipping lines?](#-skipping-lines)\n    - [\u25b6 Teleportation *](#-teleportation-)\n    - [\u25b6 Well, something is fishy...](#-well-something-is-fishy)\n  - [Section: Watch out for the landmines!](#section-watch-out-for-the-landmines)\n    - [\u25b6 Modifying a dictionary while iterating over it](#-modifying-a-dictionary-while-iterating-over-it)\n    - [\u25b6 Stubborn `del` operator *](#-stubborn-del-operator-)\n    - [\u25b6 Deleting a list item while iterating](#-deleting-a-list-item-while-iterating)\n    - [\u25b6 Loop variables leaking out!](#-loop-variables-leaking-out)\n    - [\u25b6 Beware of default mutable arguments!](#-beware-of-default-mutable-arguments)\n    - [\u25b6 Catching the Exceptions](#-catching-the-exceptions)\n    - [\u25b6 Same operands, different story!](#-same-operands-different-story)\n    - [\u25b6 The out of scope variable](#-the-out-of-scope-variable)\n    - [\u25b6 Be careful with chained operations](#-be-careful-with-chained-operations)\n    - [\u25b6 Name resolution ignoring class scope](#-name-resolution-ignoring-class-scope)\n    - [\u25b6 Needle in a Haystack](#-needle-in-a-haystack)\n    - [\u25b6 Yielding from... return!](#-yielding-from-return)\n  - [Section: The Hidden treasures!](#section-the-hidden-treasures)\n    - [\u25b6 Okay Python, Can you make me fly? *](#-okay-python-can-you-make-me-fly-)\n    - [\u25b6 `goto`, but why? *](#-goto-but-why-)\n    - [\u25b6 Brace yourself! *](#-brace-yourself-)\n    - [\u25b6 Let's meet Friendly Language Uncle For Life *](#-lets-meet-friendly-language-uncle-for-life-)\n    - [\u25b6 Even Python understands that love is complicated *](#-even-python-understands-that-love-is-complicated-)\n    - [\u25b6 Yes, it exists!](#-yes-it-exists)\n    - [\u25b6 Inpinity *](#-inpinity-)\n    - [\u25b6 Mangling time! *](#-mangling-time-)\n  - [Section: Miscellaneous](#section-miscellaneous)\n    - [\u25b6 `+=` is faster](#--is-faster)\n    - [\u25b6 Let's make a giant string!](#-lets-make-a-giant-string)\n    - [\u25b6 Explicit typecast of strings](#-explicit-typecast-of-strings)\n    - [\u25b6 Minor Ones](#-minor-ones)\n- [Contributing](#contributing)\n- [Acknowledgements](#acknowledgements)\n- [\ud83c\udf93 License](#-license)\n  - [Help](#help)\n  - [Want to share wtfpython with friends?](#want-to-share-wtfpython-with-friends)\n  - [Need a pdf version?](#need-a-pdf-version)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n# Structure of the Examples\n\nAll the examples are structured like below:\n\n> ### \u25b6 Some fancy Title *\n> The asterisk at the end of the title indicates the example was not present in the first release and has been recently added.\n>\n> ```py\n> # Setting up the code.\n> # Preparation for the magic...\n> ```\n>\n> **Output (Python version):**\n> ```py\n> >>> triggering_statement\n> Probably unexpected output\n> ```\n> (Optional): One line describing the unexpected output.\n>\n>\n> #### \ud83d\udca1 Explanation:\n>\n> * Brief explanation of what's happening and why is it happening.\n>   ```py\n>   Setting up examples for clarification (if necessary)\n>   ```\n>   **Output:**\n>   ```py\n>   >>> trigger # some example that makes it easy to unveil the magic\n>   # some justified output\n>   ```\n\n**Note:** All the examples are tested on Python 3.5.2 interactive interpreter, and they should work for all the Python versions unless explicitly specified in the description.\n\n# Usage\n\nA nice way to get the most out of these examples, in my opinion, will be just to read the examples chronologically, and for every example:\n- Carefully read the initial code for setting up the example. If you're an experienced Python programmer, most of the times you will successfully anticipate what's going to happen next.\n- Read the output snippets and,\n  + Check if the outputs are the same as you'd expect.\n  + Make sure if you know the exact reason behind the output being the way it is.\n    - If no, take a deep breath, and read the explanation (and if you still don't understand, shout out! and create an issue [here](https://github.com/satwikkansal/wtfPython)).\n    - If yes, give a gentle pat on your back, and you may skip to the next example.\n\nPS: You can also read WTFpython at the command line. There's a pypi package and an npm package (supports colored formatting) for the same.\n\nTo install the npm package [`wtfpython`](https://www.npmjs.com/package/wtfpython)\n```sh\n$ npm install -g wtfpython\n```\n\nAlternatively, to install the pypi package [`wtfpython`](https://pypi.python.org/pypi/wtfpython)\n```sh\n$ pip install wtfpython -U\n```\n\nNow, just run `wtfpython` at the command line which will open this collection in your selected `$PAGER`.\n\n---\n\n# \ud83d\udc40 Examples\n\n\n## Section: Strain your brain!\n\n### \u25b6 Strings can be tricky sometimes *\n\n1\\.\n```py\n>>> a = \"some_string\"\n>>> id(a)\n140420665652016\n>>> id(\"some\" + \"_\" + \"string\") # Notice that both the ids are same.\n140420665652016\n```\n\n2\\.\n```py\n>>> a = \"wtf\"\n>>> b = \"wtf\"\n>>> a is b\nTrue\n\n>>> a = \"wtf!\"\n>>> b = \"wtf!\"\n>>> a is b\nFalse\n\n>>> a, b = \"wtf!\", \"wtf!\"\n>>> a is b\nTrue\n```\n\n3\\.\n```py\n>>> 'a' * 20 is 'aaaaaaaaaaaaaaaaaaaa'\nTrue\n>>> 'a' * 21 is 'aaaaaaaaaaaaaaaaaaaaa'\nFalse\n```\n\nMakes sense, right?\n\n#### \ud83d\udca1 Explanation:\n+ Such behavior is due to CPython optimization (called string interning) that tries to use existing immutable objects in some cases rather than creating a new object every time.\n+ After being interned, many variables may point to the same string object in memory (thereby saving memory).\n+ In the snippets above, strings are implicitly interned. The decision of when to implicitly intern a string is implementation dependent. There are some facts that can be used to guess if a string will be interned or not:\n  * All length 0 and length 1 strings are interned.\n  * Strings are interned at compile time (`'wtf'` will be interned but `''.join(['w', 't', 'f']` will not be interned)\n  * Strings that are not composed of ASCII letters, digits or underscores, are not interned. This explains why `'wtf!'` was not interned due to `!`. Cpython implementation of this rule can be found [here](https://github.com/python/cpython/blob/3.6/Objects/codeobject.c#L19)\n  <img src=\"/images/string-intern/string_intern.png\" alt=\"\">\n+ When `a` and `b` are set to `\"wtf!\"` in the same line, the Python interpreter creates a new object, then references the second variable at the same time. If you do it on separate lines, it doesn't \"know\" that there's already `wtf!` as an object (because `\"wtf!\"` is not implicitly interned as per the facts mentioned above). It's a compiler optimization and specifically applies to the interactive environment.\n+ Constant folding is a technique for [peephole optimization](https://en.wikipedia.org/wiki/Peephole_optimization) in Python. This means the expression `'a'*20` is replaced by `'aaaaaaaaaaaaaaaaaaaa'` during compilation to reduce few clock cycles during runtime. Constant folding only occurs for strings having length less than or equal to 20. (Why? Imagine the size of `.pyc` file generated as a result of the expression `'a'*10**10`). [Here's](https://github.com/python/cpython/blob/3.6/Python/peephole.c#L288) the implementation source for the same.\n\n\n---\n\n### \u25b6 Time for some hash brownies!\n\n1\\.\n```py\nsome_dict = {}\nsome_dict[5.5] = \"Ruby\"\nsome_dict[5.0] = \"JavaScript\"\nsome_dict[5] = \"Python\"\n```\n\n**Output:**\n```py\n>>> some_dict[5.5]\n\"Ruby\"\n>>> some_dict[5.0]\n\"Python\"\n>>> some_dict[5]\n\"Python\"\n```\n\n\"Python\" destroyed the existence of \"JavaScript\"?\n\n#### \ud83d\udca1 Explanation\n\n* Python dictionaries check for equality and compare the hash value to determine if two keys are the same.\n* Immutable objects with same value always have the same hash in Python.\n  ```py\n  >>> 5 == 5.0\n  True\n  >>> hash(5) == hash(5.0)\n  True\n  ```\n  **Note:** Objects with different values may also have same hash (known as hash collision).\n* When the statement `some_dict[5] = \"Python\"` is executed, the existing value \"JavaScript\" is overwritten with \"Python\" because Python recognizes `5` and `5.0` as the same keys of the dictionary `some_dict`.\n* This StackOverflow [answer](https://stackoverflow.com/a/32211042/4354153) explains beautifully the rationale behind it.\n\n---\n\n### \u25b6 Return return everywhere!\n\n```py\ndef some_func():\n    try:\n        return 'from_try'\n    finally:\n        return 'from_finally'\n```\n\n**Output:**\n```py\n>>> some_func()\n'from_finally'\n```\n\n#### \ud83d\udca1 Explanation:\n\n- When a `return`, `break` or `continue` statement is executed in the `try` suite of a \"try\u2026finally\" statement, the `finally` clause is also executed \u2018on the way out.\n- The return value of a function is determined by the last `return` statement executed. Since the `finally` clause always executes, a `return` statement executed in the `finally` clause will always be the last one executed.\n\n---\n\n### \u25b6 Deep down, we're all the same. *\n\n```py\nclass WTF:\n  pass\n```\n\n**Output:**\n```py\n>>> WTF() == WTF() # two different instances can't be equal\nFalse\n>>> WTF() is WTF() # identities are also different\nFalse\n>>> hash(WTF()) == hash(WTF()) # hashes _should_ be different as well\nTrue\n>>> id(WTF()) == id(WTF())\nTrue\n```\n\n#### \ud83d\udca1 Explanation:\n\n* When `id` was called, Python created a `WTF` class object and passed it to the `id` function. The `id` function takes its `id` (its memory location), and throws away the object. The object is destroyed.\n* When we do this twice in succession, Python allocates the same memory location to this second object as well. Since (in CPython) `id` uses the memory location as the object id, the id of the two objects is the same.\n* So, object's id is unique only for the lifetime of the object. After the object is destroyed, or before it is created, something else can have the same id.\n* But why did the `is` operator evaluated to `False`? Let's see with this snippet.\n  ```py\n  class WTF(object):\n    def __init__(self): print(\"I\")\n    def __del__(self): print(\"D\")\n  ```\n\n  **Output:**\n  ```py\n  >>> WTF() is WTF()\n  I\n  I\n  D\n  D\n  False\n  >>> id(WTF()) == id(WTF())\n  I\n  D\n  I\n  D\n  True\n  ```\n  As you may observe, the order in which the objects are destroyed is what made all the difference here.\n\n---\n\n### \u25b6 For what?\n\n```py\nsome_string = \"wtf\"\nsome_dict = {}\nfor i, some_dict[i] in enumerate(some_string):\n    pass\n```\n\n**Output:**\n```py\n>>> some_dict # An indexed dict is created.\n{0: 'w', 1: 't', 2: 'f'}\n```\n\n####  \ud83d\udca1 Explanation:\n\n* A `for` statement is defined in the [Python grammar](https://docs.python.org/3/reference/grammar.html) as:\n  ```\n  for_stmt: 'for' exprlist 'in' testlist ':' suite ['else' ':' suite]\n  ```\n  Where `exprlist` is the assignment target. This means that the equivalent of `{exprlist} = {next_value}` is **executed for each item** in the iterable.\n  An interesting example that illustrates this:\n  ```py\n  for i in range(4):\n      print(i)\n      i = 10\n  ```\n\n  **Output:**\n  ```\n  0\n  1\n  2\n  3\n  ```\n\n  Did you expect the loop to run just once?\n\n  **\ud83d\udca1 Explanation:**\n\n  - The assignment statement `i = 10` never affects the iterations of the loop because of the way for loops work in Python. Before the beginning of every iteration, the next item provided by the iterator (`range(4)` this case) is unpacked and assigned the target list variables (`i` in this case).\n\n* The `enumerate(some_string)` function yields a new value `i` (A counter going up) and a character from the `some_string` in each iteration. It then sets the (just assigned) `i` key of the dictionary `some_dict` to that character. The unrolling of the loop can be simplified as:\n  ```py\n  >>> i, some_dict[i] = (0, 'w')\n  >>> i, some_dict[i] = (1, 't')\n  >>> i, some_dict[i] = (2, 'f')\n  >>> some_dict\n  ```\n\n---\n\n### \u25b6 Evaluation time discrepancy\n\n1\\.\n```py\narray = [1, 8, 15]\ng = (x for x in array if array.count(x) > 0)\narray = [2, 8, 22]\n```\n\n**Output:**\n```py\n>>> print(list(g))\n[8]\n```\n\n2\\.\n\n```py\narray_1 = [1,2,3,4]\ng1 = (x for x in array_1)\narray_1 = [1,2,3,4,5]\n\narray_2 = [1,2,3,4]\ng2 = (x for x in array_2)\narray_2[:] = [1,2,3,4,5]\n```\n\n**Output:**\n```py\n>>> print(list(g1))\n[1,2,3,4]\n\n>>> print(list(g2))\n[1,2,3,4,5]\n```\n\n#### \ud83d\udca1 Explanation\n\n- In a [generator](https://wiki.python.org/moin/Generators) expression, the `in` clause is evaluated at declaration time, but the conditional clause is evaluated at runtime.\n- So before runtime, `array` is re-assigned to the list `[2, 8, 22]`, and since out of `1`, `8` and `15`, only the count of `8` is greater than `0`, the generator only yields `8`.\n- The differences in the output of `g1` and `g2` in the second part is due the way variables `array_1` and `array_2` are re-assigned values.\n- In the first case, `array_1` is binded to the new object `[1,2,3,4,5]` and since the `in` clause is evaluated at the declaration time it still refers to the old object `[1,2,3,4]` (which is not destroyed).\n- In the second case, the slice assignment to `array_2` updates the same old object `[1,2,3,4]` to `[1,2,3,4,5]`. Hence both the `g2` and `array_2` still have reference to the same object (which has now been updated to `[1,2,3,4,5]`).\n\n---\n\n### \u25b6 `is` is not what it is!\n\nThe following is a very famous example present all over the internet.\n\n```py\n>>> a = 256\n>>> b = 256\n>>> a is b\nTrue\n\n>>> a = 257\n>>> b = 257\n>>> a is b\nFalse\n\n>>> a = 257; b = 257\n>>> a is b\nTrue\n```\n\n#### \ud83d\udca1 Explanation:\n\n**The difference between `is` and `==`**\n\n* `is` operator checks if both the operands refer to the same object (i.e., it checks if the identity of the operands matches or not).\n* `==` operator compares the values of both the operands and checks if they are the same.\n* So `is` is for reference equality and `==` is for value equality. An example to clear things up,\n  ```py\n  >>> [] == []\n  True\n  >>> [] is [] # These are two empty lists at two different memory locations.\n  False\n  ```\n\n**`256` is an existing object but `257` isn't**\n\nWhen you start up python the numbers from `-5` to `256` will be allocated. These numbers are used a lot, so it makes sense just to have them ready.\n\nQuoting from https://docs.python.org/3/c-api/long.html\n> The current implementation keeps an array of integer objects for all integers between -5 and 256, when you create an int in that range you just get back a reference to the existing object. So it should be possible to change the value of 1. I suspect the behavior of Python, in this case, is undefined. :-)\n\n```py\n>>> id(256)\n10922528\n>>> a = 256\n>>> b = 256\n>>> id(a)\n10922528\n>>> id(b)\n10922528\n>>> id(257)\n140084850247312\n>>> x = 257\n>>> y = 257\n>>> id(x)\n140084850247440\n>>> id(y)\n140084850247344\n```\n\nHere the interpreter isn't smart enough while executing `y = 257` to recognize that we've already created an integer of the value `257,` and so it goes on to create another object in the memory.\n\n**Both `a` and `b` refer to the same object when initialized with same value in the same line.**\n\n```py\n>>> a, b = 257, 257\n>>> id(a)\n140640774013296\n>>> id(b)\n140640774013296\n>>> a = 257\n>>> b = 257\n>>> id(a)\n140640774013392\n>>> id(b)\n140640774013488\n```\n\n* When a and b are set to `257` in the same line, the Python interpreter creates a new object, then references the second variable at the same time. If you do it on separate lines, it doesn't \"know\" that there's already `257` as an object.\n* It's a compiler optimization and specifically applies to the interactive environment. When you enter two lines in a live interpreter, they're compiled separately, therefore optimized separately. If you were to try this example in a `.py` file, you would not see the same behavior, because the file is compiled all at once.\n\n---\n\n### \u25b6 A tic-tac-toe where X wins in the first attempt!\n\n```py\n# Let's initialize a row\nrow = [\"\"]*3 #row i['', '', '']\n# Let's make a board\nboard = [row]*3\n```\n\n**Output:**\n```py\n>>> board\n[['', '', ''], ['', '', ''], ['', '', '']]\n>>> board[0]\n['', '', '']\n>>> board[0][0]\n''\n>>> board[0][0] = \"X\"\n>>> board\n[['X', '', ''], ['X', '', ''], ['X', '', '']]\n```\n\nWe didn't assign 3 \"X\"s or did we?\n\n#### \ud83d\udca1 Explanation:\n\nWhen we initialize `row` variable, this visualization explains what happens in the memory\n\n![image](/images/tic-tac-toe/after_row_initialized.png)\n\nAnd when the `board` is initialized by multiplying the `row`, this is what happens inside the memory (each of the elements `board[0]`, `board[1]` and `board[2]` is a reference to the same list referred by `row`)\n\n![image](/images/tic-tac-toe/after_board_initialized.png)\n\nWe can avoid this scenario here by not using `row` variable to generate `board`. (Asked in [this](https://github.com/satwikkansal/wtfpython/issues/68) issue).\n\n```py\n>>> board = [['']*3 for _ in range(3)]\n>>> board[0][0] = \"X\"\n>>> board\n[['X', '', ''], ['', '', ''], ['', '', '']]\n```\n\n---\n\n### \u25b6 The sticky output function\n\n```py\nfuncs = []\nresults = []\nfor x in range(7):\n    def some_func():\n        return x\n    funcs.append(some_func)\n    results.append(some_func())  # note the function call here\n\nfuncs_results = [func() for func in funcs]\n```\n\n**Output:**\n```py\n>>> results\n[0, 1, 2, 3, 4, 5, 6]\n>>> funcs_results\n[6, 6, 6, 6, 6, 6, 6]\n```\nEven when the values of `x` were different in every iteration prior to appending `some_func` to `funcs`, all the functions return 6.\n\n//OR\n\n```py\n>>> powers_of_x = [lambda x: x**i for i in range(10)]\n>>> [f(2) for f in powers_of_x]\n[512, 512, 512, 512, 512, 512, 512, 512, 512, 512]\n```\n\n#### \ud83d\udca1 Explanation\n\n- When defining a function inside a loop that uses the loop variable in its body, the loop function's closure is bound to the variable, not its value. So all of the functions use the latest value assigned to the variable for computation.\n\n- To get the desired behavior you can pass in the loop variable as a named variable to the function. **Why this works?** Because this will define the variable again within the function's scope.\n\n    ```py\n    funcs = []\n    for x in range(7):\n        def some_func(x=x):\n            return x\n        funcs.append(some_func)\n    ```\n\n    **Output:**\n    ```py\n    >>> funcs_results = [func() for func in funcs]\n    >>> funcs_results\n    [0, 1, 2, 3, 4, 5, 6]\n    ```\n\n---\n\n### \u25b6 `is not ...` is not `is (not ...)`\n\n```py\n>>> 'something' is not None\nTrue\n>>> 'something' is (not None)\nFalse\n```\n\n#### \ud83d\udca1 Explanation\n\n- `is not` is a single binary operator, and has behavior different than using `is` and `not` separated.\n- `is not` evaluates to `False` if the variables on either side of the operator point to the same object and `True` otherwise.\n\n---\n\n### \u25b6 The surprising comma\n\n**Output:**\n```py\n>>> def f(x, y,):\n...     print(x, y)\n...\n>>> def g(x=4, y=5,):\n...     print(x, y)\n...\n>>> def h(x, **kwargs,):\n  File \"<stdin>\", line 1\n    def h(x, **kwargs,):\n                     ^\nSyntaxError: invalid syntax\n>>> def h(*args,):\n  File \"<stdin>\", line 1\n    def h(*args,):\n                ^\nSyntaxError: invalid syntax\n```\n\n#### \ud83d\udca1 Explanation:\n\n- Trailing comma is not always legal in formal parameters list of a Python function.\n-  In Python, the argument list is defined partially with leading commas and partially with trailing commas. This conflict causes situations where a comma is trapped in the middle, and no rule accepts it.\n-  **Note:** The trailing comma problem is [fixed in Python 3.6](https://bugs.python.org/issue9232). The remarks in [this](https://bugs.python.org/issue9232#msg248399) post discuss in brief different usages of trailing commas in Python.\n\n---\n\n### \u25b6 Backslashes at the end of string\n\n**Output:**\n```\n>>> print(\"\\\\ C:\\\\\")\n\\ C:\\\n>>> print(r\"\\ C:\")\n\\ C:\n>>> print(r\"\\ C:\\\")\n\n    File \"<stdin>\", line 1\n      print(r\"\\ C:\\\")\n                     ^\nSyntaxError: EOL while scanning string literal\n```\n\n#### \ud83d\udca1 Explanation\n\n- In a raw string literal, as indicated by the prefix `r`, the backslash doesn't have the special meaning.\n  ```py\n  >>> print(repr(r\"wt\\\"f\"))\n  'wt\\\\\"f'\n  ```\n- What the interpreter actually does, though, is simply change the behavior of backslashes, so they pass themselves and the following character through. That's why backslashes don't work at the end of a raw string.\n\n---\n\n### \u25b6 not knot!\n\n```py\nx = True\ny = False\n```\n\n**Output:**\n```py\n>>> not x == y\nTrue\n>>> x == not y\n  File \"<input>\", line 1\n    x == not y\n           ^\nSyntaxError: invalid syntax\n```\n\n#### \ud83d\udca1 Explanation:\n\n* Operator precedence affects how an expression is evaluated, and `==` operator has higher precedence than `not` operator in Python.\n* So `not x == y` is equivalent to `not (x == y)` which is equivalent to `not (True == False)` finally evaluating to `True`.\n* But `x == not y` raises a `SyntaxError` because it can be thought of being equivalent to `(x == not) y` and not `x == (not y)` which you might have expected at first sight.\n* The parser expected the `not` token to be a part of the `not in` operator (because both `==` and `not in` operators have the same precedence), but after not being able to find an `in` token following the `not` token, it raises a `SyntaxError`.\n\n---\n\n### \u25b6 Half triple-quoted strings\n\n**Output:**\n```py\n>>> print('wtfpython''')\nwtfpython\n>>> print(\"wtfpython\"\"\")\nwtfpython\n>>> # The following statements raise `SyntaxError`\n>>> # print('''wtfpython')\n>>> # print(\"\"\"wtfpython\")\n```\n\n#### \ud83d\udca1 Explanation:\n+ Python supports implicit [string literal concatenation](https://docs.python.org/2/reference/lexical_analysis.html#string-literal-concatenation), Example,\n  ```\n  >>> print(\"wtf\" \"python\")\n  wtfpython\n  >>> print(\"wtf\" \"\") # or \"wtf\"\"\"\n  wtf\n  ```\n+ `'''` and `\"\"\"` are also string delimiters in Python which causes a SyntaxError because the Python interpreter was expecting a terminating triple quote as delimiter while scanning the currently encountered triple quoted string literal.\n\n---\n\n### \u25b6 Midnight time doesn't exist?\n\n```py\nfrom datetime import datetime\n\nmidnight = datetime(2018, 1, 1, 0, 0)\nmidnight_time = midnight.time()\n\nnoon = datetime(2018, 1, 1, 12, 0)\nnoon_time = noon.time()\n\nif midnight_time:\n    print(\"Time at midnight is\", midnight_time)\n\nif noon_time:\n    print(\"Time at noon is\", noon_time)\n```\n\n**Output:**\n```sh\n('Time at noon is', datetime.time(12, 0))\n```\nThe midnight time is not printed.\n\n#### \ud83d\udca1 Explanation:\n\nBefore Python 3.5, the boolean value for `datetime.time` object was considered to be `False` if it represented midnight in UTC. It is error-prone when using the `if obj:` syntax to check if the `obj` is null or some equivalent of \"empty.\"\n\n---\n\n### \u25b6 What's wrong with booleans?\n\n1\\.\n```py\n# A simple example to count the number of boolean and\n# integers in an iterable of mixed data types.\nmixed_list = [False, 1.0, \"some_string\", 3, True, [], False]\nintegers_found_so_far = 0\nbooleans_found_so_far = 0\n\nfor item in mixed_list:\n    if isinstance(item, int):\n        integers_found_so_far += 1\n    elif isinstance(item, bool):\n        booleans_found_so_far += 1\n```\n\n**Output:**\n```py\n>>> integers_found_so_far\n4\n>>> booleans_found_so_far\n0\n```\n\n2\\.\n```py\nanother_dict = {}\nanother_dict[True] = \"JavaScript\"\nanother_dict[1] = \"Ruby\"\nanother_dict[1.0] = \"Python\"\n```\n\n**Output:**\n```py\n>>> another_dict[True]\n\"Python\"\n```\n\n3\\.\n```py\n>>> some_bool = True\n>>> \"wtf\"*some_bool\n'wtf'\n>>> some_bool = False\n>>> \"wtf\"*some_bool\n''\n```\n\n#### \ud83d\udca1 Explanation:\n\n* Booleans are a subclass of `int`\n  ```py\n  >>> isinstance(True, int)\n  True\n  >>> isinstance(False, int)\n  True\n  ```\n\n* The integer value of `True` is `1` and that of `False` is `0`.\n  ```py\n  >>> True == 1 == 1.0 and False == 0 == 0.0\n  True\n  ```\n\n* See this StackOverflow [answer](https://stackoverflow.com/a/8169049/4354153) for the rationale behind it.\n\n---\n\n### \u25b6 Class attributes and instance attributes\n\n1\\.\n```py\nclass A:\n    x = 1\n\nclass B(A):\n    pass\n\nclass C(A):\n    pass\n```\n\n**Output:**\n```py\n>>> A.x, B.x, C.x\n(1, 1, 1)\n>>> B.x = 2\n>>> A.x, B.x, C.x\n(1, 2, 1)\n>>> A.x = 3\n>>> A.x, B.x, C.x\n(3, 2, 3)\n>>> a = A()\n>>> a.x, A.x\n(3, 3)\n>>> a.x += 1\n>>> a.x, A.x\n(4, 3)\n```\n\n2\\.\n```py\nclass SomeClass:\n    some_var = 15\n    some_list = [5]\n    another_list = [5]\n    def __init__(self, x):\n        self.some_var = x + 1\n        self.some_list = self.some_list + [x]\n        self.another_list += [x]\n```\n\n**Output:**\n\n```py\n>>> some_obj = SomeClass(420)\n>>> some_obj.some_list\n[5, 420]\n>>> some_obj.another_list\n[5, 420]\n>>> another_obj = SomeClass(111)\n>>> another_obj.some_list\n[5, 111]\n>>> another_obj.another_list\n[5, 420, 111]\n>>> another_obj.another_list is SomeClass.another_list\nTrue\n>>> another_obj.another_list is some_obj.another_list\nTrue\n```\n\n#### \ud83d\udca1 Explanation:\n\n* Class variables and variables in class instances are internally handled as dictionaries of a class object. If a variable name is not found in the dictionary of the current class, the parent classes are searched for it.\n* The `+=` operator modifies the mutable object in-place without creating a new object. So changing the attribute of one instance affects the other instances and the class attribute as well.\n\n---\n\n### \u25b6 yielding None\n\n```py\nsome_iterable = ('a', 'b')\n\ndef some_func(val):\n    return \"something\"\n```\n\n**Output:**\n```py\n>>> [x for x in some_iterable]\n['a', 'b']\n>>> [(yield x) for x in some_iterable]\n<generator object <listcomp> at 0x7f70b0a4ad58>\n>>> list([(yield x) for x in some_iterable])\n['a', 'b']\n>>> list((yield x) for x in some_iterable)\n['a', None, 'b', None]\n>>> list(some_func((yield x)) for x in some_iterable)\n['a', 'something', 'b', 'something']\n```\n\n#### \ud83d\udca1 Explanation:\n- Source and explanation can be found here: https://stackoverflow.com/questions/32139885/yield-in-list-comprehensions-and-generator-expressions\n- Related bug report: http://bugs.python.org/issue10544\n\n---\n\n### \u25b6 Mutating the immutable!\n\n```py\nsome_tuple = (\"A\", \"tuple\", \"with\", \"values\")\nanother_tuple = ([1, 2], [3, 4], [5, 6])\n```\n\n**Output:**\n```py\n>>> some_tuple[2] = \"change this\"\nTypeError: 'tuple' object does not support item assignment\n>>> another_tuple[2].append(1000) #This throws no error\n>>> another_tuple\n([1, 2], [3, 4], [5, 6, 1000])\n>>> another_tuple[2] += [99, 999]\nTypeError: 'tuple' object does not support item assignment\n>>> another_tuple\n([1, 2], [3, 4], [5, 6, 1000, 99, 999])\n```\n\nBut I thought tuples were immutable...\n\n#### \ud83d\udca1 Explanation:\n\n* Quoting from https://docs.python.org/2/reference/datamodel.html\n\n    > Immutable sequences\n        An object of an immutable sequence type cannot change once it is created. (If the object contains references to other objects, these other objects may be mutable and may be modified; however, the collection of objects directly referenced by an immutable object cannot change.)\n\n* `+=` operator changes the list in-place. The item assignment doesn't work, but when the exception occurs, the item has already been changed in place.\n\n---\n\n### \u25b6 The disappearing variable from outer scope\n\n```py\ne = 7\ntry:\n    raise Exception()\nexcept Exception as e:\n    pass\n```\n\n**Output (Python 2.x):**\n```py\n>>> print(e)\n# prints nothing\n```\n\n**Output (Python 3.x):**\n```py\n>>> print(e)\nNameError: name 'e' is not defined\n```\n\n#### \ud83d\udca1 Explanation:\n\n* Source: https://docs.python.org/3/reference/compound_stmts.html#except\n\n  When an exception has been assigned using `as` target, it is cleared at the end of the except clause. This is as if\n\n  ```py\n  except E as N:\n      foo\n  ```\n\n  was translated into\n\n  ```py\n  except E as N:\n      try:\n          foo\n      finally:\n          del N\n  ```\n\n  This means the exception must be assigned to a different name to be able to refer to it after the except clause. Exceptions are cleared because, with the traceback attached to them, they form a reference cycle with the stack frame, keeping all locals in that frame alive until the next garbage collection occurs.\n\n* The clauses are not scoped in Python. Everything in the example is present in the same scope, and the variable `e` got removed due to the execution of the `except` clause. The same is not the case with functions which have their separate inner-scopes. The example below illustrates this:\n\n     ```py\n     def f(x):\n         del(x)\n         print(x)\n\n     x = 5\n     y = [5, 4, 3]\n     ```\n\n     **Output:**\n     ```py\n     >>>f(x)\n     UnboundLocalError: local variable 'x' referenced before assignment\n     >>>f(y)\n     UnboundLocalError: local variable 'x' referenced before assignment\n     >>> x\n     5\n     >>> y\n     [5, 4, 3]\n     ```\n\n* In Python 2.x the variable name `e` gets assigned to `Exception()` instance, so when you try to print, it prints nothing.\n\n    **Output (Python 2.x):**\n    ```py\n    >>> e\n    Exception()\n    >>> print e\n    # Nothing is printed!\n    ```\n\n---\n\n### \u25b6 When True is actually False\n\n```py\nTrue = False\nif True == False:\n    print(\"I've lost faith in truth!\")\n```\n\n**Output:**\n```\nI've lost faith in truth!\n```\n\n#### \ud83d\udca1 Explanation:\n\n- Initially, Python used to have no `bool` type (people used 0 for false and non-zero value like 1 for true). Then they added `True`, `False`, and a `bool` type, but, for backward compatibility, they couldn't make `True` and `False` constants- they just were built-in variables.\n- Python 3 was backward-incompatible, so it was now finally possible to fix that, and so this example won't work with Python 3.x!\n\n---\n\n### \u25b6 From filled to None in one instruction...\n\n```py\nsome_list = [1, 2, 3]\nsome_dict = {\n  \"key_1\": 1,\n  \"key_2\": 2,\n  \"key_3\": 3\n}\n\nsome_list = some_list.append(4)\nsome_dict = some_dict.update({\"key_4\": 4})\n```\n\n**Output:**\n```py\n>>> print(some_list)\nNone\n>>> print(some_dict)\nNone\n```\n\n#### \ud83d\udca1 Explanation\n\nMost methods that modify the items of sequence/mapping objects like `list.append`, `dict.update`, `list.sort`, etc. modify the objects in-place and return `None`. The rationale behind this is to improve performance by avoiding making a copy of the object if the operation can be done in-place (Referred from [here](http://docs.python.org/2/faq/design.html#why-doesn-t-list-sort-return-the-sorted-list))\n\n---\n\n### \u25b6 Subclass relationships *\n\n**Output:**\n```py\n>>> from collections import Hashable\n>>> issubclass(list, object)\nTrue\n>>> issubclass(object, Hashable)\nTrue\n>>> issubclass(list, Hashable)\nFalse\n```\n\nThe Subclass relationships were expected to be transitive, right? (i.e., if `A` is a subclass of `B`, and `B` is a subclass of `C`, the `A` _should_ a subclass of `C`)\n\n#### \ud83d\udca1 Explanation:\n\n* Subclass relationships are not necessarily transitive in Python. Anyone is allowed to define their own, arbitrary `__subclasscheck__` in a metaclass.\n* When `issubclass(cls, Hashable)` is called, it simply looks for non-Falsey \"`__hash__`\" method in `cls` or anything it inherits from.\n* Since `object` is hashable, but `list` is non-hashable, it breaks the transitivity relation.\n* More detailed explanation can be found [here](https://www.naftaliharris.com/blog/python-subclass-intransitivity/).\n\n---\n\n### \u25b6 The mysterious key type conversion *\n\n```py\nclass SomeClass(str):\n    pass\n\nsome_dict = {'s':42}\n```\n\n**Output:**\n```py\n>>> type(list(some_dict.keys())[0])\nstr\n>>> s = SomeClass('s')\n>>> some_dict[s] = 40\n>>> some_dict # expected: Two different keys-value pairs\n{'s': 40}\n>>> type(list(some_dict.keys())[0])\nstr\n```\n\n#### \ud83d\udca1 Explanation:\n\n* Both the object `s` and the string `\"s\"` hash to the same value because `SomeClass` inherits the `__hash__` method of `str` class.\n* `SomeClass(\"s\") == \"s\"` evaluates to `True` because `SomeClass` also inherits `__eq__` method from `str` class.\n* Since both the objects hash to the same value and are equal, they are represented by the same key in the dictionary.\n* For the desired behavior, we can redefine the `__eq__` method in `SomeClass`\n  ```py\n  class SomeClass(str):\n    def __eq__(self, other):\n        return (\n            type(self) is SomeClass\n            and type(other) is SomeClass\n            and super().__eq__(other)\n        )\n\n    # When we define a custom __eq__, Python stops automatically inheriting the\n    # __hash__ method, so we need to define it as well\n    __hash__ = str.__hash__\n\n  some_dict = {'s':42}\n  ```\n\n  **Output:**\n  ```py\n  >>> s = SomeClass('s')\n  >>> some_dict[s] = 40\n  >>> some_dict\n  {'s': 40, 's': 42}\n  >>> keys = list(some_dict.keys())\n  >>> type(keys[0]), type(keys[1])\n  (__main__.SomeClass, str)\n  ```\n\n---\n\n### \u25b6 Let's see if you can guess this?\n\n```py\na, b = a[b] = {}, 5\n```\n\n**Output:**\n```py\n>>> a\n{5: ({...}, 5)}\n```\n\n#### \ud83d\udca1 Explanation:\n\n* According to [Python language reference](https://docs.python.org/2/reference/simple_stmts.html#assignment-statements), assignment statements have the form\n  ```\n  (target_list \"=\")+ (expression_list | yield_expression)\n  ```\n  and\n  > An assignment statement evaluates the expression list (remember that this can be a single expression or a comma-separated list, the latter yielding a tuple) and assigns the single resulting object to each of the target lists, from left to right.\n\n* The `+` in `(target_list \"=\")+` means there can be **one or more** target lists. In this case, target lists are `a, b` and `a[b]` (note the expression list is exactly one, which in our case is `{}, 5`).\n\n* After the expression list is evaluated, it's value is unpacked to the target lists from **left to right**. So, in our case, first the `{}, 5` tuple is unpacked to `a, b` and we now have `a = {}` and `b = 5`.\n\n* `a` is now assigned to `{}` which is a mutable object.\n\n* The second target list is `a[b]` (you may expect this to throw an error because both `a` and `b` have not been defined in the statements before. But remember, we just assigned `a` to `{}` and `b` to `5`).\n\n* Now, we are setting the key `5` in the dictionary to the tuple `({}, 5)` creating a circular reference (the `{...}` in the output refers to the same object that `a` is already referencing). Another simpler example of circular reference could be\n  ```py\n  >>> some_list = some_list[0] = [0]\n  >>> some_list\n  [[...]]\n  >>> some_list[0]\n  [[...]]\n  >>> some_list is some_list[0]\n  True\n  >>> some_list[0][0][0][0][0][0] == some_list\n  True\n  ```\n  Similar is the case in our example (`a[b][0]` is the same object as `a`)\n\n* So to sum it up, you can break the example down to\n  ```py\n  a, b = {}, 5\n  a[b] = a, b\n  ```\n  And the circular reference can be justified by the fact that `a[b][0]` is the same object as `a`\n  ```py\n  >>> a[b][0] is a\n  True\n  ```\n\n---\n\n---\n\n## Section: Appearances are deceptive!\n\n### \u25b6 Skipping lines?\n\n**Output:**\n```py\n>>> value = 11\n>>> valu\u0435 = 32\n>>> value\n11\n```\n\nWut?\n\n**Note:** The easiest way to reproduce this is to simply copy the statements from the above snippet and paste them into your file/shell.\n\n#### \ud83d\udca1 Explanation\n\nSome non-Western characters look identical to letters in the English alphabet but are considered distinct by the interpreter.\n\n```py\n>>> ord('\u0435') # cyrillic 'e' (Ye)\n1077\n>>> ord('e') # latin 'e', as used in English and typed using standard keyboard\n101\n>>> '\u0435' == 'e'\nFalse\n\n>>> value = 42 # latin e\n>>> valu\u0435 = 23 # cyrillic 'e', Python 2.x interpreter would raise a `SyntaxError` here\n>>> value\n42\n```\n\nThe built-in `ord()` function returns a character's Unicode [code point](https://en.wikipedia.org/wiki/Code_point), and different code positions of Cyrillic 'e' and Latin 'e' justify the behavior of the above example.\n\n---\n\n### \u25b6 Teleportation *\n\n```py\nimport numpy as np\n\ndef energy_send(x):\n    # Initializing a numpy array\n    np.array([float(x)])\n\ndef energy_receive():\n    # Return an empty numpy array\n    return np.empty((), dtype=np.float).tolist()\n```\n\n**Output:**\n```py\n>>> energy_send(123.456)\n>>> energy_receive()\n123.456\n```\n\nWhere's the Nobel Prize?\n\n#### \ud83d\udca1 Explanation:\n\n* Notice that the numpy array created in the `energy_send` function is not returned, so that memory space is free to reallocate.\n* `numpy.empty()` returns the next free memory slot without reinitializing it. This memory spot just happens to be the same one that was just freed (usually, but not always).\n\n---\n\n### \u25b6 Well, something is fishy...\n\n```py\ndef square(x):\n    \"\"\"\n    A simple function to calculate the square of a number by addition.\n    \"\"\"\n    sum_so_far = 0\n    for counter in range(x):\n        sum_so_far = sum_so_far + x\n  return sum_so_far\n```\n\n**Output (Python 2.x):**\n\n```py\n>>> square(10)\n10\n```\n\nShouldn't that be 100?\n\n**Note:** If you're not able to reproduce this, try running the file [mixed_tabs_and_spaces.py](/mixed_tabs_and_spaces.py) via the shell.\n\n#### \ud83d\udca1 Explanation\n\n* **Don't mix tabs and spaces!** The character just preceding return is a \"tab\",  and the code is indented by multiple of \"4 spaces\" elsewhere in the example.\n* This is how Python handles tabs:\n  > First, tabs are replaced (from left to right) by one to eight spaces such that the total number of characters up to and including the replacement is a multiple of eight <...>\n* So the \"tab\" at the last line of `square` function is replaced with eight spaces, and it gets into the loop.\n* Python 3 is kind enough to throw an error for such cases automatically.\n\n    **Output (Python 3.x):**\n    ```py\n    TabError: inconsistent use of tabs and spaces in indentation\n    ```\n\n---\n\n---\n\n## Section: Watch out for the landmines!\n\n\n### \u25b6 Modifying a dictionary while iterating over it\n\n```py\nx = {0: None}\n\nfor i in x:\n    del x[i]\n    x[i+1] = None\n    print(i)\n```\n\n**Output (Python 2.7- Python 3.5):**\n\n```\n0\n1\n2\n3\n4\n5\n6\n7\n```\n\nYes, it runs for exactly **eight** times and stops.\n\n#### \ud83d\udca1 Explanation:\n\n* Iteration over a dictionary that you edit at the same time is not supported.\n* It runs eight times because that's the point at which the dictionary resizes to hold more keys (we have eight deletion entries, so a resize is needed). This is actually an implementation detail.\n* How deleted keys are handled and when the resize occurs might be different for different Python implementations.\n* For more information, you may refer to this StackOverflow [thread](https://stackoverflow.com/questions/44763802/bug-in-python-dict) explaining a similar example in detail.\n\n---\n\n### \u25b6 Stubborn `del` operator *\n\n```py\nclass SomeClass:\n    def __del__(self):\n        print(\"Deleted!\")\n```\n\n**Output:**\n1\\.\n```py\n>>> x = SomeClass()\n>>> y = x\n>>> del x # this should print \"Deleted!\"\n>>> del y\nDeleted!\n```\n\nPhew, deleted at last. You might have guessed what saved from `__del__` being called in our first attempt to delete `x`. Let's add more twist to the example.\n\n2\\.\n```py\n>>> x = SomeClass()\n>>> y = x\n>>> del x\n>>> y # check if y exists\n<__main__.SomeClass instance at 0x7f98a1a67fc8>\n>>> del y # Like previously, this should print \"Deleted!\"\n>>> globals() # oh, it didn't. Let's check all our global variables and confirm\nDeleted!\n{'__builtins__': <module '__builtin__' (built-in)>, 'SomeClass': <class __main__.SomeClass at 0x7f98a1a5f668>, '__package__': None, '__name__': '__main__', '__doc__': None}\n```\n\nOkay, now it's deleted :confused:\n\n#### \ud83d\udca1 Explanation:\n+ `del x` doesn\u2019t directly call `x.__del__()`.\n+ Whenever `del x` is encountered, Python decrements the reference count for `x` by one, and `x.__del__()` when x\u2019s reference count reaches zero.\n+ In the second output snippet, `y.__del__()` was not called because the previous statement (`>>> y`) in the interactive interpreter created another reference to the same object, thus preventing the reference count to reach zero when `del y` was encountered.\n+ Calling `globals` caused the existing reference to be destroyed and hence we can see \"Deleted!\" being printed (finally!).\n\n---\n\n### \u25b6 Deleting a list item while iterating\n\n```py\nlist_1 = [1, 2, 3, 4]\nlist_2 = [1, 2, 3, 4]\nlist_3 = [1, 2, 3, 4]\nlist_4 = [1, 2, 3, 4]\n\nfor idx, item in enumerate(list_1):\n    del item\n\nfor idx, item in enumerate(list_2):\n    list_2.remove(item)\n\nfor idx, item in enumerate(list_3[:]):\n    list_3.remove(item)\n\nfor idx, item in enumerate(list_4):\n    list_4.pop(idx)\n```\n\n**Output:**\n```py\n>>> list_1\n[1, 2, 3, 4]\n>>> list_2\n[2, 4]\n>>> list_3\n[]\n>>> list_4\n[2, 4]\n```\n\nCan you guess why the output is `[2, 4]`?\n\n#### \ud83d\udca1 Explanation:\n\n* It's never a good idea to change the object you're iterating over. The correct way to do so is to iterate over a copy of the object instead, and `list_3[:]` does just that.\n\n     ```py\n     >>> some_list = [1, 2, 3, 4]\n     >>> id(some_list)\n     139798789457608\n     >>> id(some_list[:]) # Notice that python creates new object for sliced list.\n     139798779601192\n     ```\n\n**Difference between `del`, `remove`, and `pop`:**\n* `del var_name` just removes the binding of the `var_name` from the local or global namespace (That's why the `list_1` is unaffected).\n* `remove` removes the first matching value, not a specific index, raises `ValueError` if the value is not found.\n* `pop` removes the element at a specific index and returns it, raises `IndexError` if an invalid index is specified.\n\n**Why the output is `[2, 4]`?**\n- The list iteration is done index by index, and when we remove `1` from `list_2` or `list_4`, the contents of the lists are now `[2, 3, 4]`. The remaining elements are shifted down, i.e., `2` is at index 0, and `3` is at index 1. Since the next iteration is going to look at index 1 (which is the `3`), the `2` gets skipped entirely. A similar thing will happen with every alternate element in the list sequence.\n\n* Refer to this StackOverflow [thread](https://stackoverflow.com/questions/45946228/what-happens-when-you-try-to-delete-a-list-element-while-iterating-over-it) explaining the example\n* See also this nice StackOverflow [thread](https://stackoverflow.com/questions/45877614/how-to-change-all-the-dictionary-keys-in-a-for-loop-with-d-items) for a similar example related to dictionaries in Python.\n\n---\n\n### \u25b6 Loop variables leaking out!\n\n1\\.\n```py\nfor x in range(7):\n    if x == 6:\n        print(x, ': for x inside loop')\nprint(x, ': x in global')\n```\n\n**Output:**\n```py\n6 : for x inside loop\n6 : x in global\n```\n\nBut `x` was never defined outside the scope of for loop...\n\n2\\.\n```py\n# This time let's initialize x first\nx = -1\nfor x in range(7):\n    if x == 6:\n        print(x, ': for x inside loop')\nprint(x, ': x in global')\n```\n\n**Output:**\n```py\n6 : for x inside loop\n6 : x in global\n```\n\n3\\.\n```\nx = 1\nprint([x for x in range(5)])\nprint(x, ': x in global')\n```\n\n**Output (on Python 2.x):**\n```\n[0, 1, 2, 3, 4]\n(4, ': x in global')\n```\n\n**Output (on Python 3.x):**\n```\n[0, 1, 2, 3, 4]\n1 : x in global\n```\n\n#### \ud83d\udca1 Explanation:\n\n- In Python, for-loops use the scope they exist in and leave their defined loop-variable behind. This also applies if we explicitly defined the for-loop variable in the global namespace before. In this case, it will rebind the existing variable.\n\n- The differences in the output of Python 2.x and Python 3.x interpreters for list comprehension example can be explained by following change documented in [What\u2019s New In Python 3.0](https://docs.python.org/3/whatsnew/3.0.html) documentation:\n\n    > \"List comprehensions no longer support the syntactic form `[... for var in item1, item2, ...]`. Use `[... for var in (item1, item2, ...)]` instead. Also, note that list comprehensions have different semantics: they are closer to syntactic sugar for a generator expression inside a `list()` constructor, and in particular the loop control variables are no longer leaked into the surrounding scope.\"\n\n---\n\n### \u25b6 Beware of default mutable arguments!\n\n```py\ndef some_func(default_arg=[]):\n    default_arg.append(\"some_string\")\n    return default_arg\n```\n\n**Output:**\n```py\n>>> some_func()\n['some_string']\n>>> some_func()\n['some_string', 'some_string']\n>>> some_func([])\n['some_string']\n>>> some_func()\n['some_string', 'some_string', 'some_string']\n```\n\n#### \ud83d\udca1 Explanation:\n\n- The default mutable arguments of functions in Python aren't really initialized every time you call the function. Instead, the recently assigned value to them is used as the default value. When we explicitly passed `[]` to `some_func` as the argument, the default value of the `default_arg` variable was not used, so the function returned as expected.\n\n    ```py\n    def some_func(default_arg=[]):\n        default_arg.append(\"some_string\")\n        return default_arg\n    ```\n\n    **Output:**\n    ```py\n    >>> some_func.__defaults__ #This will show the default argument values for the function\n    ([],)\n    >>> some_func()\n    >>> some_func.__defaults__\n    (['some_string'],)\n    >>> some_func()\n    >>> some_func.__defaults__\n    (['some_string', 'some_string'],)\n    >>> some_func([])\n    >>> some_func.__defaults__\n    (['some_string', 'some_string'],)\n    ```\n\n- A common practice to avoid bugs due to mutable arguments is to assign `None` as the default value and later check if any value is passed to the function corresponding to that argument. Example:\n\n    ```py\n    def some_func(default_arg=None):\n        if not default_arg:\n            default_arg = []\n        default_arg.append(\"some_string\")\n        return default_arg\n    ```\n\n---\n\n### \u25b6 Catching the Exceptions\n\n```py\nsome_list = [1, 2, 3]\ntry:\n    # This should raise an ``IndexError``\n    print(some_list[4])\nexcept IndexError, ValueError:\n    print(\"Caught!\")\n\ntry:\n    # This should raise a ``ValueError``\n    some_list.remove(4)\nexcept IndexError, ValueError:\n    print(\"Caught again!\")\n```\n\n**Output (Python 2.x):**\n```py\nCaught!\n\nValueError: list.remove(x): x not in list\n```\n\n**Output (Python 3.x):**\n```py\n  File \"<input>\", line 3\n    except IndexError, ValueError:\n                     ^\nSyntaxError: invalid syntax\n```\n\n#### \ud83d\udca1 Explanation\n\n* To add multiple Exceptions to the except clause, you need to pass them as parenthesized tuple as the first argument. The second argument is an optional name, which when supplied will bind the Exception instance that has been raised. Example,\n  ```py\n  some_list = [1, 2, 3]\n  try:\n     # This should raise a ``ValueError``\n     some_list.remove(4)\n  except (IndexError, ValueError), e:\n     print(\"Caught again!\")\n     print(e)\n  ```\n  **Output (Python 2.x):**\n  ```\n  Caught again!\n  list.remove(x): x not in list\n  ```\n  **Output (Python 3.x):**\n  ```py\n    File \"<input>\", line 4\n      except (IndexError, ValueError), e:\n                                       ^\n  IndentationError: unindent does not match any outer indentation level\n  ```\n\n* Separating the exception from the variable with a comma is deprecated and does not work in Python 3; the correct way is to use `as`. Example,\n  ```py\n  some_list = [1, 2, 3]\n  try:\n      some_list.remove(4)\n\n  except (IndexError, ValueError) as e:\n      print(\"Caught again!\")\n      print(e)\n  ```\n  **Output:**\n  ```\n  Caught again!\n  list.remove(x): x not in list\n  ```\n\n---\n\n### \u25b6 Same operands, different story!\n\n1\\.\n```py\na = [1, 2, 3, 4]\nb = a\na = a + [5, 6, 7, 8]\n```\n\n**Output:**\n```py\n>>> a\n[1, 2, 3, 4, 5, 6, 7, 8]\n>>> b\n[1, 2, 3, 4]\n```\n\n2\\.\n```py\na = [1, 2, 3, 4]\nb = a\na += [5, 6, 7, 8]\n```\n\n**Output:**\n```py\n>>> a\n[1, 2, 3, 4, 5, 6, 7, 8]\n>>> b\n[1, 2, 3, 4, 5, 6, 7, 8]\n```\n\n#### \ud83d\udca1 Explanation:\n\n*  `a += b` doesn't always behave the same way as `a = a + b`.  Classes *may* implement the *`op=`* operators differently, and lists do this.\n\n* The expression `a = a + [5,6,7,8]` generates a new list and sets `a`'s reference to that new list, leaving `b` unchanged.\n\n* The expression `a += [5,6,7,8]` is actually mapped to an \"extend\" function that operates on the list such that `a` and `b` still point to the same list that has been modified in-place.\n\n---\n\n### \u25b6 The out of scope variable\n\n```py\na = 1\ndef some_func():\n    return a\n\ndef another_func():\n    a += 1\n    return a\n```\n\n**Output:**\n```py\n>>> some_func()\n1\n>>> another_func()\nUnboundLocalError: local variable 'a' referenced before assignment\n```\n\n#### \ud83d\udca1 Explanation:\n* When you make an assignment to a variable in scope, it becomes local to that scope. So `a` becomes local to the scope of `another_func`,  but it has not been initialized previously in the same scope which throws an error.\n* Read [this](http://sebastianraschka.com/Articles/2014_python_scope_and_namespaces.html) short but an awesome guide to learn more about how namespaces and scope resolution works in Python.\n* To modify the outer scope variable `a` in `another_func`, use `global` keyword.\n  ```py\n  def another_func()\n      global a\n      a += 1\n      return a\n  ```\n\n  **Output:**\n  ```py\n  >>> another_func()\n  2\n  ```\n\n---\n\n### \u25b6 Be careful with chained operations\n\n```py\n>>> (False == False) in [False] # makes sense\nFalse\n>>> False == (False in [False]) # makes sense\nFalse\n>>> False == False in [False] # now what?\nTrue\n\n>>> True is False == False\nFalse\n>>> False is False is False\nTrue\n\n>>> 1 > 0 < 1\nTrue\n>>> (1 > 0) < 1\nFalse\n>>> 1 > (0 < 1)\nFalse\n```\n\n#### \ud83d\udca1 Explanation:\n\nAs per https://docs.python.org/2/reference/expressions.html#not-in\n\n> Formally, if a, b, c, ..., y, z are expressions and op1, op2, ..., opN are comparison operators, then a op1 b op2 c ... y opN z is equivalent to a op1 b and b op2 c and ... y opN z, except that each expression is evaluated at most once.\n\nWhile such behavior might seem silly to you in the above examples, it's fantastic with stuff like `a == b == c` and `0 <= x <= 100`.\n\n* `False is False is False` is equivalent to `(False is False) and (False is False)`\n* `True is False == False` is equivalent to `True is False and False == False` and since the first part of the statement (`True is False`) evaluates to `False`, the overall expression evaluates to `False`.\n* `1 > 0 < 1` is equivalent to `1 > 0 and 0 < 1` which evaluates to `True`.\n* The expression `(1 > 0) < 1` is equivalent to `True < 1` and\n  ```py\n  >>> int(True)\n  1\n  >>> True + 1 #not relevant for this example, but just for fun\n  2\n  ```\n  So, `1 < 1` evaluates to `False`\n\n---\n\n### \u25b6 Name resolution ignoring class scope\n\n1\\.\n```py\nx = 5\nclass SomeClass:\n    x = 17\n    y = (x for i in range(10))\n```\n\n**Output:**\n```py\n>>> list(SomeClass.y)[0]\n5\n```\n\n2\\.\n```py\nx = 5\nclass SomeClass:\n    x = 17\n    y = [x for i in range(10)]\n```\n\n**Output (Python 2.x):**\n```py\n>>> SomeClass.y[0]\n17\n```\n\n**Output (Python 3.x):**\n```py\n>>> SomeClass.y[0]\n5\n```\n\n#### \ud83d\udca1 Explanation\n- Scopes nested inside class definition ignore names bound at the class level.\n- A generator expression has its own scope.\n- Starting from Python 3.X, list comprehensions also have their own scope.\n\n---\n\n### \u25b6 Needle in a Haystack\n\n1\\.\n```py\nx, y = (0, 1) if True else None, None\n```\n\n**Output:**\n```py\n>>> x, y  # expected (0, 1)\n((0, 1), None)\n```\n\nAlmost every Python programmer has faced a similar situation.\n\n2\\.\n```py\nt = ('one', 'two')\nfor i in t:\n    print(i)\n\nt = ('one')\nfor i in t:\n    print(i)\n\nt = ()\nprint(t)\n```\n\n**Output:**\n```py\none\ntwo\no\nn\ne\ntuple()\n```\n\n#### \ud83d\udca1 Explanation:\n* For 1, the correct statement for expected behavior is `x, y = (0, 1) if True else (None, None)`.\n* For 2, the correct statement for expected behavior is `t = ('one',)` or `t = 'one',` (missing comma) otherwise the interpreter considers `t` to be a `str` and iterates over it character by character.\n* `()` is a special token and denotes empty `tuple`.\n\n---\n\n### \u25b6 Yielding from... return!\n\n1\\.\n```py\ndef some_func(x):\n    if x == 3:\n        return [\"wtf\"]\n    else:\n        yield from range(x)\n```\n\n**Output:**\n```py\n>>> list(some_func(3))\n[]\n```\n\nWhere did the `\"wtf\"` go? Is it due to some special effect of `yield from`? Let's validate that,\n\n2\\.\n```py\ndef some_func(x):\n    if x == 3:\n        return [\"wtf\"]\n    else:\n        for i in range(x):\n          yield i\n```\n\n**Output:**\n```py\n>>> list(some_func(3))\n[]\n```\n\nSame result, that didn't work either.\n\n#### \ud83d\udca1 Explanation:\n\n+ From Python 3.3 onwards, it became possible to use `return` statement with values inside generators (See [PEP380](https://www.python.org/dev/peps/pep-0380/)). The [official docs](https://www.python.org/dev/peps/pep-0380/#enhancements-to-stopiteration) say that,\n\n> \"... `return expr` in a generator causes `StopIteration(expr)` to be raised upon exit from the generator.\"\n\n+ In case of `some_func(3)`, `StopIteration` is raised at the beginning because of `return` statement. The `StopIteration` exception is automatically catched inside the `list(...)` wrapper and the `for` loop. Therefore, the above two snippets result in an empty list.\n\n+ To get `[\"wtf\"]` from the generator `some_func` we need to catch the `StopIteration` exception,\n  ```py\n  try:\n      next(some_func(3))\n  except StopIteration as e:\n      some_string = e.value\n  ```\n\n  ```py\n  >>> some_string\n  [\"wtf\"]\n  ```\n\n\n---\n\n---\n\n\n## Section: The Hidden treasures!\n\nThis section contains few of the lesser-known interesting things about Python that most beginners like me are unaware of (well, not anymore).\n\n### \u25b6 Okay Python, Can you make me fly? *\n\nWell, here you go\n\n```py\nimport antigravity\n```\n\n**Output:**\nSshh.. It's a super secret.\n\n#### \ud83d\udca1 Explanation:\n+ `antigravity` module is one of the few easter eggs released by Python developers.\n+ `import antigravity` opens up a web browser pointing to the [classic XKCD comic](http://xkcd.com/353/) about Python.\n+ Well, there's more to it. There's **another easter egg inside the easter egg**. If you look at the [code](https://github.com/python/cpython/blob/master/Lib/antigravity.py#L7-L17), there's a function defined that purports to implement the [XKCD's geohashing algorithm](https://xkcd.com/426/).\n\n---\n\n### \u25b6 `goto`, but why? *\n\n```py\nfrom goto import goto, label\nfor i in range(9):\n    for j in range(9):\n        for k in range(9):\n            print(\"I'm trapped, please rescue!\")\n            if k == 2:\n                goto .breakout # breaking out from a deeply nested loop\nlabel .breakout\nprint(\"Freedom!\")\n```\n\n**Output (Python 2.3):**\n```py\nI'm trapped, please rescue!\nI'm trapped, please rescue!\nFreedom!\n```\n\n#### \ud83d\udca1 Explanation:\n- A working version of `goto` in Python was [announced](https://mail.python.org/pipermail/python-announce-list/2004-April/002982.html) as an April Fool's joke on 1st April 2004.\n- Current versions of Python do not have this module.\n- Although it works, but please don't use it. Here's the [reason](https://docs.python.org/3/faq/design.html#why-is-there-no-goto) to why `goto` is not present in Python.\n\n---\n\n### \u25b6 Brace yourself! *\n\nIf you are one of the people who doesn't like using whitespace in Python to denote scopes, you can use the C-style {} by importing,\n\n```py\nfrom __future__ import braces\n```\n\n**Output:**\n```py\n  File \"some_file.py\", line 1\n    from __future__ import braces\nSyntaxError: not a chance\n```\n\nBraces? No way! If you think that's disappointing, use Java.\n\n#### \ud83d\udca1 Explanation:\n+ The `__future__` module is normally used to provide features from future versions of Python. The \"future\" here is however ironic.\n+ This is an easter egg concerned with the community's feelings on this issue.\n\n---\n\n### \u25b6 Let's meet Friendly Language Uncle For Life *\n\n**Output (Python 3.x)**\n```py\n>>> from __future__ import barry_as_FLUFL\n>>> \"Ruby\" != \"Python\" # there's no doubt about it\n  File \"some_file.py\", line 1\n    \"Ruby\" != \"Python\"\n              ^\nSyntaxError: invalid syntax\n\n>>> \"Ruby\" <> \"Python\"\nTrue\n```\n\nThere we go.\n\n#### \ud83d\udca1 Explanation:\n- This is relevant to [PEP-401](https://www.python.org/dev/peps/pep-0401/) released on April 1, 2009 (now you know, what it means).\n- Quoting from the PEP-401\n  > Recognized that the != inequality operator in Python 3.0 was a horrible, finger pain inducing mistake, the FLUFL reinstates the <> diamond operator as the sole spelling.\n- There were more things that Uncle Barry had to share in the PEP; you can read them [here](https://www.python.org/dev/peps/pep-0401/).\n\n---\n\n### \u25b6 Even Python understands that love is complicated *\n\n```py\nimport this\n```\n\nWait, what's **this**? `this` is love :heart:\n\n**Output:**\n```\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!\n```\n\nIt's the Zen of Python!\n\n```py\n>>> love = this\n>>> this is love\nTrue\n>>> love is True\nFalse\n>>> love is False\nFalse\n>>> love is not True or False\nTrue\n>>> love is not True or False; love is love  # Love is complicated\nTrue\n```\n\n#### \ud83d\udca1 Explanation:\n\n* `this` module in Python is an easter egg for The Zen Of Python ([PEP 20](https://www.python.org/dev/peps/pep-0020)).\n* And if you think that's already interesting enough, check out the implementation of [this.py](https://hg.python.org/cpython/file/c3896275c0f6/Lib/this.py). Interestingly, the code for the Zen violates itself (and that's probably the only place where this happens).\n* Regarding the statement `love is not True or False; love is love`, ironic but it's self-explanatory.\n\n---\n\n### \u25b6 Yes, it exists!\n\n**The `else` clause for loops.** One typical example might be:\n\n```py\n  def does_exists_num(l, to_find):\n      for num in l:\n          if num == to_find:\n              print(\"Exists!\")\n              break\n      else:\n          print(\"Does not exist\")\n```\n\n**Output:**\n```py\n>>> some_list = [1, 2, 3, 4, 5]\n>>> does_exists_num(some_list, 4)\nExists!\n>>> does_exists_num(some_list, -1)\nDoes not exist\n```\n\n**The `else` clause in exception handling.** An example,\n\n```py\ntry:\n    pass\nexcept:\n    print(\"Exception occurred!!!\")\nelse:\n    print(\"Try block executed successfully...\")\n```\n\n**Output:**\n```py\nTry block executed successfully...\n```\n\n#### \ud83d\udca1 Explanation:\n- The `else` clause after a loop is executed only when there's no explicit `break` after all the iterations.\n- `else` clause after try block is also called \"completion clause\" as reaching the `else` clause in a `try` statement means that the try block actually completed successfully.\n\n---\n\n### \u25b6 Inpinity *\n\nThe spelling is intended. Please, don't submit a patch for this.\n\n**Output (Python 3.x):**\n```py\n>>> infinity = float('infinity')\n>>> hash(infinity)\n314159\n>>> hash(float('-inf'))\n-314159\n```\n\n#### \ud83d\udca1 Explanation:\n- Hash of infinity is 10\u2075 x \u03c0.\n- Interestingly, the hash of `float('-inf')` is \"-10\u2075 x \u03c0\" in Python 3, whereas \"-10\u2075 x e\" in Python 2.\n\n---\n\n### \u25b6 Mangling time! *\n\n```py\nclass Yo(object):\n    def __init__(self):\n        self.__honey = True\n        self.bitch = True\n```\n\n**Output:**\n```py\n>>> Yo().bitch\nTrue\n>>> Yo().__honey\nAttributeError: 'Yo' object has no attribute '__honey'\n>>> Yo()._Yo__honey\nTrue\n```\n\nWhy did `Yo()._Yo__honey` work? Only Indian readers would understand.\n\n#### \ud83d\udca1 Explanation:\n\n* [Name Mangling](https://en.wikipedia.org/wiki/Name_mangling) is used to avoid naming collisions between different namespaces.\n* In Python, the interpreter modifies (mangles) the class member names starting with `__` (double underscore) and not ending with more than one trailing underscore by adding `_NameOfTheClass` in front.\n* So, to access `__honey` attribute, we are required to append `_Yo` to the front which would prevent conflicts with the same name attribute defined in any other class.\n\n---\n\n---\n\n## Section: Miscellaneous\n\n\n### \u25b6 `+=` is faster\n\n```py\n# using \"+\", three strings:\n>>> timeit.timeit(\"s1 = s1 + s2 + s3\", setup=\"s1 = ' ' * 100000; s2 = ' ' * 100000; s3 = ' ' * 100000\", number=100)\n0.25748300552368164\n# using \"+=\", three strings:\n>>> timeit.timeit(\"s1 += s2 + s3\", setup=\"s1 = ' ' * 100000; s2 = ' ' * 100000; s3 = ' ' * 100000\", number=100)\n0.012188911437988281\n```\n\n#### \ud83d\udca1 Explanation:\n+ `+=` is faster than `+` for concatenating more than two strings because the first string (example, `s1` for `s1 += s2 + s3`) is not destroyed while calculating the complete string.\n\n---\n\n### \u25b6 Let's make a giant string!\n\n```py\ndef add_string_with_plus(iters):\n    s = \"\"\n    for i in range(iters):\n        s += \"xyz\"\n    assert len(s) == 3*iters\n\ndef add_bytes_with_plus(iters):\n    s = b\"\"\n    for i in range(iters):\n        s += b\"xyz\"\n    assert len(s) == 3*iters\n\ndef add_string_with_format(iters):\n    fs = \"{}\"*iters\n    s = fs.format(*([\"xyz\"]*iters))\n    assert len(s) == 3*iters\n\ndef add_string_with_join(iters):\n    l = []\n    for i in range(iters):\n        l.append(\"xyz\")\n    s = \"\".join(l)\n    assert len(s) == 3*iters\n\ndef convert_list_to_string(l, iters):\n    s = \"\".join(l)\n    assert len(s) == 3*iters\n```\n\n**Output:**\n```py\n>>> timeit(add_string_with_plus(10000))\n1000 loops, best of 3: 972 \u00b5s per loop\n>>> timeit(add_bytes_with_plus(10000))\n1000 loops, best of 3: 815 \u00b5s per loop\n>>> timeit(add_string_with_format(10000))\n1000 loops, best of 3: 508 \u00b5s per loop\n>>> timeit(add_string_with_join(10000))\n1000 loops, best of 3: 878 \u00b5s per loop\n>>> l = [\"xyz\"]*10000\n>>> timeit(convert_list_to_string(l, 10000))\n10000 loops, best of 3: 80 \u00b5s per loop\n```\n\nLet's increase the number of iterations by a factor of 10.\n\n```py\n>>> timeit(add_string_with_plus(100000)) # Linear increase in execution time\n100 loops, best of 3: 9.75 ms per loop\n>>> timeit(add_bytes_with_plus(100000)) # Quadratic increase\n1000 loops, best of 3: 974 ms per loop\n>>> timeit(add_string_with_format(100000)) # Linear increase\n100 loops, best of 3: 5.25 ms per loop\n>>> timeit(add_string_with_join(100000)) # Linear increase\n100 loops, best of 3: 9.85 ms per loop\n>>> l = [\"xyz\"]*100000\n>>> timeit(convert_list_to_string(l, 100000)) # Linear increase\n1000 loops, best of 3: 723 \u00b5s per loop\n```\n\n#### \ud83d\udca1 Explanation\n- You can read more about [timeit](https://docs.python.org/3/library/timeit.html) from here. It is generally used to measure the execution time of snippets.\n- Don't use `+` for generating long strings \u2014 In Python, `str` is immutable, so the left and right strings have to be copied into the new string for every pair of concatenations. If you concatenate four strings of length 10, you'll be copying (10+10) + ((10+10)+10) + (((10+10)+10)+10) = 90 characters instead of just 40 characters. Things get quadratically worse as the number and size of the string increases (justified with the execution times of `add_bytes_with_plus` function)\n- Therefore, it's advised to use `.format.` or `%` syntax (however, they are slightly slower than `+` for short strings).\n- Or better, if already you've contents available in the form of an iterable object, then use `''.join(iterable_object)` which is much faster.\n- `add_string_with_plus` didn't show a quadratic increase in execution time unlike `add_bytes_with_plus` because of the `+=` optimizations discussed in the previous example. Had the statement been `s = s + \"x\" + \"y\" + \"z\"` instead of `s += \"xyz\"`, the increase would have been quadratic.\n  ```py\n  def add_string_with_plus(iters):\n      s = \"\"\n      for i in range(iters):\n          s = s + \"x\" + \"y\" + \"z\"\n      assert len(s) == 3*iters\n\n  >>> timeit(add_string_with_plus(10000))\n  100 loops, best of 3: 9.87 ms per loop\n  >>> timeit(add_string_with_plus(100000)) # Quadratic increase in execution time\n  1 loops, best of 3: 1.09 s per loop\n  ```\n\n---\n\n### \u25b6 Explicit typecast of strings\n\n```py\na = float('inf')\nb = float('nan')\nc = float('-iNf')  #These strings are case-insensitive\nd = float('nan')\n```\n\n**Output:**\n```py\n>>> a\ninf\n>>> b\nnan\n>>> c\n-inf\n>>> float('some_other_string')\nValueError: could not convert string to float: some_other_string\n>>> a == -c #inf==inf\nTrue\n>>> None == None # None==None\nTrue\n>>> b == d #but nan!=nan\nFalse\n>>> 50/a\n0.0\n>>> a/a\nnan\n>>> 23 + b\nnan\n```\n\n#### \ud83d\udca1 Explanation:\n\n`'inf'` and `'nan'` are special strings (case-insensitive), which when explicitly typecast-ed to `float` type, are used to represent mathematical \"infinity\" and \"not a number\" respectively.\n\n---\n\n### \u25b6 Minor Ones\n\n* `join()` is a string operation instead of list operation. (sort of counter-intuitive at first usage)\n\n  **\ud83d\udca1 Explanation:**\n  If `join()` is a method on a string then it can operate on any iterable (list, tuple, iterators). If it were a method on a list, it'd have to be implemented separately by every type. Also, it doesn't make much sense to put a string-specific method on a generic `list` object API.\n\n* Few weird looking but semantically correct statements:\n  + `[] = ()` is a semantically correct statement (unpacking an empty `tuple` into an empty `list`)\n  + `'a'[0][0][0][0][0]` is also a semantically correct statement as strings are [sequences](https://docs.python.org/3/glossary.html#term-sequence)(iterables supporting element access using integer indices) in Python.\n  + `3 --0-- 5 == 8` and `--5 == 5` are both semantically correct statements and evaluate to `True`.\n\n* Given that `a` is a number, `++a` and `--a` are both valid Python statements but don't behave the same way as compared with similar statements in languages like C, C++ or Java.\n  ```py\n  >>> a = 5\n  >>> a\n  5\n  >>> ++a\n  5\n  >>> --a\n  5\n  ```\n\n  **\ud83d\udca1 Explanation:**\n  + There is no `++` operator in Python grammar. It is actually two `+` operators.\n  + `++a` parses as `+(+a)` which translates to `a`. Similarly, the output of the statement `--a` can be justified.\n  + This StackOverflow [thread](https://stackoverflow.com/questions/3654830/why-are-there-no-and-operators-in-python) discusses the rationale behind the absence of increment and decrement operators in Python.\n\n* Have you ever heard about _the space-invader operator_ in Python?\n  ```py\n  >>> a = 42\n  >>> a -=- 1\n  >>> a\n  43\n  ```\n  It is used as an alternative incrementation operator, together with another one\n  ```py\n  >>> a +=+ 1\n  >>> a\n  >>> 44\n  ```\n  **\ud83d\udca1 Explanation:**\n  This prank comes from [Raymond Hettinger's tweet](https://twitter.com/raymondh/status/1131103570856632321?lang=en). The space invader operator is actually just a malformatted `a -= (-1)`. Which is equivalent to `a = a - (- 1)`. Similar for the `a += (+ 1)` case.\n\n* Python uses 2 bytes for local variable storage in functions. In theory, this means that only 65536 variables can be defined in a function. However, python has a handy solution built in that can be used to store more than 2^16 variable names. The following code demonstrates what happens in the stack when more than 65536 local variables are defined (Warning: This code prints around 2^18 lines of text, so be prepared!):\n     ```py\n     import dis\n     exec(\"\"\"\n     def f():\n         \"\"\" + \"\"\"\n         \"\"\".join([\"X\" + str(x) + \"=\" + str(x) for x in range(65539)]))\n\n     f()\n\n     print(dis.dis(f))\n     ```\n\n* Multiple Python threads won't run your *Python code* concurrently (yes you heard it right!). It may seem intuitive to spawn several threads and let them execute your Python code concurrently, but, because of the [Global Interpreter Lock](https://wiki.python.org/moin/GlobalInterpreterLock) in Python, all you're doing is making your threads execute on the same core turn by turn. Python threads are good for IO-bound tasks, but to achieve actual parallelization in Python for CPU-bound tasks, you might want to use the Python [multiprocessing](https://docs.python.org/2/library/multiprocessing.html) module.\n\n* List slicing with out of the bounds indices throws no errors\n  ```py\n  >>> some_list = [1, 2, 3, 4, 5]\n  >>> some_list[111:]\n  []\n  ```\n\n* `int('\u0661\u0662\u0663\u0664\u0665\u0666\u0667\u0668\u0669')` returns `123456789` in Python 3. In Python, Decimal characters include digit characters, and all characters that can be used to form decimal-radix numbers, e.g. U+0660, ARABIC-INDIC DIGIT ZERO. Here's an [interesting story](http://chris.improbable.org/2014/8/25/adventures-in-unicode-digits/) related to this behavior of Python.\n\n* `'abc'.count('') == 4`. Here's an approximate implementation of `count` method, which would make the things more clear\n  ```py\n  def count(s, sub):\n      result = 0\n      for i in range(len(s) + 1 - len(sub)):\n          result += (s[i:i + len(sub)] == sub)\n      return result\n  ```\n  The behavior is due to the matching of empty substring(`''`) with slices of length 0 in the original string.\n\n---\n\n# Contributing\n\nAll patches are Welcome! Please see [CONTRIBUTING.md](/CONTRIBUTING.md) for further details.\n\nFor discussions, you can either create a new [issue](https://github.com/satwikkansal/wtfpython/issues/new) or ping on the Gitter [channel](https://gitter.im/wtfpython/Lobby)\n\n# Acknowledgements\n\nThe idea and design for this collection were initially inspired by Denys Dovhan's awesome project [wtfjs](https://github.com/denysdovhan/wtfjs). The overwhelming support by the community gave it the shape it is in right now.\n\n#### Some nice Links!\n* https://www.youtube.com/watch?v=sH4XF6pKKmk\n* https://www.reddit.com/r/Python/comments/3cu6ej/what_are_some_wtf_things_about_python\n* https://sopython.com/wiki/Common_Gotchas_In_Python\n* https://stackoverflow.com/questions/530530/python-2-x-gotchas-and-landmines\n* https://stackoverflow.com/questions/1011431/common-pitfalls-in-python\n* https://www.python.org/doc/humor/\n* https://www.codementor.io/satwikkansal/python-practices-for-efficient-code-performance-memory-and-usability-aze6oiq65\n\n# \ud83c\udf93 License\n\n[![CC 4.0][license-image]][license-url]\n\n&copy; [Satwik Kansal](https://satwikkansal.xyz)\n\n[license-url]: http://www.wtfpl.net\n[license-image]: https://img.shields.io/badge/License-WTFPL%202.0-lightgrey.svg?style=flat-square\n\n## Help\n\nIf you have any wtfs, ideas or suggestions, please share.\n\n## Surprise your geeky pythonist friends?\n\nYou can use these quick links to recommend wtfpython to your friends,\n\n[Twitter](https://twitter.com/intent/tweet?url=https://github.com/satwikkansal/wtfpython&hastags=python,wtfpython)\n | [Linkedin](https://www.linkedin.com/shareArticle?url=https://github.com/satwikkansal&title=What%20the%20f*ck%20Python!&summary=An%20interesting%20collection%20of%20subtle%20and%20tricky%20Python%20snippets.)\n\n## Need a pdf version?\n\nI've received a few requests for the pdf version of wtfpython. You can add your details [here](https://satwikkansal.xyz/wtfpython-pdf/) to get the pdf as soon as it is finished.\n"}, {"repo": "trailofbits/algo", "language": "Python", "readme_contents": "# Algo VPN\n\n[![Join the chat at https://gitter.im/trailofbits/algo](https://badges.gitter.im/trailofbits/algo.svg)](https://gitter.im/trailofbits/algo?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/fold_left.svg?style=social&label=Follow%20%40AlgoVPN)](https://twitter.com/AlgoVPN)\n[![TravisCI Status](https://api.travis-ci.org/trailofbits/algo.svg?branch=master)](https://travis-ci.org/trailofbits/algo)\n\nAlgo VPN is a set of Ansible scripts that simplify the setup of a personal WireGuard and IPsec VPN. It uses the most secure defaults available and works with common cloud providers. See our [release announcement](https://blog.trailofbits.com/2016/12/12/meet-algo-the-vpn-that-works/) for more information.\n\n## Features\n\n* Supports only IKEv2 with strong crypto (AES-GCM, SHA2, and P-256) for iOS, macOS, and Linux\n* Supports [WireGuard](https://www.wireguard.com/) for all of the above, in addition to Android and Windows 10\n* Generates .conf files and QR codes for iOS, macOS, Android, and Windows WireGuard clients\n* Generates Apple profiles to auto-configure iOS and macOS devices for IPsec - no client software required\n* Includes a helper script to add and remove users\n* Blocks ads with a local DNS resolver (optional)\n* Sets up limited SSH users for tunneling traffic (optional)\n* Based on current versions of Ubuntu and strongSwan\n* Installs to DigitalOcean, Amazon Lightsail, Amazon EC2, Vultr, Microsoft Azure, Google Compute Engine, Scaleway, OpenStack, CloudStack, Hetzner Cloud, or [your own Ubuntu server](docs/deploy-to-ubuntu.md)\n\n## Anti-features\n\n* Does not support legacy cipher suites or protocols like L2TP, IKEv1, or RSA\n* Does not install Tor, OpenVPN, or other risky servers\n* Does not depend on the security of [TLS](https://tools.ietf.org/html/rfc7457)\n* Does not claim to provide anonymity or censorship avoidance\n* Does not claim to protect you from the [FSB](https://en.wikipedia.org/wiki/Federal_Security_Service), [MSS](https://en.wikipedia.org/wiki/Ministry_of_State_Security_(China)), [DGSE](https://en.wikipedia.org/wiki/Directorate-General_for_External_Security), or [FSM](https://en.wikipedia.org/wiki/Flying_Spaghetti_Monster)\n\n## Deploy the Algo Server\n\nThe easiest way to get an Algo server running is to run it on your local system and let it set up a _new_ virtual machine in the cloud for you.\n\n1. **Setup an account on a cloud hosting provider.** Algo supports [DigitalOcean](https://m.do.co/c/4d7f4ff9cfe4) (most user friendly), [Amazon Lightsail](https://aws.amazon.com/lightsail/), [Amazon EC2](https://aws.amazon.com/), [Vultr](https://www.vultr.com/), [Microsoft Azure](https://azure.microsoft.com/), [Google Compute Engine](https://cloud.google.com/compute/), [Scaleway](https://www.scaleway.com/), [DreamCompute](https://www.dreamhost.com/cloud/computing/) or other OpenStack-based cloud hosting, [Exoscale](https://www.exoscale.com) or other CloudStack-based cloud hosting,  or [Hetzner Cloud](https://www.hetzner.com/).\n\n2. **Get a copy of Algo.** The Algo scripts will be installed on your local system. There are two ways to get a copy:\n\n    - Download the [ZIP file](https://github.com/trailofbits/algo/archive/master.zip). Unzip the file to create a directory named `algo-master` containing the Algo scripts.\n\n    - Run the command `git clone https://github.com/trailofbits/algo.git` to create a directory named `algo` containing the Algo scripts.\n\n3. **Install Algo's core dependencies.** Algo requires that **Python 3.6 or later** and at least one supporting package are installed on your system.\n\n    - **macOS:** Apple does not provide a suitable version of Python 3 with macOS. Here are two ways to obtain one:\n        * Use the [Homebrew](https://brew.sh) package manager. After installing Homebrew install Python 3 by running `brew install python3`.\n\n        * Download and install the latest stable [Python 3.7.x package](https://www.python.org/downloads/mac-osx/) (currently Python 3.8 will not work). Be sure to run the included *Install Certificates* command from Finder.\n\n        See [Deploy from macOS](docs/deploy-from-macos.md) for more detailed information on installing Python 3 on macOS.\n\n        Once Python 3 is installed on your Mac, from Terminal run:\n\n        ```bash\n        python3 -m pip install --upgrade virtualenv\n        ```\n\n    - **Linux:** Recent releases of Ubuntu, Debian, and Fedora come with Python 3 already installed. Make sure your system is up-to-date and install the supporting package(s):\n        * Ubuntu and Debian:\n        ```bash\n        sudo apt install -y python3-virtualenv\n        ```\n        * Fedora:\n        ```bash\n        sudo dnf install -y python3-virtualenv\n        ```\n        * Red Hat and CentOS 7 and later (for earlier versions see this [documentation](docs/deploy-from-redhat-centos6.md)):\n        ```bash\n        sudo yum -y install epel-release\n        sudo yum install -y python36-virtualenv\n        ```\n\n    - **Windows:** Use the Windows Subsystem for Linux (WSL) to create your own copy of Ubuntu running under Windows from which to install and run Algo. See the [Windows documentation](docs/deploy-from-windows.md).\n\n4. **Install Algo's remaining dependencies.** You'll need to run these commands from the Algo directory each time you download a new copy of Algo. In a Terminal window `cd` into the `algo-master` (ZIP file) or `algo` (`git clone`) directory and run:\n    ```bash\n    python3 -m virtualenv --python=\"$(command -v python3)\" .env &&\n      source .env/bin/activate &&\n      python3 -m pip install -U pip virtualenv &&\n      python3 -m pip install -r requirements.txt\n    ```\n    On Fedora add the option `--system-site-packages` to the first command above. On macOS install the C compiler if prompted.\n\n5. **Set your configuration options.** Open the file `config.cfg` in your favorite text editor. Specify the users you wish to create in the `users` list. Create a unique user for each device you plan to connect to your VPN. If you want to be able to add or delete users later, you **must** select `yes` at the `Do you want to retain the keys (PKI)?` prompt during the deployment. You should also review the other options before deployment, as changing your mind about them later [may require you to deploy a brand new server](https://github.com/trailofbits/algo/blob/master/docs/faq.md#i-deployed-an-algo-server-can-you-update-it-with-new-features).\n\n6. **Start the deployment.** Return to your terminal. In the Algo directory, run `./algo` and follow the instructions. There are several optional features available. None are required for a fully functional VPN server. These optional features are described in greater detail in [here](docs/deploy-from-ansible.md).\n\nThat's it! You will get the message below when the server deployment process completes. Take note of the p12 (user certificate) password and the CA key in case you need them later, **they will only be displayed this time**.\n\nYou can now set up clients to connect to your VPN. Proceed to [Configure the VPN Clients](#configure-the-vpn-clients) below.\n\n```\n    \"#                          Congratulations!                            #\"\n    \"#                     Your Algo server is running.                     #\"\n    \"#    Config files and certificates are in the ./configs/ directory.    #\"\n    \"#              Go to https://whoer.net/ after connecting               #\"\n    \"#        and ensure that all your traffic passes through the VPN.      #\"\n    \"#                     Local DNS resolver 172.16.0.1                    #\"\n    \"#        The p12 and SSH keys password for new users is XXXXXXXX       #\"\n    \"#        The CA key password is XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX       #\"\n    \"#      Shell access: ssh -i configs/algo.pem root@xxx.xxx.xx.xx        #\"\n```\n\n## Configure the VPN Clients\n\nCertificates and configuration files that users will need are placed in the `configs` directory. Make sure to secure these files since many contain private keys. All files are saved under a subdirectory named with the IP address of your new Algo VPN server.\n\n### Apple Devices\n\nWireGuard is used to provide VPN services on Apple devices. Algo generates a WireGuard configuration file, `wireguard/<username>.conf`, and a QR code, `wireguard/<username>.png`, for each user defined in `config.cfg`.\n\nOn iOS, install the [WireGuard](https://itunes.apple.com/us/app/wireguard/id1441195209?mt=8) app from the iOS App Store. Then, use the WireGuard app to scan the QR code or AirDrop the configuration file to the device.\n\nOn macOS Mojave or later, install the [WireGuard](https://itunes.apple.com/us/app/wireguard/id1451685025?mt=12) app from the Mac App Store. WireGuard will appear in the menu bar once you run the app. Click on the WireGuard icon, choose **Import tunnel(s) from file...**, then select the appropriate WireGuard configuration file.\n\nOn either iOS or macOS, you can enable \"Connect on Demand\" and/or exclude certain trusted Wi-Fi networks (such as your home or work) by editing the tunnel configuration in the WireGuard app. (Algo can't do this automatically for you.)\n\nInstalling WireGuard is a little more complicated on older version of macOS. See [Using macOS as a Client with WireGuard](docs/client-macos-wireguard.md).\n\nIf you prefer to use the built-in IPSEC VPN on Apple devices, or need \"Connect on Demand\" or excluded Wi-Fi networks automatically configured, then see [Using Apple Devices as a Client with IPSEC](docs/client-apple-ipsec.md).\n\n### Android Devices\n\nWireGuard is used to provide VPN services on Android. Install the [WireGuard VPN Client](https://play.google.com/store/apps/details?id=com.wireguard.android). Import the corresponding `wireguard/<name>.conf` file to your device, then setup a new connection with it. See the [Android setup instructions](/docs/client-android.md) for more detailed walkthrough.\n\n### Windows\n\nWireGuard is used to provide VPN services on Windows. Algo generates a WireGuard configuration file, `wireguard/<username>.conf`, for each user defined in `config.cfg`.\n\nInstall the [WireGuard VPN Client](https://www.wireguard.com/install/#windows-7-8-81-10-2012-2016-2019). Import the generated `wireguard/<username>.conf` file to your device, then setup a new connection with it.\n\n### Linux WireGuard Clients\n\nWireGuard works great with Linux clients. See [this page](docs/client-linux-wireguard.md) for an example of how to configure WireGuard on Ubuntu.\n\n### Linux strongSwan IPsec Clients (e.g., OpenWRT, Ubuntu Server, etc.)\n\nPlease see [this page](docs/client-linux-ipsec.md).\n\n### Other Devices\n\nDepending on the platform, you may need one or multiple of the following files.\n\n* ipsec/manual/cacert.pem: CA Certificate\n* ipsec/manual/<user>.p12: User Certificate and Private Key (in PKCS#12 format)\n* ipsec/manual/<user>.conf: strongSwan client configuration\n* ipsec/manual/<user>.secrets: strongSwan client configuration\n* ipsec/apple/<user>.mobileconfig: Apple Profile\n* wireguard/<user>.conf: WireGuard configuration profile\n* wireguard/<user>.png: WireGuard configuration QR code\n\n## Setup an SSH Tunnel\n\nIf you turned on the optional SSH tunneling role, then local user accounts will be created for each user in `config.cfg` and SSH authorized_key files for them will be in the `configs` directory (user.ssh.pem). SSH user accounts do not have shell access, cannot authenticate with a password, and only have limited tunneling options (e.g., `ssh -N` is required). This ensures that SSH users have the least access required to setup a tunnel and can perform no other actions on the Algo server.\n\nUse the example command below to start an SSH tunnel by replacing `user` and `ip` with your own. Once the tunnel is setup, you can configure a browser or other application to use 127.0.0.1:1080 as a SOCKS proxy to route traffic through the Algo server.\n\n `ssh -D 127.0.0.1:1080 -f -q -C -N user@ip -i configs/<server_ip>/ssh-tunnel/<user>.pem`\n\n## SSH into Algo Server\n\nYour Algo server is configured for key-only SSH access for administrative purposes. Open the Terminal app, `cd` into the `algo-master` directory where you originally downloaded Algo, and then use the command listed on the success message:\n\n `ssh -i configs/algo.pem user@ip`\n\nwhere `user` is either `root` or `ubuntu` as listed on the success message, and `ip` is the IP address of your Algo server. If you find yourself regularly logging into the server then it will be useful to load your Algo ssh key automatically. Add the following snippet to the bottom of `~/.bash_profile` to add it to your shell environment permanently.\n\n `ssh-add ~/.ssh/algo > /dev/null 2>&1`\n\n## Adding or Removing Users\n\n_If you chose to save the CA key during the deploy process,_ then Algo's own scripts can easily add and remove users from the VPN server.\n\n1. Update the `users` list in your `config.cfg`\n2. Open a terminal, `cd` to the algo directory, and activate the virtual environment with `source .env/bin/activate`\n3. Run the command: `./algo update-users`\n\nAfter this process completes, the Algo VPN server will contain only the users listed in the `config.cfg` file.\n\n## Additional Documentation\n* [Deployment instructions, cloud provider setup instructions, and further client setup instructions available here.](docs/index.md)\n* [FAQ](docs/faq.md)\n* [Troubleshooting](docs/troubleshooting.md)\n\nIf you read all the documentation and have further questions, [join the chat on Gitter](https://gitter.im/trailofbits/algo).\n\n## Endorsements\n\n> I've been ranting about the sorry state of VPN svcs for so long, probably about\n> time to give a proper talk on the subject. TL;DR: use Algo.\n\n-- [Kenn White](https://twitter.com/kennwhite/status/814166603587788800)\n\n> Before picking a VPN provider/app, make sure you do some research\n> https://research.csiro.au/ng/wp-content/uploads/sites/106/2016/08/paper-1.pdf ... \u2013 or consider Algo\n\n-- [The Register](https://twitter.com/TheRegister/status/825076303657177088)\n\n> Algo is really easy and secure.\n\n-- [the grugq](https://twitter.com/thegrugq/status/786249040228786176)\n\n> I played around with Algo VPN, a set of scripts that let you set up a VPN in the cloud in very little time, even if you don\u2019t know much about development. I\u2019ve got to say that I was quite impressed with Trail of Bits\u2019 approach.\n\n-- [Romain Dillet](https://twitter.com/romaindillet/status/851037243728965632) for [TechCrunch](https://techcrunch.com/2017/04/09/how-i-made-my-own-vpn-server-in-15-minutes/)\n\n> If you\u2019re uncomfortable shelling out the cash to an anonymous, random VPN provider, this is the best solution.\n\n-- [Thorin Klosowski](https://twitter.com/kingthor) for [Lifehacker](http://lifehacker.com/how-to-set-up-your-own-completely-free-vpn-in-the-cloud-1794302432)\n\n## Support Algo VPN\n[![Flattr](https://button.flattr.com/flattr-badge-large.png)](https://flattr.com/submit/auto?fid=kxw60j&url=https%3A%2F%2Fgithub.com%2Ftrailofbits%2Falgo)\n[![PayPal](https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=CYZZD39GXUJ3E)\n[![Patreon](https://img.shields.io/badge/back_on-patreon-red.svg)](https://www.patreon.com/algovpn)\n[![Bountysource](https://img.shields.io/bountysource/team/trailofbits/activity.svg)](https://www.bountysource.com/teams/trailofbits)\n\nAll donations support continued development. Thanks!\n\n* We accept donations via [PayPal](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=CYZZD39GXUJ3E), [Patreon](https://www.patreon.com/algovpn), and [Flattr](https://flattr.com/submit/auto?fid=kxw60j&url=https%3A%2F%2Fgithub.com%2Ftrailofbits%2Falgo).\n* Use our [referral code](https://m.do.co/c/4d7f4ff9cfe4) when you sign up to Digital Ocean for a $10 credit.\n* We also accept and appreciate contributions of new code and bugfixes via Github Pull Requests.\n\nAlgo is licensed and distributed under the AGPLv3. If you want to distribute a closed-source modification or service based on Algo, then please consider <a href=\"mailto:opensource@trailofbits.com\">purchasing an exception</a> . As with the methods above, this will help support continued development.\n"}, {"repo": "odoo/odoo", "language": "Python", "readme_contents": "[![Build Status](http://runbot.odoo.com/runbot/badge/flat/1/master.svg)](http://runbot.odoo.com/runbot)\n[![Tech Doc](http://img.shields.io/badge/master-docs-875A7B.svg?style=flat&colorA=8F8F8F)](http://www.odoo.com/documentation/master)\n[![Help](http://img.shields.io/badge/master-help-875A7B.svg?style=flat&colorA=8F8F8F)](https://www.odoo.com/forum/help-1)\n[![Nightly Builds](http://img.shields.io/badge/master-nightly-875A7B.svg?style=flat&colorA=8F8F8F)](http://nightly.odoo.com/)\n\nOdoo\n----\n\nOdoo is a suite of web based open source business apps.\n\nThe main Odoo Apps include an <a href=\"https://www.odoo.com/page/crm\">Open Source CRM</a>,\n<a href=\"https://www.odoo.com/page/website-builder\">Website Builder</a>,\n<a href=\"https://www.odoo.com/page/e-commerce\">eCommerce</a>,\n<a href=\"https://www.odoo.com/page/warehouse\">Warehouse Management</a>,\n<a href=\"https://www.odoo.com/page/project-management\">Project Management</a>,\n<a href=\"https://www.odoo.com/page/accounting\">Billing &amp; Accounting</a>,\n<a href=\"https://www.odoo.com/page/point-of-sale\">Point of Sale</a>,\n<a href=\"https://www.odoo.com/page/employees\">Human Resources</a>,\n<a href=\"https://www.odoo.com/page/lead-automation\">Marketing</a>,\n<a href=\"https://www.odoo.com/page/manufacturing\">Manufacturing</a>,\n<a href=\"https://www.odoo.com/#apps\">...</a>\n\nOdoo Apps can be used as stand-alone applications, but they also integrate seamlessly so you get\na full-featured <a href=\"https://www.odoo.com\">Open Source ERP</a> when you install several Apps.\n\n\nGetting started with Odoo\n-------------------------\nFor a standard installation please follow the <a href=\"https://www.odoo.com/documentation/master/setup/install.html\">Setup instructions</a>\nfrom the documentation.\n\nTo learn the software, we recommend the <a href=\"https://www.odoo.com/slides\">Odoo eLearning</a>, or <a href=\"https://www.odoo.com/page/scale-up-business-game\">Scale-up</a>, the <a href=\"https://www.odoo.com/page/scale-up-business-game\">business game</a>. Developers can start with <a href=\"https://www.odoo.com/documentation/master/tutorials.html\">the developer tutorials</a>\n"}, {"repo": "encode/django-rest-framework", "language": "Python", "readme_contents": "# [Django REST framework][docs]\n\n[![build-status-image]][travis]\n[![coverage-status-image]][codecov]\n[![pypi-version]][pypi]\n\n**Awesome web-browsable Web APIs.**\n\nFull documentation for the project is available at [https://www.django-rest-framework.org/][docs].\n\n---\n\n# Funding\n\nREST framework is a *collaboratively funded project*. If you use\nREST framework commercially we strongly encourage you to invest in its\ncontinued development by [signing up for a paid plan][funding].\n\nThe initial aim is to provide a single full-time position on REST framework.\n*Every single sign-up makes a significant impact towards making that possible.*\n\n[![][sentry-img]][sentry-url]\n[![][stream-img]][stream-url]\n[![][rollbar-img]][rollbar-url]\n[![][cadre-img]][cadre-url]\n[![][kloudless-img]][kloudless-url]\n[![][esg-img]][esg-url]\n[![][lightson-img]][lightson-url]\n[![][retool-img]][retool-url]\n\nMany thanks to all our [wonderful sponsors][sponsors], and in particular to our premium backers, [Sentry][sentry-url], [Stream][stream-url], [Rollbar][rollbar-url], [Cadre][cadre-url], [Kloudless][kloudless-url], [ESG][esg-url], [Lights On Software][lightson-url], and [Retool][retool-url].\n\n---\n\n# Overview\n\nDjango REST framework is a powerful and flexible toolkit for building Web APIs.\n\nSome reasons you might want to use REST framework:\n\n* The [Web browsable API][sandbox] is a huge usability win for your developers.\n* [Authentication policies][authentication] including optional packages for [OAuth1a][oauth1-section] and [OAuth2][oauth2-section].\n* [Serialization][serializers] that supports both [ORM][modelserializer-section] and [non-ORM][serializer-section] data sources.\n* Customizable all the way down - just use [regular function-based views][functionview-section] if you don't need the [more][generic-views] [powerful][viewsets] [features][routers].\n* [Extensive documentation][docs], and [great community support][group].\n\nThere is a live example API for testing purposes, [available here][sandbox].\n\n**Below**: *Screenshot from the browsable API*\n\n![Screenshot][image]\n\n----\n\n# Requirements\n\n* Python (3.5, 3.6, 3.7)\n* Django (1.11, 2.0, 2.1, 2.2)\n\nWe **highly recommend** and only officially support the latest patch release of\neach Python and Django series.\n\n# Installation\n\nInstall using `pip`...\n\n    pip install djangorestframework\n\nAdd `'rest_framework'` to your `INSTALLED_APPS` setting.\n\n    INSTALLED_APPS = [\n        ...\n        'rest_framework',\n    ]\n\n# Example\n\nLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.\n\nStartup up a new project like so...\n\n    pip install django\n    pip install djangorestframework\n    django-admin startproject example .\n    ./manage.py migrate\n    ./manage.py createsuperuser\n\n\nNow edit the `example/urls.py` module in your project:\n\n```python\nfrom django.conf.urls import url, include\nfrom django.contrib.auth.models import User\nfrom rest_framework import serializers, viewsets, routers\n\n# Serializers define the API representation.\nclass UserSerializer(serializers.HyperlinkedModelSerializer):\n    class Meta:\n        model = User\n        fields = ['url', 'username', 'email', 'is_staff']\n\n\n# ViewSets define the view behavior.\nclass UserViewSet(viewsets.ModelViewSet):\n    queryset = User.objects.all()\n    serializer_class = UserSerializer\n\n\n# Routers provide a way of automatically determining the URL conf.\nrouter = routers.DefaultRouter()\nrouter.register(r'users', UserViewSet)\n\n\n# Wire up our API using automatic URL routing.\n# Additionally, we include login URLs for the browsable API.\nurlpatterns = [\n    url(r'^', include(router.urls)),\n    url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework'))\n]\n```\n\nWe'd also like to configure a couple of settings for our API.\n\nAdd the following to your `settings.py` module:\n\n```python\nINSTALLED_APPS = [\n    ...  # Make sure to include the default installed apps here.\n    'rest_framework',\n]\n\nREST_FRAMEWORK = {\n    # Use Django's standard `django.contrib.auth` permissions,\n    # or allow read-only access for unauthenticated users.\n    'DEFAULT_PERMISSION_CLASSES': [\n        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly'\n    ]\n}\n```\n\nThat's it, we're done!\n\n    ./manage.py runserver\n\nYou can now open the API in your browser at `http://127.0.0.1:8000/`, and view your new 'users' API. If you use the `Login` control in the top right corner you'll also be able to add, create and delete users from the system.\n\nYou can also interact with the API using command line tools such as [`curl`](https://curl.haxx.se/). For example, to list the users endpoint:\n\n    $ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/\n    [\n        {\n            \"url\": \"http://127.0.0.1:8000/users/1/\",\n            \"username\": \"admin\",\n            \"email\": \"admin@example.com\",\n            \"is_staff\": true,\n        }\n    ]\n\nOr to create a new user:\n\n    $ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/\n    {\n        \"url\": \"http://127.0.0.1:8000/users/2/\",\n        \"username\": \"new\",\n        \"email\": \"new@example.com\",\n        \"is_staff\": false,\n    }\n\n# Documentation & Support\n\nFull documentation for the project is available at [https://www.django-rest-framework.org/][docs].\n\nFor questions and support, use the [REST framework discussion group][group], or `#restframework` on freenode IRC.\n\nYou may also want to [follow the author on Twitter][twitter].\n\n# Security\n\nPlease see the [security policy][security-policy].\n\n[build-status-image]: https://secure.travis-ci.org/encode/django-rest-framework.svg?branch=master\n[travis]: https://travis-ci.org/encode/django-rest-framework?branch=master\n[coverage-status-image]: https://img.shields.io/codecov/c/github/encode/django-rest-framework/master.svg\n[codecov]: https://codecov.io/github/encode/django-rest-framework?branch=master\n[pypi-version]: https://img.shields.io/pypi/v/djangorestframework.svg\n[pypi]: https://pypi.org/project/djangorestframework/\n[twitter]: https://twitter.com/_tomchristie\n[group]: https://groups.google.com/forum/?fromgroups#!forum/django-rest-framework\n[sandbox]: https://restframework.herokuapp.com/\n\n[funding]: https://fund.django-rest-framework.org/topics/funding/\n[sponsors]: https://fund.django-rest-framework.org/topics/funding/#our-sponsors\n\n[rover-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/rover-readme.png\n[sentry-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/sentry-readme.png\n[stream-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/stream-readme.png\n[rollbar-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/rollbar-readme.png\n[cadre-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/cadre-readme.png\n[load-impact-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/load-impact-readme.png\n[kloudless-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/kloudless-readme.png\n[esg-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/esg-readme.png\n[lightson-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/lightson-readme.png\n[retool-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/retool-readme.png\n\n[sentry-url]: https://getsentry.com/welcome/\n[stream-url]: https://getstream.io/try-the-api/?utm_source=drf&utm_medium=banner&utm_campaign=drf\n[rollbar-url]: https://rollbar.com/?utm_source=django&utm_medium=sponsorship&utm_campaign=freetrial\n[cadre-url]: https://cadre.com/\n[kloudless-url]: https://hubs.ly/H0f30Lf0\n[esg-url]: https://software.esg-usa.com/\n[lightson-url]: https://lightsonsoftware.com\n[retool-url]: https://retool.com/?utm_source=djangorest&utm_medium=sponsorship\n\n[oauth1-section]: https://www.django-rest-framework.org/api-guide/authentication/#django-rest-framework-oauth\n[oauth2-section]: https://www.django-rest-framework.org/api-guide/authentication/#django-oauth-toolkit\n[serializer-section]: https://www.django-rest-framework.org/api-guide/serializers/#serializers\n[modelserializer-section]: https://www.django-rest-framework.org/api-guide/serializers/#modelserializer\n[functionview-section]: https://www.django-rest-framework.org/api-guide/views/#function-based-views\n[generic-views]: https://www.django-rest-framework.org/api-guide/generic-views/\n[viewsets]: https://www.django-rest-framework.org/api-guide/viewsets/\n[routers]: https://www.django-rest-framework.org/api-guide/routers/\n[serializers]: https://www.django-rest-framework.org/api-guide/serializers/\n[authentication]: https://www.django-rest-framework.org/api-guide/authentication/\n[image]: https://www.django-rest-framework.org/img/quickstart.png\n\n[docs]: https://www.django-rest-framework.org/\n[security-policy]: https://github.com/encode/django-rest-framework/security/policy\n"}, {"repo": "google/python-fire", "language": "Python", "readme_contents": "# Python Fire [![PyPI](https://img.shields.io/pypi/pyversions/fire.svg?style=plastic)](https://github.com/google/python-fire) [![PyPI version](https://badge.fury.io/py/fire.svg)](https://badge.fury.io/py/fire)\n_Python Fire is a library for automatically generating command line interfaces\n(CLIs) from absolutely any Python object._\n\n- Python Fire is a simple way to create a CLI in Python. [[1]](docs/benefits.md#simple-cli)\n- Python Fire is a helpful tool for developing and debugging Python code. [[2]](docs/benefits.md#debugging)\n- Python Fire helps with exploring existing code or turning other people's code\ninto a CLI. [[3]](docs/benefits.md#exploring)\n- Python Fire makes transitioning between Bash and Python easier. [[4]](docs/benefits.md#bash)\n- Python Fire makes using a Python REPL easier by setting up the REPL with the\nmodules and variables you'll need already imported and created. [[5]](docs/benefits.md#repl)\n\n\n## Installation\n\nTo install Python Fire with pip, run: `pip install fire`\n\nTo install Python Fire with conda, run: `conda install fire -c conda-forge`\n\nTo install Python Fire from source, first clone the repository and then run:\n`python setup.py install`\n\n\n## Basic Usage\n\nYou can call `Fire` on any Python object:<br>\nfunctions, classes, modules, objects, dictionaries, lists, tuples, etc.\nThey all work!\n\nHere's an example of calling Fire on a function.\n\n```python\nimport fire\n\ndef hello(name=\"World\"):\n  return \"Hello %s!\" % name\n\nif __name__ == '__main__':\n  fire.Fire(hello)\n```\n\nThen, from the command line, you can run:\n\n```bash\npython hello.py  # Hello World!\npython hello.py --name=David  # Hello David!\npython hello.py --help  # Shows usage information.\n```\n\nHere's an example of calling Fire on a class.\n\n```python\nimport fire\n\nclass Calculator(object):\n  \"\"\"A simple calculator class.\"\"\"\n\n  def double(self, number):\n    return 2 * number\n\nif __name__ == '__main__':\n  fire.Fire(Calculator)\n```\n\nThen, from the command line, you can run:\n\n```bash\npython calculator.py double 10  # 20\npython calculator.py double --number=15  # 30\n```\n\nTo learn how Fire behaves on functions, objects, dicts, lists, etc, and to learn\nabout Fire's other features, see the [Using a Fire CLI page](docs/using-cli.md).\n\nFor additional examples, see [The Python Fire Guide](docs/guide.md).\n\n\n## Why is it called Fire?\n\nWhen you call `Fire`, it fires off (executes) your command.\n\n\n## Where can I learn more?\n\nPlease see [The Python Fire Guide](docs/guide.md).\n\n\n## Reference\n\n| Setup   | Command             | Notes\n| :------ | :------------------ | :---------\n| install | `pip install fire`  |\n\n| Creating a CLI | Command                | Notes\n| :--------------| :--------------------- | :---------\n| import         | `import fire`          |\n| Call           | `fire.Fire()`          | Turns the current module into a Fire CLI.\n| Call           | `fire.Fire(component)` | Turns `component` into a Fire CLI.\n\nUsing a CLI                                     | Command                                 | Notes\n:---------------------------------------------- | :-------------------------------------- | :----\n[Help](docs/using-cli.md#help-flag)             | `command --help` or `command -- --help` |\n[REPL](docs/using-cli.md#interactive-flag)      | `command -- --interactive`              | Enters interactive mode.\n[Separator](docs/using-cli.md#separator-flag)   | `command -- --separator=X`              | Sets the separator to `X`. The default separator is `-`.\n[Completion](docs/using-cli.md#completion-flag) | `command -- --completion [shell]`       | Generates a completion script for the CLI.\n[Trace](docs/using-cli.md#trace-flag)           | `command -- --trace`                    | Gets a Fire trace for the command.\n[Verbose](docs/using-cli.md#verbose-flag)       | `command -- --verbose`                  |\n\n_Note that these flags are separated from the Fire command by an isolated `--`._\n\n## License\n\nLicensed under the\n[Apache 2.0](https://github.com/google/python-fire/blob/master/LICENSE) License.\n\n## Disclaimer\n\nThis is not an official Google product.\n"}, {"repo": "geekcomputers/Python", "language": "Python", "readme_contents": "\n# My Python Examples\n\nI do not consider myself a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me at craig@geekcomputers.co.uk.\n\nThese scripts contain important functions which help reduce human workload.\nCode documentation is aligned correctly when the files are viewed in [Notepad++](https://notepad-plus-plus.org/).\n\n- [batch_file_rename.py](https://github.com/geekcomputers/Python/blob/master/batch_file_rename.py) - This batch renames a group of files in a given directory, once you pass the current and the new extensions.\n\n- [create_dir_if_not_there.py](https://github.com/geekcomputers/Python/blob/master/create_dir_if_not_there.py) - Checks to see if a directory exists in the users home directory. If a directory does not exist, then one will be created.\n\n- [Fast Youtube Downloader](https://github.com/geekcomputers/Python/blob/master/youtube-downloader%20fast.py) - Downloads YouTube videos quickly with parallel threads using aria2c.\n\n- [Google Image Downloader](https://github.com/geekcomputers/Python/tree/master/Google_Image_Downloader) - Query a given term and retrieve images from the Google Image database.\n\n- [dir_test.py](https://github.com/geekcomputers/Python/blob/master/dir_test.py) - Tests to see if the directory `testdir` exists, if not it will create the directory for you.\n\n- [env_check.py](https://github.com/geekcomputers/Python/blob/master/env_check.py) - This script will check to see if all of the environment variables required are set.\n\n- [blackjack.py](https://github.com/Ratna04priya/Python/blob/master/BlackJack_game/blackjack.py) - This script contains the Casino BlackJack-21 Game in Python.\n\n- [fileinfo.py](https://github.com/geekcomputers/Python/blob/master/fileinfo.py) - Shows file information for a given file.\n\n- [folder_size.py](https://github.com/geekcomputers/Python/blob/master/folder_size.py) - Scans the current directory and all subdirectories and displays the size.\n\n- [logs.py](https://github.com/geekcomputers/Python/blob/master/logs.py) - This script will search for all `*.log` files in the given directory, zip them using the program you specify, and then date stamp them.\n\n- [move_files_over_x_days.py](https://github.com/geekcomputers/Python/blob/master/move_files_over_x_days.py) - Moves all files over a specified age (in days) from the source directory to the destination directory.\n\n- [nslookup_check.py](https://github.com/geekcomputers/Python/blob/master/nslookup_check.py) - This simple script opens the file `server_list.txt` and then does an nslookup for each one to check the DNS entry.\n\n- [osinfo.py](https://github.com/geekcomputers/Python/blob/master/osinfo.py) - Displays some information about the OS on which you are running this script.\n\n- [ping_servers.py](https://github.com/geekcomputers/Python/blob/master/ping_servers.py) - This script, depending on the arguments supplied, will ping the servers associated with that application group.\n\n- [ping_subnet.py](https://github.com/geekcomputers/Python/blob/master/ping_subnet.py) - After supplying the first 3 octets this file scans the final range for available addresses.\n\n- [powerdown_startup.py](https://github.com/geekcomputers/Python/blob/master/powerdown_startup.py) - This file goes through the server list and pings the machine, if it is up it will load the putty session, if it is not it will notify you.\n\n- [puttylogs.py](https://github.com/geekcomputers/Python/blob/master/puttylogs.py) -  This file zips up all the logs in the given directory.\n\n- [script_count.py](https://github.com/geekcomputers/Python/blob/master/script_count.py) - This file scans the scripts directory and gives a count of the different types of scripts.\n\n- [get_youtube_view.py] - This is a simple python script used to get more views on your youtube videos. This script may also be used to repeat songs on Youtube. \n\n- [script_listing.py](https://github.com/geekcomputers/Python/blob/master/script_listing.py) - This file will list all the files in the given directory, and go through all the subdirectories as well.\n\n- [testlines.py](https://github.com/geekcomputers/Python/blob/master/testlines.py) - This simple script opens a file and prints out 100 lines of whatever is the set for the line variable.\n\n- [tweeter.py](https://github.com/geekcomputers/Python/blob/master/tweeter.py) - Allows you to tweet text or a picture from the terminal.\n\n- [serial_scanner.py](https://github.com/geekcomputers/Python/blob/master/serial_scanner.py) contains a method called ListAvailablePorts which returns a list with the names of the serial ports that are in use in the computer. This method works only on Linux and Windows (can be extended for mac osx). If no port is found, an empty list is returned.\n\n- [get_youtube_view.py](https://github.com/geekcomputers/Python/blob/master/get_youtube_view.py) - A simple python script to get more views for your YouTube videos. Useful for repeating songs on YouTube.\n\n- [CountMillionCharacter.py](https://github.com/geekcomputers/Python/blob/master/CountMillionCharacter.py) And [CountMillionCharacter2.0](https://github.com/geekcomputers/Python/blob/master/CountMillionCharacters-2.0.py).py - Gets character count of a text file.\n\n- [xkcd_downloader.py](https://github.com/geekcomputers/Python/blob/master/xkcd_downloader.py) - Downloads the latest XKCD comic and places them in a new folder called \"comics\".\n\n- [timymodule.py](https://github.com/geekcomputers/Python/blob/master/timymodule.py) - A great alternative to Pythons 'timeit' module and easier to use.\n\n- [calculator.py](https://github.com/geekcomputers/Python/blob/master/calculator.py) - Uses Python's eval() function to implement a calculator.\n\n- [Google_News.py](https://github.com/geekcomputers/Python/blob/master/Google_News.py) - Uses BeautifulSoup to provide Latest news headline along with news link.\n\n- [cricket_live_score](https://github.com/geekcomputers/Python/blob/master/Cricket_score.py) - Uses BeautifulSoup to provide live cricket score.\n\n- [youtube.py](https://github.com/geekcomputers/Python/blob/master/youtube.py) - Takes a song name as input and fetches the YouTube URL of the best matching song and plays it.  \n\n- [site_health.py](https://github.com/geekcomputers/Python/blob/master/site_health.py) - Checks the health of a remote server\n\n- [SimpleStopWatch.py](https://github.com/geekcomputers/Python/blob/master/SimpleStopWatch.py) - Simple Stop Watch implementation using Python's time module. \n\n- [Changemac.py](https://github.com/geekcomputers/Python/blob/master/changemac.py) - This script change your MAC address , generate random MAC address or enter input as new MAC address in your linux(Successfully Tested in Ubuntu 18.04). \n- [whatsapp-monitor.py](https://github.com/geekcomputers/Python/blob/master/whatsapp-monitor.py) - Uses Selenium to give online status about your contacts when your contacts become online in whatsapp you will get an update about it on terminal.\n\n- [whatsapp-chat-analyzer.py](https://github.com/subahanii/whatsapp-Chat-Analyzer) - This is whatsapp group/individual chat analyzer .\nThis script is able to analyse all activity happened in whatsapp group and visualize all thing through matplotlib library(In Graph form).\n\n- [JARVIS.py](https://git.io/fjH8m) - Control windows programs with your voice."}, {"repo": "sqlmapproject/sqlmap", "language": "Python", "readme_contents": "# sqlmap ![](https://i.imgur.com/fe85aVR.png)\n\n[![Build Status](https://api.travis-ci.org/sqlmapproject/sqlmap.svg?branch=master)](https://travis-ci.org/sqlmapproject/sqlmap) [![Python 2.6|2.7|3.x](https://img.shields.io/badge/python-2.6|2.7|3.x-yellow.svg)](https://www.python.org/) [![License](https://img.shields.io/badge/license-GPLv2-red.svg)](https://raw.githubusercontent.com/sqlmapproject/sqlmap/master/LICENSE) [![PyPI version](https://badge.fury.io/py/sqlmap.svg)](https://badge.fury.io/py/sqlmap) [![GitHub closed issues](https://img.shields.io/github/issues-closed-raw/sqlmapproject/sqlmap.svg?colorB=ff69b4)](https://github.com/sqlmapproject/sqlmap/issues?q=is%3Aissue+is%3Aclosed) [![Twitter](https://img.shields.io/badge/twitter-@sqlmap-blue.svg)](https://twitter.com/sqlmap)\n\nsqlmap is an open source penetration testing tool that automates the process of detecting and exploiting SQL injection flaws and taking over of database servers. It comes with a powerful detection engine, many niche features for the ultimate penetration tester, and a broad range of switches including database fingerprinting, over data fetching from the database, accessing the underlying file system, and executing commands on the operating system via out-of-band connections.\n\n**The sqlmap project is currently searching for sponsor(s).**\n\nScreenshots\n----\n\n![Screenshot](https://raw.github.com/wiki/sqlmapproject/sqlmap/images/sqlmap_screenshot.png)\n\nYou can visit the [collection of screenshots](https://github.com/sqlmapproject/sqlmap/wiki/Screenshots) demonstrating some of the features on the wiki.\n\nInstallation\n----\n\nYou can download the latest tarball by clicking [here](https://github.com/sqlmapproject/sqlmap/tarball/master) or latest zipball by clicking  [here](https://github.com/sqlmapproject/sqlmap/zipball/master).\n\nPreferably, you can download sqlmap by cloning the [Git](https://github.com/sqlmapproject/sqlmap) repository:\n\n    git clone --depth 1 https://github.com/sqlmapproject/sqlmap.git sqlmap-dev\n\nsqlmap works out of the box with [Python](http://www.python.org/download/) version **2.6**, **2.7** and **3.x** on any platform.\n\nUsage\n----\n\nTo get a list of basic options and switches use:\n\n    python sqlmap.py -h\n\nTo get a list of all options and switches use:\n\n    python sqlmap.py -hh\n\nYou can find a sample run [here](https://asciinema.org/a/46601).\nTo get an overview of sqlmap capabilities, a list of supported features, and a description of all options and switches, along with examples, you are advised to consult the [user's manual](https://github.com/sqlmapproject/sqlmap/wiki/Usage).\n\nLinks\n----\n\n* Homepage: http://sqlmap.org\n* Download: [.tar.gz](https://github.com/sqlmapproject/sqlmap/tarball/master) or [.zip](https://github.com/sqlmapproject/sqlmap/zipball/master)\n* Commits RSS feed: https://github.com/sqlmapproject/sqlmap/commits/master.atom\n* Issue tracker: https://github.com/sqlmapproject/sqlmap/issues\n* User's manual: https://github.com/sqlmapproject/sqlmap/wiki\n* Frequently Asked Questions (FAQ): https://github.com/sqlmapproject/sqlmap/wiki/FAQ\n* Twitter: [@sqlmap](https://twitter.com/sqlmap)\n* Demos: [http://www.youtube.com/user/inquisb/videos](http://www.youtube.com/user/inquisb/videos)\n* Screenshots: https://github.com/sqlmapproject/sqlmap/wiki/Screenshots\n\nTranslations\n----\n\n* [Bulgarian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-bg-BG.md)\n* [Chinese](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-zh-CN.md)\n* [Croatian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-hr-HR.md)\n* [French](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-fr-FR.md)\n* [German](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-de-GER.md)\n* [Greek](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-gr-GR.md)\n* [Indonesian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-id-ID.md)\n* [Italian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-it-IT.md)\n* [Japanese](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ja-JP.md)\n* [Korean](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ko-KR.md)\n* [Polish](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-pl-PL.md)\n* [Portuguese](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-pt-BR.md)\n* [Russian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ru-RUS.md)\n* [Spanish](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-es-MX.md)\n* [Turkish](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-tr-TR.md)\n* [Ukrainian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-uk-UA.md)\n"}, {"repo": "reddit-archive/reddit", "language": "Python", "readme_contents": "## This repository is archived.\n\nThis repository is archived and will not receive any updates or accept issues or pull requests.\n\nTo report bugs in reddit.com please make a post in [/r/bugs](http://www.reddit.com/r/bugs).\n\nIf you have found a bug that can in some way compromise the security of the\nsite or its users, please exercise [responsible\ndisclosure](http://www.reddit.com/wiki/whitehat) and e-mail\nsecurity@reddit.com.\n\n---\n\n### API\n\nFor notices about reddit API changes and discussion of reddit API client development, subscribe to the [/r/redditdev](http://www.reddit.com/r/redditdev) and [/r/changelog](http://www.reddit.com/r/changelog) subreddits.\n\nTo learn more about reddit's API, check out our [automated API documentation](http://www.reddit.com/dev/api) and the [API wiki page](https://github.com/reddit/reddit/wiki/API). Please use a unique User-Agent string and take care to abide by our [API rules](https://github.com/reddit/reddit/wiki/API#wiki-rules).\n\n### Quickstart\n\nTo set up your own instance of reddit see the [install guide](https://github.com/reddit/reddit/wiki/Install-guide).\n"}, {"repo": "d2l-ai/d2l-zh", "language": "Python", "readme_contents": "# \u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\n\n[![Build Status](http://ci.d2l.ai/job/d2l-zh/job/master/badge/icon)](http://ci.d2l.ai/job/d2l-zh/job/master/)\n\n[\u672c\u4e66\u7f51\u5740\uff1azh.d2l.ai](https://zh.d2l.ai/) | [1.0.0\u7248rc0\u53d1\u5e03](https://github.com/d2l-ai/d2l-zh/releases/tag/v1.0.0-rc0) | [\u5982\u4f55\u5b89\u88c5\u548c\u4f7f\u7528\u4e66\u4e2d\u6e90\u4ee3\u7801](https://zh.d2l.ai/chapter_prerequisite/install.html)\n\n## \u66f4\u65b0\n\n\u82f1\u6587\u7248\u5168\u9762\u6539\u8fdb\u4e86[\u9884\u5907\u77e5\u8bc6](https://d2l.ai/chapter_preliminaries/index.html)\u4e00\u7ae0\uff0c\n\u65b0\u589e\u4e86[\u63a8\u8350\u7cfb\u7edf](https://d2l.ai/chapter_recommender-systems/index.html)\u4e00\u7ae0\u548c<a href=\"https://d2l.ai/chapter_appendix_math/index.html\">\u6df1\u5ea6\u5b66\u4e60\u7684\u6570\u5b66</a>\u4e00\u7ae0\u3002\n\u6b22\u8fce\u5173\u6ce8\u82f1\u6587\u7248\u5f00\u6e90\u9879\u76ee\uff1a[https://github.com/d2l-ai/d2l-en](https://github.com/d2l-ai/d2l-en)\n\n## \u82f1\u6587\u7248 *Dive into Deep Learning*\n\n\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821 2019 \u5e74\u6625\u5b66\u671f [*Introduction to Deep Learning* \u8bfe\u7a0b](http://courses.d2l.ai/berkeley-stat-157/index.html)\u6559\u6750\uff08[\u4e2d\u6587\u7248\u8bfe\u4ef6\uff08\u5185\u542b\u6559\u5b66\u89c6\u9891\u5730\u5740\uff09](https://github.com/d2l-ai/berkeley-stat-157/tree/master/slides-zh)\uff09\u3002\n\n### \u82f1\u6587\u7248\u5f15\u7528\n\nBibTeX entry:\n\n```\n@book{zhang2019dive,\n    title={Dive into Deep Learning},\n    author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},\n    note={\\url{http://www.d2l.ai}},\n    year={2019}\n}\n```\n\n\n## \u8d21\u732e\n\n\u611f\u8c22[\u793e\u533a\u8d21\u732e\u8005\u4eec](https://github.com/d2l-ai/d2l-zh/graphs/contributors)\u4e3a\u6bcf\u4e00\u4f4d\u8bfb\u8005\u6539\u8fdb\u8fd9\u672c\u5f00\u6e90\u4e66\u3002\n\n[\u5982\u4f55\u8d21\u732e](https://zh.d2l.ai/chapter_appendix/how-to-contribute.html) | [\u81f4\u8c22](https://zh.d2l.ai/chapter_preface/preface.html#\u81f4\u8c22) | [\u8ba8\u8bba\u6216\u62a5\u544a\u95ee\u9898](https://discuss.gluon.ai) | [\u5176\u4ed6](INFO.md)\n"}, {"repo": "matterport/Mask_RCNN", "language": "Python", "readme_contents": "# Mask R-CNN for Object Detection and Segmentation\n\nThis is an implementation of [Mask R-CNN](https://arxiv.org/abs/1703.06870) on Python 3, Keras, and TensorFlow. The model generates bounding boxes and segmentation masks for each instance of an object in the image. It's based on Feature Pyramid Network (FPN) and a ResNet101 backbone.\n\n![Instance Segmentation Sample](assets/street.png)\n\nThe repository includes:\n* Source code of Mask R-CNN built on FPN and ResNet101.\n* Training code for MS COCO\n* Pre-trained weights for MS COCO\n* Jupyter notebooks to visualize the detection pipeline at every step\n* ParallelModel class for multi-GPU training\n* Evaluation on MS COCO metrics (AP)\n* Example of training on your own dataset\n\n\nThe code is documented and designed to be easy to extend. If you use it in your research, please consider citing this repository (bibtex below). If you work on 3D vision, you might find our recently released [Matterport3D](https://matterport.com/blog/2017/09/20/announcing-matterport3d-research-dataset/) dataset useful as well.\nThis dataset was created from 3D-reconstructed spaces captured by our customers who agreed to make them publicly available for academic use. You can see more examples [here](https://matterport.com/gallery/).\n\n# Getting Started\n* [demo.ipynb](samples/demo.ipynb) Is the easiest way to start. It shows an example of using a model pre-trained on MS COCO to segment objects in your own images.\nIt includes code to run object detection and instance segmentation on arbitrary images.\n\n* [train_shapes.ipynb](samples/shapes/train_shapes.ipynb) shows how to train Mask R-CNN on your own dataset. This notebook introduces a toy dataset (Shapes) to demonstrate training on a new dataset.\n\n* ([model.py](mrcnn/model.py), [utils.py](mrcnn/utils.py), [config.py](mrcnn/config.py)): These files contain the main Mask RCNN implementation. \n\n\n* [inspect_data.ipynb](samples/coco/inspect_data.ipynb). This notebook visualizes the different pre-processing steps\nto prepare the training data.\n\n* [inspect_model.ipynb](samples/coco/inspect_model.ipynb) This notebook goes in depth into the steps performed to detect and segment objects. It provides visualizations of every step of the pipeline.\n\n* [inspect_weights.ipynb](samples/coco/inspect_weights.ipynb)\nThis notebooks inspects the weights of a trained model and looks for anomalies and odd patterns.\n\n\n# Step by Step Detection\nTo help with debugging and understanding the model, there are 3 notebooks \n([inspect_data.ipynb](samples/coco/inspect_data.ipynb), [inspect_model.ipynb](samples/coco/inspect_model.ipynb),\n[inspect_weights.ipynb](samples/coco/inspect_weights.ipynb)) that provide a lot of visualizations and allow running the model step by step to inspect the output at each point. Here are a few examples:\n\n\n\n## 1. Anchor sorting and filtering\nVisualizes every step of the first stage Region Proposal Network and displays positive and negative anchors along with anchor box refinement.\n![](assets/detection_anchors.png)\n\n## 2. Bounding Box Refinement\nThis is an example of final detection boxes (dotted lines) and the refinement applied to them (solid lines) in the second stage.\n![](assets/detection_refinement.png)\n\n## 3. Mask Generation\nExamples of generated masks. These then get scaled and placed on the image in the right location.\n\n![](assets/detection_masks.png)\n\n## 4.Layer activations\nOften it's useful to inspect the activations at different layers to look for signs of trouble (all zeros or random noise).\n\n![](assets/detection_activations.png)\n\n## 5. Weight Histograms\nAnother useful debugging tool is to inspect the weight histograms. These are included in the inspect_weights.ipynb notebook.\n\n![](assets/detection_histograms.png)\n\n## 6. Logging to TensorBoard\nTensorBoard is another great debugging and visualization tool. The model is configured to log losses and save weights at the end of every epoch.\n\n![](assets/detection_tensorboard.png)\n\n## 6. Composing the different pieces into a final result\n\n![](assets/detection_final.png)\n\n\n# Training on MS COCO\nWe're providing pre-trained weights for MS COCO to make it easier to start. You can\nuse those weights as a starting point to train your own variation on the network.\nTraining and evaluation code is in `samples/coco/coco.py`. You can import this\nmodule in Jupyter notebook (see the provided notebooks for examples) or you\ncan run it directly from the command line as such:\n\n```\n# Train a new model starting from pre-trained COCO weights\npython3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=coco\n\n# Train a new model starting from ImageNet weights\npython3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=imagenet\n\n# Continue training a model that you had trained earlier\npython3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=/path/to/weights.h5\n\n# Continue training the last model you trained. This will find\n# the last trained weights in the model directory.\npython3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=last\n```\n\nYou can also run the COCO evaluation code with:\n```\n# Run COCO evaluation on the last trained model\npython3 samples/coco/coco.py evaluate --dataset=/path/to/coco/ --model=last\n```\n\nThe training schedule, learning rate, and other parameters should be set in `samples/coco/coco.py`.\n\n\n# Training on Your Own Dataset\n\nStart by reading this [blog post about the balloon color splash sample](https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46). It covers the process starting from annotating images to training to using the results in a sample application.\n\nIn summary, to train the model on your own dataset you'll need to extend two classes:\n\n```Config```\nThis class contains the default configuration. Subclass it and modify the attributes you need to change.\n\n```Dataset```\nThis class provides a consistent way to work with any dataset. \nIt allows you to use new datasets for training without having to change \nthe code of the model. It also supports loading multiple datasets at the\nsame time, which is useful if the objects you want to detect are not \nall available in one dataset. \n\nSee examples in `samples/shapes/train_shapes.ipynb`, `samples/coco/coco.py`, `samples/balloon/balloon.py`, and `samples/nucleus/nucleus.py`.\n\n## Differences from the Official Paper\nThis implementation follows the Mask RCNN paper for the most part, but there are a few cases where we deviated in favor of code simplicity and generalization. These are some of the differences we're aware of. If you encounter other differences, please do let us know.\n\n* **Image Resizing:** To support training multiple images per batch we resize all images to the same size. For example, 1024x1024px on MS COCO. We preserve the aspect ratio, so if an image is not square we pad it with zeros. In the paper the resizing is done such that the smallest side is 800px and the largest is trimmed at 1000px.\n* **Bounding Boxes**: Some datasets provide bounding boxes and some provide masks only. To support training on multiple datasets we opted to ignore the bounding boxes that come with the dataset and generate them on the fly instead. We pick the smallest box that encapsulates all the pixels of the mask as the bounding box. This simplifies the implementation and also makes it easy to apply image augmentations that would otherwise be harder to apply to bounding boxes, such as image rotation.\n\n    To validate this approach, we compared our computed bounding boxes to those provided by the COCO dataset.\nWe found that ~2% of bounding boxes differed by 1px or more, ~0.05% differed by 5px or more, \nand only 0.01% differed by 10px or more.\n\n* **Learning Rate:** The paper uses a learning rate of 0.02, but we found that to be\ntoo high, and often causes the weights to explode, especially when using a small batch\nsize. It might be related to differences between how Caffe and TensorFlow compute \ngradients (sum vs mean across batches and GPUs). Or, maybe the official model uses gradient\nclipping to avoid this issue. We do use gradient clipping, but don't set it too aggressively.\nWe found that smaller learning rates converge faster anyway so we go with that.\n\n## Citation\nUse this bibtex to cite this repository:\n```\n@misc{matterport_maskrcnn_2017,\n  title={Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow},\n  author={Waleed Abdulla},\n  year={2017},\n  publisher={Github},\n  journal={GitHub repository},\n  howpublished={\\url{https://github.com/matterport/Mask_RCNN}},\n}\n```\n\n## Contributing\nContributions to this repository are welcome. Examples of things you can contribute:\n* Speed Improvements. Like re-writing some Python code in TensorFlow or Cython.\n* Training on other datasets.\n* Accuracy Improvements.\n* Visualizations and examples.\n\nYou can also [join our team](https://matterport.com/careers/) and help us build even more projects like this one.\n\n## Requirements\nPython 3.4, TensorFlow 1.3, Keras 2.0.8 and other common packages listed in `requirements.txt`.\n\n### MS COCO Requirements:\nTo train or test on MS COCO, you'll also need:\n* pycocotools (installation instructions below)\n* [MS COCO Dataset](http://cocodataset.org/#home)\n* Download the 5K [minival](https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0)\n  and the 35K [validation-minus-minival](https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0)\n  subsets. More details in the original [Faster R-CNN implementation](https://github.com/rbgirshick/py-faster-rcnn/blob/master/data/README.md).\n\nIf you use Docker, the code has been verified to work on\n[this Docker container](https://hub.docker.com/r/waleedka/modern-deep-learning/).\n\n\n## Installation\n1. Clone this repository\n2. Install dependencies\n   ```bash\n   pip3 install -r requirements.txt\n   ```\n3. Run setup from the repository root directory\n    ```bash\n    python3 setup.py install\n    ``` \n3. Download pre-trained COCO weights (mask_rcnn_coco.h5) from the [releases page](https://github.com/matterport/Mask_RCNN/releases).\n4. (Optional) To train or test on MS COCO install `pycocotools` from one of these repos. They are forks of the original pycocotools with fixes for Python3 and Windows (the official repo doesn't seem to be active anymore).\n\n    * Linux: https://github.com/waleedka/coco\n    * Windows: https://github.com/philferriere/cocoapi.\n    You must have the Visual C++ 2015 build tools on your path (see the repo for additional details)\n\n# Projects Using this Model\nIf you extend this model to other datasets or build projects that use it, we'd love to hear from you.\n\n### [4K Video Demo](https://www.youtube.com/watch?v=OOT3UIXZztE) by Karol Majek.\n[![Mask RCNN on 4K Video](assets/4k_video.gif)](https://www.youtube.com/watch?v=OOT3UIXZztE)\n\n### [Images to OSM](https://github.com/jremillard/images-to-osm): Improve OpenStreetMap by adding baseball, soccer, tennis, football, and basketball fields.\n\n![Identify sport fields in satellite images](assets/images_to_osm.png)\n\n### [Splash of Color](https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46). A blog post explaining how to train this model from scratch and use it to implement a color splash effect.\n![Balloon Color Splash](assets/balloon_color_splash.gif)\n\n\n### [Segmenting Nuclei in Microscopy Images](samples/nucleus). Built for the [2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018)\nCode is in the `samples/nucleus` directory.\n\n![Nucleus Segmentation](assets/nucleus_segmentation.png)\n\n### [Detection and Segmentation for Surgery Robots](https://github.com/SUYEgit/Surgery-Robot-Detection-Segmentation) by the NUS Control & Mechatronics Lab.\n![Surgery Robot Detection and Segmentation](https://github.com/SUYEgit/Surgery-Robot-Detection-Segmentation/raw/master/assets/video.gif)\n\n### [Reconstructing 3D buildings from aerial LiDAR](https://medium.com/geoai/reconstructing-3d-buildings-from-aerial-lidar-with-ai-details-6a81cb3079c0)\nA proof of concept project by [Esri](https://www.esri.com/), in collaboration with Nvidia and Miami-Dade County. Along with a great write up and code by Dmitry Kudinov, Daniel Hedges, and Omar Maher.\n![3D Building Reconstruction](assets/project_3dbuildings.png)\n\n### [Usiigaci: Label-free Cell Tracking in Phase Contrast Microscopy](https://github.com/oist/usiigaci)\nA project from Japan to automatically track cells in a microfluidics platform. Paper is pending, but the source code is released.\n\n![](assets/project_usiigaci1.gif) ![](assets/project_usiigaci2.gif)\n\n### [Characterization of Arctic Ice-Wedge Polygons in Very High Spatial Resolution Aerial Imagery](http://www.mdpi.com/2072-4292/10/9/1487)\nResearch project to understand the complex processes between degradations in the Arctic and climate change. By Weixing Zhang, Chandi Witharana, Anna Liljedahl, and Mikhail Kanevskiy.\n![image](assets/project_ice_wedge_polygons.png)\n\n### [Mask-RCNN Shiny](https://github.com/huuuuusy/Mask-RCNN-Shiny)\nA computer vision class project by HU Shiyu to apply the color pop effect on people with beautiful results.\n![](assets/project_shiny1.jpg)\n\n### [Mapping Challenge](https://github.com/crowdAI/crowdai-mapping-challenge-mask-rcnn): Convert satellite imagery to maps for use by humanitarian organisations.\n![Mapping Challenge](assets/mapping_challenge.png)\n\n### [GRASS GIS Addon](https://github.com/ctu-geoforall-lab/i.ann.maskrcnn) to generate vector masks from geospatial imagery. Based on a [Master's thesis](https://github.com/ctu-geoforall-lab-projects/dp-pesek-2018) by Ond\u0159ej Pe\u0161ek.\n![GRASS GIS Image](assets/project_grass_gis.png)\n"}, {"repo": "HelloZeroNet/ZeroNet", "language": "Python", "readme_contents": "# ZeroNet [![Build Status](https://travis-ci.org/HelloZeroNet/ZeroNet.svg?branch=master)](https://travis-ci.org/HelloZeroNet/ZeroNet) [![Documentation](https://img.shields.io/badge/docs-faq-brightgreen.svg)](https://zeronet.io/docs/faq/) [![Help](https://img.shields.io/badge/keep_this_project_alive-donate-yellow.svg)](https://zeronet.io/docs/help_zeronet/donate/)\n\n[\u7b80\u4f53\u4e2d\u6587](./README-zh-cn.md)\n[English](./README.md)\n\n\u0414\u0435\u0446\u0435\u043d\u0442\u0440\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0432\u0435\u0431\u0441\u0430\u0439\u0442\u044b \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0438\u0435 Bitcoin \u043a\u0440\u0438\u043f\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u044e \u0438 BitTorrent \u0441\u0435\u0442\u044c - https://zeronet.io\n\n\n## \u0417\u0430\u0447\u0435\u043c?\n\n* \u041c\u044b \u0432\u0435\u0440\u0438\u043c \u0432 \u043e\u0442\u043a\u0440\u044b\u0442\u0443\u044e, \u0441\u0432\u043e\u0431\u043e\u0434\u043d\u0443\u044e, \u0438 \u043d\u0435 \u043e\u0442\u0446\u0435\u043d\u0437\u0443\u0440\u0435\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c \u0438 \u043a\u043e\u043c\u043c\u0443\u043d\u0438\u043a\u0430\u0446\u0438\u044e.\n* \u041d\u0435\u0442 \u0435\u0434\u0438\u043d\u043e\u0439 \u0442\u043e\u0447\u043a\u0438 \u043e\u0442\u043a\u0430\u0437\u0430: \u0421\u0430\u0439\u0442 \u043e\u043d\u043b\u0430\u0439\u043d \u043f\u043e\u043a\u0430 \u043f\u043e \u043a\u0440\u0430\u0439\u043d\u0435\u0439 \u043c\u0435\u0440\u0435 1 \u043f\u0438\u0440 \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u0435\u0442 \u0435\u0433\u043e.\n* \u041d\u0438\u043a\u0430\u043a\u0438\u0445 \u0437\u0430\u0442\u0440\u0430\u0442 \u043d\u0430 \u0445\u043e\u0441\u0442\u0438\u043d\u0433: \u0421\u0430\u0439\u0442\u044b \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u044e\u0442\u0441\u044f \u043f\u043e\u0441\u0435\u0442\u0438\u0442\u0435\u043b\u044f\u043c\u0438.\n* \u041d\u0435\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043e\u0442\u043a\u043b\u044e\u0447\u0438\u0442\u044c: \u041e\u043d \u043d\u0438\u0433\u0434\u0435, \u043f\u043e\u0442\u043e\u043c\u0443 \u0447\u0442\u043e \u043e\u043d \u0432\u0435\u0437\u0434\u0435.\n* \u0411\u044b\u0441\u0442\u0440 \u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043e\u0444\u0444\u043b\u0430\u0439\u043d: \u0412\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0434\u043e\u0441\u0442\u0443\u043f \u043a \u0441\u0430\u0439\u0442\u0443, \u0434\u0430\u0436\u0435 \u0435\u0441\u043b\u0438 \u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442 \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d.\n\n\n## \u041e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0438\n * \u041e\u0431\u043d\u043e\u0432\u043b\u044f\u0435\u043c\u044b\u0435 \u0432 \u0440\u0435\u0430\u043b\u044c\u043d\u043e\u043c \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0441\u0430\u0439\u0442\u044b\n * \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 Namecoin .bit \u0434\u043e\u043c\u0435\u043d\u043e\u0432\n * \u041b\u0451\u0433\u043e\u043a \u0432 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0435: \u0440\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u0430\u043b & \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u043b\n * \u041a\u043b\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0435\u0431\u0441\u0430\u0439\u0442\u043e\u0432 \u0432 \u043e\u0434\u0438\u043d \u043a\u043b\u0438\u043a\n * Password-less [BIP32](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki)\n   based authorization: \u0412\u0430\u0448\u0430 \u0443\u0447\u0435\u0442\u043d\u0430\u044f \u0437\u0430\u043f\u0438\u0441\u044c \u0437\u0430\u0449\u0438\u0449\u0435\u043d\u0430 \u0442\u043e\u0439 \u0436\u0435 \u043a\u0440\u0438\u043f\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0435\u0439, \u0447\u0442\u043e \u0438 \u0432\u0430\u0448 Bitcoin-\u043a\u043e\u0448\u0435\u043b\u0435\u043a\n * \u0412\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u044b\u0439 SQL-\u0441\u0435\u0440\u0432\u0435\u0440 \u0441 \u0441\u0438\u043d\u0445\u0440\u043e\u043d\u0438\u0437\u0430\u0446\u0438\u0435\u0439 \u0434\u0430\u043d\u043d\u044b\u0445 P2P: \u041f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0443\u043f\u0440\u043e\u0441\u0442\u0438\u0442\u044c \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u043a\u0443 \u0441\u0430\u0439\u0442\u0430 \u0438 \u0443\u0441\u043a\u043e\u0440\u0438\u0442\u044c \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0443 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b\n * \u0410\u043d\u043e\u043d\u0438\u043c\u043d\u043e\u0441\u0442\u044c: \u041f\u043e\u043b\u043d\u0430\u044f \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u0441\u0435\u0442\u0438 Tor \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u043a\u0440\u044b\u0442\u044b\u0445 \u0441\u043b\u0443\u0436\u0431 .onion \u0432\u043c\u0435\u0441\u0442\u043e \u0430\u0434\u0440\u0435\u0441\u043e\u0432 IPv4\n * TLS \u0437\u0430\u0448\u0438\u0444\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0432\u044f\u0437\u0438\n * \u0410\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043e\u0442\u043a\u0440\u044b\u0442\u0438\u0435 uPnP \u043f\u043e\u0440\u0442\u0430\n * \u041f\u043b\u0430\u0433\u0438\u043d \u0434\u043b\u044f \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u043c\u043d\u043e\u0433\u043e\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u0441\u043a\u043e\u0439 (openproxy)\n * \u0420\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0441 \u043b\u044e\u0431\u044b\u043c\u0438 \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0430\u043c\u0438 \u0438 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u043c\u0438 \u0441\u0438\u0441\u0442\u0435\u043c\u0430\u043c\u0438\n\n\n## \u041a\u0430\u043a \u044d\u0442\u043e \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442?\n\n* \u041f\u043e\u0441\u043b\u0435 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 `zeronet.py` \u0432\u044b \u0441\u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u0441\u0435\u0442\u0438\u0442\u044c \u0437\u0430\u0439\u0442\u044b (zeronet \u0441\u0430\u0439\u0442\u044b) \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u0430\u0434\u0440\u0435\u0441\n  `http://127.0.0.1:43110/{zeronet_address}`\n(\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440. `http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D`).\n* \u041a\u043e\u0433\u0434\u0430 \u0432\u044b \u043f\u043e\u0441\u0435\u0449\u0430\u0435\u0442\u0435 \u043d\u043e\u0432\u044b\u0439 \u0441\u0430\u0439\u0442 zeronet, \u043e\u043d \u043f\u044b\u0442\u0430\u0435\u0442\u0441\u044f \u043d\u0430\u0439\u0442\u0438 \u043f\u0438\u0440\u043e\u0432 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e BitTorrent\n  \u0447\u0442\u043e\u0431\u044b \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0444\u0430\u0439\u043b\u044b \u0441\u0430\u0439\u0442\u043e\u0432 (html, css, js ...) \u0438\u0437 \u043d\u0438\u0445.\n* \u041a\u0430\u0436\u0434\u044b\u0439 \u043f\u043e\u0441\u0435\u0449\u0435\u043d\u043d\u044b\u0439 \u0437\u0430\u0439\u0442 \u0442\u0430\u043a\u0436\u0435 \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0432\u0430\u043c\u0438. (\u0422.\u0435 \u0445\u0440\u0430\u043d\u0438\u0442\u0441\u044f \u0443 \u0432\u0430\u0441 \u043d\u0430 \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u0435)\n* \u041a\u0430\u0436\u0434\u044b\u0439 \u0441\u0430\u0439\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0444\u0430\u0439\u043b `content.json`, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0432\u0441\u0435 \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u0432 \u0445\u044d\u0448\u0435 sha512\n  \u0438 \u043f\u043e\u0434\u043f\u0438\u0441\u044c, \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u0443\u044e \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0447\u0430\u0441\u0442\u043d\u043e\u0433\u043e \u043a\u043b\u044e\u0447\u0430 \u0441\u0430\u0439\u0442\u0430.\n* \u0415\u0441\u043b\u0438 \u0432\u043b\u0430\u0434\u0435\u043b\u0435\u0446 \u0441\u0430\u0439\u0442\u0430 (\u0443 \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0435\u0441\u0442\u044c \u0437\u0430\u043a\u0440\u044b\u0442\u044b\u0439 \u043a\u043b\u044e\u0447 \u0434\u043b\u044f \u0430\u0434\u0440\u0435\u0441\u0430 \u0441\u0430\u0439\u0442\u0430) \u0438\u0437\u043c\u0435\u043d\u044f\u0435\u0442 \u0441\u0430\u0439\u0442, \u0442\u043e \u043e\u043d/\u043e\u043d\u0430\n  \u043f\u043e\u0434\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u0442 \u043d\u043e\u0432\u044b\u0439 `content.json` \u0438 \u043f\u0443\u0431\u043b\u0438\u043a\u0443\u0435\u0442 \u0435\u0433\u043e \u0434\u043b\u044f \u043f\u0438\u0440\u043e\u0432. \u041f\u043e\u0441\u043b\u0435 \u044d\u0442\u043e\u0433\u043e \u043f\u0438\u0440\u044b \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u044e\u0442 \u0446\u0435\u043b\u043e\u0441\u0442\u043d\u043e\u0441\u0442\u044c `content.json`\n  (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u043f\u043e\u0434\u043f\u0438\u0441\u044c), \u043e\u043d\u0438 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u044e\u0442 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u0438 \u043f\u0443\u0431\u043b\u0438\u043a\u0443\u044e\u0442 \u043d\u043e\u0432\u044b\u0439 \u043a\u043e\u043d\u0442\u0435\u043d\u0442 \u0434\u043b\u044f \u0434\u0440\u0443\u0433\u0438\u0445 \u043f\u0438\u0440\u043e\u0432.\n\n####  [\u0421\u043b\u0430\u0439\u0434-\u0448\u043e\u0443 \u043e \u043a\u0440\u0438\u043f\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0438 ZeroNet, \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f\u0445 \u0441\u0430\u0439\u0442\u043e\u0432, \u043c\u043d\u043e\u0433\u043e\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u0441\u043a\u0438\u0445 \u0441\u0430\u0439\u0442\u0430\u0445 \u00bb](https://docs.google.com/presentation/d/1_2qK1IuOKJ51pgBvllZ9Yu7Au2l551t3XBgyTSvilew/pub?start=false&loop=false&delayms=3000)\n####  [\u0427\u0430\u0441\u0442\u043e \u0437\u0430\u0434\u0430\u0432\u0430\u0435\u043c\u044b\u0435 \u0432\u043e\u043f\u0440\u043e\u0441\u044b \u00bb](https://zeronet.io/docs/faq/)\n\n####  [\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430 ZeroNet \u00bb](https://zeronet.io/docs/site_development/getting_started/)\n\n\n## \u0421\u043a\u0440\u0438\u043d\u0448\u043e\u0442\u044b\n\n![Screenshot](https://i.imgur.com/H60OAHY.png)\n![ZeroTalk](https://zeronet.io/docs/img/zerotalk.png)\n\n#### [\u0411\u043e\u043b\u044c\u0448\u0435 \u0441\u043a\u0440\u0438\u043d\u0448\u043e\u0442\u043e\u0432 \u0432 ZeroNet \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u00bb](https://zeronet.io/docs/using_zeronet/sample_sites/)\n\n\n## \u041a\u0430\u043a \u0432\u0441\u0442\u0443\u043f\u0438\u0442\u044c\n\n* \u0421\u043a\u0430\u0447\u0430\u0439\u0442\u0435 ZeroBundle \u043f\u0430\u043a\u0435\u0442:\n  * [Microsoft Windows](https://github.com/HelloZeroNet/ZeroNet-win/archive/dist/ZeroNet-win.zip)\n  * [Apple macOS](https://github.com/HelloZeroNet/ZeroNet-mac/archive/dist/ZeroNet-mac.zip)\n  * [Linux 64-bit](https://github.com/HelloZeroNet/ZeroBundle/raw/master/dist/ZeroBundle-linux64.tar.gz)\n  * [Linux 32-bit](https://github.com/HelloZeroNet/ZeroBundle/raw/master/dist/ZeroBundle-linux32.tar.gz)\n* \u0420\u0430\u0441\u043f\u0430\u043a\u0443\u0439\u0442\u0435 \u0433\u0434\u0435 \u0443\u0433\u043e\u0434\u043d\u043e\n* \u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u0435 `ZeroNet.exe` (win), `ZeroNet(.app)` (osx), `ZeroNet.sh` (linux)\n\n### Linux \u0442\u0435\u0440\u043c\u0438\u043d\u0430\u043b\n\n* `wget https://github.com/HelloZeroNet/ZeroBundle/raw/master/dist/ZeroBundle-linux64.tar.gz`\n* `tar xvpfz ZeroBundle-linux64.tar.gz`\n* `cd ZeroBundle`\n* \u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e `./ZeroNet.sh`\n\n\u041e\u043d \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u0442 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u044e\u044e \u0432\u0435\u0440\u0441\u0438\u044e ZeroNet, \u0437\u0430\u0442\u0435\u043c \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u0442 \u0435\u0451 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438.\n\n#### \u0420\u0443\u0447\u043d\u0430\u044f \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0434\u043b\u044f Debian Linux\n\n* `sudo apt-get update`\n* `sudo apt-get install msgpack-python python-gevent`\n* `wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz`\n* `tar xvpfz master.tar.gz`\n* `cd ZeroNet-master`\n* \u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e `python2 zeronet.py`\n* \u041e\u0442\u043a\u0440\u043e\u0439\u0442\u0435 http://127.0.0.1:43110/ \u0432 \u0432\u0430\u0448\u0435\u043c \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n\n### [Arch Linux](https://www.archlinux.org)\n\n* `git clone https://aur.archlinux.org/zeronet.git`\n* `cd zeronet`\n* `makepkg -srci`\n* `systemctl start zeronet`\n* \u041e\u0442\u043a\u0440\u043e\u0439\u0442\u0435 http://127.0.0.1:43110/ \u0432 \u0432\u0430\u0448\u0435\u043c \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n\n\u0421\u043c\u043e\u0442\u0440\u0438\u0442\u0435 [ArchWiki](https://wiki.archlinux.org)'s [ZeroNet\narticle](https://wiki.archlinux.org/index.php/ZeroNet) \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0439 \u043f\u043e\u043c\u043e\u0449\u0438.\n\n### [Gentoo Linux](https://www.gentoo.org)\n\n* [`layman -a raiagent`](https://github.com/leycec/raiagent)\n* `echo '>=net-vpn/zeronet-0.5.4' >> /etc/portage/package.accept_keywords`\n* *(\u041e\u043f\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e)* \u0412\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0443 Tor: `echo 'net-vpn/zeronet tor' >>\n  /etc/portage/package.use`\n* `emerge zeronet`\n* `rc-service zeronet start`\n* \u041e\u0442\u043a\u0440\u043e\u0439\u0442\u0435 http://127.0.0.1:43110/ \u0432 \u0432\u0430\u0448\u0435\u043c \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n\n\u0421\u043c\u043e\u0442\u0440\u0438\u0442\u0435 `/usr/share/doc/zeronet-*/README.gentoo.bz2` \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0439 \u043f\u043e\u043c\u043e\u0449\u0438.\n\n### [FreeBSD](https://www.freebsd.org/)\n\n* `pkg install zeronet` or `cd /usr/ports/security/zeronet/ && make install clean`\n* `sysrc zeronet_enable=\"YES\"`\n* `service zeronet start`\n* \u041e\u0442\u043a\u0440\u043e\u0439\u0442\u0435 http://127.0.0.1:43110/ \u0432 \u0432\u0430\u0448\u0435\u043c \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n\n### [Vagrant](https://www.vagrantup.com/)\n\n* `vagrant up`\n* \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0438\u0442\u0435\u0441\u044c \u043a VM \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e `vagrant ssh`\n* `cd /vagrant`\n* \u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u0435 `python2 zeronet.py --ui_ip 0.0.0.0`\n* \u041e\u0442\u043a\u0440\u043e\u0439\u0442\u0435 http://127.0.0.1:43110/ \u0432 \u0432\u0430\u0448\u0435\u043c \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n\n### [Docker](https://www.docker.com/)\n* `docker run -d -v <local_data_folder>:/root/data -p 15441:15441 -p 127.0.0.1:43110:43110 nofish/zeronet`\n* \u042d\u0442\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 Docker \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0432 \u0441\u0435\u0431\u044f \u043f\u0440\u043e\u043a\u0441\u0438-\u0441\u0435\u0440\u0432\u0435\u0440 Tor, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u043e\u0442\u043a\u043b\u044e\u0447\u0451\u043d.\n  \u041e\u0441\u0442\u0435\u0440\u0435\u0433\u0430\u0439\u0442\u0435\u0441\u044c \u0447\u0442\u043e \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0445\u043e\u0441\u0442\u0438\u043d\u0433-\u043f\u0440\u043e\u0432\u0430\u0439\u0434\u0435\u0440\u044b \u043c\u043e\u0433\u0443\u0442 \u043d\u0435 \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u0442\u044c \u0432\u0430\u043c \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0442\u044c Tor \u043d\u0430 \u0441\u0432\u043e\u0438\u0445 \u0441\u0435\u0440\u0432\u0435\u0440\u0430\u0445.\n  \u0415\u0441\u043b\u0438 \u0432\u044b \u0445\u043e\u0442\u0438\u0442\u0435 \u0432\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u0435\u0433\u043e,\u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e \u0441\u0440\u0435\u0434\u044b `ENABLE_TOR` \u0432` true` (\u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e: `false`) \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440:\n\n `docker run -d -e \"ENABLE_TOR=true\" -v <local_data_folder>:/root/data -p 15441:15441 -p 127.0.0.1:43110:43110 nofish/zeronet`\n* \u041e\u0442\u043a\u0440\u043e\u0439\u0442\u0435 http://127.0.0.1:43110/ \u0432 \u0432\u0430\u0448\u0435\u043c \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n\n### [Virtualenv](https://virtualenv.readthedocs.org/en/latest/)\n\n* `virtualenv env`\n* `source env/bin/activate`\n* `pip install msgpack gevent`\n* `python2 zeronet.py`\n* \u041e\u0442\u043a\u0440\u043e\u0439\u0442\u0435 http://127.0.0.1:43110/ \u0432 \u0432\u0430\u0448\u0435\u043c \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n\n## \u0422\u0435\u043a\u0443\u0449\u0438\u0435 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f\n\n* ~~\u041d\u0435\u0442 torrent-\u043f\u043e\u0445\u043e\u0436\u0435\u0433\u043e \u0444\u0430\u0439\u043b\u0430 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u0444\u0430\u0439\u043b\u043e\u0432~~ (\u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u0444\u0430\u0439\u043b\u043e\u0432 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430)\n* ~~\u041d\u0435 \u0430\u043d\u043e\u043d\u0438\u043c\u043d\u0435\u0435 \u0447\u0435\u043c Bittorrent~~ (\u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 \u0432\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u0430\u044f \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 Tor)\n* \u0424\u0430\u0439\u043b\u043e\u0432\u044b\u0435 \u0442\u0440\u0430\u043d\u0437\u0430\u043a\u0446\u0438\u0438 \u043d\u0435 \u0441\u0436\u0430\u0442\u044b ~~ \u0438\u043b\u0438 \u043d\u0435\u0437\u0430\u0448\u0438\u0444\u0440\u043e\u0432\u0430\u043d\u044b \u0435\u0449\u0435 ~~ (\u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043e \u0448\u0438\u0444\u0440\u043e\u0432\u0430\u043d\u0438\u0435 TLS)\n* \u041d\u0435\u0442 \u043f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u0445 \u0441\u0430\u0439\u0442\u043e\u0432\n\n\n## \u041a\u0430\u043a \u044f \u043c\u043e\u0433\u0443 \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0441\u0430\u0439\u0442 \u0432 Zeronet?\n\n\u0417\u0430\u0432\u0435\u0440\u0448\u0438\u0442\u0435 \u0440\u0430\u0431\u043e\u0442\u0443 zeronet, \u0435\u0441\u043b\u0438 \u043e\u043d \u0437\u0430\u043f\u0443\u0449\u0435\u043d\n\n```bash\n$ zeronet.py siteCreate\n...\n- Site private key (\u041f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u0439 \u043a\u043b\u044e\u0447 \u0441\u0430\u0439\u0442\u0430): 23DKQpzxhbVBrAtvLEc2uvk7DZweh4qL3fn3jpM3LgHDczMK2TtYUq\n- Site address (\u0410\u0434\u0440\u0435\u0441 \u0441\u0430\u0439\u0442\u0430): 13DNDkMUExRf9Xa9ogwPKqp7zyHFEqbhC2\n...\n- Site created! (\u0421\u0430\u0439\u0442 \u0441\u043e\u0437\u0434\u0430\u043d)\n$ zeronet.py\n...\n```\n\n\u041f\u043e\u0437\u0434\u0440\u0430\u0432\u043b\u044f\u0435\u043c, \u0432\u044b \u0437\u0430\u043a\u043e\u043d\u0447\u0438\u043b\u0438! \u0422\u0435\u043f\u0435\u0440\u044c \u043a\u0430\u0436\u0434\u044b\u0439 \u043c\u043e\u0436\u0435\u0442 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0434\u043e\u0441\u0442\u0443\u043f \u043a \u0432\u0430\u0448\u0435\u043c\u0443 \u0437\u0430\u0439\u0442\u0443 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f\n`http://localhost:43110/13DNDkMUExRf9Xa9ogwPKqp7zyHFEqbhC2`\n\n\u0421\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0448\u0430\u0433\u0438: [ZeroNet Developer Documentation](https://zeronet.io/docs/site_development/getting_started/)\n\n\n## \u041a\u0430\u043a \u044f \u043c\u043e\u0433\u0443 \u043c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u0442\u044c Zeronet \u0441\u0430\u0439\u0442?\n\n* \u0418\u0437\u043c\u0435\u043d\u0438\u0442\u0435 \u0444\u0430\u0439\u043b\u044b \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u043d\u044b\u0435 \u0432 data/13DNDkMUExRf9Xa9ogwPKqp7zyHFEqbhC2 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438.\n  \u041a\u043e\u0433\u0434\u0430 \u0437\u0430\u043a\u043e\u043d\u0447\u0438\u0442\u0435 \u0441 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c:\n\n```bash\n$ zeronet.py siteSign 13DNDkMUExRf9Xa9ogwPKqp7zyHFEqbhC2\n- Signing site (\u041f\u043e\u0434\u043f\u0438\u0441\u044c \u0441\u0430\u0439\u0442\u0430): 13DNDkMUExRf9Xa9ogwPKqp7zyHFEqbhC2...\nPrivate key (\u041f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u0439 \u043a\u043b\u044e\u0447) (input hidden):\n```\n\n* \u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0441\u0435\u043a\u0440\u0435\u0442\u043d\u044b\u0439 \u043a\u043b\u044e\u0447, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0432\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u043f\u0440\u0438 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0438 \u0441\u0430\u0439\u0442\u0430, \u043f\u043e\u0442\u043e\u043c:\n\n```bash\n$ zeronet.py sitePublish 13DNDkMUExRf9Xa9ogwPKqp7zyHFEqbhC2\n...\nSite:13DNDk..bhC2 Publishing to 3/10 peers...\nSite:13DNDk..bhC2 Successfuly published to 3 peers\n- Serving files....\n```\n\n* \u0412\u043e\u0442 \u0438 \u0432\u0441\u0451! \u0412\u044b \u0443\u0441\u043f\u0435\u0448\u043d\u043e \u043f\u043e\u0434\u043f\u0438\u0441\u0430\u043b\u0438 \u0438 \u043e\u043f\u0443\u0431\u043b\u0438\u043a\u043e\u0432\u0430\u043b\u0438 \u0441\u0432\u043e\u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f.\n\n\n## \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0442\u0435 \u043f\u0440\u043e\u0435\u043a\u0442\n\n- Bitcoin: 1QDhxQ6PraUZa21ET5fYUCPgdrwBomnFgX\n- Paypal: https://zeronet.io/docs/help_zeronet/donate/\n\n### \u0421\u043f\u043e\u043d\u0441\u043e\u0440\u044b\n\n* \u0423\u043b\u0443\u0447\u0448\u0435\u043d\u043d\u0430\u044f \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u0438\u043c\u043e\u0441\u0442\u044c \u0441 MacOS / Safari \u0441\u0442\u0430\u043b\u0430 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0439 \u0431\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u044f [BrowserStack.com](https://www.browserstack.com)\n\n#### \u0421\u043f\u0430\u0441\u0438\u0431\u043e!\n\n* \u0411\u043e\u043b\u044c\u0448\u0435 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438, \u043f\u043e\u043c\u043e\u0449\u044c, \u0436\u0443\u0440\u043d\u0430\u043b \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439, zeronet \u0441\u0430\u0439\u0442\u044b: https://www.reddit.com/r/zeronet/\n* \u041f\u0440\u0438\u0445\u043e\u0434\u0438\u0442\u0435, \u043f\u043e\u043e\u0431\u0449\u0430\u0439\u0442\u0435\u0441\u044c \u0441 \u043d\u0430\u043c\u0438: [#zeronet @ FreeNode](https://kiwiirc.com/client/irc.freenode.net/zeronet) \u0438\u043b\u0438 \u043d\u0430 [gitter](https://gitter.im/HelloZeroNet/ZeroNet)\n* Email: hello@zeronet.io (PGP: CB9613AE)\n"}, {"repo": "apache/airflow", "language": "Python", "readme_contents": "<!--\n Licensed to the Apache Software Foundation (ASF) under one\n or more contributor license agreements.  See the NOTICE file\n distributed with this work for additional information\n regarding copyright ownership.  The ASF licenses this file\n to you under the Apache License, Version 2.0 (the\n \"License\"); you may not use this file except in compliance\n with the License.  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing,\n software distributed under the License is distributed on an\n \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n KIND, either express or implied.  See the License for the\n specific language governing permissions and limitations\n under the License.\n-->\n# Apache Airflow\n\n[![PyPI version](https://badge.fury.io/py/apache-airflow.svg)](https://badge.fury.io/py/apache-airflow)\n[![Build Status](https://travis-ci.org/apache/airflow.svg?branch=master)](https://travis-ci.org/apache/airflow)\n[![Coverage Status](https://img.shields.io/codecov/c/github/apache/airflow/master.svg)](https://codecov.io/github/apache/airflow?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/airflow/badge/?version=latest)](https://airflow.readthedocs.io/en/latest/?badge=latest)\n[![License](http://img.shields.io/:license-Apache%202-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0.txt)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/apache-airflow.svg)](https://pypi.org/project/apache-airflow/)\n[![Twitter Follow](https://img.shields.io/twitter/follow/ApacheAirflow.svg?style=social&label=Follow)](https://twitter.com/ApacheAirflow)\n[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://apache-airflow-slack.herokuapp.com/)\n\nApache Airflow (or simply Airflow) is a platform to programmatically author, schedule, and monitor workflows.\n\nWhen workflows are defined as code, they become more maintainable,\nversionable, testable, and collaborative.\n\nUse Airflow to author workflows as directed acyclic graphs (DAGs) of tasks. The Airflow scheduler executes your tasks on an array of workers while following the specified dependencies. Rich command line utilities make performing complex surgeries on DAGs a snap. The rich user interface makes it easy to visualize pipelines running in production, monitor progress, and troubleshoot issues when needed.\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Table of contents**\n\n- [Getting started](#getting-started)\n- [Beyond the Horizon](#beyond-the-horizon)\n- [Principles](#principles)\n- [User Interface](#user-interface)\n- [Contributing](#contributing)\n- [Who uses Apache Airflow?](#who-uses-apache-airflow)\n- [Who Maintains Apache Airflow?](#who-maintains-apache-airflow)\n- [Can I use the Apache Airflow logo in my presentation?](#can-i-use-the-apache-airflow-logo-in-my-presentation)\n- [Links](#links)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## Getting started\n\nPlease visit the Airflow Platform documentation (latest **stable** release) for help with [installing Airflow](https://airflow.apache.org/installation.html), getting a [quick start](https://airflow.apache.org/start.html), or a more complete [tutorial](https://airflow.apache.org/tutorial.html).\n\nDocumentation of GitHub master (latest development branch): [ReadTheDocs Documentation](https://airflow.readthedocs.io/en/latest/)\n\nFor further information, please visit the [Airflow Wiki](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Home).\n\n## Beyond the Horizon\n\nAirflow **is not** a data streaming solution. Tasks do not move data from\none to the other (though tasks can exchange metadata!). Airflow is not\nin the [Spark Streaming](http://spark.apache.org/streaming/)\nor [Storm](https://storm.apache.org/) space, it is more comparable to\n[Oozie](http://oozie.apache.org/) or\n[Azkaban](https://azkaban.github.io/).\n\nWorkflows are expected to be mostly static or slowly changing. You can think\nof the structure of the tasks in your workflow as slightly more dynamic\nthan a database structure would be. Airflow workflows are expected to look\nsimilar from a run to the next, this allows for clarity around\nunit of work and continuity.\n\n## Principles\n\n- **Dynamic**:  Airflow pipelines are configuration as code (Python), allowing for dynamic pipeline generation. This allows for writing code that instantiates pipelines dynamically.\n- **Extensible**:  Easily define your own operators, executors and extend the library so that it fits the level of abstraction that suits your environment.\n- **Elegant**:  Airflow pipelines are lean and explicit. Parameterizing your scripts is built into the core of Airflow using the powerful **Jinja** templating engine.\n- **Scalable**:  Airflow has a modular architecture and uses a message queue to orchestrate an arbitrary number of workers.\n\n## User Interface\n\n- **DAGs**: Overview of all DAGs in your environment.\n\n  ![](/docs/img/dags.png)\n\n- **Tree View**: Tree representation of a DAG that spans across time.\n\n  ![](/docs/img/tree.png)\n\n- **Graph View**: Visualization of a DAG's dependencies and their current status for a specific run.\n\n  ![](/docs/img/graph.png)\n\n- **Task Duration**: Total time spent on different tasks over time.\n\n  ![](/docs/img/duration.png)\n\n- **Gantt View**: Duration and overlap of a DAG.\n\n  ![](/docs/img/gantt.png)\n\n- **Code View**:  Quick way to view source code of a DAG.\n\n  ![](/docs/img/code.png)\n\n\n## Contributing\n\nWant to help build Apache Airflow? Check out our [contributing documentation](https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst).\n\n\n## Who uses Apache Airflow?\n\nAs the Apache Airflow community grows, we'd like to keep track of who is using\nthe platform. Please send a PR with your company name and @githubhandle\nif you may.\n\nCurrently **officially** using Airflow:\n\n1. [4G Capital](http://www.4g-capital.com/) [[@posei](https://github.com/posei)]\n1. [6play](https://www.6play.fr) [[@lemourA](https://github.com/lemoura), [@achaussende](https://github.com/achaussende), [@d-nguyen](https://github.com/d-nguyen), [@julien-gm](https://github.com/julien-gm)]\n1. [8fit](https://8fit.com/) [[@nicor88](https://github.com/nicor88), [@frnzska](https://github.com/frnzska)]\n1. [90 Seconds](https://90seconds.tv/) [[@aaronmak](https://github.com/aaronmak)]\n1. [99](https://99taxis.com) [[@fbenevides](https://github.com/fbenevides), [@gustavoamigo](https://github.com/gustavoamigo) & [@mmmaia](https://github.com/mmmaia)]\n1. [AdBOOST](https://www.adboost.sk) [[AdBOOST](https://github.com/AdBOOST)]\n1. [Adobe](https://www.adobe.com/) [[@mishikaSingh](https://github.com/mishikaSingh), [@ramandumcs](https://github.com/ramandumcs), [@vardancse](https://github.com/vardancse)]\n1. [Agari](https://github.com/agaridata) [[@r39132](https://github.com/r39132)]\n1. [Agoda](https://agoda.com) [[@akki](https://github.com/akki)]\n1. [Airbnb](http://airbnb.io/) [[@mistercrunch](https://github.com/mistercrunch), [@artwr](https://github.com/artwr)]\n1. [AirDNA](https://www.airdna.co)\n1. [Airfinity](https://www.airfinity.com) [[@sibowyer](https://github.com/sibowyer)]\n1. [Airtel](https://www.airtel.in/) [[@harishbisht](https://github.com/harishbisht)]\n1. [Alan](https://alan.eu) [[@charles-go](https://github.com/charles-go)]\n1. [allegro.pl](http://allegro.tech/) [[@kretes](https://github.com/kretes)]\n1. [AloPeyk](https://alopeyk.com) [[@blcksrx](https://github.com/blcksrx), [@AloPeyk](https://github.com/AloPeyk)]\n1. [AltX](https://www.getaltx.com/about) [[@pedromduarte](https://github.com/pedromduarte)]\n1. [AMPATH](https://www.ampathkenya.org/)[[@AMPATH](https://github.com/AMPATH), [@fatmali](https://github.com/fatmali)]\n1. [Apigee](https://apigee.com) [[@btallman](https://github.com/btallman)]\n1. [ARGO Labs](http://www.argolabs.org) [[@California Data Collaborative](https://github.com/California-Data-Collaborative)]\n1. [ARMEDANGELS](https://www.armedangels.de) [[@swiffer](https://github.com/swiffer)]\n1. [Arquivei](https://www.arquivei.com.br/) [[@arquivei](https://github.com/arquivei)]\n1. [Arrive](https://www.arrive.com/)\n1. [Asana](https://asana.com/) [[@chang](https://github.com/chang), [@dima-asana](https://github.com/dima-asana), [@jdavidheiser](https://github.com/jdavidheiser), [@ricardoandresrojas](https://github.com/ricardoandresrojas)]\n1. [Astronomer](http://www.astronomer.io) [[@schnie](https://github.com/schnie), [@ashb](https://github.com/ashb), [@kaxil](https://github.com/kaxil), [@dimberman](https://github.com/dimberman), [@andriisoldatenko](https://github.com/andriisoldatenko), [@ryw](https://github.com/ryw), [@andrewhharmon](https://github.com/andrewhharmon)]\n1. [Auth0](https://auth0.com) [[@sicarul](https://github.com/sicarul)]\n1. [Automattic](https://automattic.com/) [[@anandnalya](https://github.com/anandnalya), [@bperson](https://github.com/bperson), [@khrol](https://github.com/Khrol), [@xyu](https://github.com/xyu)]\n1. [Away](https://awaytravel.com) [[@trunsky](https://github.com/trunsky)]\n1. [Azri Solutions](http://www.azrisolutions.com/) [[@userimack](https://github.com/userimack)]\n1. [Bagelcode](https://site.bagelcode.com/)\n1. [BalanceHero](http://truebalance.io/) [[@swalloow](https://github.com/swalloow)]\n1. [Banco de Formaturas](https://www.bancodeformaturas.com.br) [[@guiligan](https://github.com/guiligan)]\n1. [BandwidthX](http://www.bandwidthx.com) [[@dineshdsharma](https://github.com/dineshdsharma)]\n1. [Basetis](http://www.basetis.com)\n1. [BBM](https://www.bbm.com/)\n1. [Beamly](https://www.beamly.com/) [[@christopheralcock](https://github.com/christopheralcock)]\n1. [Beeswax](https://beeswax.com/)\n1. [Bellhops](https://github.com/bellhops)\n1. [BelugaDB](https://belugadb.com) [[@fabio-nukui](https://github.com/fabio-nukui) & [@joao-sallaberry](http://github.com/joao-sallaberry) & [@lucianoviola](https://github.com/lucianoviola) & [@tmatuki](https://github.com/tmatuki)]\n1. [Betterment](https://www.betterment.com/) [[@betterment](https://github.com/Betterment)]\n1. [Bexs Bank](https://www.bexs.com.br/en) [[@felipefb](https://github.com/felipefb) & [@ilarsen](https://github.com/ishvann)]\n1. [BigQuant](https://bigquant.com/) [[@bigquant](https://github.com/bigquant)]\n1. [BlaBlaCar](https://www.blablacar.com) [[@puckel](https://github.com/puckel) & [@wmorin](https://github.com/wmorin)]\n1. [Blacklane](https://www.blacklane.com) [[@serkef](https://github.com/serkef)]\n1. [Bloc](https://www.bloc.io) [[@dpaola2](https://github.com/dpaola2)]\n1. [Bloomberg](https://www.techatbloomberg.com) [[@dimberman](https://github.com/dimberman)]\n1. [Blue Yonder](http://www.blue-yonder.com) [[@blue-yonder](https://github.com/blue-yonder)]\n1. [BlueApron](https://www.blueapron.com) [[@jasonjho](https://github.com/jasonjho) & [@matthewdavidhauser](https://github.com/matthewdavidhauser)]\n1. [Bluecore](https://www.bluecore.com) [[@JLDLaughlin](https://github.com/JLDLaughlin)]\n1. [Bluekiri](https://bluekiri.com) [[@Bluekiri](https://github.com/bluekiri)]\n1. [Boda Telecom Suite - CE](https://github.com/bodastage/bts-ce) [[@erssebaggala](https://github.com/erssebaggala), [@bodastage](https://github.com/bodastage)]\n1. [Bodastage Solutions](http://bodastage.com) [[@erssebaggala](https://github.com/erssebaggala), [@bodastage](https://github.com/bodastage)]\n1. [Bombora Inc](https://bombora.com/) [[@jeffkpayne](https://github.com/jeffkpayne), [@pakelley](https://github.com/pakelley), [@dNavalta](https://github.com/dNavalta), [@austynh](https://github.com/austynh), [@TheOriginalAlex](https://github.com/TheOriginalAlex)]\n1. [Bonial International GmbH](https://www.bonial.com/)\n1. [Bonnier Broadcasting](http://www.bonnierbroadcasting.com) [[@wileeam](https://github.com/wileeam)]\n1. [BounceX](http://www.bouncex.com) [[@JoshFerge](https://github.com/JoshFerge), [@hudsonrio](https://github.com/hudsonrio), [@ronniekritou](https://github.com/ronniekritou)]\n1. [Braintree](https://www.braintreepayments.com) [[@coopergillan](https://github.com/coopergillan), [@curiousjazz77](https://github.com/curiousjazz77), [@raymondberg](https://github.com/raymondberg)]\n1. [Branch](https://branch.io) [[@sdebarshi](https://github.com/sdebarshi), [@dmitrig01](https://github.com/dmitrig01)]\n1. [Caesars Entertainment](https://www.caesars.com)\n1. [California Data Collaborative](https://github.com/California-Data-Collaborative) powered by [ARGO Labs](http://www.argolabs.org)\n1. [Capital One](https://www.capitalone.com) [[@anoopengineer](https://github.com/anoopengineer)]\n1. [Carbonite](https://www.carbonite.com) [[@ajbosco](https://github.com/ajbosco)]\n1. [CarLabs](https://www.carlabs.ai/) [[@sganz](https://github.com/sganz) & [@odannyc](https://github.com/odannyc)]\n1. [CAVA](https://www.cava.com) [[@minh5](http://github.com/minh5) & [@patchus](http://github.com/patchus)]\n1. [Celect](http://www.celect.com) [[@superdosh](https://github.com/superdosh) & [@chadcelect](https://github.com/chadcelect)]\n1. [Censys](https://censys.io) [[@zakird](https://github.com/zakird), [@dadrian](https://github.com/dadrian), & [@andrewsardone](https://github.com/andrewsardone)]\n1. [Change.org](https://www.change.org) [[@change](https://github.com/change), [@vijaykramesh](https://github.com/vijaykramesh)]\n1. [Chartboost](https://www.chartboost.com) [[@cgelman](https://github.com/cgelman) & [@dclubb](https://github.com/dclubb)]\n1. [Checkr](https://checkr.com) [[@tongboh](https://github.com/tongboh)]\n1. [Children's Hospital of Philadelphia Division of Genomic Diagnostics](http://www.chop.edu/centers-programs/division-genomic-diagnostics) [[@genomics-geek](https://github.com/genomics-geek/)]\n1. [Cinimex DataLab](http://cinimex.ru) [[@kdubovikov](https://github.com/kdubovikov)]\n1. [City of San Diego](http://sandiego.gov) [[@MrMaksimize](https://github.com/mrmaksimize), [@andrell81](https://github.com/andrell81) & [@arnaudvedy](https://github.com/arnaudvedy)]\n1. [City of Toronto](https://www.toronto.ca/) [[@CityofToronto](https://github.com/CityofToronto), [@radumas](https://github.com/radumas)]\n1. [ciValue](https://civalue.com/) [[@chencivalue](https://github.com/chencivalue), [@YoavGaudin](https://github.com/YoavGaudin), [@saleem-boshnak](https://github.com/saleem-boshnak)]\n1. [Civey](https://civey.com/) [[@WesleyBatista](https://github.com/WesleyBatista)]\n1. [Clairvoyant](https://clairvoyantsoft.com) [[@shekharv](https://github.com/shekharv)]\n1. [Classmethod, Inc.](https://classmethod.jp/) [[@shoito](https://github.com/shoito)]\n1. [Cleartax](https://cleartax.in/) [[@anks](https://github.com/anks) & [@codebuff](https://github.com/codebuff)]\n1. [Clover Health](https://www.cloverhealth.com) [[@gwax](https://github.com/gwax) & [@vansivallab](https://github.com/vansivallab)]\n1. [Collectivehealth Inc.](https://www.collectivehealth.com) [[@retornam](https://github.com/retornam)]\n1. [Compass](https://www.compass.com) [[@wdhorton](https://github.com/wdhorton)]\n1. [ConnectWise](https://www.connectwise.com/) [[@jacobeturpin](https://github.com/jacobeturpin)]\n1. [ContaAzul](https://www.contaazul.com) [[@bern4rdelli](https://github.com/bern4rdelli), [@renanleme](https://github.com/renanleme) & [@sabino](https://github.com/sabino)]\n1. [Cotap](https://github.com/cotap/) [[@maraca](https://github.com/maraca) & [@richardchew](https://github.com/richardchew)]\n1. [Craig@Work](https://www.craigatwork.com)\n1. [Crealytics](https://crealytics.com)\n1. [Credit Karma](https://www.creditkarma.com/) [[@preete-dixit-ck](https://github.com/preete-dixit-ck) & [@harish-gaggar-ck](https://github.com/harish-gaggar-ck) & [@greg-finley-ck](https://github.com/greg-finley-ck)]\n1. [Creditas](https://www.creditas.com.br) [[@dcassiano](https://github.com/dcassiano)]\n1. [CreditCards.com](https://www.creditcards.com/)[[@vmAggies](https://github.com/vmAggies) &  [@jay-wallaby](https://github.com/jay-wallaby)]\n1. [Cryptalizer.com](https://www.cryptalizer.com/)\n1. [Custom Ink](https://www.customink.com/) [[@david-dalisay](https://github.com/david-dalisay), [@dmartin11](https://github.com/dmartin11) & [@mpeteuil](https://github.com/mpeteuil)]\n1. [Cyscale](https://cyscale.com) [[@ocical](https://github.com/ocical)]\n1. [Dailymotion](http://www.dailymotion.com/fr) [[@germaintanguy](https://github.com/germaintanguy) & [@hc](https://github.com/hc)]\n1. [Danamica](https://www.danamica.dk) [[@testvinder](https://github.com/testvinder)]\n1. [Data Reply](https://www.datareply.co.uk/) [[@kaxil](https://github.com/kaxil)]\n1. [DataCamp](https://datacamp.com/) [[@dgrtwo](https://github.com/dgrtwo)]\n1. [DataFox](https://www.datafox.com/) [[@sudowork](https://github.com/sudowork)]\n1. [Dentsu Inc.](http://www.dentsu.com/) [[@bryan831](https://github.com/bryan831) & [@loozhengyuan](https://github.com/loozhengyuan)]\n1. [Digital First Media](http://www.digitalfirstmedia.com/) [[@duffn](https://github.com/duffn) & [@mschmo](https://github.com/mschmo) & [@seanmuth](https://github.com/seanmuth)]\n1. [DigitalOcean](https://digitalocean.com/) [[@ajbosco](https://github.com/ajbosco)]\n1. [DoorDash](https://www.doordash.com/)\n1. [Dotmodus](http://dotmodus.com) [[@dannylee12](https://github.com/dannylee12)]\n1. [Drivy](https://www.drivy.com) [[@AntoineAugusti](https://github.com/AntoineAugusti)]\n1. [Easy Taxi](http://www.easytaxi.com/) [[@caique-lima](https://github.com/caique-lima) & [@diraol](https://github.com/diraol)]\n1. [EllisDon](http://www.ellisdon.com/) [[@d2kalra](https://github.com/d2kalra) & [@zbasama](https://github.com/zbasama)]\n1. [Endesa](https://www.endesa.com) [[@drexpp](https://github.com/drexpp)]\n1. [Enigma](https://www.enigma.com) [[@hydrosquall](https://github.com/hydrosquall)]\n1. [Datamaran](https://www.datamaran.com) [[@valexharo](https://github.com/valexharo)]\n1. [Etsy](https://www.etsy.com) [[@mchalek](https://github.com/mchalek)]\n1. [evo.company](https://evo.company/) [[@orhideous](https://github.com/orhideous)]\n1. [Experity (formerly DocuTAP)](https://www.experityhealth.com/) [[@cloneluke](https://github.com/cloneluke) & [@tobyjoliver](https://github.com/tobyjoliver)]\n1. [Fathom Health](https://www.fathomhealth.co/)\n1. [Firestone Inventing](https://www.hsmap.com/) [[@zihengCat](https://github.com/zihengCat)]\n1. [Flipp](https://www.flipp.com) [[@sethwilsonwishabi](https://github.com/sethwilsonwishabi)]\n1. [Format](https://www.format.com) [[@format](https://github.com/4ormat) & [@jasonicarter](https://github.com/jasonicarter)]\n1. [FreshBooks](https://github.com/freshbooks) [[@DinoCow](https://github.com/DinoCow)]\n1. [Freshworks](https://www.freshworks.com/) [[@shaikshakeel](https://github.com/shaikshakeel)]\n1. [FullContact](https://github.com/fullcontact)\n1. [Fuller, Inc.](https://en.fuller-inc.com/) [[@wutali](https://github.com/wutali) & [@sh-tech](https://github.com/sh-tech)]\n1. [Fundera](https://fundera.com) [[@andyxhadji](https://github.com/andyxhadji)]\n1. [G Adventures](https://gadventures.com) [[@chchtv11](https://github.com/chchtv11), [@tgumbley](https://github.com/tgumbley), [@tomwross](https://github.com/tomwross)]\n1. [GameWisp](https://gamewisp.com) [[@tjbiii](https://github.com/TJBIII) & [@theryanwalls](https://github.com/theryanwalls)]\n1. [GeneCards](https://www.genecards.org) [[@oferze](https://github.com/oferze)]\n1. [Gentner Lab](http://github.com/gentnerlab) [[@neuromusic](https://github.com/neuromusic)]\n1. [Get Simpl](https://getsimpl.com/) [[@rootcss](https://github.com/rootcss)]\n1. [GitLab](https://about.gitlab.com/) [[@tlapiana](https://gitlab.com/tlapiana) & [@tayloramurphy](https://gitlab.com/tayloramurphy)]\n1. [Glassdoor](https://github.com/Glassdoor) [[@syvineckruyk](https://github.com/syvineckruyk) & [@sid88in](https://github.com/sid88in)]\n1. [Global Fashion Group](http://global-fashion-group.com) [[@GFG](https://github.com/GFG)]\n1. [GoDataDriven](https://godatadriven.com/) [[@BasPH](https://github.com/basph), [@danielvdende](https://github.com/danielvdende), [@ffinfo](https://github.com/ffinfo), [@Fokko](https://github.com/Fokko), [@gglanzani](https://github.com/gglanzani), [@hgrif](https://github.com/hgrif), [@jrderuiter](https://github.com/jrderuiter), [@NielsZeilemaker](https://github.com/NielsZeilemaker)]\n1. [GovTech GDS](https://gds-gov.tech) [[@chrissng](https://github.com/chrissng) & [@datagovsg](https://github.com/datagovsg)]\n1. [Grab](https://www.grab.com/sg/) [[@calvintran](https://github.com/canhtran)]\n1. [Gradeup](https://gradeup.co) [[@gradeup](https://github.com/gradeup)]\n1. [Grand Rounds](https://www.grandrounds.com/) [[@richddr](https://github.com/richddr), [@timz1290](https://github.com/timz1290), [@wenever](https://github.com/@wenever), & [@runongirlrunon](https://github.com/runongirlrunon)]\n1. [Groupalia](http://es.groupalia.com) [[@jesusfcr](https://github.com/jesusfcr)]\n1. [Groupon](https://groupon.com) [[@stevencasey](https://github.com/stevencasey)]\n1. [Growbots](https://www.growbots.com/)[[@exploy](https://github.com/exploy)]\n1. [GSN Games](https://www.gsngames.com)\n1. [Gusto](https://gusto.com) [[@frankhsu](https://github.com/frankhsu)]\n1. [Handshake](https://joinhandshake.com/) [[@mhickman](https://github.com/mhickman)]\n1. [Handy](http://www.handy.com/careers/73115?gh_jid=73115&gh_src=o5qcxn) [[@marcintustin](https://github.com/marcintustin) / [@mtustin-handy](https://github.com/mtustin-handy)]\n1. [happn](https://www.happn.com) [[@pcorbel](https://github.com/pcorbel)]\n1. [HAVAN](https://www.havan.com.br) [[@botbiz](https://github.com/botbiz)]\n1. [HBC Digital](http://tech.hbc.com) [[@tmccartan](https://github.com/tmccartan) & [@dmateusp](https://github.com/dmateusp)]\n1. [HBO](http://www.hbo.com/)[[@yiwang](https://github.com/yiwang)]\n1. [Healthjump](http://www.healthjump.com/) [[@miscbits](https://github.com/miscbits)]\n1. [HelloFresh](https://www.hellofresh.com) [[@tammymendt](https://github.com/tammymendt) & [@davidsbatista](https://github.com/davidsbatista) & [@iuriinedostup](https://github.com/iuriinedostup)]\n1. [Hipages](https://www.hipages.com.au/) [[@arihantsurana](https://github.com/arihantsurana)]\n1. [Holimetrix](http://holimetrix.com/) [[@thibault-ketterer](https://github.com/thibault-ketterer)]\n1. [Hootsuite](https://github.com/hootsuite)\n1. [Hostnfly](https://www.hostnfly.com/) [[@CyrilLeMat](https://github.com/CyrilLeMat) & [@pierrechopin](https://github.com/pierrechopin) & [@alexisrosuel](https://github.com/alexisrosuel)]\n1. [HotelQuickly](https://github.com/HotelQuickly) [[@zinuzoid](https://github.com/zinuzoid)]\n1. [Huq Industries](https://huq.io) [[@huqindustries](https://github.com/huq-industries), [@alepuccetti](https://github.com/alepuccetti), [@turbomerl](https://github.com/turbomerl)]\n1. [Iflix](https://piay.iflix.com) [[@ChaturvediSulabh](https://github.com/ChaturvediSulabh)]\n1. [IFTTT](https://www.ifttt.com/) [[@apurvajoshi](https://github.com/apurvajoshi)]\n1. [iHeartRadio](http://www.iheart.com/)[[@yiwang](https://github.com/yiwang)]\n1. [imgix](https://www.imgix.com/) [[@dclubb](https://github.com/dclubb)]\n1. [ING](http://www.ing.com/)\n1. [Instacart \ud83e\udd55](http://www.instacart.com/) [[@arp1t](https://github.com/arp1t) & [@code-sauce](https://github.com/code-sauce) & [@jasonlew](https://github.com/jasonlew) & [@j4p3](https://github.com/j4p3) & [@lubert](https://github.com/lubert) & [@mmontagna](https://github.com/mmontagna) & [@RyanAD](https://github.com/RyanAD) &[@zzadeh](https://github.com/zzadeh)]\n1. [Intercom](http://www.intercom.com/) [[@fox](https://github.com/fox) & [@paulvic](https://github.com/paulvic)]\n1. [Interia](http://www.interia.pl)\n1. [Investorise](https://investorise.com/) [[@svenvarkel](https://github.com/svenvarkel)]\n1. [iS2.co](https://www.is2.co) [[@iS2co](https://github.com/iS2co)]\n1. [Jampp](https://github.com/jampp)\n1. [Jeitto](https://www.jeitto.com.br) [[@BrennerPablo](https://github.com/BrennerPablo) & [@ds-mauri](https://github.com/ds-mauri)]\n1. [Jetlore](http://www.jetlore.com/) [[@bderose](https://github.com/bderose)]\n1. [JobTeaser](https://www.jobteaser.com) [[@stefani75](https://github.com/stefani75) &  [@knil-sama](https://github.com/knil-sama)]\n1. [JULO](https://www.julo.co.id/) [[@sepam](https://github.com/sepam) & [@tenapril](https://github.com/tenapril) & [@verzqy](https://github.com/verzqy)]\n1. [Kalibrr](https://www.kalibrr.com/) [[@charlesverdad](https://github.com/charlesverdad)]\n1. [Kargo](https://kargo.com) [[@chaithra-yenikapati](https://github.com/chaithra-yenikapati), [@akarsh3007](https://github.com/akarsh3007) & [@dineshanchan](https://github.com/dineshanchan)]\n1. [Karmic](https://karmiclabs.com) [[@hyw](https://github.com/hyw)]\n1. [King](https://king.com) [[@nathadfield](https://github.com/nathadfield)]\n1. [King Abdullah Petroleum Studies and Research Center(KAPSARC)](https://github.com/kapsarc) [[@saianupkumarp](https://github.com/saianupkumarp)]\n1. [Kiwi.com](https://kiwi.com/) [[@underyx](https://github.com/underyx)]\n1. [Kogan.com](https://github.com/kogan) [[@geeknam](https://github.com/geeknam)]\n1. [Korbit](https://www.korbit.co.kr/) [[@jensenity](https://github.com/jensenity)]\n1. [KPN B.V.](https://www.kpn.com/) [[@biyanisuraj](https://github.com/biyanisuraj) & [@gmic](https://github.com/gmic)]\n1. [Kroton Educacional](http://www.kroton.com.br/)\n1. [Lemann Foundation](http://fundacaolemann.org.br) [[@fernandosjp](https://github.com/fernandosjp)]\n1. [LeMans Corporation](https://www.parts-unlimited.com/) [[@alloydwhitlock](https://github.com/alloydwhitlock)] & [[@tinyrye](https://github.com/tinyrye)]\n1. [LendUp](https://www.lendup.com/) [[@lendup](https://github.com/lendup)]\n1. [LetsBonus](http://www.letsbonus.com) [[@jesusfcr](https://github.com/jesusfcr) & [@OpringaoDoTurno](https://github.com/OpringaoDoTurno)]\n1. [Liberty Global](https://www.libertyglobal.com/) [[@LibertyGlobal](https://github.com/LibertyGlobal/)]\n1. [liligo](http://liligo.com/) [[@tromika](https://github.com/tromika)]\n1. [LingoChamp](http://www.liulishuo.com/) [[@haitaoyao](https://github.com/haitaoyao)]\n1. [Logitravel Group](https://www.logitravel.com/)\n1. [Los Angeles Times](http://www.latimes.com/) [[@standyro](https://github.com/standyro)]\n1. [LokSuvidha](http://loksuvidha.com/) [[@saurabhwahile](https://github.com/saurabhwahile)]\n1. [Lucid](http://luc.id) [[@jbrownlucid](https://github.com/jbrownlucid) & [@kkourtchikov](https://github.com/kkourtchikov)]\n1. [Lumos Labs](https://www.lumosity.com/) [[@rfroetscher](https://github.com/rfroetscher/) & [@zzztimbo](https://github.com/zzztimbo/)]\n1. [Lyft](https://www.lyft.com/) [[@feng-tao](https://github.com/feng-tao), [@milton0825](https://github.com/milton0825), [@astahlman](https://github.com/astahlman),\n [@youngyjd](https://github.com/youngyjd), [@ArgentFalcon](https://github.com/ArgentFalcon)]\n1. [M4U](https://www.m4u.com.br/) [[@msantino](https://github.com/msantino)]\n1. [Madrone](http://madroneco.com/) [[@mbreining](https://github.com/mbreining) & [@scotthb](https://github.com/scotthb)]\n1. [Markovian](https://markovian.com/) [[@al-xv](https://github.com/al-xv), [@skogsbaeck](https://github.com/skogsbaeck), [@waltherg](https://github.com/waltherg)]\n1. [Mercadoni](https://www.mercadoni.com.co) [[@demorenoc](https://github.com/demorenoc)]\n1. [Mercari](http://www.mercari.com/) [[@yu-iskw](https://github.com/yu-iskw)]\n1. [MFG Labs](https://github.com/MfgLabs)\n1. [MiNODES](https://www.minodes.com) [[@dice89](https://github.com/dice89), [@diazcelsa](https://github.com/diazcelsa)]\n1. [Modernizing Medicine](https://www.modmed.com/)[[@kehv1n](https://github.com/kehv1n), [@dalupus](https://github.com/dalupus)]\n1. [Multiply](https://www.multiply.com) [[@nrhvyc](https://github.com/nrhvyc)]\n1. [mytaxi](https://mytaxi.com) [[@mytaxi](https://github.com/mytaxi)]\n1. [National Bank of Canada](https://nbc.ca) [[@brilhana](https://github.com/brilhana)]\n1. [Neoway](https://www.neoway.com.br/) [[@neowaylabs](https://github.com/orgs/NeowayLabs/people)]\n1. [Nerdwallet](https://www.nerdwallet.com)\n1. [New Relic](https://www.newrelic.com) [[@marcweil](https://github.com/marcweil)]\n1. [Newzoo](https://www.newzoo.com) [[@newzoo-nexus](https://github.com/newzoo-nexus)]\n1. [NEXT Trucking](https://www.nexttrucking.com/) [[@earthmancash2](https://github.com/earthmancash2), [@kppullin](https://github.com/kppullin)]\n1. [Nextdoor](https://nextdoor.com) [[@SivaPandeti](https://github.com/SivaPandeti), [@zshapiro](https://github.com/zshapiro) & [@jthomas123](https://github.com/jthomas123)]\n1. [Nine](https://nine.com.au) [[@TheZepto](https://github.com/TheZepto)]\n1. [OdysseyPrime](https://www.goprime.io/) [[@davideberdin](https://github.com/davideberdin)]\n1. [OfferUp](https://offerupnow.com)\n1. [OneFineStay](https://www.onefinestay.com) [[@slangwald](https://github.com/slangwald)]\n1. [Open Knowledge International](https://okfn.org) [@vitorbaptista](https://github.com/vitorbaptista)\n1. [Optum](https://www.optum.com/) - [UnitedHealthGroup](https://www.unitedhealthgroup.com/) [[@hiteshrd](https://github.com/hiteshrd)]\n1. [Outcome Health](https://www.outcomehealth.com/) [[@mikethoun](https://github.com/mikethoun), [@rolandotribo](https://github.com/rolandotribo)]\n1. [Overstock](https://www.github.com/overstock) [[@mhousley](https://github.com/mhousley) & [@mct0006](https://github.com/mct0006)]\n1. [OVH](https://www.ovh.com) [[@ncrocfer](https://github.com/ncrocfer) & [@anthonyolea](https://github.com/anthonyolea)]\n1. [Pagar.me](https://pagar.me/) [[@pagarme](https://github.com/pagarme)]\n1. [Palo Alto Networks](https://www.paloaltonetworks.com/) [[@PaloAltoNetworks](https://github.com/PaloAltoNetworks)]\n1. [Pandora Media](https://www.pandora.com/) [[@Acehaidrey](https://github.com/Acehaidrey) & [@wolfier](https://github.com/wolfier)]\n1. [PayFit](https://payfit.com) [[@pcorbel](https://github.com/pcorbel)]\n1. [PAYMILL](https://www.paymill.com/) [[@paymill](https://github.com/paymill) & [@matthiashuschle](https://github.com/matthiashuschle)]\n1. [PayPal](https://www.paypal.com/) [[@r39132](https://github.com/r39132) & [@jhsenjaliya](https://github.com/jhsenjaliya)]\n1. [Pecan](https://www.pecan.ai) [[@ohadmata](https://github.com/ohadmata)]\n1. [Pernod-Ricard](https://www.pernod-ricard.com/) [[@romain-nio](https://github.com/romain-nio)]\n1. [Plaid](https://www.plaid.com/) [[@plaid](https://github.com/plaid), [@AustinBGibbons](https://github.com/AustinBGibbons) & [@jeeyoungk](https://github.com/jeeyoungk)]\n1. [Playbuzz](https://www.playbuzz.com/) [[@clintonboys](https://github.com/clintonboys) & [@dbn](https://github.com/dbn)]\n1. [PMC](https://pmc.com/) [[@andrewm4894](https://github.com/andrewm4894)]\n1. [Poshmark](https://www.poshmark.com)\n1. [Postmates](http://www.postmates.com) [[@syeoryn](https://github.com/syeoryn)]\n1. [Premise](http://www.premise.com) [[@jmccallum-premise](https://github.com/jmccallum-premise)]\n1. [Pronto Tools](http://www.prontotools.io/) [[@zkan](https://github.com/zkan) & [@mesodiar](https://github.com/mesodiar)]\n1. [proton.ai](https://proton.ai/) [[@prmsolutions](https://github.com/prmsolutions)]\n1. [Publicis Pixelpark](https://www.publicispixelpark.de/) [[@feluelle](https://github.com/feluelle)]\n1. [PubNub](https://pubnub.com) [[@jzucker2](https://github.com/jzucker2)]\n1. [PXYData](https://www.pxydata.com) [[@patchus](http://github.com/patchus)]\n1. [Qplum](https://qplum.co) [[@manti](https://github.com/manti)]\n1. [Quantopian](https://www.quantopian.com/) [[@eronarn](http://github.com/eronarn)]\n1. [Qubole](https://qubole.com) [[@msumit](https://github.com/msumit)]\n1. [Quizlet](https://quizlet.com) [[@quizlet](https://github.com/quizlet)]\n1. [Quora](https://www.quora.com/)\n1. [Ra\u00edzen](https://www.raizen.com.br/) [[@rudlac](https://github.com/rudlac) & [@guifneves](https://github.com/guifneves)]\n1. [REA Group](https://www.rea-group.com/)\n1. [Reddit](https://www.reddit.com/) [[@reddit](https://github.com/reddit/)]\n1. [Reverb](https://reverb.com)[[@reverbdotcom](https://github.com/reverbdotcom)]\n1. [Revolut](https://www.revolut.com/) [[@sztanko](https://github.com/sztanko) & [@nautilus28](https://github.com/nautilus28)]\n1. [Robinhood](https://robinhood.com) [[@vineet-rh](https://github.com/vineet-rh)]\n1. [Scaleway](https://scaleway.com) [[@kdeldycke](https://github.com/kdeldycke)]\n1. [Seasoned](https://www.seasoned.co/) [[@joshuacano](https://github.com/joshuacano)] & [[@mmyers](https://github.com/mmyers5)] & [[@tjward](https://github.com/tjward)]\n1. [Secret Escapes](https://www.secretescapes.com) [[@secretescapes](https://github.com/secretescapes)]\n1. [Semantics3](https://www.semantics3.com) [[@abishekk92](https://github.com/abishekk92)]\n1. [Sense360](https://github.com/Sense360) [[@kamilmroczek](https://github.com/KamilMroczek)]\n1. [Sentry.io](https://www.sentry.io) [[@tiopi](https://github.com/tiopi)]\n1. [Shopkick](https://shopkick.com/) [[@shopkick](https://github.com/shopkick)]\n1. [Sidecar](https://hello.getsidecar.com/) [[@getsidecar](https://github.com/getsidecar)]\n1. [SimilarWeb](https://www.similarweb.com/) [[@similarweb](https://github.com/similarweb)]\n1. [Skyscanner](https://www.skyscanner.net/) [[@skyscanner](https://github.com/Skyscanner)]\n1. [SmartNews](https://www.smartnews.com/) [[@takus](https://github.com/takus)]\n1. [SnapTravel](https://www.snaptravel.com/)\n1. [SocialCops](https://www.socialcops.com/) [[@vinayak-mehta](https://github.com/vinayak-mehta) & [@sharky93](https://github.com/sharky93)]\n1. [Soci\u00e9t\u00e9 g\u00e9n\u00e9rale](https://www.societegenerale.fr/) [[@medmrgh](https://github.com/medmrgh) & [@s83](https://github.com/s83)]\n1. [Spotahome](https://www.spotahome.com/) [[@spotahome](https://github.com/spotahome)]\n1. [SpotHero](https://github.com/spothero) [[@benjigoldberg](https://github.com/benjigoldberg)]\n1. [Spotify](https://github.com/spotify) [[@znichols](https://github.com/znichols)]\n1. [Square](https://squareup.com/)\n1. [Stackspace](https://beta.stackspace.io/)\n1. [StoneCo](https://www.stone.co) [[@lgwacker](https://github.com/lgwacker)]\n1. [Strava](https://strava.com) [[@strava](https://github.com/strava), [@dhuang](https://github.com/dhuang) & [@liamstewart](https://github.com/liamstewart)]\n1. [Stripe](https://stripe.com) [[@jbalogh](https://github.com/jbalogh)]\n1. [Strongmind](https://www.strongmind.com) [[@tomchapin](https://github.com/tomchapin) & [@wongstein](https://github.com/wongstein)]\n1. [Surfline](https://www.surfline.com/) [[@jawang35](https://github.com/jawang35)]\n1. [T2 Systems](http://t2systems.com) [[@unclaimedpants](https://github.com/unclaimedpants)]\n1. [Tails.com](https://tails.com/) [[@alanmcruickshank](https://github.com/alanmcruickshank)]\n1. [TEK](https://www.tek.fi/en) [[@telac](https://github.com/telac)]\n1. [Telefonica Innovation Alpha](https://www.alpha.company/) [[@Alpha-Health](https://github.com/Alpha-health)]\n1. [Telia Company](https://www.teliacompany.com/en)\n1. [Tesla](https://www.tesla.com/) [[@thoralf-gutierrez](https://github.com/thoralf-gutierrez)]\n1. [The Home Depot](https://www.homedepot.com/)[[@apekshithr](https://github.com/apekshithr)]\n1. [THE ICONIC](https://www.theiconic.com.au/) [[@revathijay](https://github.com/revathijay)] [[@ilikedata](https://github.com/ilikedata)]\n1. [Thinking Machines](https://thinkingmachin.es) [[@marksteve](https://github.com/marksteve)]\n1. [Thinknear](https://www.thinknear.com/) [[@d3cay1](https://github.com/d3cay1), [@ccson](https://github.com/ccson), & [@ababian](https://github.com/ababian)]\n1. [ThoughtWorks](https://www.thoughtworks.com/) [[@sann3](https://github.com/sann3)]\n1. [Thumbtack](https://www.thumbtack.com/) [[@natekupp](https://github.com/natekupp)]\n1. [Tictail](https://tictail.com/)\n1. [Tile](https://tile.com/) [[@ranjanmanish](https://github.com/ranjanmanish)]\n1. [Tinder](https://tinder.com/) [[@kbendick](https://github.com/kbendick)]\n1. [TokenAnalyst](https://github.com/tokenanalyst) [[@simonohanlon101](https://github.com/simonohanlon101), [@ankitchiplunkar](https://github.com/ankitchiplunkar), [@sidshekhar](https://github.com/sidshekhar), [@sp6pe](https://github.com/sp6pe)]\n1. [Tokopedia](https://www.tokopedia.com/) [[@topedmaria](https://github.com/topedmaria)]\n1. [Trocafone](https://www.trocafone.com/) [[@idontdomath](https://github.com/idontdomath) & [@gseva](https://github.com/gseva) & [@ordonezf](https://github.com/ordonezf) & [@PalmaLeandro](https://github.com/PalmaLeandro)]\n1. [Twine Labs](https://www.twinelabs.com/) [[@ivorpeles](https://github.com/ivorpeles)]\n1. [Twitter](https://www.twitter.com/) [[@aoen](https://github.com/aoen)]\n1. [Ubisoft](https://www.ubisoft.com/) [[@Walkoss](https://github.com/Walkoss)]\n1. [United Airlines](https://www.united.com/) [[@ilopezfr](https://github.com/ilopezfr)]\n1. [Upsight](https://www.upsight.com)\n1. [VeeR VR](https://veer.tv) [[@pishilong](https://github.com/pishilong)]\n1. [Veikkaus](https://www.veikkaus.fi) [[@hixus](https://github.com/hixus)]\n1. [Vente-Exclusive.com](http://www.vente-exclusive.com/) [[@alexvanboxel](https://github.com/alexvanboxel)]\n1. [Vevo](https://www.vevo.com/) [[@csetiawan](https://github.com/csetiawan) & [@jerrygillespie](https://github.com/jerrygillespie)]\n1. [Vidio](https://www.vidio.com/)\n1. [Ville de Montr\u00e9al](http://ville.montreal.qc.ca/)[@VilledeMontreal](https://github.com/VilledeMontreal/)]\n1. [Vnomics](https://github.com/vnomics) [[@lpalum](https://github.com/lpalum)]\n1. [Walmart Labs](https://www.walmartlabs.com) [[@bharathpalaksha](https://github.com/bharathpalaksha), [@vipul007ravi](https://github.com/vipul007ravi)]\n1. [Waze](https://www.waze.com) [[@waze](https://github.com/wazeHQ)]\n1. [WePay](http://www.wepay.com) [[@criccomini](https://github.com/criccomini) & [@mtagle](https://github.com/mtagle)]\n1. [WeTransfer](https://github.com/WeTransfer) [[@coredipper](https://github.com/coredipper) & [@higee](https://github.com/higee) & [@azclub](https://github.com/azclub)]\n1. [Whistle Labs](http://www.whistle.com) [[@ananya77041](https://github.com/ananya77041)]\n1. [WiseBanyan](https://wisebanyan.com/)\n1. [Wooga](https://www.wooga.com/)\n1. [Wrike](https://www.wrike.com) [[@eliseealex](https://github.com/eliseealex) & [teoretic6](https://github.com/Teoretic6)]\n1. [Xero](https://www.xero.com/) [[@yan9yu](https://github.com/yan9yu) & [adamantnz](https://github.com/adamantnz/)]\n1. [Xoom](https://www.xoom.com/)\n1. [Yahoo!](https://www.yahoo.com/)\n1. [Yieldr](https://www.yieldr.com/) [[@ggeorgiadis](https://github.com/ggeorgiadis)]\n1. [Zapier](https://www.zapier.com) [[@drknexus](https://github.com/drknexus) & [@statwonk](https://github.com/statwonk)]\n1. [Zego](https://www.zego.com/) [[@ruimffl](https://github.com/ruimffl), [@james-welly](https://github.com/james-welly), [@ken-payne](https://github.com/ken-payne)]\n1. [Zendesk](https://www.github.com/zendesk)\n1. [Zenly](https://zen.ly) [[@cerisier](https://github.com/cerisier) & [@jbdalido](https://github.com/jbdalido)]\n1. [Zymergen](https://www.zymergen.com/)\n1. [Zynga](https://www.zynga.com)\n\n## Who Maintains Apache Airflow?\n\nAirflow is the work of the [community](https://github.com/apache/airflow/graphs/contributors),\nbut the [core committers/maintainers](https://people.apache.org/committers-by-project.html#airflow)\nare responsible for reviewing and merging PRs as well as steering conversation around new feature requests.\nIf you would like to become a maintainer, please review the Apache Airflow\n[committer requirements](https://cwiki.apache.org/confluence/display/AIRFLOW/Committers).\n\n## Can I use the Apache Airflow logo in my presentation?\n\nYes! Be sure to abide by the Apache Foundation [trademark policies](https://www.apache.org/foundation/marks/#books) and the Apache Airflow [Brandbook](https://cwiki.apache.org/confluence/display/AIRFLOW/Brandbook). The most up to date logos are found in [this repo](/docs/img/logos) and on the Apache Software Foundation [website](https://www.apache.org/logos/about.html).\n\n## Links\n\n- [Documentation](https://airflow.apache.org/)\n- [Chat](https://apache-airflow-slack.herokuapp.com/)\n- [More](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Links)\n"}, {"repo": "yunjey/pytorch-tutorial", "language": "Python", "readme_contents": "<p align=\"center\"><img width=\"40%\" src=\"logo/pytorch_logo_2018.svg\" /></p>\n\n--------------------------------------------------------------------------------\n\nThis repository provides tutorial code for deep learning researchers to learn [PyTorch](https://github.com/pytorch/pytorch). In the tutorial, most of the models were implemented with less than 30 lines of code. Before starting this tutorial, it is recommended to finish [Official Pytorch Tutorial](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n\n\n<br/>\n\n## Table of Contents\n\n#### 1. Basics\n* [PyTorch Basics](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/pytorch_basics/main.py)\n* [Linear Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/linear_regression/main.py#L22-L23)\n* [Logistic Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/logistic_regression/main.py#L33-L34)\n* [Feedforward Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49)\n\n#### 2. Intermediate\n* [Convolutional Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/convolutional_neural_network/main.py#L35-L56)\n* [Deep Residual Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/deep_residual_network/main.py#L76-L113)\n* [Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L39-L58)\n* [Bidirectional Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/bidirectional_recurrent_neural_network/main.py#L39-L58)\n* [Language Model (RNN-LM)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model/main.py#L30-L50)\n\n#### 3. Advanced\n* [Generative Adversarial Networks](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.py#L41-L57)\n* [Variational Auto-Encoder](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65)\n* [Neural Style Transfer](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/neural_style_transfer)\n* [Image Captioning (CNN-RNN)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning)\n\n#### 4. Utilities\n* [TensorBoard in PyTorch](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard)\n\n\n\n<br/>\n\n## Getting Started\n```bash\n$ git clone https://github.com/yunjey/pytorch-tutorial.git\n$ cd pytorch-tutorial/tutorials/PATH_TO_PROJECT\n$ python main.py\n```\n\n<br/>\n\n## Dependencies\n* [Python 2.7 or 3.5+](https://www.continuum.io/downloads)\n* [PyTorch 0.4.0+](http://pytorch.org/)\n\n\n\n<br/>\n\n\n## Author\nYunjey Choi/ [@yunjey](https://github.com/yunjey)\n"}, {"repo": "nicolargo/glances", "language": "Python", "readme_contents": "===============================\nGlances - An eye on your system\n===============================\n\n.. image:: https://img.shields.io/pypi/v/glances.svg\n    :target: https://pypi.python.org/pypi/Glances\n\n.. image:: https://img.shields.io/github/stars/nicolargo/glances.svg\n    :target: https://github.com/nicolargo/glances/\n    :alt: Github stars\n\n.. image:: https://pepy.tech/badge/glances/month\n    :target: https://pepy.tech/project/glances\n    :alt: Downloads\n\n.. image:: https://img.shields.io/travis/nicolargo/glances/master.svg?maxAge=3600&label=Linux%20/%20BSD%20/%20macOS\n    :target: https://travis-ci.org/nicolargo/glances\n    :alt: Linux tests (Travis)\n\n.. image:: https://img.shields.io/appveyor/ci/nicolargo/glances/master.svg?maxAge=3600&label=Windows\n    :target: https://ci.appveyor.com/project/nicolargo/glances\n    :alt: Windows tests (Appveyor)\n\n.. image:: https://scrutinizer-ci.com/g/nicolargo/glances/badges/quality-score.png?b=develop\n    :target: https://scrutinizer-ci.com/g/nicolargo/glances/?branch=develop\n\n.. image:: https://img.shields.io/badge/Donate-PayPal-green.svg\n    :target: https://www.paypal.me/nicolargo\n\n.. image:: https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&label=Follow%20%40nicolargo\n    :target: https://twitter.com/nicolargo\n\nSummary\n=======\n\n**Glances** is a cross-platform monitoring tool which aims to present a\nlarge amount of monitoring information through a curses or Web\nbased interface. The information dynamically adapts depending on the\nsize of the user interface.\n\n.. image:: https://raw.githubusercontent.com/nicolargo/glances/develop/docs/_static/glances-summary.png\n\nIt can also work in client/server mode. Remote monitoring could be done\nvia terminal, Web interface or API (XML-RPC and RESTful). Stats can also\nbe exported to files or external time/value databases.\n\n.. image:: https://raw.githubusercontent.com/nicolargo/glances/develop/docs/_static/glances-responsive-webdesign.png\n\nGlances is written in Python and uses libraries to grab information from\nyour system. It is based on an open architecture where developers can\nadd new plugins or exports modules.\n\nRequirements\n============\n\n- ``python 2.7,>=3.4``\n- ``psutil>=5.3.0`` (better with latest version)\n\nOptional dependencies:\n\n- ``bernhard`` (for the Riemann export module)\n- ``bottle`` (for Web server mode)\n- ``cassandra-driver`` (for the Cassandra export module)\n- ``couchdb`` (for the CouchDB export module)\n- ``docker`` (for the Docker monitoring support) [Linux/macOS-only]\n- ``elasticsearch`` (for the Elastic Search export module)\n- ``hddtemp`` (for HDD temperature monitoring support) [Linux-only]\n- ``influxdb`` (for the InfluxDB export module)\n- ``kafka-python`` (for the Kafka export module)\n- ``netifaces`` (for the IP plugin)\n- ``nvidia-ml-py3`` (for the GPU plugin)\n- ``pika`` (for the RabbitMQ/ActiveMQ export module)\n- ``potsdb`` (for the OpenTSDB export module)\n- ``prometheus_client`` (for the Prometheus export module)\n- ``py-cpuinfo`` (for the Quicklook CPU info module)\n- ``pygal`` (for the graph export module)\n- ``pymdstat`` (for RAID support) [Linux-only]\n- ``pySMART.smartx`` (for HDD Smart support) [Linux-only]\n- ``pysnmp`` (for SNMP support)\n- ``pystache`` (for the action script feature)\n- ``pyzmq`` (for the ZeroMQ export module)\n- ``requests`` (for the Ports, Cloud plugins and RESTful export module)\n- ``scandir`` (for the Folders plugin) [Only for Python < 3.5]\n- ``statsd`` (for the StatsD export module)\n- ``wifi`` (for the wifi plugin) [Linux-only]\n- ``zeroconf`` (for the autodiscover mode)\n\n*Note for Python 2.6 users*\n\nGlances no longer supports Python 2.6. Please upgrade\nto a minimum Python version of 2.7/3.4+ or downgrade to Glances 2.6.2 (last version\nwith Python 2.6 support).\n\n*Note for CentOS Linux 6 and 7 users*\n\nPython 2.7 and 3.4 are now available via SCL repositories. See:\nhttps://lists.centos.org/pipermail/centos-announce/2015-December/021555.html.\n\nInstallation\n============\n\nThere are several methods to test/install Glances on your system. Choose your weapon!\n\nGlances Auto Install script: the total way\n------------------------------------------\n\nTo install both dependencies and the latest Glances production ready version\n(aka *master* branch), just enter the following command line:\n\n.. code-block:: console\n\n    curl -L https://bit.ly/glances | /bin/bash\n\nor\n\n.. code-block:: console\n\n    wget -O- https://bit.ly/glances | /bin/bash\n\n*Note*: This is only supported on some GNU/Linux distributions and Mac OS X.\nIf you want to support other distributions, please contribute to `glancesautoinstall`_.\n\nPyPI: The simple way\n--------------------\n\nGlances is on ``PyPI``. By using PyPI, you will be using the latest\nstable version.\n\nTo install, simply use ``pip``:\n\n.. code-block:: console\n\n    pip install glances\n\n*Note*: Python headers are required to install `psutil`_. For example,\non Debian/Ubuntu you need to install first the *python-dev* package.\nFor Fedora/CentOS/RHEL install first *python-devel* package. For Windows,\njust install psutil from the binary installation file.\n\n*Note 2 (for the Wifi plugin)*: If you want to use the Wifi plugin, you need\nto install the *wireless-tools* package on your system.\n\nYou can also install the following libraries in order to use optional\nfeatures (like the Web interface, exports modules...):\n\n.. code-block:: console\n\n    pip install 'glances[action,browser,cloud,cpuinfo,docker,export,folders,gpu,graph,ip,raid,snmp,web,wifi]'\n\nTo upgrade Glances to the latest version:\n\n.. code-block:: console\n\n    pip install --upgrade glances\n    pip install --upgrade glances[...]\n\nIf you need to install Glances in a specific user location, use:\n\n.. code-block:: console\n\n    export PYTHONUSERBASE=~/mylocalpath\n    pip install --user glances\n\nDocker: the funny way\n---------------------\n\nA Glances container is available. It includes the latest development\nHEAD version. You can use it to monitor your server and all your other\ncontainers!\n\nGet the Glances container:\n\n.. code-block:: console\n\n    docker pull nicolargo/glances\n\nRun the container in *console mode*:\n\n.. code-block:: console\n\n    docker run --rm -v /var/run/docker.sock:/var/run/docker.sock:ro --pid host --network host -it docker.io/nicolargo/glances\n\nAdditionally, if you want to use your own glances.conf file, you can\ncreate your own Dockerfile:\n\n.. code-block:: console\n\n    FROM nicolargo/glances\n    COPY glances.conf /glances/conf/glances.conf\n    CMD python -m glances -C /glances/conf/glances.conf $GLANCES_OPT\n\nAlternatively, you can specify something along the same lines with\ndocker run options:\n\n.. code-block:: console\n\n    docker run -v `pwd`/glances.conf:/glances/conf/glances.conf -v /var/run/docker.sock:/var/run/docker.sock:ro --pid host -it docker.io/nicolargo/glances\n\nWhere \\`pwd\\`/glances.conf is a local directory containing your glances.conf file.\n\nRun the container in *Web server mode* (notice the `GLANCES_OPT` environment\nvariable setting parameters for the glances startup command):\n\n.. code-block:: console\n\n    docker run -d --restart=\"always\" -p 61208-61209:61208-61209 -e GLANCES_OPT=\"-w\" -v /var/run/docker.sock:/var/run/docker.sock:ro --pid host docker.io/nicolargo/glances\n\nGNU/Linux\n---------\n\n`Glances` is available on many Linux distributions, so you should be\nable to install it using your favorite package manager. Be aware that\nwhen you use this method the operating system `package`_ for `Glances`\nmay not be the latest version.\n\n\nFreeBSD\n-------\n\nTo install the binary package:\n\n.. code-block:: console\n\n    # pkg install py27-glances\n\nTo install Glances from ports:\n\n.. code-block:: console\n\n    # cd /usr/ports/sysutils/py-glances/\n    # make install clean\n\nmacOS\n-----\n\nIf you do not want to use the glancesautoinstall script, follow this procedure.\n\nmacOS users can install Glances using ``Homebrew`` or ``MacPorts``.\n\nHomebrew\n````````\n\n.. code-block:: console\n\n    $ brew install glances\n\nMacPorts\n````````\n\n.. code-block:: console\n\n    $ sudo port install glances\n\nWindows\n-------\n\nInstall `Python`_ for Windows (Python 2.7.9+ and 3.4+ ship with pip) and\nthen run the following command:\n\n.. code-block:: console\n\n    $ pip install glances\n\nAlternatively, you could clone the repository and install with the following command.\n\n.. code-block:: console\n\n    $ git clone https://github.com/nicolargo/glances.git\n    $ cd glances\n    $ python setup.py install\n\n\nAndroid\n-------\n\nYou need a rooted device and the `Termux`_ application (available on the\nGoogle Play Store).\n\nStart Termux on your device and enter:\n\n.. code-block:: console\n\n    $ apt update\n    $ apt upgrade\n    $ apt install clang python python-dev\n    $ pip install bottle\n    $ pip install glances\n\nAnd start Glances:\n\n.. code-block:: console\n\n    $ glances\n\nYou can also run Glances in server mode (-s or -w) in order to remotely\nmonitor your Android device.\n\nSource\n------\n\nTo install Glances from source:\n\n.. code-block:: console\n\n    $ wget https://github.com/nicolargo/glances/archive/vX.Y.tar.gz -O - | tar xz\n    $ cd glances-*\n    # python setup.py install\n\n*Note*: Python headers are required to install psutil.\n\nChef\n----\n\nAn awesome ``Chef`` cookbook is available to monitor your infrastructure:\nhttps://supermarket.chef.io/cookbooks/glances (thanks to Antoine Rouyer)\n\nPuppet\n------\n\nYou can install Glances using ``Puppet``: https://github.com/rverchere/puppet-glances\n\nAnsible\n-------\n\nA Glances ``Ansible`` role is available: https://galaxy.ansible.com/zaxos/glances-ansible-role/\n\nUsage\n=====\n\nFor the standalone mode, just run:\n\n.. code-block:: console\n\n    $ glances\n\nFor the Web server mode, run:\n\n.. code-block:: console\n\n    $ glances -w\n\nand enter the URL ``http://<ip>:61208`` in your favorite web browser.\n\nFor the client/server mode, run:\n\n.. code-block:: console\n\n    $ glances -s\n\non the server side and run:\n\n.. code-block:: console\n\n    $ glances -c <ip>\n\non the client one.\n\nYou can also detect and display all Glances servers available on your\nnetwork or defined in the configuration file:\n\n.. code-block:: console\n\n    $ glances --browser\n\nYou can also display raw stats on stdout:\n\n.. code-block:: console\n\n    $ glances --stdout cpu.user,mem.used,load\n    cpu.user: 30.7\n    mem.used: 3278204928\n    load: {'cpucore': 4, 'min1': 0.21, 'min5': 0.4, 'min15': 0.27}\n    cpu.user: 3.4\n    mem.used: 3275251712\n    load: {'cpucore': 4, 'min1': 0.19, 'min5': 0.39, 'min15': 0.27}\n    ...\n\nor in a CSV format thanks to the stdout-csv option:\n\n.. code-block:: console\n\n    $ glances --stdout-csv now,cpu.user,mem.used,load\n    now,cpu.user,mem.used,load.cpucore,load.min1,load.min5,load.min15\n    2018-12-08 22:04:20 CEST,7.3,5948149760,4,1.04,0.99,1.04\n    2018-12-08 22:04:23 CEST,5.4,5949136896,4,1.04,0.99,1.04\n    ...\n\nand RTFM, always.\n\nDocumentation\n=============\n\nFor complete documentation have a look at the readthedocs_ website.\n\nIf you have any question (after RTFM!), please post it on the official Q&A `forum`_.\n\nGateway to other services\n=========================\n\nGlances can export stats to: ``CSV`` file, ``JSON`` file, ``InfluxDB``, ``Cassandra``, ``CouchDB``,\n``OpenTSDB``, ``Prometheus``, ``StatsD``, ``ElasticSearch``, ``RabbitMQ/ActiveMQ``,\n``ZeroMQ``, ``Kafka``, ``Riemann`` and ``RESTful`` server.\n\nHow to contribute ?\n===================\n\nIf you want to contribute to the Glances project, read this `wiki`_ page.\n\nThere is also a chat dedicated to the Glances developers:\n\n.. image:: https://badges.gitter.im/Join%20Chat.svg\n        :target: https://gitter.im/nicolargo/glances?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\nDonation\n========\n\nIf this project help you, you can give me a tip ;)\n\n.. image:: https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif\n        :target: https://www.paypal.me/nicolargo\n\nAuthor\n======\n\nNicolas Hennion (@nicolargo) <nicolas@nicolargo.com>\n\n.. image:: https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&label=Follow%20%40nicolargo\n    :target: https://twitter.com/nicolargo\n\nLicense\n=======\n\nGlances is distributed under the LGPL version 3 license. See ``COPYING`` for more details.\n\n.. _psutil: https://github.com/giampaolo/psutil\n.. _glancesautoinstall: https://github.com/nicolargo/glancesautoinstall\n.. _Python: https://www.python.org/getit/\n.. _Termux: https://play.google.com/store/apps/details?id=com.termux\n.. _readthedocs: https://glances.readthedocs.io/\n.. _forum: https://groups.google.com/forum/?hl=en#!forum/glances-users\n.. _wiki: https://github.com/nicolargo/glances/wiki/How-to-contribute-to-Glances-%3F\n.. _package: https://repology.org/metapackage/glances/packages\n"}, {"repo": "tensorflow/magenta", "language": "Python", "readme_contents": "\n<img src=\"magenta-logo-bg.png\" height=\"75\">\n\n[![Build Status](https://travis-ci.org/tensorflow/magenta.svg?branch=master)](https://travis-ci.org/tensorflow/magenta)\n [![PyPI version](https://badge.fury.io/py/magenta.svg)](https://badge.fury.io/py/magenta)\n\n**Magenta** is a research project exploring the role of machine learning\nin the process of creating art and music.  Primarily this\ninvolves developing new deep learning and reinforcement learning\nalgorithms for generating songs, images, drawings, and other materials. But it's also\nan exploration in building smart tools and interfaces that allow\nartists and musicians to extend (not replace!) their processes using\nthese models.  Magenta was started by some researchers and engineers\nfrom the [Google Brain team](https://research.google.com/teams/brain/),\nbut many others have contributed significantly to the project. We use\n[TensorFlow](https://www.tensorflow.org) and release our models and\ntools in open source on this GitHub.  If you\u2019d like to learn more\nabout Magenta, check out our [blog](https://magenta.tensorflow.org),\nwhere we post technical details.  You can also join our [discussion\ngroup](https://groups.google.com/a/tensorflow.org/forum/#!forum/magenta-discuss).\n\nThis is the home for our Python TensorFlow library. To use our models in the browser with [TensorFlow.js](https://js.tensorflow.org/), head to the [Magenta.js](https://github.com/tensorflow/magenta-js) repository.\n\n## Getting Started\n\n* [Installation](#installation)\n* [Using Magenta](#using-magenta)\n* [Playing a MIDI Instrument](#playing-a-midi-instrument)\n* [Development Environment (Advanced)](#development-environment)\n\n## Installation\n\nMagenta maintains a [pip package](https://pypi.python.org/pypi/magenta) for easy\ninstallation. We recommend using Anaconda to install it, but it can work in any\nstandard Python environment. We support both Python 2 (>= 2.7) and Python 3 (>= 3.5).\nThese instructions will assume you are using Anaconda.\n\n### Automated Install (w/ Anaconda)\n\nIf you are running Mac OS X or Ubuntu, you can try using our automated\ninstallation script. Just paste the following command into your terminal.\n\n```bash\ncurl https://raw.githubusercontent.com/tensorflow/magenta/master/magenta/tools/magenta-install.sh > /tmp/magenta-install.sh\nbash /tmp/magenta-install.sh\n```\n\nAfter the script completes, open a new terminal window so the environment\nvariable changes take effect.\n\nThe Magenta libraries are now available for use within Python programs and\nJupyter notebooks, and the Magenta scripts are installed in your path!\n\nNote that you will need to run `source activate magenta` to use Magenta every\ntime you open a new terminal window.\n\n### Manual Install (w/o Anaconda)\n\nIf the automated script fails for any reason, or you'd prefer to install by\nhand, do the following steps.\n\nInstall the Magenta pip package:\n\n```bash\npip install magenta\n```\n\n**NOTE**: In order to install the `rtmidi` and `pyaudio` packages that we depend on, you may need to install headers for some sound libraries. On Linux, this command should install the necessary packages:\n\n```bash\nsudo apt-get install build-essential libasound2-dev libjack-dev portaudio19-dev\n```\n\nThe Magenta libraries are now available for use within Python programs and\nJupyter notebooks, and the Magenta scripts are installed in your path!\n\n## Using Magenta\n\nYou can now train our various models and use them to generate music, audio, and images. You can\nfind instructions for each of the models by exploring the [models directory](magenta/models).\n\nTo get started, create your own melodies with TensorFlow using one of the various configurations of our [Melody RNN](magenta/models/melody_rnn) model; a recurrent neural network for predicting melodies.\n\n## Playing a MIDI Instrument\n\nAfter you've trained one of the models above, you can use our [MIDI interface](magenta/interfaces/midi) to play with it interactively.\n\nWe also have created several [demos](https://github.com/tensorflow/magenta-demos) that provide a UI for this interface, making it easier to use (e.g., the browser-based [AI Jam](https://github.com/tensorflow/magenta-demos/tree/master/ai-jam-js)).\n\n## Development Environment\nIf you want to develop on Magenta, you'll need to set up the full Development Environment.\n\nFirst, clone this repository:\n\n```bash\ngit clone https://github.com/tensorflow/magenta.git\n```\n\nNext, install the dependencies by changing to the base directory and executing the setup command:\n\n```bash\npip install -e .\n```\n\nYou can now edit the files and run scripts by calling Python as usual. For example, this is how you would run the `melody_rnn_generate` script from the base directory:\n\n```bash\npython magenta/models/melody_rnn/melody_rnn_generate --config=...\n```\n\nYou can also install the (potentially modified) package with:\n\n```bash\npip install .\n```\n\nBefore creating a pull request, please also test your changes with:\n\n```bash\npip install pytest-pylint\npytest\n```\n\n## PIP Release\n\nTo build a new version for pip, bump the version and then run:\n\n```bash\npython setup.py test\npython setup.py bdist_wheel --universal\ntwine upload dist/magenta-N.N.N-py2.py3-none-any.whl\n```\n"}, {"repo": "StevenBlack/hosts", "language": "Python", "readme_contents": "----\n**Take Note!**  This version of the Hosts file generator, and tests, are for Python 3.5+ only.\n\n----\n\n![readme](https://user-images.githubusercontent.com/36028424/40330477-9df2c2e0-5d7f-11e8-8ac8-511d719a5eae.png)\n[![latest release](https://img.shields.io/github/release/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/releases)\n[![license](https://img.shields.io/github/license/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/blob/master/license.txt)\n[![repo size](https://img.shields.io/github/repo-size/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts)\n[![contributors](https://img.shields.io/github/contributors/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/graphs/contributors)\n[![Build Status](https://travis-ci.org/StevenBlack/hosts.svg?branch=master)](https://travis-ci.org/StevenBlack/hosts)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)\n[![commits since last release](https://img.shields.io/github/commits-since/StevenBlack/hosts/latest.svg)](https://github.com/StevenBlack/hosts/commits/master)\n[![last commit](https://img.shields.io/github/last-commit/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/commits/master)\n[![commit activity](https://img.shields.io/github/commit-activity/y/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/commits/master)\n\n# Unified hosts file with base extensions\n\nThis repository consolidates several reputable `hosts` files, and merges them\ninto a unified hosts file with duplicates removed.  A variety of tailored hosts files are provided.\n\n* Last updated: **December 02 2019**.\n* Here's the [raw hosts file with base extensions](https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts) containing 43,154 entries.\n* Logo by [@Tobaloidee](https://github.com/Tobaloidee).\n\n\n### List of all hosts file variants\n\nThis repository offers [15 different host file variants](https://github.com/StevenBlack/hosts/tree/master/alternates), in addition to the base variant.\n\nThe **Non GitHub mirror** is the link to use for some hosts file managers like\n[Hostsman for Windows](http://www.abelhadigital.com/hostsman) that don't work\nwith Github download links.\n\nHost file recipe | Readme | Raw hosts | Unique domains | Non Github mirror\n---------------- |:------:|:---------:|:--------------:|:-------------:\nUnified hosts = **(adware + malware)** | [Readme](https://github.com/StevenBlack/hosts/blob/master/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts) | 43,154 | [link](http://sbc.io/hosts/hosts)\nUnified hosts **+ fakenews** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews/hosts) | 44,096 | [link](http://sbc.io/hosts/alternates/fakenews/hosts)\nUnified hosts **+ gambling** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling/hosts) | 45,426 | [link](http://sbc.io/hosts/alternates/gambling/hosts)\nUnified hosts **+ porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/porn/hosts) | 58,797 | [link](http://sbc.io/hosts/alternates/porn/hosts)\nUnified hosts **+ social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/social/hosts) | 45,629 | [link](http://sbc.io/hosts/alternates/social/hosts)\nUnified hosts **+ fakenews + gambling** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling/hosts) | 46,368 | [link](http://sbc.io/hosts/alternates/fakenews-gambling/hosts)\nUnified hosts **+ fakenews + porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-porn/hosts) | 59,739 | [link](http://sbc.io/hosts/alternates/fakenews-porn/hosts)\nUnified hosts **+ fakenews + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-social/hosts) | 46,571 | [link](http://sbc.io/hosts/alternates/fakenews-social/hosts)\nUnified hosts **+ gambling + porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling-porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling-porn/hosts) | 61,069 | [link](http://sbc.io/hosts/alternates/gambling-porn/hosts)\nUnified hosts **+ gambling + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling-social/hosts) | 47,901 | [link](http://sbc.io/hosts/alternates/gambling-social/hosts)\nUnified hosts **+ porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/porn-social/hosts) | 61,271 | [link](http://sbc.io/hosts/alternates/porn-social/hosts)\nUnified hosts **+ fakenews + gambling + porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling-porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling-porn/hosts) | 62,011 | [link](http://sbc.io/hosts/alternates/fakenews-gambling-porn/hosts)\nUnified hosts **+ fakenews + gambling + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling-social/hosts) | 48,843 | [link](http://sbc.io/hosts/alternates/fakenews-gambling-social/hosts)\nUnified hosts **+ fakenews + porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-porn-social/hosts) | 62,213 | [link](http://sbc.io/hosts/alternates/fakenews-porn-social/hosts)\nUnified hosts **+ gambling + porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling-porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling-porn-social/hosts) | 63,543 | [link](http://sbc.io/hosts/alternates/gambling-porn-social/hosts)\nUnified hosts **+ fakenews + gambling + porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling-porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling-porn-social/hosts) | 64,485 | [link](http://sbc.io/hosts/alternates/fakenews-gambling-porn-social/hosts)\n\n\n**Expectation**: These unified hosts files should serve all devices, regardless\nof OS.\n\n## Sources of hosts data unified in this variant\n\nUpdated `hosts` files from the following locations are always unified and\nincluded:\n\nHost file source | Description | Home page | Raw hosts | Update frequency | License | Issues\n-----------------|-------------|:---------:|:---------:|:----------------:|:-------:|:------:\nSteven Black's ad-hoc list | Additional sketch domains as I come across them. |[link](https://github.com/StevenBlack/hosts/blob/master/data/StevenBlack/hosts) | [raw](https://raw.githubusercontent.com/StevenBlack/hosts/master/data/StevenBlack/hosts) | occasionally | MIT  | [issues](https://github.com/StevenBlack/hosts/issues) \nMalware Domain List | Malware Domain List is a non-commercial community project. |[link](https://www.malwaredomainlist.com/) | [raw](https://www.malwaredomainlist.com/hostslist/hosts.txt) | weekly | 'can be used for free by anyone'  | [issues](https://www.malwaredomainlist.com/contact.php) \nadd.Dead | Dead sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Dead/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nhostsVN | Hosts block ads of Vietnamese |[link](https://github.com/bigdargon/hostsVN) | [raw](https://raw.githubusercontent.com/bigdargon/hostsVN/master/option/hosts-VN) | occasionally | MIT  | [issues](https://github.com/bigdargon/hostsVN/issues) \nadd.Spam | Spam sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Spam/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nDan Pollock \u2013 [someonewhocares](https://someonewhocares.org) | How to make the internet not suck (as much). |[link](https://someonewhocares.org/hosts/) | [raw](https://someonewhocares.org/hosts/zero/hosts) | frequently | non-commercial with attribution  | [issues](hosts@someonewhocares.org) \nMVPS hosts file | The purpose of this site is to provide the user with a high quality custom HOSTS file. |[link](http://winhelp2002.mvps.org/) | [raw](http://winhelp2002.mvps.org/hosts.txt) | monthly | CC BY-NC-SA 4.0  | [issues](mailto:winhelp2002@gmail.com) \nyoyo.org | Blocking with ad server and tracking server hostnames. |[link](https://pgl.yoyo.org/adservers/) | [raw](https://pgl.yoyo.org/adservers/serverlist.php?hostformat=hosts&mimetype=plaintext&useip=0.0.0.0) | frequently |   | [issues](mailto:pgl@yoyo.org) \nMitchell Krog's - Badd Boyz Hosts | Sketchy domains and Bad Referrers from my Nginx and Apache Bad Bot and Spam Referrer Blockers |[link](https://github.com/mitchellkrogza/Badd-Boyz-Hosts) | [raw](https://raw.githubusercontent.com/mitchellkrogza/Badd-Boyz-Hosts/master/hosts) | weekly | MIT  | [issues](https://github.com/mitchellkrogza/Badd-Boyz-Hosts/issues) \nCoinBlocker | Simple lists that can help prevent cryptomining in the browser or other applications |[link](https://gitlab.com/ZeroDot1/CoinBlockerLists) | [raw](https://zerodot1.gitlab.io/CoinBlockerLists/hosts_browser) | frequently | GPLv3  | [issues](https://gitlab.com/ZeroDot1/CoinBlockerLists/issues) \nUncheckyAds | Windows installers ads sources sites based on https://unchecky.com/ content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/UncheckyAds/hosts) | occasionally |   | [issues](https://github.com/FadeMind/hosts.extras/issues) \nadd.2o7Net | 2o7Net tracking sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.2o7Net/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nKADhosts | Fraud/adware/scam websites. |[link](https://kadantiscam.netlify.com) | [raw](https://raw.githubusercontent.com/PolishFiltersTeam/KADhosts/master/KADhosts_without_controversies.txt) | frequently | CC BY-SA 4.0  | [issues](https://github.com/PolishFiltersTeam/KADhosts/issues) \nAdAway | AdAway is an open source ad blocker for Android using the hosts file. |[link](https://adaway.org/) | [raw](https://raw.githubusercontent.com/AdAway/adaway.github.io/master/hosts.txt) | occasionally | CC BY 3.0  | [issues](https://github.com/AdAway/AdAway/issues) \nadd.Risk | Risk content sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Risk/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nTiuxo hostlist - ads | Categorized hosts files for DNS based content blocking |[link](https://github.com/tiuxo/hosts) | [raw](https://raw.githubusercontent.com/tiuxo/hosts/master/ads) | occasional | CC BY 4.0  | [issues](https://github.com/tiuxo/hosts/issues) \n\n\n\n## Extensions\nThe unified hosts file is optionally extensible.  Extensions are used to include domains by category.  Currently we offer the following categories: `fakenews`, `social`, `gambling`, and `porn`.\n\nExtensions are optional, and can be combined in various ways wth the base hosts file.  The combined products are stored in the [`alternates`](https://github.com/StevenBlack/hosts/tree/master/alternates) folder.\n\nData for extensions is stored in the [`extensions`](https://github.com/StevenBlack/hosts/tree/master/extensions) folder. You manage extensions by curating this\nfolder tree, where you will find the data for `fakenews`, `social`, `gambling`, and `porn` extension data that we maintain and provide for you.\n\n## Generate your own unified hosts file\n\nTo generate your own unified hosts file you will need Python 3.5 or later.\n\nFirst install the dependencies with:\n\n    pip3 install --user -r requirements.txt\n\n**Note** we recommend the `--user` flag which installs the required dependencies at the user level. More information about it can be found on pip [documentation](https://pip.pypa.io/en/stable/reference/pip_install/?highlight=--user#cmdoption-user).\n\nTo run unit tests, in the top level directory, run:\n\n    python3 testUpdateHostsFile.py\n\nThe `updateHostsFile.py` script will generate a unified hosts file based on the sources in the\nlocal `data/` subfolder.  The script will prompt you whether it should fetch updated versions\n(from locations defined by the `update.json` text file in each source's folder). Otherwise, it\nwill use the `hosts` file that's already there.\n\n### Usage\n\n#### Using Python 3:\n\n    python3 updateHostsFile.py [--auto] [--replace] [--ip nnn.nnn.nnn.nnn] [--extensions ext1 ext2 ext3]\n\n#### Command line options:\n\n`--help`, or `-h`: display help.\n\n`--auto`, or `-a`: run the script without prompting. When `--auto` is invoked,\n\n* Hosts data sources, including extensions, are updated.\n* No extensions are included by default.  Use the `--extensions` or `-e` flag\nto include any you want.\n* Your active hosts file is *not* replaced unless you include the `--replace`\nflag.\n\n`--backup`, or `-b`: Make a backup of existing hosts file(s) as you generate\nover them.\n\n`--extensions <ext1> <ext2> <ext3>`, or `-e <ext1> <ext2> <ext3>`: the names\nof subfolders below the `extensions` folder containing additional\ncategory-specific hosts files to include in the amalgamation. Example:\n`--extensions porn` or `-e social porn`.\n\n`--flush-dns-cache`, or `-f`: skip the prompt for flushing the DNS cache.\nOnly active when `--replace` is also active.\n\n`--ip nnn.nnn.nnn.nnn`, or `-i nnn.nnn.nnn.nnn`: the IP address to use as the\ntarget.  Default is `0.0.0.0`.\n\n`--keepdomaincomments`, or `-k`: `true` (default) or `false`, keep the comments\nthat appear on the same line as domains.  The default is `true`.\n\n`--noupdate`, or `-n`: skip fetching updates from hosts data sources.\n\n`--output <subfolder>`, or `-o <subfolder>`: place the generated source file\nin a subfolder.  If the subfolder does not exist, it will be created.\n\n`--replace`, or `-r`: trigger replacing your active hosts\n\n`--skipstatichosts`, or `-s`: `false` (default) or `true`, omit the standard\nsection at the top, containing lines like `127.0.0.1 localhost`.  This is\nuseful for configuring proximate DNS services on the local network.\n\n`--compress`, or `-c`: `false` (default) or `true`, *Compress* the hosts file\nignoring non-necessary lines (empty lines and comments) and putting multiple\ndomains in each line. Reducing the number of lines of the hosts file improves\nthe performances under Windows (with DNS Client service enabled).\n\n`--minimise`, or `-m`: `false` (default) or `true`, like `--compress`, but puts\neach domain on a separate line. This is necessary because many implementations\nof URL blockers that rely on `hosts` files do not conform to the standard which\nallows multiple hosts on a single line.\n\n## How do I control which sources are unified?\n\nAdd one or more  *additional* sources, each in a subfolder of the `data/`\nfolder, and specify the `url` key in its `update.json` file.\n\nAdd one or more *optional* extensions, which originate from subfolders of the\n`extensions/` folder.  Again the url in `update.json` controls where this\nextension finds its updates.\n\nCreate an *optional* `blacklist` file. The contents of this file (containing a\nlisting of additional domains in `hosts` file format) are appended to the\nunified hosts file during the update process. A sample `blacklist` is\nincluded, and may be modified as you need.\n\n  * NOTE: The `blacklist` is not tracked by git, so any changes you make won't\nbe overridden when you `git pull`   this repo from `origin` in the future.\n\n### How do I include my own custom domain mappings?\n\nIf you have custom hosts records, place them in file `myhosts`.  The contents\nof this file are prepended to the unified hosts file during the update\nprocess.\n\nThe `myhosts` file is not tracked by git, so any changes you make won't be\noverridden when you `git pull` this repo from `origin` in the future.\n\n### How do I prevent domains from being included?\n\nThe domains you list in the `whitelist` file are excluded from the final hosts\nfile.\n\nThe `whitelist` uses partial matching.  Therefore if you whitelist\n`google-analytics.com`, that domain and all its subdomains won't be merged\ninto the final hosts file.\n\nThe `whitelist` is not tracked by git, so any changes you make won't be\noverridden when you `git pull` this repo  from `origin` in the future.\n\n## How can I contribute hosts records?\n\nIf you discover sketchy domains you feel should be included here, here are some ways to contribute them.\n\n### Option 1: contact one of our hosts sources\n\nThe best way to get new domains included is to submit an issue to any of the data providers whose home pages are [listed here](https://github.com/StevenBlack/hosts#sources-of-hosts-data-unified-in-this-variant). This is best because once you submit new domains, they will be curated and updated by the dedicated folks who maintain these sources.\n\n\n### Option 2: add your domains to Steven Black's personal data file\n\nFork this hosts this repo and add your links to [https://github.com/StevenBlack/hosts/blob/master/data/StevenBlack/hosts](https://github.com/StevenBlack/hosts/blob/master/data/StevenBlack/hosts).\n\nThen, submit a pull request.\n\n**WARNING**: this is less desirable than Option 1 because the ongoing curation falls on us. So this creates more work for us.\n\n### Option 3: create your own hosts list as a repo on Github\n\nIf you're able to curate your own collection of sketchy domains, then curate your own hosts list.  Then signal the existence of your repo as [a new issue](https://github.com/StevenBlack/hosts/issues) and we may include your new repo into the collection of sources we pull whenever we create new versions.\n\n\n## What is a hosts file?\n\nA hosts file, named `hosts` (with no file extension), is a plain-text file\nused by all operating systems to map hostnames to IP addresses.\n\nIn most operating systems, the `hosts` file is preferential to `DNS`.\nTherefore if a domain name is resolved by the `hosts` file, the request never\nleaves your computer.\n\nHaving a smart `hosts` file goes a long way towards blocking malware, adware,\nand other irritants.\n\nFor example, to nullify requests to some doubleclick.net servers, adding these\nlines to your hosts file will do it:\n\n    # block doubleClick's servers\n    0.0.0.0 ad.ae.doubleclick.net\n    0.0.0.0 ad.ar.doubleclick.net\n    0.0.0.0 ad.at.doubleclick.net\n    0.0.0.0 ad.au.doubleclick.net\n    0.0.0.0 ad.be.doubleclick.net\n    # etc...\n\n\n## We recommend using `0.0.0.0` instead of `127.0.0.1`\n\nTraditionally most host files use `127.0.0.1`, the *loopback address*, to establish an IP connection to the local machine.\n\nWe prefer to use `0.0.0.0`, which is defined as a non-routable meta-address used to designate an invalid, unknown, or non applicable target.\n\nUsing `0.0.0.0` is empirically faster, possibly because there's no wait for a timeout resolution. It also does not\ninterfere with a web server that may be running on the local PC.\n\n## Why not use `0` instead of `0.0.0.0`?\nWe tried that.  Using `0` doesn't work universally.\n\n\n## Location of your hosts file\nTo modify your current `hosts` file, look for it in the following places and modify it with a text\neditor.\n\n**mac OS (until 10.14.x macOS Mojave), iOS, Android, Linux**: `/etc/hosts` file.\n\n**macOS Catalina:** `/private/etc/hosts` file.\n\n**Windows**: `%SystemRoot%\\system32\\drivers\\etc\\hosts` file.\n\n## Gentoo\nGentoo users may find [`sb-hosts`](https://github.com/PF4Public/gentoo-overlay/tree/master/net-misc/sb-hosts) in [::pf4public](https://github.com/PF4Public/gentoo-overlay) Gentoo overlay\n\n## Updating hosts file on Windows\n\nOn Linux and Mac OS X, run the Python script. On Windows more\nwork is required due to compatibility issues so it's preferable to run the batch file as follows:\n\n```\nupdateHostsWindows.bat\n```\n\nThis file MUST be run in command prompt with administrator privileges in\nthe repository directory. In addition to updating the hosts file, it can also\nreplace the existing hosts file, and reload the DNS cache. It goes without\nsaying that in order for this to work, you must be connected to the internet.\n\nTo open a command prompt as administrator in the repository's directory, do the following:\n\n**Windows XP**: Start -> Run -> `cmd`\n\n**Windows Vista, 7**: Start Button -> type `cmd` -> right-click Command Prompt ->\n\"Run as Administrator\"\n\n**Windows 8**: Start -> Swipe Up -> All Apps -> Windows System -> right-click Command Prompt ->\n\"Run as Administrator\"\n\n**Windows 10**: Start Button -> type `cmd` -> right-click Command Prompt ->\n\"Run as Administrator\"\n\nYou can also refer to the \"Third-Party Hosts Managers\" section for further recommended solutions from third parties.\n\n## Reloading hosts file\nYour operating system will cache DNS lookups. You can either reboot or run the following commands to\nmanually flush your DNS cache once the new hosts file is in place.\n\n| The Google Chrome browser may require manually cleaning up its DNS Cache on `chrome://net-internals/#dns` page to thereafter see the changes in your hosts file. See: https://superuser.com/questions/723703\n:-----------------------------------------------------------------------------------------\n\n### Windows\n\nOpen a command prompt with administrator privileges and run this command:\n\n```\nipconfig /flushdns\n```\n\n|If you want to use a huge hosts file by merging [hphosts](https://www.hosts-file.net) (NOT INCLUDED HERE) you need to DISABLE and STOP `Dnscache` service before you replace hosts file in Windows Systems. You have been warned.|\n:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nBefore flushing the DNS cache, open a command prompt with administrator privileges and run this command:\n\n```\nsc config \"Dnscache\" start= disabled\nsc stop \"Dnscache\"\n```\n\n### Linux\n\nOpen a Terminal and run with root privileges:\n\n**Debian/Ubuntu** `sudo service network-manager restart`\n\n**Linux Mint** `sudo /etc/init.d/dns-clean start`\n\n**Linux with systemd**: `sudo systemctl restart network.service`\n\n**Fedora Linux**: `sudo systemctl restart NetworkManager.service`\n\n**Arch Linux/Manjaro with Network Manager**: `sudo systemctl restart NetworkManager.service`\n\n**Arch Linux/Manjaro with Wicd**: `sudo systemctl restart wicd.service`\n\n**RHEL/Centos**: `sudo /etc/init.d/network restart`\n\n**FreeBSD**: `sudo service nscd restart`\n\nTo enable the `nscd` daemon initially, it is recommended that you run the following commands:\n\n```\nsudo sysrc nscd_enable=\"YES\"\nsudo service nscd start\n```\n\nThen modify the `hosts` line in your `/etc/nsswitch.conf` file to the following:\n\n```\nhosts: cache files dns\n```\n\n**Others**: Consult [this wikipedia article](https://en.wikipedia.org/wiki/Hosts_%28file%29#Location_in_the_file_system).\n\n### Mac OS X\n\nOpen a Terminal and run:\n```\nsudo dscacheutil -flushcache;sudo killall -HUP mDNSResponder\n```\n\n## Release management\n\nThis repository uses [Release-It!](https://webpro.github.io/release-it/), an excellent CLI release\ntool for Github repos and npm packages, to automate creating [releases](https://github.com/StevenBlack/hosts/releases).\nThis is why the [package.json](https://github.com/StevenBlack/hosts/blob/master/package.json) and\n[.release-it.json](https://github.com/StevenBlack/hosts/blob/master/.release-it.json) files are bundled.\n\n## Goals of this unified hosts file\n\nThe goals of this repo are to:\n\n1. automatically combine high-quality lists of hosts,\n\n2. provide situation-appropriate extensions,\n\n3. de-dupe the resultant combined list,\n\n4. and keep the resultant file reasonably sized.\n\nA high-quality source is defined here as one that is actively curated.  A\nhosts source should be frequently updated by its maintainers with both\nadditions and removals.  The larger the hosts file, the higher the level of\ncuration is expected.\n\nFor example, the (huge) hosts file from [hosts-file.net](https://hosts-file.net)\nis **not** included here because it is very large (780,000+ entries)\nand doesn't currently display a corresponding high level of curation activity.\n\nIt is expected that this unified hosts file will serve both desktop and mobile\ndevices under a variety of operating systems.\n\n## Third-Party Hosts Managers\n\n* [Unified Hosts AutoUpdate](https://github.com/ScriptTiger/Unified-Hosts-AutoUpdate \"Unified Hosts AutoUpdate\") (for Windows): The Unified Hosts AutUpdate package is purpose-built for this unified hosts project as well as in active development by community members. You can install and uninstall any blacklist  and keep it automatically up to date, and can be placed in a shared network location and deployed across an organization via group policies. And since it is in active development by community members, your bug reports, feature requests, and other feedback are most welcome.\n\n* [ViHoMa](https://github.com/cmabad/ViHoMa) is a Visual Hosts file Manager, written in Java, by Christian Mart\u00ednez.  Check it out!\n\n## Interesting Applications\n\n* [Hostile](https://github.com/feross/hostile) is a nifty command line utility to easily add or remove domains from your hosts file.  If our hosts files are too aggressive for you, you can use `hostile` to remove domains, or you can use `hostile` in a bash script to automate a post process each time you download fresh versions of hosts.\n\n* [macOS Scripting for Configuration, Backup and Restore](https://github.com/tiiiecherle/osx_install_config) helps customizing, re-installing and using macOS. It also provides a [script](https://github.com/tiiiecherle/osx_install_config/blob/master/09_launchd/9b_run_on_boot/root/1_hosts_file/launchd_and_script/hosts_file_generator.sh) to install and update the hosts file using this project on macOS. In combination with a [launchd](https://github.com/tiiiecherle/osx_install_config/blob/master/09_launchd/9b_run_on_boot/root/1_hosts_file/launchd_and_script/com.hostsfile.install_update.plist) it updates the hosts file every x days (default is 4). To install both download the github repo and run the [install script](https://github.com/tiiiecherle/osx_install_config/blob/master/09_launchd/9b_run_on_boot/root/1_hosts_file/install_hosts_file_generator_and_launchdservice.sh) from the directory one level up.\n\n* [Pi-hole](https://pi-hole.net/) is a network-wide DHCP server and ad blocker that runs on [Raspberry Pi](https://en.wikipedia.org/wiki/Raspberry_Pi). Pi-hole uses this repository as one of its sources.     This is a very interesting project to setup yourself, or you can [buy one pre-loaded](https://uk.pi-supply.com/products/pi-hole-kit-network-wide-ad-blocker).\n\n* [Block ads and malware via local BIND9 DNS server](https://github.com/mueller-ma/block-ads-via-dns \"Block ads and malware via local DNS server\") (for Debian, Raspbian & Ubuntu): Set up a local DNS server with a `/etc/bind/named.conf.blocked` file, sourced from here.\n\n* [Block ads, malware, and deploy parental controls via local DualServer DNS/DHCP server](https://scripttiger.github.io/dualserver \"Block ads, malware, and deploy parental controls via local DualServer DNS/DHCP server\") (for BSD, Windows & Linux): Set up a blacklist for everyone on your network using the power of the unified hosts reformatted for DualServer. And if you're on Windows, this project also maintains an update script to make updating DualServer's blacklist even easier.\n\n* [Blocking ads and malwares with unbound](https://deadc0de.re/articles/unbound-blocking-ads.html \"Blocking ads and malwares with unbound\") \u2013 [Unbound](https://www.unbound.net/ \"Unbound is a validating, recursive, and caching DNS resolver.\")  is a validating, recursive, and caching DNS resolver.\n\n* [DNSMasq conversion script](https://gist.github.com/erlepereira/c11f4f7a3f60cd2071e79018e895fc8a#file-dnsmasq-antimalware) This github gist has a short shell script (bash, will work on any 'nix) and uses 'wget' & 'awk' present in most distros, to fetch a specified hosts file and convert it the format required by dnsmasq. Supports ipv4 and ipv6. Designed to be used as either a shell script, or can be dropped into /etc/cron.weekly (or wherever suits). Script is short and easily edited, also has a short document attached with notes on dnsmasq setup.\n\n## Contribute!\n\nPlease read our [Contributing Guide](https://github.com/StevenBlack/hosts/blob/master/contributing.md). Among other things, this explains how we organize files and folders in this repository.\n\nWe are always interested in discovering well-curated sources of hosts.  If you find one, please open an [issue](https://github.com/StevenBlack/hosts/issues) to draw our attention.\n\nBefore you create or respond to any issue, please read our [code of conduct](https://github.com/StevenBlack/hosts/blob/master/code_of_conduct.md).\n"}, {"repo": "celery/celery", "language": "Python", "readme_contents": ".. image:: http://docs.celeryproject.org/en/latest/_images/celery-banner-small.png\n\n|build-status| |coverage| |license| |wheel| |pyversion| |pyimp| |ocbackerbadge| |ocsponsorbadge|\n\n:Version: 4.4.0rc5 (cliffs)\n:Web: http://celeryproject.org/\n:Download: https://pypi.org/project/celery/\n:Source: https://github.com/celery/celery/\n:Keywords: task, queue, job, async, rabbitmq, amqp, redis,\n  python, distributed, actors\n\nDonations\n=========\n\nThis project relies on your generous donations.\n\nIf you are using Celery to create a commercial product, please consider becoming our `backer`_ or our `sponsor`_ to ensure Celery's future.\n\n.. _`backer`: https://opencollective.com/celery#backer\n.. _`sponsor`: https://opencollective.com/celery#sponsor\n\nFor enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of ``celery`` and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. `Learn more. <https://tidelift.com/subscription/pkg/pypi-celery?utm_source=pypi-celery&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_\n\nWhat's a Task Queue?\n====================\n\nTask queues are used as a mechanism to distribute work across threads or\nmachines.\n\nA task queue's input is a unit of work, called a task, dedicated worker\nprocesses then constantly monitor the queue for new work to perform.\n\nCelery communicates via messages, usually using a broker\nto mediate between clients and workers. To initiate a task a client puts a\nmessage on the queue, the broker then delivers the message to a worker.\n\nA Celery system can consist of multiple workers and brokers, giving way\nto high availability and horizontal scaling.\n\nCelery is written in Python, but the protocol can be implemented in any\nlanguage. In addition to Python there's node-celery_ for Node.js,\na `PHP client`_ and `gocelery`_ for golang.\n\nLanguage interoperability can also be achieved by using webhooks\nin such a way that the client enqueues an URL to be requested by a worker.\n\n.. _node-celery: https://github.com/mher/node-celery\n.. _`PHP client`: https://github.com/gjedeer/celery-php\n.. _`gocelery`: https://github.com/gocelery/gocelery\n\nWhat do I need?\n===============\n\nCelery version 4.3 runs on,\n\n- Python (2.7, 3.4, 3.5, 3.6, 3.7)\n- PyPy2.7 (6.0)\n- PyPy3.5 (6.0)\n\n\nThis is the last version to support Python 2.7,\nand from the next version (Celery 5.x) Python 3.5 or newer is required.\n\nIf you're running an older version of Python, you need to be running\nan older version of Celery:\n\n- Python 2.6: Celery series 3.1 or earlier.\n- Python 2.5: Celery series 3.0 or earlier.\n- Python 2.4 was Celery series 2.2 or earlier.\n\nCelery is a project with minimal funding,\nso we don't support Microsoft Windows.\nPlease don't open any issues related to that platform.\n\n*Celery* is usually used with a message broker to send and receive messages.\nThe RabbitMQ, Redis transports are feature complete,\nbut there's also experimental support for a myriad of other solutions, including\nusing SQLite for local development.\n\n*Celery* can run on a single machine, on multiple machines, or even\nacross datacenters.\n\nGet Started\n===========\n\nIf this is the first time you're trying to use Celery, or you're\nnew to Celery 4.2 coming from previous versions then you should read our\ngetting started tutorials:\n\n- `First steps with Celery`_\n\n    Tutorial teaching you the bare minimum needed to get started with Celery.\n\n- `Next steps`_\n\n    A more complete overview, showing more features.\n\n.. _`First steps with Celery`:\n    http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html\n\n.. _`Next steps`:\n    http://docs.celeryproject.org/en/latest/getting-started/next-steps.html\n\nCelery is...\n=============\n\n- **Simple**\n\n    Celery is easy to use and maintain, and does *not need configuration files*.\n\n    It has an active, friendly community you can talk to for support,\n    like at our `mailing-list`_, or the IRC channel.\n\n    Here's one of the simplest applications you can make::\n\n        from celery import Celery\n\n        app = Celery('hello', broker='amqp://guest@localhost//')\n\n        @app.task\n        def hello():\n            return 'hello world'\n\n- **Highly Available**\n\n    Workers and clients will automatically retry in the event\n    of connection loss or failure, and some brokers support\n    HA in way of *Primary/Primary* or *Primary/Replica* replication.\n\n- **Fast**\n\n    A single Celery process can process millions of tasks a minute,\n    with sub-millisecond round-trip latency (using RabbitMQ,\n    py-librabbitmq, and optimized settings).\n\n- **Flexible**\n\n    Almost every part of *Celery* can be extended or used on its own,\n    Custom pool implementations, serializers, compression schemes, logging,\n    schedulers, consumers, producers, broker transports, and much more.\n\nIt supports...\n================\n\n    - **Message Transports**\n\n        - RabbitMQ_, Redis_, Amazon SQS\n\n    - **Concurrency**\n\n        - Prefork, Eventlet_, gevent_, single threaded (``solo``)\n\n    - **Result Stores**\n\n        - AMQP, Redis\n        - memcached\n        - SQLAlchemy, Django ORM\n        - Apache Cassandra, IronCache, Elasticsearch\n\n    - **Serialization**\n\n        - *pickle*, *json*, *yaml*, *msgpack*.\n        - *zlib*, *bzip2* compression.\n        - Cryptographic message signing.\n\n.. _`Eventlet`: http://eventlet.net/\n.. _`gevent`: http://gevent.org/\n\n.. _RabbitMQ: https://rabbitmq.com\n.. _Redis: https://redis.io\n.. _SQLAlchemy: http://sqlalchemy.org\n\nFramework Integration\n=====================\n\nCelery is easy to integrate with web frameworks, some of which even have\nintegration packages:\n\n    +--------------------+------------------------+\n    | `Django`_          | not needed             |\n    +--------------------+------------------------+\n    | `Pyramid`_         | `pyramid_celery`_      |\n    +--------------------+------------------------+\n    | `Pylons`_          | `celery-pylons`_       |\n    +--------------------+------------------------+\n    | `Flask`_           | not needed             |\n    +--------------------+------------------------+\n    | `web2py`_          | `web2py-celery`_       |\n    +--------------------+------------------------+\n    | `Tornado`_         | `tornado-celery`_      |\n    +--------------------+------------------------+\n\nThe integration packages aren't strictly necessary, but they can make\ndevelopment easier, and sometimes they add important hooks like closing\ndatabase connections at ``fork``.\n\n.. _`Django`: https://djangoproject.com/\n.. _`Pylons`: http://pylonsproject.org/\n.. _`Flask`: http://flask.pocoo.org/\n.. _`web2py`: http://web2py.com/\n.. _`Bottle`: https://bottlepy.org/\n.. _`Pyramid`: http://docs.pylonsproject.org/en/latest/docs/pyramid.html\n.. _`pyramid_celery`: https://pypi.org/project/pyramid_celery/\n.. _`celery-pylons`: https://pypi.org/project/celery-pylons/\n.. _`web2py-celery`: https://code.google.com/p/web2py-celery/\n.. _`Tornado`: http://www.tornadoweb.org/\n.. _`tornado-celery`: https://github.com/mher/tornado-celery/\n\n.. _celery-documentation:\n\nDocumentation\n=============\n\nThe `latest documentation`_ is hosted at Read The Docs, containing user guides,\ntutorials, and an API reference.\n\n\u6700\u65b0\u7684\u4e2d\u6587\u6587\u6863\u6258\u7ba1\u5728 https://www.celerycn.io/ \u4e2d\uff0c\u5305\u542b\u7528\u6237\u6307\u5357\u3001\u6559\u7a0b\u3001API\u63a5\u53e3\u7b49\u3002\n\n.. _`latest documentation`: http://docs.celeryproject.org/en/latest/\n\n.. _celery-installation:\n\nInstallation\n============\n\nYou can install Celery either via the Python Package Index (PyPI)\nor from source.\n\nTo install using ``pip``:\n\n::\n\n\n    $ pip install -U Celery\n\n.. _bundles:\n\nBundles\n-------\n\nCelery also defines a group of bundles that can be used\nto install Celery and the dependencies for a given feature.\n\nYou can specify these in your requirements or on the ``pip``\ncommand-line by using brackets. Multiple bundles can be specified by\nseparating them by commas.\n\n::\n\n\n    $ pip install \"celery[librabbitmq]\"\n\n    $ pip install \"celery[librabbitmq,redis,auth,msgpack]\"\n\nThe following bundles are available:\n\nSerializers\n~~~~~~~~~~~\n\n:``celery[auth]``:\n    for using the ``auth`` security serializer.\n\n:``celery[msgpack]``:\n    for using the msgpack serializer.\n\n:``celery[yaml]``:\n    for using the yaml serializer.\n\nConcurrency\n~~~~~~~~~~~\n\n:``celery[eventlet]``:\n    for using the ``eventlet`` pool.\n\n:``celery[gevent]``:\n    for using the ``gevent`` pool.\n\nTransports and Backends\n~~~~~~~~~~~~~~~~~~~~~~~\n\n:``celery[librabbitmq]``:\n    for using the librabbitmq C library.\n\n:``celery[redis]``:\n    for using Redis as a message transport or as a result backend.\n\n:``celery[sqs]``:\n    for using Amazon SQS as a message transport.\n\n:``celery[tblib``]:\n    for using the ``task_remote_tracebacks`` feature.\n\n:``celery[memcache]``:\n    for using Memcached as a result backend (using ``pylibmc``)\n\n:``celery[pymemcache]``:\n    for using Memcached as a result backend (pure-Python implementation).\n\n:``celery[cassandra]``:\n    for using Apache Cassandra as a result backend with DataStax driver.\n\n:``celery[azureblockblob]``:\n    for using Azure Storage as a result backend (using ``azure-storage``)\n\n:``celery[s3]``:\n    for using S3 Storage as a result backend.\n\n:``celery[couchbase]``:\n    for using Couchbase as a result backend.\n\n:``celery[arangodb]``:\n    for using ArangoDB as a result backend.\n\n:``celery[elasticsearch]``:\n    for using Elasticsearch as a result backend.\n\n:``celery[riak]``:\n    for using Riak as a result backend.\n\n:``celery[cosmosdbsql]``:\n    for using Azure Cosmos DB as a result backend (using ``pydocumentdb``)\n\n:``celery[zookeeper]``:\n    for using Zookeeper as a message transport.\n\n:``celery[sqlalchemy]``:\n    for using SQLAlchemy as a result backend (*supported*).\n\n:``celery[pyro]``:\n    for using the Pyro4 message transport (*experimental*).\n\n:``celery[slmq]``:\n    for using the SoftLayer Message Queue transport (*experimental*).\n\n:``celery[consul]``:\n    for using the Consul.io Key/Value store as a message transport or result backend (*experimental*).\n\n:``celery[django]``:\n    specifies the lowest version possible for Django support.\n\n    You should probably not use this in your requirements, it's here\n    for informational purposes only.\n\n\n.. _celery-installing-from-source:\n\nDownloading and installing from source\n--------------------------------------\n\nDownload the latest version of Celery from PyPI:\n\nhttps://pypi.org/project/celery/\n\nYou can install it by doing the following,:\n\n::\n\n\n    $ tar xvfz celery-0.0.0.tar.gz\n    $ cd celery-0.0.0\n    $ python setup.py build\n    # python setup.py install\n\nThe last command must be executed as a privileged user if\nyou aren't currently using a virtualenv.\n\n.. _celery-installing-from-git:\n\nUsing the development version\n-----------------------------\n\nWith pip\n~~~~~~~~\n\nThe Celery development version also requires the development\nversions of ``kombu``, ``amqp``, ``billiard``, and ``vine``.\n\nYou can install the latest snapshot of these using the following\npip commands:\n\n::\n\n\n    $ pip install https://github.com/celery/celery/zipball/master#egg=celery\n    $ pip install https://github.com/celery/billiard/zipball/master#egg=billiard\n    $ pip install https://github.com/celery/py-amqp/zipball/master#egg=amqp\n    $ pip install https://github.com/celery/kombu/zipball/master#egg=kombu\n    $ pip install https://github.com/celery/vine/zipball/master#egg=vine\n\nWith git\n~~~~~~~~\n\nPlease see the Contributing section.\n\n.. _getting-help:\n\nGetting Help\n============\n\n.. _mailing-list:\n\nMailing list\n------------\n\nFor discussions about the usage, development, and future of Celery,\nplease join the `celery-users`_ mailing list.\n\n.. _`celery-users`: https://groups.google.com/group/celery-users/\n\n.. _irc-channel:\n\nIRC\n---\n\nCome chat with us on IRC. The **#celery** channel is located at the `Freenode`_\nnetwork.\n\n.. _`Freenode`: https://freenode.net\n\n.. _bug-tracker:\n\nBug tracker\n===========\n\nIf you have any suggestions, bug reports, or annoyances please report them\nto our issue tracker at https://github.com/celery/celery/issues/\n\n.. _wiki:\n\nWiki\n====\n\nhttps://github.com/celery/celery/wiki\n\nCredits\n=======\n\n.. _contributing-short:\n\nContributors\n------------\n\nThis project exists thanks to all the people who contribute. Development of\n`celery` happens at GitHub: https://github.com/celery/celery\n\nYou're highly encouraged to participate in the development\nof `celery`. If you don't like GitHub (for some reason) you're welcome\nto send regular patches.\n\nBe sure to also read the `Contributing to Celery`_ section in the\ndocumentation.\n\n.. _`Contributing to Celery`:\n    http://docs.celeryproject.org/en/master/contributing.html\n\n|oc-contributors|\n\n.. |oc-contributors| image:: https://opencollective.com/celery/contributors.svg?width=890&button=false\n    :target: https://github.com/celery/celery/graphs/contributors\n\nBackers\n-------\n\nThank you to all our backers! \ud83d\ude4f [`Become a backer`_]\n\n.. _`Become a backer`: https://opencollective.com/celery#backer\n\n|oc-backers|\n\n.. |oc-backers| image:: https://opencollective.com/celery/backers.svg?width=890\n    :target: https://opencollective.com/celery#backers\n\nSponsors\n--------\n\nSupport this project by becoming a sponsor. Your logo will show up here with a\nlink to your website. [`Become a sponsor`_]\n\n.. _`Become a sponsor`: https://opencollective.com/celery#sponsor\n\n|oc-sponsors|\n\n.. |oc-sponsors| image:: https://opencollective.com/celery/sponsor/0/avatar.svg\n    :target: https://opencollective.com/celery/sponsor/0/website\n\n.. _license:\n\nLicense\n=======\n\nThis software is licensed under the `New BSD License`. See the ``LICENSE``\nfile in the top distribution directory for the full license text.\n\n.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround\n\n.. |build-status| image:: https://secure.travis-ci.org/celery/celery.png?branch=master\n    :alt: Build status\n    :target: https://travis-ci.org/celery/celery\n\n.. |coverage| image:: https://codecov.io/github/celery/celery/coverage.svg?branch=master\n    :target: https://codecov.io/github/celery/celery?branch=master\n\n.. |license| image:: https://img.shields.io/pypi/l/celery.svg\n    :alt: BSD License\n    :target: https://opensource.org/licenses/BSD-3-Clause\n\n.. |wheel| image:: https://img.shields.io/pypi/wheel/celery.svg\n    :alt: Celery can be installed via wheel\n    :target: https://pypi.org/project/celery/\n\n.. |pyversion| image:: https://img.shields.io/pypi/pyversions/celery.svg\n    :alt: Supported Python versions.\n    :target: https://pypi.org/project/celery/\n\n.. |pyimp| image:: https://img.shields.io/pypi/implementation/celery.svg\n    :alt: Support Python implementations.\n    :target: https://pypi.org/project/celery/\n\n.. |ocbackerbadge| image:: https://opencollective.com/celery/backers/badge.svg\n    :alt: Backers on Open Collective\n    :target: #backers\n\n.. |ocsponsorbadge| image:: https://opencollective.com/celery/sponsors/badge.svg\n    :alt: Sponsors on Open Collective\n    :target: #sponsors\n\n.. |downloads| image:: https://pepy.tech/badge/celery\n    :alt: Downloads\n    :target: https://pepy.tech/project/celery\n"}, {"repo": "nicolargo/glances", "language": "Python", "readme_contents": "===============================\nGlances - An eye on your system\n===============================\n\n.. image:: https://img.shields.io/pypi/v/glances.svg\n    :target: https://pypi.python.org/pypi/Glances\n\n.. image:: https://img.shields.io/github/stars/nicolargo/glances.svg\n    :target: https://github.com/nicolargo/glances/\n    :alt: Github stars\n\n.. image:: https://pepy.tech/badge/glances/month\n    :target: https://pepy.tech/project/glances\n    :alt: Downloads\n\n.. image:: https://img.shields.io/travis/nicolargo/glances/master.svg?maxAge=3600&label=Linux%20/%20BSD%20/%20macOS\n    :target: https://travis-ci.org/nicolargo/glances\n    :alt: Linux tests (Travis)\n\n.. image:: https://img.shields.io/appveyor/ci/nicolargo/glances/master.svg?maxAge=3600&label=Windows\n    :target: https://ci.appveyor.com/project/nicolargo/glances\n    :alt: Windows tests (Appveyor)\n\n.. image:: https://scrutinizer-ci.com/g/nicolargo/glances/badges/quality-score.png?b=develop\n    :target: https://scrutinizer-ci.com/g/nicolargo/glances/?branch=develop\n\n.. image:: https://img.shields.io/badge/Donate-PayPal-green.svg\n    :target: https://www.paypal.me/nicolargo\n\n.. image:: https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&label=Follow%20%40nicolargo\n    :target: https://twitter.com/nicolargo\n\nSummary\n=======\n\n**Glances** is a cross-platform monitoring tool which aims to present a\nlarge amount of monitoring information through a curses or Web\nbased interface. The information dynamically adapts depending on the\nsize of the user interface.\n\n.. image:: https://raw.githubusercontent.com/nicolargo/glances/develop/docs/_static/glances-summary.png\n\nIt can also work in client/server mode. Remote monitoring could be done\nvia terminal, Web interface or API (XML-RPC and RESTful). Stats can also\nbe exported to files or external time/value databases.\n\n.. image:: https://raw.githubusercontent.com/nicolargo/glances/develop/docs/_static/glances-responsive-webdesign.png\n\nGlances is written in Python and uses libraries to grab information from\nyour system. It is based on an open architecture where developers can\nadd new plugins or exports modules.\n\nRequirements\n============\n\n- ``python 2.7,>=3.4``\n- ``psutil>=5.3.0`` (better with latest version)\n\nOptional dependencies:\n\n- ``bernhard`` (for the Riemann export module)\n- ``bottle`` (for Web server mode)\n- ``cassandra-driver`` (for the Cassandra export module)\n- ``couchdb`` (for the CouchDB export module)\n- ``docker`` (for the Docker monitoring support) [Linux/macOS-only]\n- ``elasticsearch`` (for the Elastic Search export module)\n- ``hddtemp`` (for HDD temperature monitoring support) [Linux-only]\n- ``influxdb`` (for the InfluxDB export module)\n- ``kafka-python`` (for the Kafka export module)\n- ``netifaces`` (for the IP plugin)\n- ``nvidia-ml-py3`` (for the GPU plugin)\n- ``pika`` (for the RabbitMQ/ActiveMQ export module)\n- ``potsdb`` (for the OpenTSDB export module)\n- ``prometheus_client`` (for the Prometheus export module)\n- ``py-cpuinfo`` (for the Quicklook CPU info module)\n- ``pygal`` (for the graph export module)\n- ``pymdstat`` (for RAID support) [Linux-only]\n- ``pySMART.smartx`` (for HDD Smart support) [Linux-only]\n- ``pysnmp`` (for SNMP support)\n- ``pystache`` (for the action script feature)\n- ``pyzmq`` (for the ZeroMQ export module)\n- ``requests`` (for the Ports, Cloud plugins and RESTful export module)\n- ``scandir`` (for the Folders plugin) [Only for Python < 3.5]\n- ``statsd`` (for the StatsD export module)\n- ``wifi`` (for the wifi plugin) [Linux-only]\n- ``zeroconf`` (for the autodiscover mode)\n\n*Note for Python 2.6 users*\n\nGlances no longer supports Python 2.6. Please upgrade\nto a minimum Python version of 2.7/3.4+ or downgrade to Glances 2.6.2 (last version\nwith Python 2.6 support).\n\n*Note for CentOS Linux 6 and 7 users*\n\nPython 2.7 and 3.4 are now available via SCL repositories. See:\nhttps://lists.centos.org/pipermail/centos-announce/2015-December/021555.html.\n\nInstallation\n============\n\nThere are several methods to test/install Glances on your system. Choose your weapon!\n\nGlances Auto Install script: the total way\n------------------------------------------\n\nTo install both dependencies and the latest Glances production ready version\n(aka *master* branch), just enter the following command line:\n\n.. code-block:: console\n\n    curl -L https://bit.ly/glances | /bin/bash\n\nor\n\n.. code-block:: console\n\n    wget -O- https://bit.ly/glances | /bin/bash\n\n*Note*: This is only supported on some GNU/Linux distributions and Mac OS X.\nIf you want to support other distributions, please contribute to `glancesautoinstall`_.\n\nPyPI: The simple way\n--------------------\n\nGlances is on ``PyPI``. By using PyPI, you will be using the latest\nstable version.\n\nTo install, simply use ``pip``:\n\n.. code-block:: console\n\n    pip install glances\n\n*Note*: Python headers are required to install `psutil`_. For example,\non Debian/Ubuntu you need to install first the *python-dev* package.\nFor Fedora/CentOS/RHEL install first *python-devel* package. For Windows,\njust install psutil from the binary installation file.\n\n*Note 2 (for the Wifi plugin)*: If you want to use the Wifi plugin, you need\nto install the *wireless-tools* package on your system.\n\nYou can also install the following libraries in order to use optional\nfeatures (like the Web interface, exports modules...):\n\n.. code-block:: console\n\n    pip install 'glances[action,browser,cloud,cpuinfo,docker,export,folders,gpu,graph,ip,raid,snmp,web,wifi]'\n\nTo upgrade Glances to the latest version:\n\n.. code-block:: console\n\n    pip install --upgrade glances\n    pip install --upgrade glances[...]\n\nIf you need to install Glances in a specific user location, use:\n\n.. code-block:: console\n\n    export PYTHONUSERBASE=~/mylocalpath\n    pip install --user glances\n\nDocker: the funny way\n---------------------\n\nA Glances container is available. It includes the latest development\nHEAD version. You can use it to monitor your server and all your other\ncontainers!\n\nGet the Glances container:\n\n.. code-block:: console\n\n    docker pull nicolargo/glances\n\nRun the container in *console mode*:\n\n.. code-block:: console\n\n    docker run --rm -v /var/run/docker.sock:/var/run/docker.sock:ro --pid host --network host -it docker.io/nicolargo/glances\n\nAdditionally, if you want to use your own glances.conf file, you can\ncreate your own Dockerfile:\n\n.. code-block:: console\n\n    FROM nicolargo/glances\n    COPY glances.conf /glances/conf/glances.conf\n    CMD python -m glances -C /glances/conf/glances.conf $GLANCES_OPT\n\nAlternatively, you can specify something along the same lines with\ndocker run options:\n\n.. code-block:: console\n\n    docker run -v `pwd`/glances.conf:/glances/conf/glances.conf -v /var/run/docker.sock:/var/run/docker.sock:ro --pid host -it docker.io/nicolargo/glances\n\nWhere \\`pwd\\`/glances.conf is a local directory containing your glances.conf file.\n\nRun the container in *Web server mode* (notice the `GLANCES_OPT` environment\nvariable setting parameters for the glances startup command):\n\n.. code-block:: console\n\n    docker run -d --restart=\"always\" -p 61208-61209:61208-61209 -e GLANCES_OPT=\"-w\" -v /var/run/docker.sock:/var/run/docker.sock:ro --pid host docker.io/nicolargo/glances\n\nGNU/Linux\n---------\n\n`Glances` is available on many Linux distributions, so you should be\nable to install it using your favorite package manager. Be aware that\nwhen you use this method the operating system `package`_ for `Glances`\nmay not be the latest version.\n\n\nFreeBSD\n-------\n\nTo install the binary package:\n\n.. code-block:: console\n\n    # pkg install py27-glances\n\nTo install Glances from ports:\n\n.. code-block:: console\n\n    # cd /usr/ports/sysutils/py-glances/\n    # make install clean\n\nmacOS\n-----\n\nIf you do not want to use the glancesautoinstall script, follow this procedure.\n\nmacOS users can install Glances using ``Homebrew`` or ``MacPorts``.\n\nHomebrew\n````````\n\n.. code-block:: console\n\n    $ brew install glances\n\nMacPorts\n````````\n\n.. code-block:: console\n\n    $ sudo port install glances\n\nWindows\n-------\n\nInstall `Python`_ for Windows (Python 2.7.9+ and 3.4+ ship with pip) and\nthen run the following command:\n\n.. code-block:: console\n\n    $ pip install glances\n\nAlternatively, you could clone the repository and install with the following command.\n\n.. code-block:: console\n\n    $ git clone https://github.com/nicolargo/glances.git\n    $ cd glances\n    $ python setup.py install\n\n\nAndroid\n-------\n\nYou need a rooted device and the `Termux`_ application (available on the\nGoogle Play Store).\n\nStart Termux on your device and enter:\n\n.. code-block:: console\n\n    $ apt update\n    $ apt upgrade\n    $ apt install clang python python-dev\n    $ pip install bottle\n    $ pip install glances\n\nAnd start Glances:\n\n.. code-block:: console\n\n    $ glances\n\nYou can also run Glances in server mode (-s or -w) in order to remotely\nmonitor your Android device.\n\nSource\n------\n\nTo install Glances from source:\n\n.. code-block:: console\n\n    $ wget https://github.com/nicolargo/glances/archive/vX.Y.tar.gz -O - | tar xz\n    $ cd glances-*\n    # python setup.py install\n\n*Note*: Python headers are required to install psutil.\n\nChef\n----\n\nAn awesome ``Chef`` cookbook is available to monitor your infrastructure:\nhttps://supermarket.chef.io/cookbooks/glances (thanks to Antoine Rouyer)\n\nPuppet\n------\n\nYou can install Glances using ``Puppet``: https://github.com/rverchere/puppet-glances\n\nAnsible\n-------\n\nA Glances ``Ansible`` role is available: https://galaxy.ansible.com/zaxos/glances-ansible-role/\n\nUsage\n=====\n\nFor the standalone mode, just run:\n\n.. code-block:: console\n\n    $ glances\n\nFor the Web server mode, run:\n\n.. code-block:: console\n\n    $ glances -w\n\nand enter the URL ``http://<ip>:61208`` in your favorite web browser.\n\nFor the client/server mode, run:\n\n.. code-block:: console\n\n    $ glances -s\n\non the server side and run:\n\n.. code-block:: console\n\n    $ glances -c <ip>\n\non the client one.\n\nYou can also detect and display all Glances servers available on your\nnetwork or defined in the configuration file:\n\n.. code-block:: console\n\n    $ glances --browser\n\nYou can also display raw stats on stdout:\n\n.. code-block:: console\n\n    $ glances --stdout cpu.user,mem.used,load\n    cpu.user: 30.7\n    mem.used: 3278204928\n    load: {'cpucore': 4, 'min1': 0.21, 'min5': 0.4, 'min15': 0.27}\n    cpu.user: 3.4\n    mem.used: 3275251712\n    load: {'cpucore': 4, 'min1': 0.19, 'min5': 0.39, 'min15': 0.27}\n    ...\n\nor in a CSV format thanks to the stdout-csv option:\n\n.. code-block:: console\n\n    $ glances --stdout-csv now,cpu.user,mem.used,load\n    now,cpu.user,mem.used,load.cpucore,load.min1,load.min5,load.min15\n    2018-12-08 22:04:20 CEST,7.3,5948149760,4,1.04,0.99,1.04\n    2018-12-08 22:04:23 CEST,5.4,5949136896,4,1.04,0.99,1.04\n    ...\n\nand RTFM, always.\n\nDocumentation\n=============\n\nFor complete documentation have a look at the readthedocs_ website.\n\nIf you have any question (after RTFM!), please post it on the official Q&A `forum`_.\n\nGateway to other services\n=========================\n\nGlances can export stats to: ``CSV`` file, ``JSON`` file, ``InfluxDB``, ``Cassandra``, ``CouchDB``,\n``OpenTSDB``, ``Prometheus``, ``StatsD``, ``ElasticSearch``, ``RabbitMQ/ActiveMQ``,\n``ZeroMQ``, ``Kafka``, ``Riemann`` and ``RESTful`` server.\n\nHow to contribute ?\n===================\n\nIf you want to contribute to the Glances project, read this `wiki`_ page.\n\nThere is also a chat dedicated to the Glances developers:\n\n.. image:: https://badges.gitter.im/Join%20Chat.svg\n        :target: https://gitter.im/nicolargo/glances?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\nDonation\n========\n\nIf this project help you, you can give me a tip ;)\n\n.. image:: https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif\n        :target: https://www.paypal.me/nicolargo\n\nAuthor\n======\n\nNicolas Hennion (@nicolargo) <nicolas@nicolargo.com>\n\n.. image:: https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&label=Follow%20%40nicolargo\n    :target: https://twitter.com/nicolargo\n\nLicense\n=======\n\nGlances is distributed under the LGPL version 3 license. See ``COPYING`` for more details.\n\n.. _psutil: https://github.com/giampaolo/psutil\n.. _glancesautoinstall: https://github.com/nicolargo/glancesautoinstall\n.. _Python: https://www.python.org/getit/\n.. _Termux: https://play.google.com/store/apps/details?id=com.termux\n.. _readthedocs: https://glances.readthedocs.io/\n.. _forum: https://groups.google.com/forum/?hl=en#!forum/glances-users\n.. _wiki: https://github.com/nicolargo/glances/wiki/How-to-contribute-to-Glances-%3F\n.. _package: https://repology.org/metapackage/glances/packages\n"}, {"repo": "tensorflow/magenta", "language": "Python", "readme_contents": "\n<img src=\"magenta-logo-bg.png\" height=\"75\">\n\n[![Build Status](https://travis-ci.org/tensorflow/magenta.svg?branch=master)](https://travis-ci.org/tensorflow/magenta)\n [![PyPI version](https://badge.fury.io/py/magenta.svg)](https://badge.fury.io/py/magenta)\n\n**Magenta** is a research project exploring the role of machine learning\nin the process of creating art and music.  Primarily this\ninvolves developing new deep learning and reinforcement learning\nalgorithms for generating songs, images, drawings, and other materials. But it's also\nan exploration in building smart tools and interfaces that allow\nartists and musicians to extend (not replace!) their processes using\nthese models.  Magenta was started by some researchers and engineers\nfrom the [Google Brain team](https://research.google.com/teams/brain/),\nbut many others have contributed significantly to the project. We use\n[TensorFlow](https://www.tensorflow.org) and release our models and\ntools in open source on this GitHub.  If you\u2019d like to learn more\nabout Magenta, check out our [blog](https://magenta.tensorflow.org),\nwhere we post technical details.  You can also join our [discussion\ngroup](https://groups.google.com/a/tensorflow.org/forum/#!forum/magenta-discuss).\n\nThis is the home for our Python TensorFlow library. To use our models in the browser with [TensorFlow.js](https://js.tensorflow.org/), head to the [Magenta.js](https://github.com/tensorflow/magenta-js) repository.\n\n## Getting Started\n\n* [Installation](#installation)\n* [Using Magenta](#using-magenta)\n* [Playing a MIDI Instrument](#playing-a-midi-instrument)\n* [Development Environment (Advanced)](#development-environment)\n\n## Installation\n\nMagenta maintains a [pip package](https://pypi.python.org/pypi/magenta) for easy\ninstallation. We recommend using Anaconda to install it, but it can work in any\nstandard Python environment. We support both Python 2 (>= 2.7) and Python 3 (>= 3.5).\nThese instructions will assume you are using Anaconda.\n\n### Automated Install (w/ Anaconda)\n\nIf you are running Mac OS X or Ubuntu, you can try using our automated\ninstallation script. Just paste the following command into your terminal.\n\n```bash\ncurl https://raw.githubusercontent.com/tensorflow/magenta/master/magenta/tools/magenta-install.sh > /tmp/magenta-install.sh\nbash /tmp/magenta-install.sh\n```\n\nAfter the script completes, open a new terminal window so the environment\nvariable changes take effect.\n\nThe Magenta libraries are now available for use within Python programs and\nJupyter notebooks, and the Magenta scripts are installed in your path!\n\nNote that you will need to run `source activate magenta` to use Magenta every\ntime you open a new terminal window.\n\n### Manual Install (w/o Anaconda)\n\nIf the automated script fails for any reason, or you'd prefer to install by\nhand, do the following steps.\n\nInstall the Magenta pip package:\n\n```bash\npip install magenta\n```\n\n**NOTE**: In order to install the `rtmidi` and `pyaudio` packages that we depend on, you may need to install headers for some sound libraries. On Linux, this command should install the necessary packages:\n\n```bash\nsudo apt-get install build-essential libasound2-dev libjack-dev portaudio19-dev\n```\n\nThe Magenta libraries are now available for use within Python programs and\nJupyter notebooks, and the Magenta scripts are installed in your path!\n\n## Using Magenta\n\nYou can now train our various models and use them to generate music, audio, and images. You can\nfind instructions for each of the models by exploring the [models directory](magenta/models).\n\nTo get started, create your own melodies with TensorFlow using one of the various configurations of our [Melody RNN](magenta/models/melody_rnn) model; a recurrent neural network for predicting melodies.\n\n## Playing a MIDI Instrument\n\nAfter you've trained one of the models above, you can use our [MIDI interface](magenta/interfaces/midi) to play with it interactively.\n\nWe also have created several [demos](https://github.com/tensorflow/magenta-demos) that provide a UI for this interface, making it easier to use (e.g., the browser-based [AI Jam](https://github.com/tensorflow/magenta-demos/tree/master/ai-jam-js)).\n\n## Development Environment\nIf you want to develop on Magenta, you'll need to set up the full Development Environment.\n\nFirst, clone this repository:\n\n```bash\ngit clone https://github.com/tensorflow/magenta.git\n```\n\nNext, install the dependencies by changing to the base directory and executing the setup command:\n\n```bash\npip install -e .\n```\n\nYou can now edit the files and run scripts by calling Python as usual. For example, this is how you would run the `melody_rnn_generate` script from the base directory:\n\n```bash\npython magenta/models/melody_rnn/melody_rnn_generate --config=...\n```\n\nYou can also install the (potentially modified) package with:\n\n```bash\npip install .\n```\n\nBefore creating a pull request, please also test your changes with:\n\n```bash\npip install pytest-pylint\npytest\n```\n\n## PIP Release\n\nTo build a new version for pip, bump the version and then run:\n\n```bash\npython setup.py test\npython setup.py bdist_wheel --universal\ntwine upload dist/magenta-N.N.N-py2.py3-none-any.whl\n```\n"}, {"repo": "StevenBlack/hosts", "language": "Python", "readme_contents": "----\n**Take Note!**  This version of the Hosts file generator, and tests, are for Python 3.5+ only.\n\n----\n\n![readme](https://user-images.githubusercontent.com/36028424/40330477-9df2c2e0-5d7f-11e8-8ac8-511d719a5eae.png)\n[![latest release](https://img.shields.io/github/release/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/releases)\n[![license](https://img.shields.io/github/license/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/blob/master/license.txt)\n[![repo size](https://img.shields.io/github/repo-size/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts)\n[![contributors](https://img.shields.io/github/contributors/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/graphs/contributors)\n[![Build Status](https://travis-ci.org/StevenBlack/hosts.svg?branch=master)](https://travis-ci.org/StevenBlack/hosts)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)\n[![commits since last release](https://img.shields.io/github/commits-since/StevenBlack/hosts/latest.svg)](https://github.com/StevenBlack/hosts/commits/master)\n[![last commit](https://img.shields.io/github/last-commit/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/commits/master)\n[![commit activity](https://img.shields.io/github/commit-activity/y/StevenBlack/hosts.svg)](https://github.com/StevenBlack/hosts/commits/master)\n\n# Unified hosts file with base extensions\n\nThis repository consolidates several reputable `hosts` files, and merges them\ninto a unified hosts file with duplicates removed.  A variety of tailored hosts files are provided.\n\n* Last updated: **December 02 2019**.\n* Here's the [raw hosts file with base extensions](https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts) containing 43,154 entries.\n* Logo by [@Tobaloidee](https://github.com/Tobaloidee).\n\n\n### List of all hosts file variants\n\nThis repository offers [15 different host file variants](https://github.com/StevenBlack/hosts/tree/master/alternates), in addition to the base variant.\n\nThe **Non GitHub mirror** is the link to use for some hosts file managers like\n[Hostsman for Windows](http://www.abelhadigital.com/hostsman) that don't work\nwith Github download links.\n\nHost file recipe | Readme | Raw hosts | Unique domains | Non Github mirror\n---------------- |:------:|:---------:|:--------------:|:-------------:\nUnified hosts = **(adware + malware)** | [Readme](https://github.com/StevenBlack/hosts/blob/master/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts) | 43,154 | [link](http://sbc.io/hosts/hosts)\nUnified hosts **+ fakenews** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews/hosts) | 44,096 | [link](http://sbc.io/hosts/alternates/fakenews/hosts)\nUnified hosts **+ gambling** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling/hosts) | 45,426 | [link](http://sbc.io/hosts/alternates/gambling/hosts)\nUnified hosts **+ porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/porn/hosts) | 58,797 | [link](http://sbc.io/hosts/alternates/porn/hosts)\nUnified hosts **+ social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/social/hosts) | 45,629 | [link](http://sbc.io/hosts/alternates/social/hosts)\nUnified hosts **+ fakenews + gambling** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling/hosts) | 46,368 | [link](http://sbc.io/hosts/alternates/fakenews-gambling/hosts)\nUnified hosts **+ fakenews + porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-porn/hosts) | 59,739 | [link](http://sbc.io/hosts/alternates/fakenews-porn/hosts)\nUnified hosts **+ fakenews + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-social/hosts) | 46,571 | [link](http://sbc.io/hosts/alternates/fakenews-social/hosts)\nUnified hosts **+ gambling + porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling-porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling-porn/hosts) | 61,069 | [link](http://sbc.io/hosts/alternates/gambling-porn/hosts)\nUnified hosts **+ gambling + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling-social/hosts) | 47,901 | [link](http://sbc.io/hosts/alternates/gambling-social/hosts)\nUnified hosts **+ porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/porn-social/hosts) | 61,271 | [link](http://sbc.io/hosts/alternates/porn-social/hosts)\nUnified hosts **+ fakenews + gambling + porn** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling-porn/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling-porn/hosts) | 62,011 | [link](http://sbc.io/hosts/alternates/fakenews-gambling-porn/hosts)\nUnified hosts **+ fakenews + gambling + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling-social/hosts) | 48,843 | [link](http://sbc.io/hosts/alternates/fakenews-gambling-social/hosts)\nUnified hosts **+ fakenews + porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-porn-social/hosts) | 62,213 | [link](http://sbc.io/hosts/alternates/fakenews-porn-social/hosts)\nUnified hosts **+ gambling + porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/gambling-porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/gambling-porn-social/hosts) | 63,543 | [link](http://sbc.io/hosts/alternates/gambling-porn-social/hosts)\nUnified hosts **+ fakenews + gambling + porn + social** | [Readme](https://github.com/StevenBlack/hosts/blob/master/alternates/fakenews-gambling-porn-social/readme.md) | [link](https://raw.githubusercontent.com/StevenBlack/hosts/master/alternates/fakenews-gambling-porn-social/hosts) | 64,485 | [link](http://sbc.io/hosts/alternates/fakenews-gambling-porn-social/hosts)\n\n\n**Expectation**: These unified hosts files should serve all devices, regardless\nof OS.\n\n## Sources of hosts data unified in this variant\n\nUpdated `hosts` files from the following locations are always unified and\nincluded:\n\nHost file source | Description | Home page | Raw hosts | Update frequency | License | Issues\n-----------------|-------------|:---------:|:---------:|:----------------:|:-------:|:------:\nSteven Black's ad-hoc list | Additional sketch domains as I come across them. |[link](https://github.com/StevenBlack/hosts/blob/master/data/StevenBlack/hosts) | [raw](https://raw.githubusercontent.com/StevenBlack/hosts/master/data/StevenBlack/hosts) | occasionally | MIT  | [issues](https://github.com/StevenBlack/hosts/issues) \nMalware Domain List | Malware Domain List is a non-commercial community project. |[link](https://www.malwaredomainlist.com/) | [raw](https://www.malwaredomainlist.com/hostslist/hosts.txt) | weekly | 'can be used for free by anyone'  | [issues](https://www.malwaredomainlist.com/contact.php) \nadd.Dead | Dead sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Dead/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nhostsVN | Hosts block ads of Vietnamese |[link](https://github.com/bigdargon/hostsVN) | [raw](https://raw.githubusercontent.com/bigdargon/hostsVN/master/option/hosts-VN) | occasionally | MIT  | [issues](https://github.com/bigdargon/hostsVN/issues) \nadd.Spam | Spam sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Spam/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nDan Pollock \u2013 [someonewhocares](https://someonewhocares.org) | How to make the internet not suck (as much). |[link](https://someonewhocares.org/hosts/) | [raw](https://someonewhocares.org/hosts/zero/hosts) | frequently | non-commercial with attribution  | [issues](hosts@someonewhocares.org) \nMVPS hosts file | The purpose of this site is to provide the user with a high quality custom HOSTS file. |[link](http://winhelp2002.mvps.org/) | [raw](http://winhelp2002.mvps.org/hosts.txt) | monthly | CC BY-NC-SA 4.0  | [issues](mailto:winhelp2002@gmail.com) \nyoyo.org | Blocking with ad server and tracking server hostnames. |[link](https://pgl.yoyo.org/adservers/) | [raw](https://pgl.yoyo.org/adservers/serverlist.php?hostformat=hosts&mimetype=plaintext&useip=0.0.0.0) | frequently |   | [issues](mailto:pgl@yoyo.org) \nMitchell Krog's - Badd Boyz Hosts | Sketchy domains and Bad Referrers from my Nginx and Apache Bad Bot and Spam Referrer Blockers |[link](https://github.com/mitchellkrogza/Badd-Boyz-Hosts) | [raw](https://raw.githubusercontent.com/mitchellkrogza/Badd-Boyz-Hosts/master/hosts) | weekly | MIT  | [issues](https://github.com/mitchellkrogza/Badd-Boyz-Hosts/issues) \nCoinBlocker | Simple lists that can help prevent cryptomining in the browser or other applications |[link](https://gitlab.com/ZeroDot1/CoinBlockerLists) | [raw](https://zerodot1.gitlab.io/CoinBlockerLists/hosts_browser) | frequently | GPLv3  | [issues](https://gitlab.com/ZeroDot1/CoinBlockerLists/issues) \nUncheckyAds | Windows installers ads sources sites based on https://unchecky.com/ content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/UncheckyAds/hosts) | occasionally |   | [issues](https://github.com/FadeMind/hosts.extras/issues) \nadd.2o7Net | 2o7Net tracking sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.2o7Net/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nKADhosts | Fraud/adware/scam websites. |[link](https://kadantiscam.netlify.com) | [raw](https://raw.githubusercontent.com/PolishFiltersTeam/KADhosts/master/KADhosts_without_controversies.txt) | frequently | CC BY-SA 4.0  | [issues](https://github.com/PolishFiltersTeam/KADhosts/issues) \nAdAway | AdAway is an open source ad blocker for Android using the hosts file. |[link](https://adaway.org/) | [raw](https://raw.githubusercontent.com/AdAway/adaway.github.io/master/hosts.txt) | occasionally | CC BY 3.0  | [issues](https://github.com/AdAway/AdAway/issues) \nadd.Risk | Risk content sites based on [hostsfile.org](http://www.hostsfile.org/hosts.html) content. |[link](https://github.com/FadeMind/hosts.extras) | [raw](https://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Risk/hosts) | occasionally | GPLv3+  | [issues](https://github.com/FadeMind/hosts.extras/issues) \nTiuxo hostlist - ads | Categorized hosts files for DNS based content blocking |[link](https://github.com/tiuxo/hosts) | [raw](https://raw.githubusercontent.com/tiuxo/hosts/master/ads) | occasional | CC BY 4.0  | [issues](https://github.com/tiuxo/hosts/issues) \n\n\n\n## Extensions\nThe unified hosts file is optionally extensible.  Extensions are used to include domains by category.  Currently we offer the following categories: `fakenews`, `social`, `gambling`, and `porn`.\n\nExtensions are optional, and can be combined in various ways wth the base hosts file.  The combined products are stored in the [`alternates`](https://github.com/StevenBlack/hosts/tree/master/alternates) folder.\n\nData for extensions is stored in the [`extensions`](https://github.com/StevenBlack/hosts/tree/master/extensions) folder. You manage extensions by curating this\nfolder tree, where you will find the data for `fakenews`, `social`, `gambling`, and `porn` extension data that we maintain and provide for you.\n\n## Generate your own unified hosts file\n\nTo generate your own unified hosts file you will need Python 3.5 or later.\n\nFirst install the dependencies with:\n\n    pip3 install --user -r requirements.txt\n\n**Note** we recommend the `--user` flag which installs the required dependencies at the user level. More information about it can be found on pip [documentation](https://pip.pypa.io/en/stable/reference/pip_install/?highlight=--user#cmdoption-user).\n\nTo run unit tests, in the top level directory, run:\n\n    python3 testUpdateHostsFile.py\n\nThe `updateHostsFile.py` script will generate a unified hosts file based on the sources in the\nlocal `data/` subfolder.  The script will prompt you whether it should fetch updated versions\n(from locations defined by the `update.json` text file in each source's folder). Otherwise, it\nwill use the `hosts` file that's already there.\n\n### Usage\n\n#### Using Python 3:\n\n    python3 updateHostsFile.py [--auto] [--replace] [--ip nnn.nnn.nnn.nnn] [--extensions ext1 ext2 ext3]\n\n#### Command line options:\n\n`--help`, or `-h`: display help.\n\n`--auto`, or `-a`: run the script without prompting. When `--auto` is invoked,\n\n* Hosts data sources, including extensions, are updated.\n* No extensions are included by default.  Use the `--extensions` or `-e` flag\nto include any you want.\n* Your active hosts file is *not* replaced unless you include the `--replace`\nflag.\n\n`--backup`, or `-b`: Make a backup of existing hosts file(s) as you generate\nover them.\n\n`--extensions <ext1> <ext2> <ext3>`, or `-e <ext1> <ext2> <ext3>`: the names\nof subfolders below the `extensions` folder containing additional\ncategory-specific hosts files to include in the amalgamation. Example:\n`--extensions porn` or `-e social porn`.\n\n`--flush-dns-cache`, or `-f`: skip the prompt for flushing the DNS cache.\nOnly active when `--replace` is also active.\n\n`--ip nnn.nnn.nnn.nnn`, or `-i nnn.nnn.nnn.nnn`: the IP address to use as the\ntarget.  Default is `0.0.0.0`.\n\n`--keepdomaincomments`, or `-k`: `true` (default) or `false`, keep the comments\nthat appear on the same line as domains.  The default is `true`.\n\n`--noupdate`, or `-n`: skip fetching updates from hosts data sources.\n\n`--output <subfolder>`, or `-o <subfolder>`: place the generated source file\nin a subfolder.  If the subfolder does not exist, it will be created.\n\n`--replace`, or `-r`: trigger replacing your active hosts\n\n`--skipstatichosts`, or `-s`: `false` (default) or `true`, omit the standard\nsection at the top, containing lines like `127.0.0.1 localhost`.  This is\nuseful for configuring proximate DNS services on the local network.\n\n`--compress`, or `-c`: `false` (default) or `true`, *Compress* the hosts file\nignoring non-necessary lines (empty lines and comments) and putting multiple\ndomains in each line. Reducing the number of lines of the hosts file improves\nthe performances under Windows (with DNS Client service enabled).\n\n`--minimise`, or `-m`: `false` (default) or `true`, like `--compress`, but puts\neach domain on a separate line. This is necessary because many implementations\nof URL blockers that rely on `hosts` files do not conform to the standard which\nallows multiple hosts on a single line.\n\n## How do I control which sources are unified?\n\nAdd one or more  *additional* sources, each in a subfolder of the `data/`\nfolder, and specify the `url` key in its `update.json` file.\n\nAdd one or more *optional* extensions, which originate from subfolders of the\n`extensions/` folder.  Again the url in `update.json` controls where this\nextension finds its updates.\n\nCreate an *optional* `blacklist` file. The contents of this file (containing a\nlisting of additional domains in `hosts` file format) are appended to the\nunified hosts file during the update process. A sample `blacklist` is\nincluded, and may be modified as you need.\n\n  * NOTE: The `blacklist` is not tracked by git, so any changes you make won't\nbe overridden when you `git pull`   this repo from `origin` in the future.\n\n### How do I include my own custom domain mappings?\n\nIf you have custom hosts records, place them in file `myhosts`.  The contents\nof this file are prepended to the unified hosts file during the update\nprocess.\n\nThe `myhosts` file is not tracked by git, so any changes you make won't be\noverridden when you `git pull` this repo from `origin` in the future.\n\n### How do I prevent domains from being included?\n\nThe domains you list in the `whitelist` file are excluded from the final hosts\nfile.\n\nThe `whitelist` uses partial matching.  Therefore if you whitelist\n`google-analytics.com`, that domain and all its subdomains won't be merged\ninto the final hosts file.\n\nThe `whitelist` is not tracked by git, so any changes you make won't be\noverridden when you `git pull` this repo  from `origin` in the future.\n\n## How can I contribute hosts records?\n\nIf you discover sketchy domains you feel should be included here, here are some ways to contribute them.\n\n### Option 1: contact one of our hosts sources\n\nThe best way to get new domains included is to submit an issue to any of the data providers whose home pages are [listed here](https://github.com/StevenBlack/hosts#sources-of-hosts-data-unified-in-this-variant). This is best because once you submit new domains, they will be curated and updated by the dedicated folks who maintain these sources.\n\n\n### Option 2: add your domains to Steven Black's personal data file\n\nFork this hosts this repo and add your links to [https://github.com/StevenBlack/hosts/blob/master/data/StevenBlack/hosts](https://github.com/StevenBlack/hosts/blob/master/data/StevenBlack/hosts).\n\nThen, submit a pull request.\n\n**WARNING**: this is less desirable than Option 1 because the ongoing curation falls on us. So this creates more work for us.\n\n### Option 3: create your own hosts list as a repo on Github\n\nIf you're able to curate your own collection of sketchy domains, then curate your own hosts list.  Then signal the existence of your repo as [a new issue](https://github.com/StevenBlack/hosts/issues) and we may include your new repo into the collection of sources we pull whenever we create new versions.\n\n\n## What is a hosts file?\n\nA hosts file, named `hosts` (with no file extension), is a plain-text file\nused by all operating systems to map hostnames to IP addresses.\n\nIn most operating systems, the `hosts` file is preferential to `DNS`.\nTherefore if a domain name is resolved by the `hosts` file, the request never\nleaves your computer.\n\nHaving a smart `hosts` file goes a long way towards blocking malware, adware,\nand other irritants.\n\nFor example, to nullify requests to some doubleclick.net servers, adding these\nlines to your hosts file will do it:\n\n    # block doubleClick's servers\n    0.0.0.0 ad.ae.doubleclick.net\n    0.0.0.0 ad.ar.doubleclick.net\n    0.0.0.0 ad.at.doubleclick.net\n    0.0.0.0 ad.au.doubleclick.net\n    0.0.0.0 ad.be.doubleclick.net\n    # etc...\n\n\n## We recommend using `0.0.0.0` instead of `127.0.0.1`\n\nTraditionally most host files use `127.0.0.1`, the *loopback address*, to establish an IP connection to the local machine.\n\nWe prefer to use `0.0.0.0`, which is defined as a non-routable meta-address used to designate an invalid, unknown, or non applicable target.\n\nUsing `0.0.0.0` is empirically faster, possibly because there's no wait for a timeout resolution. It also does not\ninterfere with a web server that may be running on the local PC.\n\n## Why not use `0` instead of `0.0.0.0`?\nWe tried that.  Using `0` doesn't work universally.\n\n\n## Location of your hosts file\nTo modify your current `hosts` file, look for it in the following places and modify it with a text\neditor.\n\n**mac OS (until 10.14.x macOS Mojave), iOS, Android, Linux**: `/etc/hosts` file.\n\n**macOS Catalina:** `/private/etc/hosts` file.\n\n**Windows**: `%SystemRoot%\\system32\\drivers\\etc\\hosts` file.\n\n## Gentoo\nGentoo users may find [`sb-hosts`](https://github.com/PF4Public/gentoo-overlay/tree/master/net-misc/sb-hosts) in [::pf4public](https://github.com/PF4Public/gentoo-overlay) Gentoo overlay\n\n## Updating hosts file on Windows\n\nOn Linux and Mac OS X, run the Python script. On Windows more\nwork is required due to compatibility issues so it's preferable to run the batch file as follows:\n\n```\nupdateHostsWindows.bat\n```\n\nThis file MUST be run in command prompt with administrator privileges in\nthe repository directory. In addition to updating the hosts file, it can also\nreplace the existing hosts file, and reload the DNS cache. It goes without\nsaying that in order for this to work, you must be connected to the internet.\n\nTo open a command prompt as administrator in the repository's directory, do the following:\n\n**Windows XP**: Start -> Run -> `cmd`\n\n**Windows Vista, 7**: Start Button -> type `cmd` -> right-click Command Prompt ->\n\"Run as Administrator\"\n\n**Windows 8**: Start -> Swipe Up -> All Apps -> Windows System -> right-click Command Prompt ->\n\"Run as Administrator\"\n\n**Windows 10**: Start Button -> type `cmd` -> right-click Command Prompt ->\n\"Run as Administrator\"\n\nYou can also refer to the \"Third-Party Hosts Managers\" section for further recommended solutions from third parties.\n\n## Reloading hosts file\nYour operating system will cache DNS lookups. You can either reboot or run the following commands to\nmanually flush your DNS cache once the new hosts file is in place.\n\n| The Google Chrome browser may require manually cleaning up its DNS Cache on `chrome://net-internals/#dns` page to thereafter see the changes in your hosts file. See: https://superuser.com/questions/723703\n:-----------------------------------------------------------------------------------------\n\n### Windows\n\nOpen a command prompt with administrator privileges and run this command:\n\n```\nipconfig /flushdns\n```\n\n|If you want to use a huge hosts file by merging [hphosts](https://www.hosts-file.net) (NOT INCLUDED HERE) you need to DISABLE and STOP `Dnscache` service before you replace hosts file in Windows Systems. You have been warned.|\n:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nBefore flushing the DNS cache, open a command prompt with administrator privileges and run this command:\n\n```\nsc config \"Dnscache\" start= disabled\nsc stop \"Dnscache\"\n```\n\n### Linux\n\nOpen a Terminal and run with root privileges:\n\n**Debian/Ubuntu** `sudo service network-manager restart`\n\n**Linux Mint** `sudo /etc/init.d/dns-clean start`\n\n**Linux with systemd**: `sudo systemctl restart network.service`\n\n**Fedora Linux**: `sudo systemctl restart NetworkManager.service`\n\n**Arch Linux/Manjaro with Network Manager**: `sudo systemctl restart NetworkManager.service`\n\n**Arch Linux/Manjaro with Wicd**: `sudo systemctl restart wicd.service`\n\n**RHEL/Centos**: `sudo /etc/init.d/network restart`\n\n**FreeBSD**: `sudo service nscd restart`\n\nTo enable the `nscd` daemon initially, it is recommended that you run the following commands:\n\n```\nsudo sysrc nscd_enable=\"YES\"\nsudo service nscd start\n```\n\nThen modify the `hosts` line in your `/etc/nsswitch.conf` file to the following:\n\n```\nhosts: cache files dns\n```\n\n**Others**: Consult [this wikipedia article](https://en.wikipedia.org/wiki/Hosts_%28file%29#Location_in_the_file_system).\n\n### Mac OS X\n\nOpen a Terminal and run:\n```\nsudo dscacheutil -flushcache;sudo killall -HUP mDNSResponder\n```\n\n## Release management\n\nThis repository uses [Release-It!](https://webpro.github.io/release-it/), an excellent CLI release\ntool for Github repos and npm packages, to automate creating [releases](https://github.com/StevenBlack/hosts/releases).\nThis is why the [package.json](https://github.com/StevenBlack/hosts/blob/master/package.json) and\n[.release-it.json](https://github.com/StevenBlack/hosts/blob/master/.release-it.json) files are bundled.\n\n## Goals of this unified hosts file\n\nThe goals of this repo are to:\n\n1. automatically combine high-quality lists of hosts,\n\n2. provide situation-appropriate extensions,\n\n3. de-dupe the resultant combined list,\n\n4. and keep the resultant file reasonably sized.\n\nA high-quality source is defined here as one that is actively curated.  A\nhosts source should be frequently updated by its maintainers with both\nadditions and removals.  The larger the hosts file, the higher the level of\ncuration is expected.\n\nFor example, the (huge) hosts file from [hosts-file.net](https://hosts-file.net)\nis **not** included here because it is very large (780,000+ entries)\nand doesn't currently display a corresponding high level of curation activity.\n\nIt is expected that this unified hosts file will serve both desktop and mobile\ndevices under a variety of operating systems.\n\n## Third-Party Hosts Managers\n\n* [Unified Hosts AutoUpdate](https://github.com/ScriptTiger/Unified-Hosts-AutoUpdate \"Unified Hosts AutoUpdate\") (for Windows): The Unified Hosts AutUpdate package is purpose-built for this unified hosts project as well as in active development by community members. You can install and uninstall any blacklist  and keep it automatically up to date, and can be placed in a shared network location and deployed across an organization via group policies. And since it is in active development by community members, your bug reports, feature requests, and other feedback are most welcome.\n\n* [ViHoMa](https://github.com/cmabad/ViHoMa) is a Visual Hosts file Manager, written in Java, by Christian Mart\u00ednez.  Check it out!\n\n## Interesting Applications\n\n* [Hostile](https://github.com/feross/hostile) is a nifty command line utility to easily add or remove domains from your hosts file.  If our hosts files are too aggressive for you, you can use `hostile` to remove domains, or you can use `hostile` in a bash script to automate a post process each time you download fresh versions of hosts.\n\n* [macOS Scripting for Configuration, Backup and Restore](https://github.com/tiiiecherle/osx_install_config) helps customizing, re-installing and using macOS. It also provides a [script](https://github.com/tiiiecherle/osx_install_config/blob/master/09_launchd/9b_run_on_boot/root/1_hosts_file/launchd_and_script/hosts_file_generator.sh) to install and update the hosts file using this project on macOS. In combination with a [launchd](https://github.com/tiiiecherle/osx_install_config/blob/master/09_launchd/9b_run_on_boot/root/1_hosts_file/launchd_and_script/com.hostsfile.install_update.plist) it updates the hosts file every x days (default is 4). To install both download the github repo and run the [install script](https://github.com/tiiiecherle/osx_install_config/blob/master/09_launchd/9b_run_on_boot/root/1_hosts_file/install_hosts_file_generator_and_launchdservice.sh) from the directory one level up.\n\n* [Pi-hole](https://pi-hole.net/) is a network-wide DHCP server and ad blocker that runs on [Raspberry Pi](https://en.wikipedia.org/wiki/Raspberry_Pi). Pi-hole uses this repository as one of its sources.     This is a very interesting project to setup yourself, or you can [buy one pre-loaded](https://uk.pi-supply.com/products/pi-hole-kit-network-wide-ad-blocker).\n\n* [Block ads and malware via local BIND9 DNS server](https://github.com/mueller-ma/block-ads-via-dns \"Block ads and malware via local DNS server\") (for Debian, Raspbian & Ubuntu): Set up a local DNS server with a `/etc/bind/named.conf.blocked` file, sourced from here.\n\n* [Block ads, malware, and deploy parental controls via local DualServer DNS/DHCP server](https://scripttiger.github.io/dualserver \"Block ads, malware, and deploy parental controls via local DualServer DNS/DHCP server\") (for BSD, Windows & Linux): Set up a blacklist for everyone on your network using the power of the unified hosts reformatted for DualServer. And if you're on Windows, this project also maintains an update script to make updating DualServer's blacklist even easier.\n\n* [Blocking ads and malwares with unbound](https://deadc0de.re/articles/unbound-blocking-ads.html \"Blocking ads and malwares with unbound\") \u2013 [Unbound](https://www.unbound.net/ \"Unbound is a validating, recursive, and caching DNS resolver.\")  is a validating, recursive, and caching DNS resolver.\n\n* [DNSMasq conversion script](https://gist.github.com/erlepereira/c11f4f7a3f60cd2071e79018e895fc8a#file-dnsmasq-antimalware) This github gist has a short shell script (bash, will work on any 'nix) and uses 'wget' & 'awk' present in most distros, to fetch a specified hosts file and convert it the format required by dnsmasq. Supports ipv4 and ipv6. Designed to be used as either a shell script, or can be dropped into /etc/cron.weekly (or wherever suits). Script is short and easily edited, also has a short document attached with notes on dnsmasq setup.\n\n## Contribute!\n\nPlease read our [Contributing Guide](https://github.com/StevenBlack/hosts/blob/master/contributing.md). Among other things, this explains how we organize files and folders in this repository.\n\nWe are always interested in discovering well-curated sources of hosts.  If you find one, please open an [issue](https://github.com/StevenBlack/hosts/issues) to draw our attention.\n\nBefore you create or respond to any issue, please read our [code of conduct](https://github.com/StevenBlack/hosts/blob/master/code_of_conduct.md).\n"}, {"repo": "celery/celery", "language": "Python", "readme_contents": ".. image:: http://docs.celeryproject.org/en/latest/_images/celery-banner-small.png\n\n|build-status| |coverage| |license| |wheel| |pyversion| |pyimp| |ocbackerbadge| |ocsponsorbadge|\n\n:Version: 4.4.0rc5 (cliffs)\n:Web: http://celeryproject.org/\n:Download: https://pypi.org/project/celery/\n:Source: https://github.com/celery/celery/\n:Keywords: task, queue, job, async, rabbitmq, amqp, redis,\n  python, distributed, actors\n\nDonations\n=========\n\nThis project relies on your generous donations.\n\nIf you are using Celery to create a commercial product, please consider becoming our `backer`_ or our `sponsor`_ to ensure Celery's future.\n\n.. _`backer`: https://opencollective.com/celery#backer\n.. _`sponsor`: https://opencollective.com/celery#sponsor\n\nFor enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of ``celery`` and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. `Learn more. <https://tidelift.com/subscription/pkg/pypi-celery?utm_source=pypi-celery&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_\n\nWhat's a Task Queue?\n====================\n\nTask queues are used as a mechanism to distribute work across threads or\nmachines.\n\nA task queue's input is a unit of work, called a task, dedicated worker\nprocesses then constantly monitor the queue for new work to perform.\n\nCelery communicates via messages, usually using a broker\nto mediate between clients and workers. To initiate a task a client puts a\nmessage on the queue, the broker then delivers the message to a worker.\n\nA Celery system can consist of multiple workers and brokers, giving way\nto high availability and horizontal scaling.\n\nCelery is written in Python, but the protocol can be implemented in any\nlanguage. In addition to Python there's node-celery_ for Node.js,\na `PHP client`_ and `gocelery`_ for golang.\n\nLanguage interoperability can also be achieved by using webhooks\nin such a way that the client enqueues an URL to be requested by a worker.\n\n.. _node-celery: https://github.com/mher/node-celery\n.. _`PHP client`: https://github.com/gjedeer/celery-php\n.. _`gocelery`: https://github.com/gocelery/gocelery\n\nWhat do I need?\n===============\n\nCelery version 4.3 runs on,\n\n- Python (2.7, 3.4, 3.5, 3.6, 3.7)\n- PyPy2.7 (6.0)\n- PyPy3.5 (6.0)\n\n\nThis is the last version to support Python 2.7,\nand from the next version (Celery 5.x) Python 3.5 or newer is required.\n\nIf you're running an older version of Python, you need to be running\nan older version of Celery:\n\n- Python 2.6: Celery series 3.1 or earlier.\n- Python 2.5: Celery series 3.0 or earlier.\n- Python 2.4 was Celery series 2.2 or earlier.\n\nCelery is a project with minimal funding,\nso we don't support Microsoft Windows.\nPlease don't open any issues related to that platform.\n\n*Celery* is usually used with a message broker to send and receive messages.\nThe RabbitMQ, Redis transports are feature complete,\nbut there's also experimental support for a myriad of other solutions, including\nusing SQLite for local development.\n\n*Celery* can run on a single machine, on multiple machines, or even\nacross datacenters.\n\nGet Started\n===========\n\nIf this is the first time you're trying to use Celery, or you're\nnew to Celery 4.2 coming from previous versions then you should read our\ngetting started tutorials:\n\n- `First steps with Celery`_\n\n    Tutorial teaching you the bare minimum needed to get started with Celery.\n\n- `Next steps`_\n\n    A more complete overview, showing more features.\n\n.. _`First steps with Celery`:\n    http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html\n\n.. _`Next steps`:\n    http://docs.celeryproject.org/en/latest/getting-started/next-steps.html\n\nCelery is...\n=============\n\n- **Simple**\n\n    Celery is easy to use and maintain, and does *not need configuration files*.\n\n    It has an active, friendly community you can talk to for support,\n    like at our `mailing-list`_, or the IRC channel.\n\n    Here's one of the simplest applications you can make::\n\n        from celery import Celery\n\n        app = Celery('hello', broker='amqp://guest@localhost//')\n\n        @app.task\n        def hello():\n            return 'hello world'\n\n- **Highly Available**\n\n    Workers and clients will automatically retry in the event\n    of connection loss or failure, and some brokers support\n    HA in way of *Primary/Primary* or *Primary/Replica* replication.\n\n- **Fast**\n\n    A single Celery process can process millions of tasks a minute,\n    with sub-millisecond round-trip latency (using RabbitMQ,\n    py-librabbitmq, and optimized settings).\n\n- **Flexible**\n\n    Almost every part of *Celery* can be extended or used on its own,\n    Custom pool implementations, serializers, compression schemes, logging,\n    schedulers, consumers, producers, broker transports, and much more.\n\nIt supports...\n================\n\n    - **Message Transports**\n\n        - RabbitMQ_, Redis_, Amazon SQS\n\n    - **Concurrency**\n\n        - Prefork, Eventlet_, gevent_, single threaded (``solo``)\n\n    - **Result Stores**\n\n        - AMQP, Redis\n        - memcached\n        - SQLAlchemy, Django ORM\n        - Apache Cassandra, IronCache, Elasticsearch\n\n    - **Serialization**\n\n        - *pickle*, *json*, *yaml*, *msgpack*.\n        - *zlib*, *bzip2* compression.\n        - Cryptographic message signing.\n\n.. _`Eventlet`: http://eventlet.net/\n.. _`gevent`: http://gevent.org/\n\n.. _RabbitMQ: https://rabbitmq.com\n.. _Redis: https://redis.io\n.. _SQLAlchemy: http://sqlalchemy.org\n\nFramework Integration\n=====================\n\nCelery is easy to integrate with web frameworks, some of which even have\nintegration packages:\n\n    +--------------------+------------------------+\n    | `Django`_          | not needed             |\n    +--------------------+------------------------+\n    | `Pyramid`_         | `pyramid_celery`_      |\n    +--------------------+------------------------+\n    | `Pylons`_          | `celery-pylons`_       |\n    +--------------------+------------------------+\n    | `Flask`_           | not needed             |\n    +--------------------+------------------------+\n    | `web2py`_          | `web2py-celery`_       |\n    +--------------------+------------------------+\n    | `Tornado`_         | `tornado-celery`_      |\n    +--------------------+------------------------+\n\nThe integration packages aren't strictly necessary, but they can make\ndevelopment easier, and sometimes they add important hooks like closing\ndatabase connections at ``fork``.\n\n.. _`Django`: https://djangoproject.com/\n.. _`Pylons`: http://pylonsproject.org/\n.. _`Flask`: http://flask.pocoo.org/\n.. _`web2py`: http://web2py.com/\n.. _`Bottle`: https://bottlepy.org/\n.. _`Pyramid`: http://docs.pylonsproject.org/en/latest/docs/pyramid.html\n.. _`pyramid_celery`: https://pypi.org/project/pyramid_celery/\n.. _`celery-pylons`: https://pypi.org/project/celery-pylons/\n.. _`web2py-celery`: https://code.google.com/p/web2py-celery/\n.. _`Tornado`: http://www.tornadoweb.org/\n.. _`tornado-celery`: https://github.com/mher/tornado-celery/\n\n.. _celery-documentation:\n\nDocumentation\n=============\n\nThe `latest documentation`_ is hosted at Read The Docs, containing user guides,\ntutorials, and an API reference.\n\n\u6700\u65b0\u7684\u4e2d\u6587\u6587\u6863\u6258\u7ba1\u5728 https://www.celerycn.io/ \u4e2d\uff0c\u5305\u542b\u7528\u6237\u6307\u5357\u3001\u6559\u7a0b\u3001API\u63a5\u53e3\u7b49\u3002\n\n.. _`latest documentation`: http://docs.celeryproject.org/en/latest/\n\n.. _celery-installation:\n\nInstallation\n============\n\nYou can install Celery either via the Python Package Index (PyPI)\nor from source.\n\nTo install using ``pip``:\n\n::\n\n\n    $ pip install -U Celery\n\n.. _bundles:\n\nBundles\n-------\n\nCelery also defines a group of bundles that can be used\nto install Celery and the dependencies for a given feature.\n\nYou can specify these in your requirements or on the ``pip``\ncommand-line by using brackets. Multiple bundles can be specified by\nseparating them by commas.\n\n::\n\n\n    $ pip install \"celery[librabbitmq]\"\n\n    $ pip install \"celery[librabbitmq,redis,auth,msgpack]\"\n\nThe following bundles are available:\n\nSerializers\n~~~~~~~~~~~\n\n:``celery[auth]``:\n    for using the ``auth`` security serializer.\n\n:``celery[msgpack]``:\n    for using the msgpack serializer.\n\n:``celery[yaml]``:\n    for using the yaml serializer.\n\nConcurrency\n~~~~~~~~~~~\n\n:``celery[eventlet]``:\n    for using the ``eventlet`` pool.\n\n:``celery[gevent]``:\n    for using the ``gevent`` pool.\n\nTransports and Backends\n~~~~~~~~~~~~~~~~~~~~~~~\n\n:``celery[librabbitmq]``:\n    for using the librabbitmq C library.\n\n:``celery[redis]``:\n    for using Redis as a message transport or as a result backend.\n\n:``celery[sqs]``:\n    for using Amazon SQS as a message transport.\n\n:``celery[tblib``]:\n    for using the ``task_remote_tracebacks`` feature.\n\n:``celery[memcache]``:\n    for using Memcached as a result backend (using ``pylibmc``)\n\n:``celery[pymemcache]``:\n    for using Memcached as a result backend (pure-Python implementation).\n\n:``celery[cassandra]``:\n    for using Apache Cassandra as a result backend with DataStax driver.\n\n:``celery[azureblockblob]``:\n    for using Azure Storage as a result backend (using ``azure-storage``)\n\n:``celery[s3]``:\n    for using S3 Storage as a result backend.\n\n:``celery[couchbase]``:\n    for using Couchbase as a result backend.\n\n:``celery[arangodb]``:\n    for using ArangoDB as a result backend.\n\n:``celery[elasticsearch]``:\n    for using Elasticsearch as a result backend.\n\n:``celery[riak]``:\n    for using Riak as a result backend.\n\n:``celery[cosmosdbsql]``:\n    for using Azure Cosmos DB as a result backend (using ``pydocumentdb``)\n\n:``celery[zookeeper]``:\n    for using Zookeeper as a message transport.\n\n:``celery[sqlalchemy]``:\n    for using SQLAlchemy as a result backend (*supported*).\n\n:``celery[pyro]``:\n    for using the Pyro4 message transport (*experimental*).\n\n:``celery[slmq]``:\n    for using the SoftLayer Message Queue transport (*experimental*).\n\n:``celery[consul]``:\n    for using the Consul.io Key/Value store as a message transport or result backend (*experimental*).\n\n:``celery[django]``:\n    specifies the lowest version possible for Django support.\n\n    You should probably not use this in your requirements, it's here\n    for informational purposes only.\n\n\n.. _celery-installing-from-source:\n\nDownloading and installing from source\n--------------------------------------\n\nDownload the latest version of Celery from PyPI:\n\nhttps://pypi.org/project/celery/\n\nYou can install it by doing the following,:\n\n::\n\n\n    $ tar xvfz celery-0.0.0.tar.gz\n    $ cd celery-0.0.0\n    $ python setup.py build\n    # python setup.py install\n\nThe last command must be executed as a privileged user if\nyou aren't currently using a virtualenv.\n\n.. _celery-installing-from-git:\n\nUsing the development version\n-----------------------------\n\nWith pip\n~~~~~~~~\n\nThe Celery development version also requires the development\nversions of ``kombu``, ``amqp``, ``billiard``, and ``vine``.\n\nYou can install the latest snapshot of these using the following\npip commands:\n\n::\n\n\n    $ pip install https://github.com/celery/celery/zipball/master#egg=celery\n    $ pip install https://github.com/celery/billiard/zipball/master#egg=billiard\n    $ pip install https://github.com/celery/py-amqp/zipball/master#egg=amqp\n    $ pip install https://github.com/celery/kombu/zipball/master#egg=kombu\n    $ pip install https://github.com/celery/vine/zipball/master#egg=vine\n\nWith git\n~~~~~~~~\n\nPlease see the Contributing section.\n\n.. _getting-help:\n\nGetting Help\n============\n\n.. _mailing-list:\n\nMailing list\n------------\n\nFor discussions about the usage, development, and future of Celery,\nplease join the `celery-users`_ mailing list.\n\n.. _`celery-users`: https://groups.google.com/group/celery-users/\n\n.. _irc-channel:\n\nIRC\n---\n\nCome chat with us on IRC. The **#celery** channel is located at the `Freenode`_\nnetwork.\n\n.. _`Freenode`: https://freenode.net\n\n.. _bug-tracker:\n\nBug tracker\n===========\n\nIf you have any suggestions, bug reports, or annoyances please report them\nto our issue tracker at https://github.com/celery/celery/issues/\n\n.. _wiki:\n\nWiki\n====\n\nhttps://github.com/celery/celery/wiki\n\nCredits\n=======\n\n.. _contributing-short:\n\nContributors\n------------\n\nThis project exists thanks to all the people who contribute. Development of\n`celery` happens at GitHub: https://github.com/celery/celery\n\nYou're highly encouraged to participate in the development\nof `celery`. If you don't like GitHub (for some reason) you're welcome\nto send regular patches.\n\nBe sure to also read the `Contributing to Celery`_ section in the\ndocumentation.\n\n.. _`Contributing to Celery`:\n    http://docs.celeryproject.org/en/master/contributing.html\n\n|oc-contributors|\n\n.. |oc-contributors| image:: https://opencollective.com/celery/contributors.svg?width=890&button=false\n    :target: https://github.com/celery/celery/graphs/contributors\n\nBackers\n-------\n\nThank you to all our backers! \ud83d\ude4f [`Become a backer`_]\n\n.. _`Become a backer`: https://opencollective.com/celery#backer\n\n|oc-backers|\n\n.. |oc-backers| image:: https://opencollective.com/celery/backers.svg?width=890\n    :target: https://opencollective.com/celery#backers\n\nSponsors\n--------\n\nSupport this project by becoming a sponsor. Your logo will show up here with a\nlink to your website. [`Become a sponsor`_]\n\n.. _`Become a sponsor`: https://opencollective.com/celery#sponsor\n\n|oc-sponsors|\n\n.. |oc-sponsors| image:: https://opencollective.com/celery/sponsor/0/avatar.svg\n    :target: https://opencollective.com/celery/sponsor/0/website\n\n.. _license:\n\nLicense\n=======\n\nThis software is licensed under the `New BSD License`. See the ``LICENSE``\nfile in the top distribution directory for the full license text.\n\n.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround\n\n.. |build-status| image:: https://secure.travis-ci.org/celery/celery.png?branch=master\n    :alt: Build status\n    :target: https://travis-ci.org/celery/celery\n\n.. |coverage| image:: https://codecov.io/github/celery/celery/coverage.svg?branch=master\n    :target: https://codecov.io/github/celery/celery?branch=master\n\n.. |license| image:: https://img.shields.io/pypi/l/celery.svg\n    :alt: BSD License\n    :target: https://opensource.org/licenses/BSD-3-Clause\n\n.. |wheel| image:: https://img.shields.io/pypi/wheel/celery.svg\n    :alt: Celery can be installed via wheel\n    :target: https://pypi.org/project/celery/\n\n.. |pyversion| image:: https://img.shields.io/pypi/pyversions/celery.svg\n    :alt: Supported Python versions.\n    :target: https://pypi.org/project/celery/\n\n.. |pyimp| image:: https://img.shields.io/pypi/implementation/celery.svg\n    :alt: Support Python implementations.\n    :target: https://pypi.org/project/celery/\n\n.. |ocbackerbadge| image:: https://opencollective.com/celery/backers/badge.svg\n    :alt: Backers on Open Collective\n    :target: #backers\n\n.. |ocsponsorbadge| image:: https://opencollective.com/celery/sponsors/badge.svg\n    :alt: Sponsors on Open Collective\n    :target: #sponsors\n\n.. |downloads| image:: https://pepy.tech/badge/celery\n    :alt: Downloads\n    :target: https://pepy.tech/project/celery\n"}, {"repo": "eriklindernoren/ML-From-Scratch", "language": "Python", "readme_contents": "# Machine Learning From Scratch\n\n## About\nPython implementations of some of the fundamental Machine Learning models and algorithms from scratch.\n\nThe purpose of this project is not to produce as optimized and computationally efficient algorithms as possible\nbut rather to present the inner workings of them in a transparent and accessible way.\n\n## Table of Contents\n- [Machine Learning From Scratch](#machine-learning-from-scratch)\n  * [About](#about)\n  * [Table of Contents](#table-of-contents)\n  * [Installation](#installation)\n  * [Examples](#examples)\n    + [Polynomial Regression](#polynomial-regression)\n    + [Classification With CNN](#classification-with-cnn)\n    + [Density-Based Clustering](#density-based-clustering)\n    + [Generating Handwritten Digits](#generating-handwritten-digits)\n    + [Deep Reinforcement Learning](#deep-reinforcement-learning)\n    + [Image Reconstruction With RBM](#image-reconstruction-with-rbm)\n    + [Evolutionary Evolved Neural Network](#evolutionary-evolved-neural-network)\n    + [Genetic Algorithm](#genetic-algorithm)\n    + [Association Analysis](#association-analysis)\n  * [Implementations](#implementations)\n    + [Supervised Learning](#supervised-learning)\n    + [Unsupervised Learning](#unsupervised-learning)\n    + [Reinforcement Learning](#reinforcement-learning)\n    + [Deep Learning](#deep-learning)\n  * [Contact](#contact)\n\n## Installation\n    $ git clone https://github.com/eriklindernoren/ML-From-Scratch\n    $ cd ML-From-Scratch\n    $ python setup.py install\n\n## Examples\n### Polynomial Regression\n    $ python mlfromscratch/examples/polynomial_regression.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/p_reg.gif\" width=\"640\"\\>\n</p>\n<p align=\"center\">\n    Figure: Training progress of a regularized polynomial regression model fitting <br>\n    temperature data measured in Link\u00f6ping, Sweden 2016.\n</p>\n\n### Classification With CNN\n    $ python mlfromscratch/examples/convolutional_neural_network.py\n\n    +---------+\n    | ConvNet |\n    +---------+\n    Input Shape: (1, 8, 8)\n    +----------------------+------------+--------------+\n    | Layer Type           | Parameters | Output Shape |\n    +----------------------+------------+--------------+\n    | Conv2D               | 160        | (16, 8, 8)   |\n    | Activation (ReLU)    | 0          | (16, 8, 8)   |\n    | Dropout              | 0          | (16, 8, 8)   |\n    | BatchNormalization   | 2048       | (16, 8, 8)   |\n    | Conv2D               | 4640       | (32, 8, 8)   |\n    | Activation (ReLU)    | 0          | (32, 8, 8)   |\n    | Dropout              | 0          | (32, 8, 8)   |\n    | BatchNormalization   | 4096       | (32, 8, 8)   |\n    | Flatten              | 0          | (2048,)      |\n    | Dense                | 524544     | (256,)       |\n    | Activation (ReLU)    | 0          | (256,)       |\n    | Dropout              | 0          | (256,)       |\n    | BatchNormalization   | 512        | (256,)       |\n    | Dense                | 2570       | (10,)        |\n    | Activation (Softmax) | 0          | (10,)        |\n    +----------------------+------------+--------------+\n    Total Parameters: 538570\n\n    Training: 100% [------------------------------------------------------------------------] Time: 0:01:55\n    Accuracy: 0.987465181058\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_cnn1.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Classification of the digit dataset using CNN.\n</p>\n\n### Density-Based Clustering\n    $ python mlfromscratch/examples/dbscan.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_dbscan.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Clustering of the moons dataset using DBSCAN.\n</p>\n\n### Generating Handwritten Digits\n    $ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py\n\n    +-----------+\n    | Generator |\n    +-----------+\n    Input Shape: (100,)\n    +------------------------+------------+--------------+\n    | Layer Type             | Parameters | Output Shape |\n    +------------------------+------------+--------------+\n    | Dense                  | 25856      | (256,)       |\n    | Activation (LeakyReLU) | 0          | (256,)       |\n    | BatchNormalization     | 512        | (256,)       |\n    | Dense                  | 131584     | (512,)       |\n    | Activation (LeakyReLU) | 0          | (512,)       |\n    | BatchNormalization     | 1024       | (512,)       |\n    | Dense                  | 525312     | (1024,)      |\n    | Activation (LeakyReLU) | 0          | (1024,)      |\n    | BatchNormalization     | 2048       | (1024,)      |\n    | Dense                  | 803600     | (784,)       |\n    | Activation (TanH)      | 0          | (784,)       |\n    +------------------------+------------+--------------+\n    Total Parameters: 1489936\n\n    +---------------+\n    | Discriminator |\n    +---------------+\n    Input Shape: (784,)\n    +------------------------+------------+--------------+\n    | Layer Type             | Parameters | Output Shape |\n    +------------------------+------------+--------------+\n    | Dense                  | 401920     | (512,)       |\n    | Activation (LeakyReLU) | 0          | (512,)       |\n    | Dropout                | 0          | (512,)       |\n    | Dense                  | 131328     | (256,)       |\n    | Activation (LeakyReLU) | 0          | (256,)       |\n    | Dropout                | 0          | (256,)       |\n    | Dense                  | 514        | (2,)         |\n    | Activation (Softmax)   | 0          | (2,)         |\n    +------------------------+------------+--------------+\n    Total Parameters: 533762\n\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/gan_mnist5.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Training progress of a Generative Adversarial Network generating <br>\n    handwritten digits.\n</p>\n\n### Deep Reinforcement Learning\n    $ python mlfromscratch/examples/deep_q_network.py\n\n    +----------------+\n    | Deep Q-Network |\n    +----------------+\n    Input Shape: (4,)\n    +-------------------+------------+--------------+\n    | Layer Type        | Parameters | Output Shape |\n    +-------------------+------------+--------------+\n    | Dense             | 320        | (64,)        |\n    | Activation (ReLU) | 0          | (64,)        |\n    | Dense             | 130        | (2,)         |\n    +-------------------+------------+--------------+\n    Total Parameters: 450\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_dql1.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym.\n</p>\n\n### Image Reconstruction With RBM\n    $ python mlfromscratch/examples/restricted_boltzmann_machine.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/rbm_digits1.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Shows how the network gets better during training at reconstructing <br>\n    the digit 2 in the MNIST dataset.\n</p>\n\n### Evolutionary Evolved Neural Network\n    $ python mlfromscratch/examples/neuroevolution.py\n\n    +---------------+\n    | Model Summary |\n    +---------------+\n    Input Shape: (64,)\n    +----------------------+------------+--------------+\n    | Layer Type           | Parameters | Output Shape |\n    +----------------------+------------+--------------+\n    | Dense                | 1040       | (16,)        |\n    | Activation (ReLU)    | 0          | (16,)        |\n    | Dense                | 170        | (10,)        |\n    | Activation (Softmax) | 0          | (10,)        |\n    +----------------------+------------+--------------+\n    Total Parameters: 1210\n\n    Population Size: 100\n    Generations: 3000\n    Mutation Rate: 0.01\n\n    [0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]\n    [1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]\n    ...\n    [2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]\n    Test set accuracy: 96.7%\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/evo_nn4.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Classification of the digit dataset by a neural network which has<br>\n    been evolutionary evolved.\n</p>\n\n### Genetic Algorithm\n    $ python mlfromscratch/examples/genetic_algorithm.py\n\n    +--------+\n    |   GA   |\n    +--------+\n    Description: Implementation of a Genetic Algorithm which aims to produce\n    the user specified target string. This implementation calculates each\n    candidate's fitness based on the alphabetical distance between the candidate\n    and the target. A candidate is selected as a parent with probabilities proportional\n    to the candidate's fitness. Reproduction is implemented as a single-point\n    crossover between pairs of parents. Mutation is done by randomly assigning\n    new characters with uniform probability.\n\n    Parameters\n    ----------\n    Target String: 'Genetic Algorithm'\n    Population Size: 100\n    Mutation Rate: 0.05\n\n    [0 Closest Candidate: 'CJqlJguPlqzvpoJmb', Fitness: 0.00]\n    [1 Closest Candidate: 'MCxZxdr nlfiwwGEk', Fitness: 0.01]\n    [2 Closest Candidate: 'MCxZxdm nlfiwwGcx', Fitness: 0.01]\n    [3 Closest Candidate: 'SmdsAklMHn kBIwKn', Fitness: 0.01]\n    [4 Closest Candidate: '  lotneaJOasWfu Z', Fitness: 0.01]\n    ...\n    [292 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n    [293 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n    [294 Answer: 'Genetic Algorithm']\n\n### Association Analysis\n    $ python mlfromscratch/examples/apriori.py\n    +-------------+\n    |   Apriori   |\n    +-------------+\n    Minimum Support: 0.25\n    Minimum Confidence: 0.8\n    Transactions:\n        [1, 2, 3, 4]\n        [1, 2, 4]\n        [1, 2]\n        [2, 3, 4]\n        [2, 3]\n        [3, 4]\n        [2, 4]\n    Frequent Itemsets:\n        [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]\n    Rules:\n        1 -> 2 (support: 0.43, confidence: 1.0)\n        4 -> 2 (support: 0.57, confidence: 0.8)\n        [1, 4] -> 2 (support: 0.29, confidence: 1.0)\n\n\n## Implementations\n### Supervised Learning\n- [Adaboost](mlfromscratch/supervised_learning/adaboost.py)\n- [Bayesian Regression](mlfromscratch/supervised_learning/bayesian_regression.py)\n- [Decision Tree](mlfromscratch/supervised_learning/decision_tree.py)\n- [Elastic Net](mlfromscratch/supervised_learning/regression.py)\n- [Gradient Boosting](mlfromscratch/supervised_learning/gradient_boosting.py)\n- [K Nearest Neighbors](mlfromscratch/supervised_learning/k_nearest_neighbors.py)\n- [Lasso Regression](mlfromscratch/supervised_learning/regression.py)\n- [Linear Discriminant Analysis](mlfromscratch/supervised_learning/linear_discriminant_analysis.py)\n- [Linear Regression](mlfromscratch/supervised_learning/regression.py)\n- [Logistic Regression](mlfromscratch/supervised_learning/logistic_regression.py)\n- [Multi-class Linear Discriminant Analysis](mlfromscratch/supervised_learning/multi_class_lda.py)\n- [Multilayer Perceptron](mlfromscratch/supervised_learning/multilayer_perceptron.py)\n- [Naive Bayes](mlfromscratch/supervised_learning/naive_bayes.py)\n- [Neuroevolution](mlfromscratch/supervised_learning/neuroevolution.py)\n- [Particle Swarm Optimization of Neural Network](mlfromscratch/supervised_learning/particle_swarm_optimization.py)\n- [Perceptron](mlfromscratch/supervised_learning/perceptron.py)\n- [Polynomial Regression](mlfromscratch/supervised_learning/regression.py)\n- [Random Forest](mlfromscratch/supervised_learning/random_forest.py)\n- [Ridge Regression](mlfromscratch/supervised_learning/regression.py)\n- [Support Vector Machine](mlfromscratch/supervised_learning/support_vector_machine.py)\n- [XGBoost](mlfromscratch/supervised_learning/xgboost.py)\n\n### Unsupervised Learning\n- [Apriori](mlfromscratch/unsupervised_learning/apriori.py)\n- [Autoencoder](mlfromscratch/unsupervised_learning/autoencoder.py)\n- [DBSCAN](mlfromscratch/unsupervised_learning/dbscan.py)\n- [FP-Growth](mlfromscratch/unsupervised_learning/fp_growth.py)\n- [Gaussian Mixture Model](mlfromscratch/unsupervised_learning/gaussian_mixture_model.py)\n- [Generative Adversarial Network](mlfromscratch/unsupervised_learning/generative_adversarial_network.py)\n- [Genetic Algorithm](mlfromscratch/unsupervised_learning/genetic_algorithm.py)\n- [K-Means](mlfromscratch/unsupervised_learning/k_means.py)\n- [Partitioning Around Medoids](mlfromscratch/unsupervised_learning/partitioning_around_medoids.py)\n- [Principal Component Analysis](mlfromscratch/unsupervised_learning/principal_component_analysis.py)\n- [Restricted Boltzmann Machine](mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py)\n\n### Reinforcement Learning\n- [Deep Q-Network](mlfromscratch/reinforcement_learning/deep_q_network.py)\n\n### Deep Learning\n  + [Neural Network](mlfromscratch/deep_learning/neural_network.py)\n  + [Layers](mlfromscratch/deep_learning/layers.py)\n    * Activation Layer\n    * Average Pooling Layer\n    * Batch Normalization Layer\n    * Constant Padding Layer\n    * Convolutional Layer\n    * Dropout Layer\n    * Flatten Layer\n    * Fully-Connected (Dense) Layer\n    * Fully-Connected RNN Layer\n    * Max Pooling Layer\n    * Reshape Layer\n    * Up Sampling Layer\n    * Zero Padding Layer\n  + Model Types\n    * [Convolutional Neural Network](mlfromscratch/examples/convolutional_neural_network.py)\n    * [Multilayer Perceptron](mlfromscratch/examples/multilayer_perceptron.py)\n    * [Recurrent Neural Network](mlfromscratch/examples/recurrent_neural_network.py)\n\n## Contact\nIf there's some implementation you would like to see here or if you're just feeling social,\nfeel free to [email](mailto:eriklindernoren@gmail.com) me or connect with me on [LinkedIn](https://www.linkedin.com/in/eriklindernoren/).\n"}, {"repo": "ipython/ipython", "language": "Python", "readme_contents": ".. image:: https://codecov.io/github/ipython/ipython/coverage.svg?branch=master\n    :target: https://codecov.io/github/ipython/ipython?branch=master\n\n.. image:: https://img.shields.io/pypi/v/IPython.svg\n    :target: https://pypi.python.org/pypi/ipython\n\n.. image:: https://img.shields.io/travis/ipython/ipython.svg\n    :target: https://travis-ci.org/ipython/ipython\n\n.. image:: https://www.codetriage.com/ipython/ipython/badges/users.svg\n    :target: https://www.codetriage.com/ipython/ipython/\n\n.. image:: https://raster.shields.io/badge/Follows-NEP29-brightgreen.png\n    :target: https://numpy.org/neps/nep-0029-deprecation_policy.html\n\n\n===========================================\n IPython: Productive Interactive Computing\n===========================================\n\nOverview\n========\n\nWelcome to IPython.  Our full documentation is available on `ipython.readthedocs.io\n<https://ipython.readthedocs.io/en/stable/>`_ and contains information on how to install, use, and\ncontribute to the project.\n\n**IPython versions and Python Support**\n\nStarting with IPython 7.10, IPython follows `NEP 29 <https://numpy.org/neps/nep-0029-deprecation_policy.html>`_\n\n**IPython 7.10+** requires Python version 3.6 and above.\n\n**IPython 7.0** requires Python version 3.5 and above.\n\n**IPython 6.x** requires Python version 3.3 and above.\n\n**IPython 5.x LTS** is the compatible release for Python 2.7.\nIf you require Python 2 support, you **must** use IPython 5.x LTS. Please\nupdate your project configurations and requirements as necessary.\n\n\nThe Notebook, Qt console and a number of other pieces are now parts of *Jupyter*.\nSee the `Jupyter installation docs <https://jupyter.readthedocs.io/en/latest/install.html>`__\nif you want to use these.\n\n\n\n\nDevelopment and Instant running\n===============================\n\nYou can find the latest version of the development documentation on `readthedocs\n<https://ipython.readthedocs.io/en/latest/>`_.\n\nYou can run IPython from this directory without even installing it system-wide\nby typing at the terminal::\n\n   $ python -m IPython\n\nOr see the `development installation docs\n<https://ipython.readthedocs.io/en/latest/install/install.html#installing-the-development-version>`_\nfor the latest revision on read the docs.\n\nDocumentation and installation instructions for older version of IPython can be\nfound on the `IPython website <https://ipython.org/documentation.html>`_\n\n\n\nIPython requires Python version 3 or above\n==========================================\n\nStarting with version 6.0, IPython does not support Python 2.7, 3.0, 3.1, or\n3.2.\n\nFor a version compatible with Python 2.7, please install the 5.x LTS Long Term\nSupport version.\n\nIf you are encountering this error message you are likely trying to install or\nuse IPython from source. You need to checkout the remote 5.x branch. If you are\nusing git the following should work::\n\n  $ git fetch origin\n  $ git checkout 5.x\n\nIf you encounter this error message with a regular install of IPython, then you\nlikely need to update your package manager, for example if you are using `pip`\ncheck the version of pip with::\n\n  $ pip --version\n\nYou will need to update pip to the version 9.0.1 or greater. If you are not using\npip, please inquiry with the maintainers of the package for your package\nmanager.\n\nFor more information see one of our blog posts:\n\n    https://blog.jupyter.org/release-of-ipython-5-0-8ce60b8d2e8e\n\nAs well as the following Pull-Request for discussion:\n\n    https://github.com/ipython/ipython/pull/9900\n\nThis error does also occur if you are invoking ``setup.py`` directly \u2013\u00a0which you\nshould not \u2013\u00a0or are using ``easy_install`` If this is the case, use ``pip\ninstall .`` instead of ``setup.py install`` , and ``pip install -e .`` instead\nof ``setup.py develop`` If you are depending on IPython as a dependency you may\nalso want to have a conditional dependency on IPython depending on the Python\nversion::\n\n    install_req = ['ipython']\n    if sys.version_info[0] < 3 and 'bdist_wheel' not in sys.argv:\n        install_req.remove('ipython')\n        install_req.append('ipython<6')\n\n    setup(\n        ...\n        install_requires=install_req\n    )\n\nAlternatives to IPython\n=======================\n\nIPython may not be to your taste; if that's the case there might be similar\nproject that you might want to use:\n\n- the classic Python REPL.\n- `bpython <https://bpython-interpreter.org/>`_\n- `mypython <https://www.asmeurer.com/mypython/>`_\n- `ptpython and ptipython <https://pypi.org/project/ptpython/>`\n- `xonsh <https://xon.sh/>`\n"}, {"repo": "wangshub/wechat_jump_game", "language": "Python", "readme_contents": "# \u6559\u4f60\u7528 Python \u6765\u73a9\u5fae\u4fe1\u8df3\u4e00\u8df3\n[![GitHub stars](https://img.shields.io/github/stars/wangshub/wechat_jump_game.svg)](https://github.com/wangshub/wechat_jump_game/stargazers) [![GitHub forks](https://img.shields.io/github/forks/wangshub/wechat_jump_game.svg)](https://github.com/wangshub/wechat_jump_game/network) [![GitHub license](https://img.shields.io/github/license/wangshub/wechat_jump_game.svg)](https://github.com/wangshub/wechat_jump_game/blob/master/LICENSE)\n\n[![Throughput Graph](https://graphs.waffle.io/wangshub/wechat_jump_game/throughput.svg)](https://waffle.io/wangshub/wechat_jump_game/metrics/throughput) \n\n## \u6e38\u620f\u6a21\u5f0f\n\n> 2017 \u5e74 12 \u6708 28 \u65e5\u4e0b\u5348\uff0c\u5fae\u4fe1\u53d1\u5e03\u4e86 6.6.1 \u7248\u672c\uff0c\u52a0\u5165\u4e86\u300c\u5c0f\u6e38\u620f\u300d\u529f\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b98\u65b9 DEMO\u300c\u8df3\u4e00\u8df3\u300d\u3002\u8fd9\u662f\u4e00\u4e2a 2.5D \u63d2\u753b\u98ce\u683c\u7684\u76ca\u667a\u6e38\u620f\uff0c\u73a9\u5bb6\u53ef\u4ee5\u901a\u8fc7\u6309\u538b\u5c4f\u5e55\u65f6\u95f4\u7684\u957f\u77ed\u6765\u63a7\u5236\u8fd9\u4e2a\u300c\u5c0f\u4eba\u300d\u8df3\u8dc3\u7684\u8ddd\u79bb\u3002\u5206\u6570\u8d8a\u9ad8\uff0c\u90a3\u4e48\u5728\u597d\u53cb\u6392\u884c\u699c\u66f4\u52a0\u9760\u524d\u3002\u901a\u8fc7 Python \u811a\u672c\u81ea\u52a8\u8fd0\u884c\uff0c\u8ba9\u4f60\u8f7b\u677e\u9738\u699c\u3002\n\n![](./resource/image/jump.gif)\n\n\u53ef\u80fd\u521a\u5f00\u59cb\u4e0a\u624b\u7684\u65f6\u5019\uff0c\u56e0\u4e3a\u65f6\u95f4\u8ddd\u79bb\u4e4b\u95f4\u7684\u5173\u7cfb\u628a\u63e1\u4e0d\u6070\u5f53\uff0c\u53ea\u80fd\u8df3\u51fa\u51e0\u4e2a\u5c31\u6389\u5230\u4e86\u53f0\u5b50\u4e0b\u9762\u3002**\u5982\u679c\u80fd\u5229\u7528\u56fe\u50cf\u8bc6\u522b\u7cbe\u786e\u6d4b\u91cf\u51fa\u8d77\u59cb\u548c\u76ee\u6807\u70b9\u4e4b\u95f4\u6d4b\u8ddd\u79bb\uff0c\u5c31\u53ef\u4ee5\u4f30\u8ba1\u6309\u538b\u7684\u65f6\u95f4\u6765\u7cbe\u786e\u8df3\u8dc3\u3002**\n\n## \u539f\u7406\u8bf4\u660e\n\n##### \u7531\u4e8e\u5fae\u4fe1\u68c0\u6d4b\u975e\u5e38\u4e25\u5389\uff0c\u8fd9\u91cc\u7684\u9632\u7981\u4ee3\u7801\u53ef\u80fd\u5df2\u7ecf\u4e0d\u8d77\u4f5c\u7528\uff0c\u4e3b\u8981\u4f9b\u5b66\u4e60\u7528\u9014\n\n1. \u5c06\u624b\u673a\u70b9\u51fb\u5230\u300a\u8df3\u4e00\u8df3\u300b\u5c0f\u7a0b\u5e8f\u754c\u9762\n\n2. \u7528 ADB \u5de5\u5177\u83b7\u53d6\u5f53\u524d\u624b\u673a\u622a\u56fe\uff0c\u5e76\u7528 ADB \u5c06\u622a\u56fe pull \u4e0a\u6765\n```shell\nadb shell screencap -p /sdcard/autojump.png\nadb pull /sdcard/autojump.png .\n```\n\n3. \u8ba1\u7b97\u6309\u538b\u65f6\u95f4\n  * \u624b\u52a8\u7248\uff1a\u7528 Matplotlib \u663e\u793a\u622a\u56fe\uff0c\u7528\u9f20\u6807\u5148\u70b9\u51fb\u8d77\u59cb\u70b9\u4f4d\u7f6e\uff0c\u7136\u540e\u70b9\u51fb\u76ee\u6807\u4f4d\u7f6e\uff0c\u8ba1\u7b97\u50cf\u7d20\u8ddd\u79bb\uff1b\n  * \u81ea\u52a8\u7248\uff1a\u9760\u68cb\u5b50\u7684\u989c\u8272\u6765\u8bc6\u522b\u68cb\u5b50\uff0c\u9760\u5e95\u8272\u548c\u65b9\u5757\u7684\u8272\u5dee\u6765\u8bc6\u522b\u68cb\u76d8\uff1b\n\n4. \u7528 ADB \u5de5\u5177\u70b9\u51fb\u5c4f\u5e55\u84c4\u529b\u4e00\u8df3\n```shell\nadb shell input swipe x y x y time(ms)\n```\n\n\n\n## \u4f7f\u7528\u6559\u7a0b\n\n\u76f8\u5173\u8f6f\u4ef6\u5de5\u5177\u5b89\u88c5\u548c\u4f7f\u7528\u6b65\u9aa4\u8bf7\u53c2\u8003 [Android \u548c iOS \u64cd\u4f5c\u6b65\u9aa4](https://github.com/wangshub/wechat_jump_game/wiki/Android-%E5%92%8C-iOS-%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4)\n\n#### \u83b7\u53d6\u6e90\u7801\n\n```\n- git clone https://github.com/wangshub/wechat_jump_game.git\n\n```\n##### \u975e\u5e38\u63a8\u8350\u4f7f\u7528Python3\uff0c\u907f\u514d\u7f16\u7801\u53caimport\u95ee\u9898\n## PR \u8981\u6c42\n##### \u8bf7\u9009\u62e9 merge \u8fdb master \u5206\u652f\uff0c\u5e76\u4e14\u6807\u9898\u5199\u4e0a\u7b80\u77ed\u63cf\u8ff0\uff0c\u4f8b\u5b50 \n[\u4f18\u5316] \u4f7f\u7528PEP8\u4f18\u5316\u4ee3\u7801\n\n## \u7248\u672c\u8bf4\u660e\n\n- master \u5206\u652f\uff1a\u7a33\u5b9a\u7248\u672c\uff0c\u5df2\u901a\u8fc7\u6d4b\u8bd5\n- dev \u5206\u652f\uff1a\u5f00\u53d1\u7248\u672c\uff0c\u5305\u542b\u4e00\u4e9b\u8f83\u7a33\u5b9a\u7684\u65b0\u529f\u80fd\uff0c\u7d2f\u8ba1\u591a\u4e2a\u529f\u80fd\u5e76\u6d4b\u8bd5\u901a\u8fc7\u540e\u5408\u5e76\u81f3 prod \u5206\u652f\n- \u5176\u4ed6\u5206\u652f\uff1a\u529f\u80fd\u5f00\u53d1 (feature) \u6216\u95ee\u9898\u4fee\u590d (bugfix)\uff0c\u5c5e\u4e8e\u6700\u65b0\u5c1d\u9c9c\u7248\u672c\uff0c\u53ef\u80fd\u5904\u4e8e\u5f00\u53d1\u4e2d\u7684\u72b6\u6001\uff0c\u57fa\u672c\u5b8c\u6210\u540e\u5408\u5e76\u81f3 dev \u5206\u652f\n\n## FAQ\n\n- \u8be6\u89c1 [Wiki-FAQ](https://github.com/wangshub/wechat_jump_game/wiki/FAQ)\n\n## \u66f4\u65b0\u65e5\u5fd7\n\n- \u8be6\u89c1 [changelog](https://github.com/wangshub/wechat_jump_game/blob/master/changelog.md)\n\n## \u5f00\u53d1\u8005\u5217\u8868\n\n- \u8be6\u89c1 [contributors](https://github.com/wangshub/wechat_jump_game/graphs/contributors)\n\n## \u4ea4\u6d41\n\n- 314659953 (1000 \u4eba)\n- 176740763 (500 \u4eba)\n\n- \u6216\u8005\u5173\u6ce8\u6211\u7684\u5fae\u4fe1\u516c\u4f17\u53f7\u540e\u53f0\u7559\u8a00\n\n![](./resource/image/qrcode_for_gh_3586401957c4_258.jpg)\n\n"}, {"repo": "binux/pyspider", "language": "Python", "readme_contents": "pyspider [![Build Status]][Travis CI] [![Coverage Status]][Coverage] [![Try]][Demo]\n========\n\nA Powerful Spider(Web Crawler) System in Python. **[TRY IT NOW!][Demo]**\n\n- Write script in Python\n- Powerful WebUI with script editor, task monitor, project manager and result viewer\n- [MySQL](https://www.mysql.com/), [CouchDB](https://couchdb.apache.org), [MongoDB](https://www.mongodb.org/), [Redis](http://redis.io/), [SQLite](https://www.sqlite.org/), [Elasticsearch](https://www.elastic.co/products/elasticsearch); [PostgreSQL](http://www.postgresql.org/) with [SQLAlchemy](http://www.sqlalchemy.org/) as database backend\n- [RabbitMQ](http://www.rabbitmq.com/), [Redis](http://redis.io/) and [Kombu](http://kombu.readthedocs.org/) as message queue\n- Task priority, retry, periodical, recrawl by age, etc...\n- Distributed architecture, Crawl Javascript pages, Python 2.{6,7}, 3.{3,4,5,6} support, etc...\n\nTutorial: [http://docs.pyspider.org/en/latest/tutorial/](http://docs.pyspider.org/en/latest/tutorial/)  \nDocumentation: [http://docs.pyspider.org/](http://docs.pyspider.org/)  \nRelease notes: [https://github.com/binux/pyspider/releases](https://github.com/binux/pyspider/releases)  \n\nSample Code \n-----------\n\n```python\nfrom pyspider.libs.base_handler import *\n\n\nclass Handler(BaseHandler):\n    crawl_config = {\n    }\n\n    @every(minutes=24 * 60)\n    def on_start(self):\n        self.crawl('http://scrapy.org/', callback=self.index_page)\n\n    @config(age=10 * 24 * 60 * 60)\n    def index_page(self, response):\n        for each in response.doc('a[href^=\"http\"]').items():\n            self.crawl(each.attr.href, callback=self.detail_page)\n\n    def detail_page(self, response):\n        return {\n            \"url\": response.url,\n            \"title\": response.doc('title').text(),\n        }\n```\n\n[![Demo][Demo Img]][Demo]\n\n\nInstallation\n------------\n\n* `pip install pyspider`\n* run command `pyspider`, visit [http://localhost:5000/](http://localhost:5000/)\n\n**WARNING:** WebUI is open to the public by default, it can be used to execute any command which may harm your system. Please use it in an internal network or [enable `need-auth` for webui](http://docs.pyspider.org/en/latest/Command-Line/#-config).\n\nQuickstart: [http://docs.pyspider.org/en/latest/Quickstart/](http://docs.pyspider.org/en/latest/Quickstart/)\n\nContribute\n----------\n\n* Use It\n* Open [Issue], send PR\n* [User Group]\n* [\u4e2d\u6587\u95ee\u7b54](http://segmentfault.com/t/pyspider)\n\n\nTODO\n----\n\n### v0.4.0\n\n- [ ] a visual scraping interface like [portia](https://github.com/scrapinghub/portia)\n\n\nLicense\n-------\nLicensed under the Apache License, Version 2.0\n\n\n[Build Status]:         https://img.shields.io/travis/binux/pyspider/master.svg?style=flat\n[Travis CI]:            https://travis-ci.org/binux/pyspider\n[Coverage Status]:      https://img.shields.io/coveralls/binux/pyspider.svg?branch=master&style=flat\n[Coverage]:             https://coveralls.io/r/binux/pyspider\n[Try]:                  https://img.shields.io/badge/try-pyspider-blue.svg?style=flat\n[Demo]:                 http://demo.pyspider.org/\n[Demo Img]:             https://github.com/binux/pyspider/blob/master/docs/imgs/demo.png\n[Issue]:                https://github.com/binux/pyspider/issues\n[User Group]:           https://groups.google.com/group/pyspider-users\n"}, {"repo": "psf/black", "language": "Python", "readme_contents": "![Black Logo](https://raw.githubusercontent.com/psf/black/master/docs/_static/logo2-readme.png)\n\n<h2 align=\"center\">The Uncompromising Code Formatter</h2>\n\n<p align=\"center\">\n<a href=\"https://travis-ci.com/psf/black\"><img alt=\"Build Status\" src=\"https://travis-ci.com/psf/black.svg?branch=master\"></a>\n<a href=\"https://github.com/psf/black/actions\"><img alt=\"Actions Status\" src=\"https://github.com/psf/black/workflows/Test/badge.svg\"></a>\n<a href=\"https://black.readthedocs.io/en/stable/?badge=stable\"><img alt=\"Documentation Status\" src=\"https://readthedocs.org/projects/black/badge/?version=stable\"></a>\n<a href=\"https://coveralls.io/github/psf/black?branch=master\"><img alt=\"Coverage Status\" src=\"https://coveralls.io/repos/github/psf/black/badge.svg?branch=master\"></a>\n<a href=\"https://github.com/psf/black/blob/master/LICENSE\"><img alt=\"License: MIT\" src=\"https://black.readthedocs.io/en/stable/_static/license.svg\"></a>\n<a href=\"https://pypi.org/project/black/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/black\"></a>\n<a href=\"https://pepy.tech/project/black\"><img alt=\"Downloads\" src=\"https://pepy.tech/badge/black\"></a>\n<a href=\"https://github.com/psf/black\"><img alt=\"Code style: black\" src=\"https://img.shields.io/badge/code%20style-black-000000.svg\"></a>\n</p>\n\n> \u201cAny color you like.\u201d\n\n_Black_ is the uncompromising Python code formatter. By using it, you agree to cede\ncontrol over minutiae of hand-formatting. In return, _Black_ gives you speed,\ndeterminism, and freedom from `pycodestyle` nagging about formatting. You will save time\nand mental energy for more important matters.\n\nBlackened code looks the same regardless of the project you're reading. Formatting\nbecomes transparent after a while and you can focus on the content instead.\n\n_Black_ makes code review faster by producing the smallest diffs possible.\n\nTry it out now using the [Black Playground](https://black.now.sh). Watch the\n[PyCon 2019 talk](https://youtu.be/esZLCuWs_2Y) to learn more.\n\n---\n\n_Contents:_ **[Installation and usage](#installation-and-usage)** |\n**[Code style](#the-black-code-style)** | **[pyproject.toml](#pyprojecttoml)** |\n**[Editor integration](#editor-integration)** | **[blackd](#blackd)** |\n**[Version control integration](#version-control-integration)** |\n**[Ignoring unmodified files](#ignoring-unmodified-files)** | **[Used by](#used-by)** |\n**[Testimonials](#testimonials)** | **[Show your style](#show-your-style)** |\n**[Contributing](#contributing-to-black)** | **[Change Log](#change-log)** |\n**[Authors](#authors)**\n\n---\n\n## Installation and usage\n\n### Installation\n\n_Black_ can be installed by running `pip install black`. It requires Python 3.6.0+ to\nrun but you can reformat Python 2 code with it, too.\n\n### Usage\n\nTo get started right away with sensible defaults:\n\n```\nblack {source_file_or_directory}\n```\n\n### Command line options\n\n_Black_ doesn't provide many options. You can list them by running `black --help`:\n\n```text\nblack [OPTIONS] [SRC]...\n\nOptions:\n  -c, --code TEXT                 Format the code passed in as a string.\n  -l, --line-length INTEGER       How many characters per line to allow.\n                                  [default: 88]\n  -t, --target-version [py27|py33|py34|py35|py36|py37|py38]\n                                  Python versions that should be supported by\n                                  Black's output. [default: per-file auto-\n                                  detection]\n  --py36                          Allow using Python 3.6-only syntax on all\n                                  input files.  This will put trailing commas\n                                  in function signatures and calls also after\n                                  *args and **kwargs. Deprecated; use\n                                  --target-version instead. [default: per-file\n                                  auto-detection]\n  --pyi                           Format all input files like typing stubs\n                                  regardless of file extension (useful when\n                                  piping source on standard input).\n  -S, --skip-string-normalization\n                                  Don't normalize string quotes or prefixes.\n  --check                         Don't write the files back, just return the\n                                  status.  Return code 0 means nothing would\n                                  change.  Return code 1 means some files\n                                  would be reformatted.  Return code 123 means\n                                  there was an internal error.\n  --diff                          Don't write the files back, just output a\n                                  diff for each file on stdout.\n  --fast / --safe                 If --fast given, skip temporary sanity\n                                  checks. [default: --safe]\n  --include TEXT                  A regular expression that matches files and\n                                  directories that should be included on\n                                  recursive searches.  An empty value means\n                                  all files are included regardless of the\n                                  name.  Use forward slashes for directories\n                                  on all platforms (Windows, too).  Exclusions\n                                  are calculated first, inclusions later.\n                                  [default: \\.pyi?$]\n  --exclude TEXT                  A regular expression that matches files and\n                                  directories that should be excluded on\n                                  recursive searches.  An empty value means no\n                                  paths are excluded. Use forward slashes for\n                                  directories on all platforms (Windows, too).\n                                  Exclusions are calculated first, inclusions\n                                  later.  [default: /(\\.eggs|\\.git|\\.hg|\\.mypy\n                                  _cache|\\.nox|\\.tox|\\.venv|_build|buck-\n                                  out|build|dist)/]\n  -q, --quiet                     Don't emit non-error messages to stderr.\n                                  Errors are still emitted, silence those with\n                                  2>/dev/null.\n  -v, --verbose                   Also emit messages to stderr about files\n                                  that were not changed or were ignored due to\n                                  --exclude=.\n  --version                       Show the version and exit.\n  --config PATH                   Read configuration from PATH.\n  -h, --help                      Show this message and exit.\n```\n\n_Black_ is a well-behaved Unix-style command-line tool:\n\n- it does nothing if no sources are passed to it;\n- it will read from standard input and write to standard output if `-` is used as the\n  filename;\n- it only outputs messages to users on standard error;\n- exits with code 0 unless an internal error occurred (or `--check` was used).\n\n### NOTE: This is a beta product\n\n_Black_ is already [successfully used](#used-by) by many projects, small and big. It\nalso sports a decent test suite. However, it is still very new. Things will probably be\nwonky for a while. This is made explicit by the \"Beta\" trove classifier, as well as by\nthe \"b\" in the version number. What this means for you is that **until the formatter\nbecomes stable, you should expect some formatting to change in the future**. That being\nsaid, no drastic stylistic changes are planned, mostly responses to bug reports.\n\nAlso, as a temporary safety measure, _Black_ will check that the reformatted code still\nproduces a valid AST that is equivalent to the original. This slows it down. If you're\nfeeling confident, use `--fast`.\n\n## The _Black_ code style\n\n_Black_ reformats entire files in place. It is not configurable. It doesn't take\nprevious formatting into account. It doesn't reformat blocks that start with\n`# fmt: off` and end with `# fmt: on`. `# fmt: on/off` have to be on the same level of\nindentation. It also recognizes [YAPF](https://github.com/google/yapf)'s block comments\nto the same effect, as a courtesy for straddling code.\n\n### How _Black_ wraps lines\n\n_Black_ ignores previous formatting and applies uniform horizontal and vertical\nwhitespace to your code. The rules for horizontal whitespace can be summarized as: do\nwhatever makes `pycodestyle` happy. The coding style used by _Black_ can be viewed as a\nstrict subset of PEP 8.\n\nAs for vertical whitespace, _Black_ tries to render one full expression or simple\nstatement per line. If this fits the allotted line length, great.\n\n```py3\n# in:\n\nj = [1,\n     2,\n     3\n]\n\n# out:\n\nj = [1, 2, 3]\n```\n\nIf not, _Black_ will look at the contents of the first outer matching brackets and put\nthat in a separate indented line.\n\n```py3\n# in:\n\nImportantClass.important_method(exc, limit, lookup_lines, capture_locals, extra_argument)\n\n# out:\n\nImportantClass.important_method(\n    exc, limit, lookup_lines, capture_locals, extra_argument\n)\n```\n\nIf that still doesn't fit the bill, it will decompose the internal expression further\nusing the same rule, indenting matching brackets every time. If the contents of the\nmatching brackets pair are comma-separated (like an argument list, or a dict literal,\nand so on) then _Black_ will first try to keep them on the same line with the matching\nbrackets. If that doesn't work, it will put all of them in separate lines.\n\n```py3\n# in:\n\ndef very_important_function(template: str, *variables, file: os.PathLike, engine: str, header: bool = True, debug: bool = False):\n    \"\"\"Applies `variables` to the `template` and writes to `file`.\"\"\"\n    with open(file, 'w') as f:\n        ...\n\n# out:\n\ndef very_important_function(\n    template: str,\n    *variables,\n    file: os.PathLike,\n    engine: str,\n    header: bool = True,\n    debug: bool = False,\n):\n    \"\"\"Applies `variables` to the `template` and writes to `file`.\"\"\"\n    with open(file, \"w\") as f:\n        ...\n```\n\nYou might have noticed that closing brackets are always dedented and that a trailing\ncomma is always added. Such formatting produces smaller diffs; when you add or remove an\nelement, it's always just one line. Also, having the closing bracket dedented provides a\nclear delimiter between two distinct sections of the code that otherwise share the same\nindentation level (like the arguments list and the docstring in the example above).\n\nIf a data structure literal (tuple, list, set, dict) or a line of \"from\" imports cannot\nfit in the allotted length, it's always split into one element per line. This minimizes\ndiffs as well as enables readers of code to find which commit introduced a particular\nentry. This also makes _Black_ compatible with [isort](https://pypi.org/p/isort/) with\nthe following configuration.\n\n<details>\n<summary>A compatible `.isort.cfg`</summary>\n\n```\n[settings]\nmulti_line_output=3\ninclude_trailing_comma=True\nforce_grid_wrap=0\nuse_parentheses=True\nline_length=88\n```\n\nThe equivalent command line is:\n\n```\n$ isort --multi-line=3 --trailing-comma --force-grid-wrap=0 --use-parentheses --line-width=88 [ file.py ]\n```\n\n</details>\n\n### Line length\n\nYou probably noticed the peculiar default line length. _Black_ defaults to 88 characters\nper line, which happens to be 10% over 80. This number was found to produce\nsignificantly shorter files than sticking with 80 (the most popular), or even 79 (used\nby the standard library). In general,\n[90-ish seems like the wise choice](https://youtu.be/wf-BqAjZb8M?t=260).\n\nIf you're paid by the line of code you write, you can pass `--line-length` with a lower\nnumber. _Black_ will try to respect that. However, sometimes it won't be able to without\nbreaking other rules. In those rare cases, auto-formatted code will exceed your allotted\nlimit.\n\nYou can also increase it, but remember that people with sight disabilities find it\nharder to work with line lengths exceeding 100 characters. It also adversely affects\nside-by-side diff review on typical screen resolutions. Long lines also make it harder\nto present code neatly in documentation or talk slides.\n\nIf you're using Flake8, you can bump `max-line-length` to 88 and forget about it.\nAlternatively, use [Bugbear](https://github.com/PyCQA/flake8-bugbear)'s B950 warning\ninstead of E501 and keep the max line length at 80 which you are probably already using.\nYou'd do it like this:\n\n```ini\n[flake8]\nmax-line-length = 80\n...\nselect = C,E,F,W,B,B950\nignore = E203, E501, W503\n```\n\nYou'll find _Black_'s own .flake8 config file is configured like this. Explanation of\nwhy W503 and E203 are disabled can be found further in this documentation. And if you're\ncurious about the reasoning behind B950,\n[Bugbear's documentation](https://github.com/PyCQA/flake8-bugbear#opinionated-warnings)\nexplains it. The tl;dr is \"it's like highway speed limits, we won't bother you if you\noverdo it by a few km/h\".\n\n**If you're looking for a minimal, black-compatible flake8 configuration:**\n\n```ini\n[flake8]\nmax-line-length = 88\nextend-ignore = E203\n```\n\n### Empty lines\n\n_Black_ avoids spurious vertical whitespace. This is in the spirit of PEP 8 which says\nthat in-function vertical whitespace should only be used sparingly.\n\n_Black_ will allow single empty lines inside functions, and single and double empty\nlines on module level left by the original editors, except when they're within\nparenthesized expressions. Since such expressions are always reformatted to fit minimal\nspace, this whitespace is lost.\n\nIt will also insert proper spacing before and after function definitions. It's one line\nbefore and after inner functions and two lines before and after module-level functions\nand classes. _Black_ will not put empty lines between function/class definitions and\nstandalone comments that immediately precede the given function/class.\n\n_Black_ will enforce single empty lines between a class-level docstring and the first\nfollowing field or method. This conforms to\n[PEP 257](https://www.python.org/dev/peps/pep-0257/#multi-line-docstrings).\n\n_Black_ won't insert empty lines after function docstrings unless that empty line is\nrequired due to an inner function starting immediately after.\n\n### Trailing commas\n\n_Black_ will add trailing commas to expressions that are split by comma where each\nelement is on its own line. This includes function signatures.\n\nUnnecessary trailing commas are removed if an expression fits in one line. This makes it\n1% more likely that your line won't exceed the allotted line length limit. Moreover, in\nthis scenario, if you added another argument to your call, you'd probably fit it in the\nsame line anyway. That doesn't make diffs any larger.\n\nOne exception to removing trailing commas is tuple expressions with just one element. In\nthis case _Black_ won't touch the single trailing comma as this would unexpectedly\nchange the underlying data type. Note that this is also the case when commas are used\nwhile indexing. This is a tuple in disguise: `numpy_array[3, ]`.\n\nOne exception to adding trailing commas is function signatures containing `*`, `*args`,\nor `**kwargs`. In this case a trailing comma is only safe to use on Python 3.6. _Black_\nwill detect if your file is already 3.6+ only and use trailing commas in this situation.\nIf you wonder how it knows, it looks for f-strings and existing use of trailing commas\nin function signatures that have stars in them. In other words, if you'd like a trailing\ncomma in this situation and _Black_ didn't recognize it was safe to do so, put it there\nmanually and _Black_ will keep it.\n\n### Strings\n\n_Black_ prefers double quotes (`\"` and `\"\"\"`) over single quotes (`'` and `'''`). It\nwill replace the latter with the former as long as it does not result in more backslash\nescapes than before.\n\n_Black_ also standardizes string prefixes, making them always lowercase. On top of that,\nif your code is already Python 3.6+ only or it's using the `unicode_literals` future\nimport, _Black_ will remove `u` from the string prefix as it is meaningless in those\nscenarios.\n\nThe main reason to standardize on a single form of quotes is aesthetics. Having one kind\nof quotes everywhere reduces reader distraction. It will also enable a future version of\n_Black_ to merge consecutive string literals that ended up on the same line (see\n[#26](https://github.com/psf/black/issues/26) for details).\n\nWhy settle on double quotes? They anticipate apostrophes in English text. They match the\ndocstring standard described in\n[PEP 257](https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring). An empty\nstring in double quotes (`\"\"`) is impossible to confuse with a one double-quote\nregardless of fonts and syntax highlighting used. On top of this, double quotes for\nstrings are consistent with C which Python interacts a lot with.\n\nOn certain keyboard layouts like US English, typing single quotes is a bit easier than\ndouble quotes. The latter requires use of the Shift key. My recommendation here is to\nkeep using whatever is faster to type and let _Black_ handle the transformation.\n\nIf you are adopting _Black_ in a large project with pre-existing string conventions\n(like the popular\n[\"single quotes for data, double quotes for human-readable strings\"](https://stackoverflow.com/a/56190)),\nyou can pass `--skip-string-normalization` on the command line. This is meant as an\nadoption helper, avoid using this for new projects.\n\n### Numeric literals\n\n_Black_ standardizes most numeric literals to use lowercase letters for the syntactic\nparts and uppercase letters for the digits themselves: `0xAB` instead of `0XAB` and\n`1e10` instead of `1E10`. Python 2 long literals are styled as `2L` instead of `2l` to\navoid confusion between `l` and `1`.\n\n### Line breaks & binary operators\n\n_Black_ will break a line before a binary operator when splitting a block of code over\nmultiple lines. This is so that _Black_ is compliant with the recent changes in the\n[PEP 8](https://www.python.org/dev/peps/pep-0008/#should-a-line-break-before-or-after-a-binary-operator)\nstyle guide, which emphasizes that this approach improves readability.\n\nThis behaviour may raise `W503 line break before binary operator` warnings in style\nguide enforcement tools like Flake8. Since `W503` is not PEP 8 compliant, you should\ntell Flake8 to ignore these warnings.\n\n### Slices\n\nPEP 8\n[recommends](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements)\nto treat `:` in slices as a binary operator with the lowest priority, and to leave an\nequal amount of space on either side, except if a parameter is omitted (e.g.\n`ham[1 + 1 :]`). It also states that for extended slices, both `:` operators have to\nhave the same amount of spacing, except if a parameter is omitted (`ham[1 + 1 ::]`).\n_Black_ enforces these rules consistently.\n\nThis behaviour may raise `E203 whitespace before ':'` warnings in style guide\nenforcement tools like Flake8. Since `E203` is not PEP 8 compliant, you should tell\nFlake8 to ignore these warnings.\n\n### Parentheses\n\nSome parentheses are optional in the Python grammar. Any expression can be wrapped in a\npair of parentheses to form an atom. There are a few interesting cases:\n\n- `if (...):`\n- `while (...):`\n- `for (...) in (...):`\n- `assert (...), (...)`\n- `from X import (...)`\n- assignments like:\n  - `target = (...)`\n  - `target: type = (...)`\n  - `some, *un, packing = (...)`\n  - `augmented += (...)`\n\nIn those cases, parentheses are removed when the entire statement fits in one line, or\nif the inner expression doesn't have any delimiters to further split on. If there is\nonly a single delimiter and the expression starts or ends with a bracket, the\nparenthesis can also be successfully omitted since the existing bracket pair will\norganize the expression neatly anyway. Otherwise, the parentheses are added.\n\nPlease note that _Black_ does not add or remove any additional nested parentheses that\nyou might want to have for clarity or further code organization. For example those\nparentheses are not going to be removed:\n\n```py3\nreturn not (this or that)\ndecision = (maybe.this() and values > 0) or (maybe.that() and values < 0)\n```\n\n### Call chains\n\nSome popular APIs, like ORMs, use call chaining. This API style is known as a\n[fluent interface](https://en.wikipedia.org/wiki/Fluent_interface). _Black_ formats\nthose by treating dots that follow a call or an indexing operation like a very low\npriority delimiter. It's easier to show the behavior than to explain it. Look at the\nexample:\n\n```py3\ndef example(session):\n    result = (\n        session.query(models.Customer.id)\n        .filter(\n            models.Customer.account_id == account_id,\n            models.Customer.email == email_address,\n        )\n        .order_by(models.Customer.id.asc())\n        .all()\n    )\n```\n\n### Typing stub files\n\nPEP 484 describes the syntax for type hints in Python. One of the use cases for typing\nis providing type annotations for modules which cannot contain them directly (they might\nbe written in C, or they might be third-party, or their implementation may be overly\ndynamic, and so on).\n\nTo solve this,\n[stub files with the `.pyi` file extension](https://www.python.org/dev/peps/pep-0484/#stub-files)\ncan be used to describe typing information for an external module. Those stub files omit\nthe implementation of classes and functions they describe, instead they only contain the\nstructure of the file (listing globals, functions, and classes with their members). The\nrecommended code style for those files is more terse than PEP 8:\n\n- prefer `...` on the same line as the class/function signature;\n- avoid vertical whitespace between consecutive module-level functions, names, or\n  methods and fields within a single class;\n- use a single blank line between top-level class definitions, or none if the classes\n  are very small.\n\n_Black_ enforces the above rules. There are additional guidelines for formatting `.pyi`\nfile that are not enforced yet but might be in a future version of the formatter:\n\n- all function bodies should be empty (contain `...` instead of the body);\n- do not use docstrings;\n- prefer `...` over `pass`;\n- for arguments with a default, use `...` instead of the actual default;\n- avoid using string literals in type annotations, stub files support forward references\n  natively (like Python 3.7 code with `from __future__ import annotations`);\n- use variable annotations instead of type comments, even for stubs that target older\n  versions of Python;\n- for arguments that default to `None`, use `Optional[]` explicitly;\n- use `float` instead of `Union[int, float]`.\n\n## pyproject.toml\n\n_Black_ is able to read project-specific default values for its command line options\nfrom a `pyproject.toml` file. This is especially useful for specifying custom\n`--include` and `--exclude` patterns for your project.\n\n**Pro-tip**: If you're asking yourself \"Do I need to configure anything?\" the answer is\n\"No\". _Black_ is all about sensible defaults.\n\n### What on Earth is a `pyproject.toml` file?\n\n[PEP 518](https://www.python.org/dev/peps/pep-0518/) defines `pyproject.toml` as a\nconfiguration file to store build system requirements for Python projects. With the help\nof tools like [Poetry](https://poetry.eustace.io/) or\n[Flit](https://flit.readthedocs.io/en/latest/) it can fully replace the need for\n`setup.py` and `setup.cfg` files.\n\n### Where _Black_ looks for the file\n\nBy default _Black_ looks for `pyproject.toml` starting from the common base directory of\nall files and directories passed on the command line. If it's not there, it looks in\nparent directories. It stops looking when it finds the file, or a `.git` directory, or a\n`.hg` directory, or the root of the file system, whichever comes first.\n\nIf you're formatting standard input, _Black_ will look for configuration starting from\nthe current working directory.\n\nYou can also explicitly specify the path to a particular file that you want with\n`--config`. In this situation _Black_ will not look for any other file.\n\nIf you're running with `--verbose`, you will see a blue message if a file was found and\nused.\n\nPlease note `blackd` will not use `pyproject.toml` configuration.\n\n### Configuration format\n\nAs the file extension suggests, `pyproject.toml` is a\n[TOML](https://github.com/toml-lang/toml) file. It contains separate sections for\ndifferent tools. _Black_ is using the `[tool.black]` section. The option keys are the\nsame as long names of options on the command line.\n\nNote that you have to use single-quoted strings in TOML for regular expressions. It's\nthe equivalent of r-strings in Python. Multiline strings are treated as verbose regular\nexpressions by Black. Use `[ ]` to denote a significant space character.\n\n<details>\n<summary>Example `pyproject.toml`</summary>\n\n```toml\n[tool.black]\nline-length = 88\ntarget-version = ['py37']\ninclude = '\\.pyi?$'\nexclude = '''\n\n(\n  /(\n      \\.eggs         # exclude a few common directories in the\n    | \\.git          # root of the project\n    | \\.hg\n    | \\.mypy_cache\n    | \\.tox\n    | \\.venv\n    | _build\n    | buck-out\n    | build\n    | dist\n  )/\n  | foo.py           # also separately exclude a file named foo.py in\n                     # the root of the project\n)\n'''\n```\n\n</details>\n\n### Lookup hierarchy\n\nCommand-line options have defaults that you can see in `--help`. A `pyproject.toml` can\noverride those defaults. Finally, options provided by the user on the command line\noverride both.\n\n_Black_ will only ever use one `pyproject.toml` file during an entire run. It doesn't\nlook for multiple files, and doesn't compose configuration from different levels of the\nfile hierarchy.\n\n## Editor integration\n\n### Emacs\n\nUse [proofit404/blacken](https://github.com/proofit404/blacken) or\n[Elpy](https://github.com/jorgenschaefer/elpy).\n\n### PyCharm/IntelliJ IDEA\n\n1. Install `black`.\n\n```console\n$ pip install black\n```\n\n2. Locate your `black` installation folder.\n\nOn macOS / Linux / BSD:\n\n```console\n$ which black\n/usr/local/bin/black  # possible location\n```\n\nOn Windows:\n\n```console\n$ where black\n%LocalAppData%\\Programs\\Python\\Python36-32\\Scripts\\black.exe  # possible location\n```\n\n3. Open External tools in PyCharm/IntelliJ IDEA\n\nOn macOS:\n\n`PyCharm -> Preferences -> Tools -> External Tools`\n\nOn Windows / Linux / BSD:\n\n`File -> Settings -> Tools -> External Tools`\n\n4. Click the + icon to add a new external tool with the following values:\n\n   - Name: Black\n   - Description: Black is the uncompromising Python code formatter.\n   - Program: <install_location_from_step_2>\n   - Arguments: `\"$FilePath$\"`\n\n5. Format the currently opened file by selecting `Tools -> External Tools -> black`.\n\n   - Alternatively, you can set a keyboard shortcut by navigating to\n     `Preferences or Settings -> Keymap -> External Tools -> External Tools - Black`.\n\n6. Optionally, run _Black_ on every file save:\n\n   1. Make sure you have the\n      [File Watcher](https://plugins.jetbrains.com/plugin/7177-file-watchers) plugin\n      installed.\n   2. Go to `Preferences or Settings -> Tools -> File Watchers` and click `+` to add a\n      new watcher:\n      - Name: Black\n      - File type: Python\n      - Scope: Project Files\n      - Program: <install_location_from_step_2>\n      - Arguments: `$FilePath$`\n      - Output paths to refresh: `$FilePath$`\n      - Working directory: `$ProjectFileDir$`\n\n   - Uncheck \"Auto-save edited files to trigger the watcher\"\n\n### Wing IDE\n\nWing supports black via the OS Commands tool, as explained in the Wing documentation on\n[pep8 formatting](https://wingware.com/doc/edit/pep8). The detailed procedure is:\n\n1. Install `black`.\n\n```console\n$ pip install black\n```\n\n2. Make sure it runs from the command line, e.g.\n\n```console\n$ black --help\n```\n\n3. In Wing IDE, activate the **OS Commands** panel and define the command **black** to\n   execute black on the currently selected file:\n\n- Use the Tools -> OS Commands menu selection\n- click on **+** in **OS Commands** -> New: Command line..\n  - Title: black\n  - Command Line: black %s\n  - I/O Encoding: Use Default\n  - Key Binding: F1\n  - [x] Raise OS Commands when executed\n  - [x] Auto-save files before execution\n  - [x] Line mode\n\n4. Select a file in the editor and press **F1** , or whatever key binding you selected\n   in step 3, to reformat the file.\n\n### Vim\n\nCommands and shortcuts:\n\n- `:Black` to format the entire file (ranges not supported);\n- `:BlackUpgrade` to upgrade _Black_ inside the virtualenv;\n- `:BlackVersion` to get the current version of _Black_ inside the virtualenv.\n\nConfiguration:\n\n- `g:black_fast` (defaults to `0`)\n- `g:black_linelength` (defaults to `88`)\n- `g:black_skip_string_normalization` (defaults to `0`)\n- `g:black_virtualenv` (defaults to `~/.vim/black` or `~/.local/share/nvim/black`)\n\nTo install with [vim-plug](https://github.com/junegunn/vim-plug):\n\n```\nPlug 'psf/black'\n```\n\nor with [Vundle](https://github.com/VundleVim/Vundle.vim):\n\n```\nPlugin 'psf/black'\n```\n\nor you can copy the plugin from\n[plugin/black.vim](https://github.com/psf/black/tree/master/plugin/black.vim).\n\n```\nmkdir -p ~/.vim/pack/python/start/black/plugin\ncurl https://raw.githubusercontent.com/psf/black/master/plugin/black.vim -o ~/.vim/pack/python/start/black/plugin/black.vim\n```\n\nLet me know if this requires any changes to work with Vim 8's builtin `packadd`, or\nPathogen, and so on.\n\nThis plugin **requires Vim 7.0+ built with Python 3.6+ support**. It needs Python 3.6 to\nbe able to run _Black_ inside the Vim process which is much faster than calling an\nexternal command.\n\nOn first run, the plugin creates its own virtualenv using the right Python version and\nautomatically installs _Black_. You can upgrade it later by calling `:BlackUpgrade` and\nrestarting Vim.\n\nIf you need to do anything special to make your virtualenv work and install _Black_ (for\nexample you want to run a version from master), create a virtualenv manually and point\n`g:black_virtualenv` to it. The plugin will use it.\n\nTo run _Black_ on save, add the following line to `.vimrc` or `init.vim`:\n\n```\nautocmd BufWritePre *.py execute ':Black'\n```\n\nTo run _Black_ on a key press (e.g. F9 below), add this:\n\n```\nnnoremap <F9> :Black<CR>\n```\n\n**How to get Vim with Python 3.6?** On Ubuntu 17.10 Vim comes with Python 3.6 by\ndefault. On macOS with Homebrew run: `brew install vim --with-python3`. When building\nVim from source, use: `./configure --enable-python3interp=yes`. There's many guides\nonline how to do this.\n\n### Visual Studio Code\n\nUse the\n[Python extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python)\n([instructions](https://code.visualstudio.com/docs/python/editing#_formatting)).\n\n### SublimeText 3\n\nUse [sublack plugin](https://github.com/jgirardet/sublack).\n\n### Jupyter Notebook Magic\n\nUse [blackcellmagic](https://github.com/csurfer/blackcellmagic).\n\n### Python Language Server\n\nIf your editor supports the [Language Server Protocol](https://langserver.org/) (Atom,\nSublime Text, Visual Studio Code and many more), you can use the\n[Python Language Server](https://github.com/palantir/python-language-server) with the\n[pyls-black](https://github.com/rupert/pyls-black) plugin.\n\n### Atom/Nuclide\n\nUse [python-black](https://atom.io/packages/python-black).\n\n### Kakoune\n\nAdd the following hook to your kakrc, then run black with `:format`.\n\n```\nhook global WinSetOption filetype=python %{\n    set-option window formatcmd 'black -q  -'\n}\n```\n\n### Thonny\n\nUse [Thonny-black-code-format](https://github.com/Franccisco/thonny-black-code-format).\n\n### Other editors\n\nOther editors will require external contributions.\n\nPatches welcome! \u2728 \ud83c\udf70 \u2728\n\nAny tool that can pipe code through _Black_ using its stdio mode (just\n[use `-` as the file name](https://www.tldp.org/LDP/abs/html/special-chars.html#DASHREF2)).\nThe formatted code will be returned on stdout (unless `--check` was passed). _Black_\nwill still emit messages on stderr but that shouldn't affect your use case.\n\nThis can be used for example with PyCharm's or IntelliJ's\n[File Watchers](https://www.jetbrains.com/help/pycharm/file-watchers.html).\n\n## blackd\n\n`blackd` is a small HTTP server that exposes _Black_'s functionality over a simple\nprotocol. The main benefit of using it is to avoid paying the cost of starting up a new\n_Black_ process every time you want to blacken a file.\n\n### Usage\n\n`blackd` is not packaged alongside _Black_ by default because it has additional\ndependencies. You will need to do `pip install black[d]` to install it.\n\nYou can start the server on the default port, binding only to the local interface by\nrunning `blackd`. You will see a single line mentioning the server's version, and the\nhost and port it's listening on. `blackd` will then print an access log similar to most\nweb servers on standard output, merged with any exception traces caused by invalid\nformatting requests.\n\n`blackd` provides even less options than _Black_. You can see them by running\n`blackd --help`:\n\n```text\nUsage: blackd [OPTIONS]\n\nOptions:\n  --bind-host TEXT                Address to bind the server to.\n  --bind-port INTEGER             Port to listen on\n  --version                       Show the version and exit.\n  -h, --help                      Show this message and exit.\n```\n\nThere is no official blackd client tool (yet!). You can test that blackd is working\nusing `curl`:\n\n```\nblackd --bind-port 9090 &  # or let blackd choose a port\ncurl -s -XPOST \"localhost:9090\" -d \"print('valid')\"\n```\n\n### Protocol\n\n`blackd` only accepts `POST` requests at the `/` path. The body of the request should\ncontain the python source code to be formatted, encoded according to the `charset` field\nin the `Content-Type` request header. If no `charset` is specified, `blackd` assumes\n`UTF-8`.\n\nThere are a few HTTP headers that control how the source is formatted. These correspond\nto command line flags for _Black_. There is one exception to this: `X-Protocol-Version`\nwhich if present, should have the value `1`, otherwise the request is rejected with\n`HTTP 501` (Not Implemented).\n\nThe headers controlling how code is formatted are:\n\n- `X-Line-Length`: corresponds to the `--line-length` command line flag.\n- `X-Skip-String-Normalization`: corresponds to the `--skip-string-normalization`\n  command line flag. If present and its value is not the empty string, no string\n  normalization will be performed.\n- `X-Fast-Or-Safe`: if set to `fast`, `blackd` will act as _Black_ does when passed the\n  `--fast` command line flag.\n- `X-Python-Variant`: if set to `pyi`, `blackd` will act as _Black_ does when passed the\n  `--pyi` command line flag. Otherwise, its value must correspond to a Python version or\n  a set of comma-separated Python versions, optionally prefixed with `py`. For example,\n  to request code that is compatible with Python 3.5 and 3.6, set the header to\n  `py3.5,py3.6`.\n- `X-Diff`: corresponds to the `--diff` command line flag. If present, a diff of the\n  formats will be output.\n\nIf any of these headers are set to invalid values, `blackd` returns a `HTTP 400` error\nresponse, mentioning the name of the problematic header in the message body.\n\nApart from the above, `blackd` can produce the following response codes:\n\n- `HTTP 204`: If the input is already well-formatted. The response body is empty.\n- `HTTP 200`: If formatting was needed on the input. The response body contains the\n  blackened Python code, and the `Content-Type` header is set accordingly.\n- `HTTP 400`: If the input contains a syntax error. Details of the error are returned in\n  the response body.\n- `HTTP 500`: If there was any kind of error while trying to format the input. The\n  response body contains a textual representation of the error.\n\nThe response headers include a `X-Black-Version` header containing the version of\n_Black_.\n\n## Version control integration\n\nUse [pre-commit](https://pre-commit.com/). Once you\n[have it installed](https://pre-commit.com/#install), add this to the\n`.pre-commit-config.yaml` in your repository:\n\n```yaml\nrepos:\n  - repo: https://github.com/psf/black\n    rev: stable\n    hooks:\n      - id: black\n        language_version: python3.6\n```\n\nThen run `pre-commit install` and you're ready to go.\n\nAvoid using `args` in the hook. Instead, store necessary configuration in\n`pyproject.toml` so that editors and command-line usage of Black all behave consistently\nfor your project. See _Black_'s own [pyproject.toml](/pyproject.toml) for an example.\n\nIf you're already using Python 3.7, switch the `language_version` accordingly. Finally,\n`stable` is a tag that is pinned to the latest release on PyPI. If you'd rather run on\nmaster, this is also an option.\n\n## Ignoring unmodified files\n\n_Black_ remembers files it has already formatted, unless the `--diff` flag is used or\ncode is passed via standard input. This information is stored per-user. The exact\nlocation of the file depends on the _Black_ version and the system on which _Black_ is\nrun. The file is non-portable. The standard location on common operating systems is:\n\n- Windows:\n  `C:\\\\Users\\<username>\\AppData\\Local\\black\\black\\Cache\\<version>\\cache.<line-length>.<file-mode>.pickle`\n- macOS:\n  `/Users/<username>/Library/Caches/black/<version>/cache.<line-length>.<file-mode>.pickle`\n- Linux:\n  `/home/<username>/.cache/black/<version>/cache.<line-length>.<file-mode>.pickle`\n\n`file-mode` is an int flag that determines whether the file was formatted as 3.6+ only,\nas .pyi, and whether string normalization was omitted.\n\nTo override the location of these files on macOS or Linux, set the environment variable\n`XDG_CACHE_HOME` to your preferred location. For example, if you want to put the cache\nin the directory you're running _Black_ from, set `XDG_CACHE_HOME=.cache`. _Black_ will\nthen write the above files to `.cache/black/<version>/`.\n\n## Used by\n\nThe following notable open-source projects trust _Black_ with enforcing a consistent\ncode style: pytest, tox, Pyramid, Django Channels, Hypothesis, attrs, SQLAlchemy,\nPoetry, PyPA applications (Warehouse, Pipenv, virtualenv), pandas, Pillow, every Datadog\nAgent Integration, Home Assistant.\n\nAre we missing anyone? Let us know.\n\n## Testimonials\n\n**Dusty Phillips**,\n[writer](https://smile.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Daps&field-keywords=dusty+phillips):\n\n> _Black_ is opinionated so you don't have to be.\n\n**Hynek Schlawack**, [creator of `attrs`](https://www.attrs.org/), core developer of\nTwisted and CPython:\n\n> An auto-formatter that doesn't suck is all I want for Xmas!\n\n**Carl Meyer**, [Django](https://www.djangoproject.com/) core developer:\n\n> At least the name is good.\n\n**Kenneth Reitz**, creator of [`requests`](http://python-requests.org/) and\n[`pipenv`](https://docs.pipenv.org/):\n\n> This vastly improves the formatting of our code. Thanks a ton!\n\n## Show your style\n\nUse the badge in your project's README.md:\n\n```markdown\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n```\n\nUsing the badge in README.rst:\n\n```\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/psf/black\n```\n\nLooks like this:\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n## License\n\nMIT\n\n## Contributing to _Black_\n\nIn terms of inspiration, _Black_ is about as configurable as _gofmt_. This is\ndeliberate.\n\nBug reports and fixes are always welcome! However, before you suggest a new feature or\nconfiguration knob, ask yourself why you want it. If it enables better integration with\nsome workflow, fixes an inconsistency, speeds things up, and so on - go for it! On the\nother hand, if your answer is \"because I don't like a particular formatting\" then you're\nnot ready to embrace _Black_ yet. Such changes are unlikely to get accepted. You can\nstill try but prepare to be disappointed.\n\nMore details can be found in [CONTRIBUTING](CONTRIBUTING.md).\n\n## Change Log\n\n### 19.10b0\n\n- added support for PEP 572 assignment expressions (#711)\n\n- added support for PEP 570 positional-only arguments (#943)\n\n- added support for async generators (#593)\n\n- added support for pre-splitting collections by putting an explicit trailing comma\n  inside (#826)\n\n- added `black -c` as a way to format code passed from the command line (#761)\n\n- --safe now works with Python 2 code (#840)\n\n- fixed grammar selection for Python 2-specific code (#765)\n\n- fixed feature detection for trailing commas in function definitions and call sites\n  (#763)\n\n- `# fmt: off`/`# fmt: on` comment pairs placed multiple times within the same block of\n  code now behave correctly (#1005)\n\n- _Black_ no longer crashes on Windows machines with more than 61 cores (#838)\n\n- _Black_ no longer crashes on standalone comments prepended with a backslash (#767)\n\n- _Black_ no longer crashes on `from` ... `import` blocks with comments (#829)\n\n- _Black_ no longer crashes on Python 3.7 on some platform configurations (#494)\n\n- _Black_ no longer fails on comments in from-imports (#671)\n\n- _Black_ no longer fails when the file starts with a backslash (#922)\n\n- _Black_ no longer merges regular comments with type comments (#1027)\n\n- _Black_ no longer splits long lines that contain type comments (#997)\n\n- removed unnecessary parentheses around `yield` expressions (#834)\n\n- added parentheses around long tuples in unpacking assignments (#832)\n\n- added parentheses around complex powers when they are prefixed by a unary operator\n  (#646)\n\n- fixed bug that led _Black_ format some code with a line length target of 1 (#762)\n\n- _Black_ no longer introduces quotes in f-string subexpressions on string boundaries\n  (#863)\n\n- if _Black_ puts parenthesis around a single expression, it moves comments to the\n  wrapped expression instead of after the brackets (#872)\n\n- `blackd` now returns the version of _Black_ in the response headers (#1013)\n\n- `blackd` can now output the diff of formats on source code when the `X-Diff` header is\n  provided (#969)\n\n### 19.3b0\n\n- new option `--target-version` to control which Python versions _Black_-formatted code\n  should target (#618)\n\n- deprecated `--py36` (use `--target-version=py36` instead) (#724)\n\n- _Black_ no longer normalizes numeric literals to include `_` separators (#696)\n\n- long `del` statements are now split into multiple lines (#698)\n\n- type comments are no longer mangled in function signatures\n\n- improved performance of formatting deeply nested data structures (#509)\n\n- _Black_ now properly formats multiple files in parallel on Windows (#632)\n\n- _Black_ now creates cache files atomically which allows it to be used in parallel\n  pipelines (like `xargs -P8`) (#673)\n\n- _Black_ now correctly indents comments in files that were previously formatted with\n  tabs (#262)\n\n- `blackd` now supports CORS (#622)\n\n### 18.9b0\n\n- numeric literals are now formatted by _Black_ (#452, #461, #464, #469):\n\n  - numeric literals are normalized to include `_` separators on Python 3.6+ code\n\n  - added `--skip-numeric-underscore-normalization` to disable the above behavior and\n    leave numeric underscores as they were in the input\n\n  - code with `_` in numeric literals is recognized as Python 3.6+\n\n  - most letters in numeric literals are lowercased (e.g., in `1e10`, `0x01`)\n\n  - hexadecimal digits are always uppercased (e.g. `0xBADC0DE`)\n\n- added `blackd`, see [its documentation](#blackd) for more info (#349)\n\n- adjacent string literals are now correctly split into multiple lines (#463)\n\n- trailing comma is now added to single imports that don't fit on a line (#250)\n\n- cache is now populated when `--check` is successful for a file which speeds up\n  consecutive checks of properly formatted unmodified files (#448)\n\n- whitespace at the beginning of the file is now removed (#399)\n\n- fixed mangling [pweave](http://mpastell.com/pweave/) and\n  [Spyder IDE](https://pythonhosted.org/spyder/) special comments (#532)\n\n- fixed unstable formatting when unpacking big tuples (#267)\n\n- fixed parsing of `__future__` imports with renames (#389)\n\n- fixed scope of `# fmt: off` when directly preceding `yield` and other nodes (#385)\n\n- fixed formatting of lambda expressions with default arguments (#468)\n\n- fixed `async for` statements: _Black_ no longer breaks them into separate lines (#372)\n\n- note: the Vim plugin stopped registering `,=` as a default chord as it turned out to\n  be a bad idea (#415)\n\n### 18.6b4\n\n- hotfix: don't freeze when multiple comments directly precede `# fmt: off` (#371)\n\n### 18.6b3\n\n- typing stub files (`.pyi`) now have blank lines added after constants (#340)\n\n- `# fmt: off` and `# fmt: on` are now much more dependable:\n\n  - they now work also within bracket pairs (#329)\n\n  - they now correctly work across function/class boundaries (#335)\n\n  - they now work when an indentation block starts with empty lines or misaligned\n    comments (#334)\n\n- made Click not fail on invalid environments; note that Click is right but the\n  likelihood we'll need to access non-ASCII file paths when dealing with Python source\n  code is low (#277)\n\n- fixed improper formatting of f-strings with quotes inside interpolated expressions\n  (#322)\n\n- fixed unnecessary slowdown when long list literals where found in a file\n\n- fixed unnecessary slowdown on AST nodes with very many siblings\n\n- fixed cannibalizing backslashes during string normalization\n\n- fixed a crash due to symbolic links pointing outside of the project directory (#338)\n\n### 18.6b2\n\n- added `--config` (#65)\n\n- added `-h` equivalent to `--help` (#316)\n\n- fixed improper unmodified file caching when `-S` was used\n\n- fixed extra space in string unpacking (#305)\n\n- fixed formatting of empty triple quoted strings (#313)\n\n- fixed unnecessary slowdown in comment placement calculation on lines without comments\n\n### 18.6b1\n\n- hotfix: don't output human-facing information on stdout (#299)\n\n- hotfix: don't output cake emoji on non-zero return code (#300)\n\n### 18.6b0\n\n- added `--include` and `--exclude` (#270)\n\n- added `--skip-string-normalization` (#118)\n\n- added `--verbose` (#283)\n\n- the header output in `--diff` now actually conforms to the unified diff spec\n\n- fixed long trivial assignments being wrapped in unnecessary parentheses (#273)\n\n- fixed unnecessary parentheses when a line contained multiline strings (#232)\n\n- fixed stdin handling not working correctly if an old version of Click was used (#276)\n\n- _Black_ now preserves line endings when formatting a file in place (#258)\n\n### 18.5b1\n\n- added `--pyi` (#249)\n\n- added `--py36` (#249)\n\n- Python grammar pickle caches are stored with the formatting caches, making _Black_\n  work in environments where site-packages is not user-writable (#192)\n\n- _Black_ now enforces a PEP 257 empty line after a class-level docstring (and/or\n  fields) and the first method\n\n- fixed invalid code produced when standalone comments were present in a trailer that\n  was omitted from line splitting on a large expression (#237)\n\n- fixed optional parentheses being removed within `# fmt: off` sections (#224)\n\n- fixed invalid code produced when stars in very long imports were incorrectly wrapped\n  in optional parentheses (#234)\n\n- fixed unstable formatting when inline comments were moved around in a trailer that was\n  omitted from line splitting on a large expression (#238)\n\n- fixed extra empty line between a class declaration and the first method if no class\n  docstring or fields are present (#219)\n\n- fixed extra empty line between a function signature and an inner function or inner\n  class (#196)\n\n### 18.5b0\n\n- call chains are now formatted according to the\n  [fluent interfaces](https://en.wikipedia.org/wiki/Fluent_interface) style (#67)\n\n- data structure literals (tuples, lists, dictionaries, and sets) are now also always\n  exploded like imports when they don't fit in a single line (#152)\n\n- slices are now formatted according to PEP 8 (#178)\n\n- parentheses are now also managed automatically on the right-hand side of assignments\n  and return statements (#140)\n\n- math operators now use their respective priorities for delimiting multiline\n  expressions (#148)\n\n- optional parentheses are now omitted on expressions that start or end with a bracket\n  and only contain a single operator (#177)\n\n- empty parentheses in a class definition are now removed (#145, #180)\n\n- string prefixes are now standardized to lowercase and `u` is removed on Python 3.6+\n  only code and Python 2.7+ code with the `unicode_literals` future import (#188, #198,\n  #199)\n\n- typing stub files (`.pyi`) are now formatted in a style that is consistent with PEP\n  484 (#207, #210)\n\n- progress when reformatting many files is now reported incrementally\n\n- fixed trailers (content with brackets) being unnecessarily exploded into their own\n  lines after a dedented closing bracket (#119)\n\n- fixed an invalid trailing comma sometimes left in imports (#185)\n\n- fixed non-deterministic formatting when multiple pairs of removable parentheses were\n  used (#183)\n\n- fixed multiline strings being unnecessarily wrapped in optional parentheses in long\n  assignments (#215)\n\n- fixed not splitting long from-imports with only a single name\n\n- fixed Python 3.6+ file discovery by also looking at function calls with unpacking.\n  This fixed non-deterministic formatting if trailing commas where used both in function\n  signatures with stars and function calls with stars but the former would be\n  reformatted to a single line.\n\n- fixed crash on dealing with optional parentheses (#193)\n\n- fixed \"is\", \"is not\", \"in\", and \"not in\" not considered operators for splitting\n  purposes\n\n- fixed crash when dead symlinks where encountered\n\n### 18.4a4\n\n- don't populate the cache on `--check` (#175)\n\n### 18.4a3\n\n- added a \"cache\"; files already reformatted that haven't changed on disk won't be\n  reformatted again (#109)\n\n- `--check` and `--diff` are no longer mutually exclusive (#149)\n\n- generalized star expression handling, including double stars; this fixes\n  multiplication making expressions \"unsafe\" for trailing commas (#132)\n\n- _Black_ no longer enforces putting empty lines behind control flow statements (#90)\n\n- _Black_ now splits imports like \"Mode 3 + trailing comma\" of isort (#127)\n\n- fixed comment indentation when a standalone comment closes a block (#16, #32)\n\n- fixed standalone comments receiving extra empty lines if immediately preceding a\n  class, def, or decorator (#56, #154)\n\n- fixed `--diff` not showing entire path (#130)\n\n- fixed parsing of complex expressions after star and double stars in function calls\n  (#2)\n\n- fixed invalid splitting on comma in lambda arguments (#133)\n\n- fixed missing splits of ternary expressions (#141)\n\n### 18.4a2\n\n- fixed parsing of unaligned standalone comments (#99, #112)\n\n- fixed placement of dictionary unpacking inside dictionary literals (#111)\n\n- Vim plugin now works on Windows, too\n\n- fixed unstable formatting when encountering unnecessarily escaped quotes in a string\n  (#120)\n\n### 18.4a1\n\n- added `--quiet` (#78)\n\n- added automatic parentheses management (#4)\n\n- added [pre-commit](https://pre-commit.com) integration (#103, #104)\n\n- fixed reporting on `--check` with multiple files (#101, #102)\n\n- fixed removing backslash escapes from raw strings (#100, #105)\n\n### 18.4a0\n\n- added `--diff` (#87)\n\n- add line breaks before all delimiters, except in cases like commas, to better comply\n  with PEP 8 (#73)\n\n- standardize string literals to use double quotes (almost) everywhere (#75)\n\n- fixed handling of standalone comments within nested bracketed expressions; _Black_\n  will no longer produce super long lines or put all standalone comments at the end of\n  the expression (#22)\n\n- fixed 18.3a4 regression: don't crash and burn on empty lines with trailing whitespace\n  (#80)\n\n- fixed 18.3a4 regression: `# yapf: disable` usage as trailing comment would cause\n  _Black_ to not emit the rest of the file (#95)\n\n- when CTRL+C is pressed while formatting many files, _Black_ no longer freaks out with\n  a flurry of asyncio-related exceptions\n\n- only allow up to two empty lines on module level and only single empty lines within\n  functions (#74)\n\n### 18.3a4\n\n- `# fmt: off` and `# fmt: on` are implemented (#5)\n\n- automatic detection of deprecated Python 2 forms of print statements and exec\n  statements in the formatted file (#49)\n\n- use proper spaces for complex expressions in default values of typed function\n  arguments (#60)\n\n- only return exit code 1 when --check is used (#50)\n\n- don't remove single trailing commas from square bracket indexing (#59)\n\n- don't omit whitespace if the previous factor leaf wasn't a math operator (#55)\n\n- omit extra space in kwarg unpacking if it's the first argument (#46)\n\n- omit extra space in\n  [Sphinx auto-attribute comments](http://www.sphinx-doc.org/en/stable/ext/autodoc.html#directive-autoattribute)\n  (#68)\n\n### 18.3a3\n\n- don't remove single empty lines outside of bracketed expressions (#19)\n\n- added ability to pipe formatting from stdin to stdin (#25)\n\n- restored ability to format code with legacy usage of `async` as a name (#20, #42)\n\n- even better handling of numpy-style array indexing (#33, again)\n\n### 18.3a2\n\n- changed positioning of binary operators to occur at beginning of lines instead of at\n  the end, following\n  [a recent change to PEP 8](https://github.com/python/peps/commit/c59c4376ad233a62ca4b3a6060c81368bd21e85b)\n  (#21)\n\n- ignore empty bracket pairs while splitting. This avoids very weirdly looking\n  formattings (#34, #35)\n\n- remove a trailing comma if there is a single argument to a call\n\n- if top level functions were separated by a comment, don't put four empty lines after\n  the upper function\n\n- fixed unstable formatting of newlines with imports\n\n- fixed unintentional folding of post scriptum standalone comments into last statement\n  if it was a simple statement (#18, #28)\n\n- fixed missing space in numpy-style array indexing (#33)\n\n- fixed spurious space after star-based unary expressions (#31)\n\n### 18.3a1\n\n- added `--check`\n\n- only put trailing commas in function signatures and calls if it's safe to do so. If\n  the file is Python 3.6+ it's always safe, otherwise only safe if there are no `*args`\n  or `**kwargs` used in the signature or call. (#8)\n\n- fixed invalid spacing of dots in relative imports (#6, #13)\n\n- fixed invalid splitting after comma on unpacked variables in for-loops (#23)\n\n- fixed spurious space in parenthesized set expressions (#7)\n\n- fixed spurious space after opening parentheses and in default arguments (#14, #17)\n\n- fixed spurious space after unary operators when the operand was a complex expression\n  (#15)\n\n### 18.3a0\n\n- first published version, Happy \ud83c\udf70 Day 2018!\n\n- alpha quality\n\n- date-versioned (see: https://calver.org/)\n\n## Authors\n\nGlued together by [\u0141ukasz Langa](mailto:lukasz@langa.pl).\n\nMaintained with [Carol Willing](mailto:carolcode@willingconsulting.com),\n[Carl Meyer](mailto:carl@oddbird.net),\n[Jelle Zijlstra](mailto:jelle.zijlstra@gmail.com),\n[Mika Naylor](mailto:mail@autophagy.io), and\n[Zsolt Dollenstein](mailto:zsol.zsol@gmail.com).\n\nMultiple contributions by:\n\n- [Abdur-Rahmaan Janhangeer](mailto:cryptolabour@gmail.com)\n- [Adam Johnson](mailto:me@adamj.eu)\n- [Alexander Huynh](mailto:github@grande.coffee)\n- [Andrew Thorp](mailto:andrew.thorp.dev@gmail.com)\n- [Andrey](mailto:dyuuus@yandex.ru)\n- [Andy Freeland](mailto:andy@andyfreeland.net)\n- [Anthony Sottile](mailto:asottile@umich.edu)\n- [Arjaan Buijk](mailto:arjaan.buijk@gmail.com)\n- [Artem Malyshev](mailto:proofit404@gmail.com)\n- [Asger Hautop Drewsen](mailto:asgerdrewsen@gmail.com)\n- [Augie Fackler](mailto:raf@durin42.com)\n- [Aviskar KC](mailto:aviskarkc10@gmail.com)\n- [Benjamin Woodruff](mailto:github@benjam.info)\n- [Brandt Bucher](mailto:brandtbucher@gmail.com)\n- Charles Reid\n- [Christian Heimes](mailto:christian@python.org)\n- [Chuck Wooters](mailto:chuck.wooters@microsoft.com)\n- [Daniel Hahler](mailto:github@thequod.de)\n- [Daniel M. Capella](mailto:polycitizen@gmail.com)\n- Daniele Esposti\n- dylanjblack\n- [Eli Treuherz](mailto:eli@treuherz.com)\n- [Florent Thiery](mailto:fthiery@gmail.com)\n- hauntsaninja\n- Hugo van Kemenade\n- [Ivan Katani\u0107](mailto:ivan.katanic@gmail.com)\n- [Jason Fried](mailto:me@jasonfried.info)\n- [jgirardet](mailto:ijkl@netc.fr)\n- [Joe Antonakakis](mailto:jma353@cornell.edu)\n- [Jon Dufresne](mailto:jon.dufresne@gmail.com)\n- [Jonas Obrist](mailto:ojiidotch@gmail.com)\n- [Josh Bode](mailto:joshbode@fastmail.com)\n- [Juan Luis Cano Rodr\u00edguez](mailto:hello@juanlu.space)\n- [Katie McLaughlin](mailto:katie@glasnt.com)\n- Lawrence Chan\n- [Linus Groh](mailto:mail@linusgroh.de)\n- [Luka Sterbic](mailto:luka.sterbic@gmail.com)\n- Mariatta\n- [Matt VanEseltine](mailto:vaneseltine@gmail.com)\n- [Michael Flaxman](mailto:michael.flaxman@gmail.com)\n- [Michael J. Sullivan](mailto:sully@msully.net)\n- [Michael McClimon](mailto:michael@mcclimon.org)\n- [Miguel Gaiowski](mailto:miggaiowski@gmail.com)\n- [Mike](mailto:roshi@fedoraproject.org)\n- [Min ho Kim](mailto:minho42@gmail.com)\n- [Miroslav Shubernetskiy](mailto:miroslav@miki725.com)\n- [Neraste](mailto:neraste.herr10@gmail.com)\n- [Ofek Lev](mailto:ofekmeister@gmail.com)\n- [Osaetin Daniel](mailto:osaetindaniel@gmail.com)\n- [Pablo Galindo](mailto:Pablogsal@gmail.com)\n- [Peter Bengtsson](mailto:mail@peterbe.com)\n- pmacosta\n- [Rishikesh Jha](mailto:rishijha424@gmail.com)\n- [Stavros Korokithakis](mailto:hi@stavros.io)\n- [Stephen Rosen](mailto:sirosen@globus.org)\n- [Sunil Kapil](mailto:snlkapil@gmail.com)\n- [Thom Lu](mailto:thomas.c.lu@gmail.com)\n- [Tom Christie](mailto:tom@tomchristie.com)\n- [Tzu-ping Chung](mailto:uranusjr@gmail.com)\n- [Utsav Shah](mailto:ukshah2@illinois.edu)\n- vezeli\n- [Vishwas B Sharma](mailto:sharma.vishwas88@gmail.com)\n- [Yngve H\u00f8iseth](mailto:yngve@hoiseth.net)\n- [Yurii Karabas](mailto:1998uriyyo@gmail.com)\n"}, {"repo": "machinelearningmindset/TensorFlow-Course", "language": "Python", "readme_contents": "\n\n********************\n`TensorFlow Course`_\n********************\n.. image:: https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\n    :target: https://github.com/open-source-for-science/TensorFlow-Course/pulls\n.. image:: https://badges.frapsoft.com/os/v2/open-source.svg?v=102\n    :target: https://github.com/ellerbrock/open-source-badge/\n.. image:: https://img.shields.io/twitter/follow/machinemindset.svg?label=Follow&style=social\n    :target: https://twitter.com/machinemindset\n\n\nThis repository aims to provide simple and ready-to-use tutorials for TensorFlow.\nEach tutorial includes ``source code`` and most of them are associated with a ``documentation``.\n\n.. .. image:: _img/mainpage/TensorFlow_World.gif\n\n.. The links.\n.. _TensorFlow: https://www.tensorflow.org/install/\n.. _Wikipedia: https://en.wikipedia.org/wiki/TensorFlow/\n\n#################\nTable of Contents\n#################\n.. contents::\n  :local:\n  :depth: 3\n\n\n==========================================\nDownload Free TensorFlow Roadmap EBook\n==========================================\n\n.. raw:: html\n\n   <div align=\"center\">\n\n.. raw:: html\n\n <a href=\"http://www.machinelearningmindset.com/tensorflow-roadmap-ebook/\" target=\"_blank\">\n  <img width=\"850\" height=\"600\" align=\"center\" src=\"https://github.com/machinelearningmindset/TensorFlow-Course/blob/master/_img/mainpage/booksubscribe.png\"/>\n </a>\n\n.. raw:: html\n\n   </div>\n\n~~~~~~~~~~~~~~~~~~~~~\nWhat is TensorFlow?\n~~~~~~~~~~~~~~~~~~~~~\nTensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks. It is used for both research and production at Google often replacing its closed-source predecessor, DistBelief.\n\nTensorFlow was developed by the Google Brain team for internal Google use. It was released under the Apache 2.0 open source license on November 9, 2015.\n\nThe current stable release as of September 27, 2018 is 1.11.0\n\n============\nMotivation\n============\n\nThere are different motivations for this open source project. TensorFlow (as we write this document) is one of / the best deep learning frameworks available. The question that should be asked is why has this repository been created when there are so many other tutorials about TensorFlow available on the web?\n\n~~~~~~~~~~~~~~~~~~~~~\nWhy use TensorFlow?\n~~~~~~~~~~~~~~~~~~~~~\n\nDeep Learning is in very high interest these days - there's a crucial need for rapid and optimized implementations of the algorithms and architectures. TensorFlow is designed to facilitate this goal.\n\nThe strong advantage of TensorFlow is it flexibility in designing highly modular models which can also be a disadvantage for beginners since a lot of the pieces must be considered together when creating the model.\n\nThis issue has been facilitated as well by developing high-level APIs such as `Keras <https://keras.io/>`_ and `Slim <https://github.com/tensorflow/models/blob/031a5a4ab41170d555bc3e8f8545cf9c8e3f1b28/research/inception/inception/slim/README.md>`_ which abstract a lot of the pieces used in designing machine learning algorithms.\n\nThe interesting thing about TensorFlow is that **it can be found anywhere these days**. Lots of the researchers and developers are using it and *its community is growing at the speed of light*! So many issues can be dealt with easily since they're usually the same issues that a lot of other people run into considering the large number of people involved in the TensorFlow community.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nWhat's the point of this repository?\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n**Developing open source projects for the sake of just developing something is not the reason behind this effort**.\nConsidering the large number of tutorials that are being added to this large community, this repository has been created to break the jump-in and jump-out process that usually happens to most of the open source projects, **but why and how**?\n\nFirst of all, what's the point of putting effort into something that most of the people won't stop by and take a look? What's the point of creating something that does not help anyone in the developers and researchers community? Why spend time for something that can easily be forgotten? But **how we try to do it?** Even up to this\nvery moment there are countless tutorials on TensorFlow whether on the model design or TensorFlow\nworkflow.\n\nMost of them are too complicated or suffer from a lack of documentation. There are only a few available tutorials which are concise and well-structured and provide enough insight for their specific implemented models.\n\nThe goal of this project is to help the community with structured tutorials and simple and optimized code implementations to provide better insight about how to use TensorFlow *quick and effectively*.\n\nIt is worth noting that, **the main goal of this project is to provide well-documented tutorials and less-complicated code**!\n\n=================================================\nTensorFlow Installation and Setup the Environment\n=================================================\n\n.. image:: _img/mainpage/installation-logo.gif\n   :height: 100px\n   :width: 200 px\n   :scale: 50 %\n   :alt: alternate text\n   :align: right\n   :target: docs/tutorials/installation\n\n.. _TensorFlow Installation: docs/tutorials/installation\n\nIn order to install TensorFlow please refer to the following link:\n\n  * `TensorFlow Installation`_\n\n\n.. image:: _img/mainpage/installation.gif\n    :target: https://www.youtube.com/watch?v=_3JFEPk4qQY&t=2s\n\nThe virtual environment installation is recommended in order to prevent package conflict and having the capacity to customize the working environment.\n\n====================\nTensorFlow Tutorials\n====================\n\nThe tutorials in this repository are partitioned into relevant categories.\n\n==========================\n\n~~~~~~~~\nWarm-up\n~~~~~~~~\n\n.. image:: _img/mainpage/welcome.gif\n   :height: 100px\n   :width: 200 px\n   :scale: 50 %\n   :alt: alternate text\n   :align: right\n\n+----+---------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n| #  |       topic         |   Source Code                                                                          |                                              |\n+====+=====================+========================================================================================+==============================================+\n| 1  | Start-up            | `Welcome <welcomesourcecode_>`_  / `IPython <ipythonwelcome_>`_                        |  `Documentation <Documentationcnnwelcome_>`_ |\n+----+---------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n\n==========================\n\n~~~~~~\nBasics\n~~~~~~\n\n.. image:: _img/mainpage/basics.gif\n   :height: 100px\n   :width: 200 px\n   :scale: 50 %\n   :alt: alternate text\n   :align: right\n\n+----+---------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n| #  |       topic         |   Source Code                                                                          |                                              |\n+====+=====================+========================================================================================+==============================================+\n| 2  | *TensorFLow Basics* | `Basic Math Operations <basicmathsourcecode_>`_   / `IPython <ipythonbasicmath_>`_     |  `Documentation <Documentationbasicmath_>`_  |\n+----+---------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n| 3  | *TensorFLow Basics* | `TensorFlow Variables <variablssourcecode_>`_   / `IPython <ipythonvariabls_>`_        |  `Documentation <Documentationvariabls_>`_   |\n+----+---------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n\n==========================\n\n~~~~~~~~~~~~~~~~~~~~~~\nBasic Machine Learning\n~~~~~~~~~~~~~~~~~~~~~~\n\n.. image:: _img/mainpage/basicmodels.gif\n   :height: 100px\n   :width: 200 px\n   :scale: 50 %\n   :alt: alternate text\n   :align: right\n\n+----+----------------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n| #  |       topic                |   Source Code                                                                          |                                              |\n+====+============================+========================================================================================+==============================================+\n| 4  | *Linear Models*            |`Linear Regression`_  / `IPython <LinearRegressionipython_>`_                           | `Documentation <Documentationlr_>`_          |\n+----+----------------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n| 5  | *Predictive Models*        | `Logistic Regression`_  / `IPython <LogisticRegressionipython_>`_                      | `Documentation <LogisticRegDOC_>`_           |\n+----+----------------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n| 6  | *Support Vector Machines*  | `Linear SVM`_  / `IPython <LinearSVMipython_>`_                                        |                                              |\n+----+----------------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n| 7  | *Support Vector Machines*  |`MultiClass Kernel SVM`_  / `IPython <MultiClassKernelSVMipython_>`_                    |                                              |\n+----+----------------------------+----------------------------------------------------------------------------------------+----------------------------------------------+\n\n==========================\n\n~~~~~~~~~~~~~~~~\nNeural Networks\n~~~~~~~~~~~~~~~~\n\n.. image:: _img/mainpage/CNNs.png\n   :height: 100px\n   :width: 200 px\n   :scale: 50 %\n   :alt: alternate text\n   :align: right\n\n+----+-----------------------------------+-----------------------------------------------------------------------------------------------+----------------------------------------------+\n| #  |       topic                       |   Source Code                                                                                 |                                              |\n+====+===================================+===============================================================================================+==============================================+\n| 8  | *Multi Layer Perceptron*          |`Simple Multi Layer Perceptron`_   / `IPython <MultiLayerPerceptronipython_>`_                 |                                              |\n+----+-----------------------------------+-----------------------------------------------------------------------------------------------+----------------------------------------------+\n| 9  | *Convolutional Neural Network*    | `Simple Convolutional Neural Networks`_                                                       |       `Documentation <Documentationcnn_>`_   |\n+----+-----------------------------------+-----------------------------------------------------------------------------------------------+----------------------------------------------+\n| 10 | *Recurrent Neural Network*        | `RNN`_  / `IPython <RNNIpython_>`_                                                            |                                              |\n+----+-----------------------------------+-----------------------------------------------------------------------------------------------+----------------------------------------------+\n\n.. ~~~~~~~~~~~~\n.. **Welcome**\n.. ~~~~~~~~~~~~\n\n.. The tutorial in this section is just a simple entrance to TensorFlow.\n\n.. _welcomesourcecode: codes/python/0-welcome\n.. _Documentationcnnwelcome: docs/tutorials/0-welcome\n.. _ipythonwelcome: codes/ipython/0-welcome/code/0-welcome.ipynb\n\n\n\n.. +---+---------------------------------------------+-------------------------------------------------+\n.. | # |          Source Code                        |                                                 |\n.. +===+=============================================+=================================================+\n.. | 1 |    `Welcome <welcomesourcecode_>`_          |  `Documentation <Documentationcnnwelcome_>`_    |\n.. +---+---------------------------------------------+-------------------------------------------------+\n\n.. ~~~~~~~~~~\n.. **Basics**\n.. ~~~~~~~~~~\n.. These tutorials are related to basics of TensorFlow.\n\n.. _basicmathsourcecode: codes/python/1-basics/basic_math_operations\n.. _Documentationbasicmath: docs/tutorials/1-basics/basic_math_operations\n.. _ipythonbasicmath: codes/ipython/1-basics/basic_math_operations/code/basic_math_operation.ipynb\n\n.. _ipythonvariabls: codes/ipython/1-basics/variables/code/variables.ipynb\n.. _variablssourcecode: codes/python/1-basics/variables/README.rst\n.. _Documentationvariabls: docs/tutorials/1-basics/variables\n\n\n.. +---+-----------------------------------------------------+-------------------------------------------------+\n.. | # |          Source Code                                |                                                 |\n.. +===+=====================================================+=================================================+\n.. | 1 |    `Basic Math Operations <basicmathsourcecode_>`_  |  `Documentation <Documentationbasicmath_>`_     |\n.. +---+-----------------------------------------------------+-------------------------------------------------+\n.. | 2 |    `TensorFlow Variables <variablssourcecode_>`_    |  `Documentation <Documentationvariabls_>`_      |\n.. +---+-----------------------------------------------------+-------------------------------------------------+\n\n.. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n.. **Machine Learning Basics**\n.. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n.. We are going to present concepts of basic machine learning models and methods and show how to implement them in Tensorflow.\n\n.. _Linear Regression: codes/python/2-basics_in_machine_learning/linear_regression\n.. _LinearRegressionipython: codes/ipython/2-basics_in_machine_learning/linear_regression/code/linear_regression.ipynb\n.. _Documentationlr: docs/tutorials/2-basics_in_machine_learning/linear_regression\n\n.. _Logistic Regression: codes/python/2-basics_in_machine_learning/logistic_regression\n.. _LogisticRegressionipython: codes//ipython/2-basics_in_machine_learning/logistic_regression/code/logistic_regression.ipynb\n.. _LogisticRegDOC: docs/tutorials/2-basics_in_machine_learning/logistic_regression\n\n.. _Linear SVM: codes/python/2-basics_in_machine_learning/linear_svm\n.. _LinearSVMipython: codes//ipython/2-basics_in_machine_learning/linear_svm/code/linear_svm.ipynb\n\n\n.. _MultiClass Kernel SVM: codes/python/2-basics_in_machine_learning/multiclass_svm\n.. _MultiClassKernelSVMipython: codes/ipython/2-basics_in_machine_learning/multiclass_svm/code/multiclass_svm.ipynb\n\n\n.. +---+---------------------------------------------+----------------------------------------+\n.. | # |          Source Code                        |                                        |\n.. +===+=============================================+========================================+\n.. | 1 |    `Linear Regression`_                     |  `Documentation <Documentationlr_>`_   |\n.. +---+---------------------------------------------+----------------------------------------+\n.. | 2 |    `Logistic Regression`_                   |  `Documentation <LogisticRegDOC_>`_    |\n.. +---+---------------------------------------------+----------------------------------------+\n.. | 3 |    `Linear SVM`_                            |                                        |\n.. +---+---------------------------------------------+----------------------------------------+\n.. | 4 |    `MultiClass Kernel SVM`_                 |                                        |\n.. +---+---------------------------------------------+----------------------------------------+\n\n.. ~~~~~~~~~~~~~~~~~~~\n.. **Neural Networks**\n.. ~~~~~~~~~~~~~~~~~~~\n.. The tutorials in this section are related to neural network architectures.\n\n.. _Simple Convolutional Neural Networks: codes/python/3-neural_networks/convolutional-neural-network\n.. _Documentationcnn: docs/tutorials/3-neural_network/convolutiona_neural_network\n\n.. _Simple Multi Layer Perceptron: codes/python/3-neural_networks/multi-layer-perceptron\n.. _MultiLayerPerceptronipython: codes/ipython/3-neural_networks/multi-layer-perceptron/code/train_mlp.ipynb\n\n.. _RNN: codes/python/3-neural_networks/recurrent-neural-networks/code/rnn.py\n.. _RNNIpython: codes/ipython/3-neural_networks/recurrent-neural-networks/code/rnn.ipynb\n\n\n.. +---+---------------------------------------------+----------------------------------------+\n.. | # |          Source Code                        |                                        |\n.. +===+=============================================+========================================+\n.. | 1 |    `Multi Layer Perceptron`_                |                                        |\n.. +---+---------------------------------------------+----------------------------------------+\n.. | 2 |    `Convolutional Neural Networks`_         |  `Documentation <Documentationcnn_>`_  |\n.. +---+---------------------------------------------+----------------------------------------+\n\n\n=====================\nSome Useful Tutorials\n=====================\n\n  * `TensorFlow Examples <https://github.com/aymericdamien/TensorFlow-Examples>`_ - TensorFlow tutorials and code examples for beginners\n  * `Sungjoon's TensorFlow-101 <https://github.com/sjchoi86/Tensorflow-101>`_ - TensorFlow tutorials written in Python with Jupyter Notebook\n  * `Terry Um\u2019s TensorFlow Exercises <https://github.com/terryum/TensorFlow_Exercises>`_ - Re-create the codes from other TensorFlow examples\n  * `Classification on time series <https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition>`_ - Recurrent Neural Network classification in TensorFlow with LSTM on cellphone sensor data\n\n\n=============\nContributing\n=============\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. *For typos, please\ndo not create a pull request. Instead, declare them in issues or email the repository owner*.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n~~~~~~~~~~~~~~~~~~~~\nPull Request Process\n~~~~~~~~~~~~~~~~~~~~\n\nPlease consider the following criterions in order to help us in a better way:\n\n  * The pull request is mainly expected to be a code script suggestion or improvement.\n  * A pull request related to non-code-script sections is expected to make a significant difference in the documentation. Otherwise, it is expected to be announced in the issues section.\n  * Ensure any install or build dependencies are removed before the end of the layer when doing a build and creating a pull request.\n  * Add comments with details of changes to the interface, this includes new environment variables, exposed ports, useful file locations and container parameters.\n  * You may merge the Pull Request in once you have the sign-off of at least one other developer, or if you do not have permission to do that, you may request the owner to merge it for you if you believe all checks are passed.\n\n\n~~~~~~~~~~~\nFinal Note\n~~~~~~~~~~~\n\nWe are looking forward to your kind feedback. Please help us to improve this open source project and make our work better.\nFor contribution, please create a pull request and we will investigate it promptly. Once again, we appreciate\nyour kind feedback and elaborate code inspections.\n\n========================\nDevelopers\n========================\n\n**Creator**: Machine Learning Mindset [`Blog\n<https://machinelearningmindset.com/blog/>`_, `GitHub\n<https://github.com/machinelearningmindset>`_, `Twitter\n<https://twitter.com/machinemindset>`_]\n\n**Developer**: Amirsina Torfi [`GitHub\n<https://github.com/astorfi>`_, `Personal Website\n<https://astorfi.github.io/>`_, `Linkedin\n<https://www.linkedin.com/in/amirsinatorfi/>`_ ]\n\n================\nAcknowledgement\n================\n\nI have taken huge efforts in this project for hopefully being a small part of TensorFlow world. However, it would not have been plausible without the kind support and help of my friend and colleague `Domenick Poster <https://github.com/vonclites/>`_ for his valuable advices. He helped me for having a better understanding of TensorFlow and my special appreciation goes to him.\n"}]