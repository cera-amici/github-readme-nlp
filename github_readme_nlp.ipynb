{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github_readme_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# matplotlib default plotting styles\n",
    "plt.rc(\"patch\", edgecolor=\"black\", force_edgecolor=True)\n",
    "plt.rc(\"axes\", grid=True)\n",
    "plt.rc(\"grid\", linestyle=\":\", linewidth=0.8, alpha=0.7)\n",
    "plt.rc(\"axes.spines\", right=False, top=False)\n",
    "plt.rc(\"figure\", figsize=(11, 10))\n",
    "plt.rc(\"font\", size=12.0)\n",
    "plt.rc(\"hist\", bins=25)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire/Prepare\n",
    "\n",
    "**Task** show steps to acquire and prepare\n",
    "\n",
    "- original, cleaned, stem, lemmatize notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-c39d090ae890>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-c39d090ae890>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df.()\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df.()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Summary\n",
    "\n",
    "- Create data frame with cleaned data and language listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df = df[['language', 'title', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore & Define Features\n",
    "\n",
    "### Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df.language.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts().plot.pie(\n",
    "    colors = ['pink', 'lightblue', 'green', 'orange'], autopct = '%.0f%%')\n",
    "plt.title(\"Language Distribution\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('n = %d' % df.shape[0])\n",
    "\n",
    "pd.concat(\n",
    "    [df.language.value_counts(), df.language.value_counts(normalize = True)], axis = 1).set_axis([\"n\", \"percent\"], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** join all Readme and find high count of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\" \".join(lemmas_df.lemmatized).split()).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** words within each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(lemmas_df.lemmatized).split()\n",
    "\n",
    "python_words = ' '.join(lemmas_df[lemmas_df.language == 'Python'].lemmatized).split()\n",
    "\n",
    "javascript_words = ' '.join(lemmas_df[lemmas_df.language == 'JavaScript'].lemmatized).split()\n",
    "\n",
    "php_words = ' '.join(lemmas_df[lemmas_df.language == 'PHP'].lemmatized).split()\n",
    "\n",
    "shell_words = ' '.join(lemmas_df[lemmas_df.language == 'Shell'].lemmatized).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we have a list of words, we can transform it into a pandas Series, which we can then use to show us how often each of the words occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freq = pd.Series(all_words).value_counts()\n",
    "\n",
    "python_words_freq = pd.Series(python_words).value_counts()\n",
    "\n",
    "javascript_words_freq = pd.Series(javascript_words).value_counts()\n",
    "\n",
    "php_words_freq = pd.Series(php_words).value_counts()\n",
    "\n",
    "shell_words_freq = pd.Series(shell_words).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency\n",
    "\n",
    "Generally, when you hear 'Term Frequency', it is referring to the number of documents in which a word appears. When we move on to computing TF-IDF, this basic definition of Term Frequency applies.\n",
    "\n",
    "However, term frequency can be calculated in a number of ways, all of which reflect how frequently a word appears in a document.\n",
    "\n",
    "Raw Count: This is simply the count of the number of occurances of each word.\n",
    "Frequency: The number of times each word appears divided by the total number of words.\n",
    "Augmented Frequency: The frequency of each word divided by the maximum frequency. This can help prevent bias towards larger documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count = (\n",
    "    pd.concat([all_freq, python_words_freq, javascript_words_freq, php_words_freq, shell_words_freq], axis=1, sort=True)\n",
    "    .rename(columns={0: \"All\", 1: \"Python\", 2: \"JavaScript\", 3: \"PHP\", 4: \"Shell\"})\n",
    "    .fillna(0)\n",
    "    .apply(lambda col: col.astype(int))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** Find record that has &#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.sort_values(by=\"All\").tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most common words overall?\n",
    "- Most common Python, JavaScript, PHP, Shell words?\n",
    "- Any words that uniquely Python, JavaScript, PHP, Shell words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.sort_values(by='All')['All'].tail(10).plot.barh(width=.9)\n",
    "plt.title('10 most common words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.sort_values(by='Python').Python.tail(10).plot.barh(width=1, color='Orange')\n",
    "plt.title('10 most common Python words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.sort_values(by='JavaScript').JavaScript.tail(10).plot.barh(width=1, color='lightblue')\n",
    "plt.title('What are the most common JavaScript words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.sort_values(by='PHP').PHP.tail(10).plot.barh(width=1, color='pink')\n",
    "plt.title('What are the most common PHP words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.sort_values(by='Shell').Shell.tail(10).plot.barh(width=1, color='green')\n",
    "plt.title('What are the most common Shell words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_df = raw_count[['All']];\n",
    "tf_df = tf_df.rename(columns={'All': 'raw_count'})\n",
    "tf_df = tf_df.assign(frequency = lambda lemmas_df: lemmas_df.raw_count / lemmas_df.raw_count.sum())\n",
    "tf_df = tf_df.assign(augmented_frequency = lambda lemmas_df: lemmas_df.frequency / lemmas_df.frequency.max())\n",
    "tf_df.frequency.max()\n",
    "\n",
    "tf_df.sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams\n",
    "\n",
    "- Bigrams and visualizations of most frequent for all, Python, JavaScript, PHP, and Shell languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(all_words)).value_counts().head(15).plot.barh(width=.95).set_title('Bigrams for All Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(python_words)).value_counts().head(15).plot.barh(width=.95, color='orange').set_title('Bigrams for Python Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(javascript_words)).value_counts().head(15).plot.barh(width=.95, color='lightblue').set_title('Bigrams for JavaScript Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(php_words)).value_counts().head(15).plot.barh(width=.95, color='pink').set_title('Bigrams for PHP Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(shell_words)).value_counts().head(15).plot.barh(width=.95, color='green').set_title('Bigrams for Shell Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trigrams and visualizations of most frequent for all, Python, JavaScript, PHP, and Shell languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.ngrams(all_words, 3)).value_counts().head(15).plot.barh(width=.95).set_title('Trigrams for All Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.ngrams(python_words, 3)).value_counts().head(15).plot.barh(width=.95).set_title('Trigrams for Python Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.ngrams(javascript_words, 3)).value_counts().head(15).plot.barh(width=.95).set_title('Trigrams for JavaScript Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.ngrams(php_words, 3)).value_counts().head(15).plot.barh(width=.95).set_title('Trigrams for PHP Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(nltk.ngrams(shell_words, 3)).value_counts().head(15).plot.barh(width=.95).set_title('Trigrams for Shell Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df[\"length\"] = lemmas_df.lemmatized.apply(len)\n",
    "lemmas_df.drop(index = lemmas_df[lemmas_df.length > 140000].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df.length.plot.hist().set_title('Document Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = lemmas_df.hist(\"length\", by=\"language\", sharex=True, sharey = True, layout=(2, 2), bins=15, figsize=(12, 9))\n",
    "plt.suptitle('Distribution of Length of Characters for All Languages')\n",
    "\n",
    "for ax in ar.flatten():\n",
    "    ax.set_xlabel('Document Length in Characters')\n",
    "    ax.set_ylabel('Number of Documents')\n",
    "    ax.set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "ax = sns.boxplot(data=lemmas_df, y=\"length\", x=\"language\")\n",
    "ax.set_title('Document Length in Number of Characters')\n",
    "ax.set_ylabel('Language')\n",
    "ax.margins(.005) \n",
    "ax.set_xlabel('Length in Characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df[\"n_words\"] = lemmas_df.lemmatized.str.count(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df.groupby(\"language\").n_words.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmas_df.n_words.plot.hist(bins = 25).set_title('Document Length in Number of Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ar = lemmas_df.hist(\"n_words\", by=\"language\", sharex=True, sharey = True, layout=(2, 2), bins=15, figsize=(12, 9))\n",
    "plt.suptitle(\"Distribution of Number of Words for All Languages\")\n",
    "\n",
    "for ax in ar.flatten():\n",
    "    ax.set_xlabel('Document Length in Number of Words')\n",
    "    ax.set_ylabel('Number of Documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WordCloud with all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ' '.join(all_words)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "img = WordCloud(background_color=\"white\", height=1000, width=1500, random_state=123).generate(corpus)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WordCloud with all words by languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_corpus = ' '.join(python_words)\n",
    "javascript_corpus = ' '.join(javascript_words)\n",
    "php_corpus = ' '.join(php_words)\n",
    "shell_corpus = ' '.join(shell_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_cloud = WordCloud(background_color=\"white\", height=600, width=800).generate(\n",
    "    \" \".join(python_words)\n",
    ")\n",
    "javascript_cloud = WordCloud(background_color=\"white\", height=600, width=800).generate(\n",
    "    \" \".join(javascript_words)\n",
    ")\n",
    "php_cloud = WordCloud(background_color=\"white\", height=600, width=800).generate(\n",
    "    \" \".join(php_words)\n",
    ")\n",
    "shell_cloud = WordCloud(background_color=\"white\", height=600, width=800).generate(\n",
    "    \" \".join(shell_words)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "axs = [\n",
    "    plt.axes([0, 0, 0.5, 0.5]),\n",
    "    plt.axes([0, 0.55, 0.5, .5]),\n",
    "    plt.axes([0.6, 0.55, 0.5, 0.5]),\n",
    "    plt.axes([0.6, 0, 0.5, 0.5]),\n",
    "]\n",
    "\n",
    "axs[0].imshow(python_cloud)\n",
    "axs[1].imshow(javascript_cloud)\n",
    "axs[2].imshow(php_cloud)\n",
    "axs[3].imshow(shell_cloud)\n",
    "\n",
    "axs[0].set_title(\"Python\")\n",
    "axs[1].set_title(\"JavaScript\")\n",
    "axs[2].set_title(\"PHP\")\n",
    "axs[3].set_title(\"Shell\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis(\"off\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud with Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bigrams = pd.Series(nltk.bigrams(all_words)).value_counts().head(15)\n",
    "\n",
    "all_data = {p1 + \" \" + p2: v for (p1, p2), v in all_bigrams.to_dict().items()}\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=600, width=800).generate_from_frequencies(all_data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Bigrams Word Cloud with All Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_bigrams = pd.Series(nltk.bigrams(python_words)).value_counts().head(15)\n",
    "\n",
    "python_data = {p1 + \" \" + p2: v for (p1, p2), v in python_bigrams.to_dict().items()}\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=600, width=800).generate_from_frequencies(python_data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Bigrams Word Cloud with Python Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_bigrams = pd.Series(nltk.bigrams(javascript_words)).value_counts().head(15)\n",
    "\n",
    "javascript_data = {p1 + \" \" + p2: v for (p1, p2), v in javascript_bigrams.to_dict().items()}\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=600, width=800).generate_from_frequencies(javascript_data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Bigrams Word Cloud with JavaScript Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "php_bigrams = pd.Series(nltk.bigrams(php_words)).value_counts().head(15)\n",
    "\n",
    "php_data = {p1 + \" \" + p2: v for (p1, p2), v in php_bigrams.to_dict().items()}\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=600, width=800).generate_from_frequencies(php_data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Bigrams Word Cloud with PHP Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_bigrams = pd.Series(nltk.bigrams(shell_words)).value_counts().head(15)\n",
    "\n",
    "shell_data = {p1 + \" \" + p2: v for (p1, p2), v in shell_bigrams.to_dict().items()}\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=600, width=800).generate_from_frequencies(shell_data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Bigrams Word Cloud with Shell Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud with Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trigrams = pd.Series(nltk.ngrams(all_words, 3)).value_counts().head(15)\n",
    "\n",
    "data = {p1 + \" \" + p2 + \" \" + p3: v for (p1, p2, p3), v in all_trigrams.to_dict().items()}\n",
    "\n",
    "frequencies = data\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=500, width=800).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Trigrams with All Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_trigrams = pd.Series(nltk.ngrams(python_words, 3)).value_counts().head(15)\n",
    "\n",
    "data = {p1 + \" \" + p2 + \" \" + p3: v for (p1, p2, p3), v in python_trigrams.to_dict().items()}\n",
    "\n",
    "frequencies = data\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=500, width=800).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Trigrams with Python Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript_trigrams = pd.Series(nltk.ngrams(javascript_words, 3)).value_counts().head(15)\n",
    "\n",
    "data = {p1 + \" \" + p2 + \" \" + p3: v for (p1, p2, p3), v in javascript_trigrams.to_dict().items()}\n",
    "\n",
    "frequencies = data\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=500, width=800).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Trigrams with JavaScript Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "php_trigrams = pd.Series(nltk.ngrams(php_words, 3)).value_counts().head(15)\n",
    "\n",
    "data = {p1 + \" \" + p2 + \" \" + p3: v for (p1, p2, p3), v in php_trigrams.to_dict().items()}\n",
    "\n",
    "frequencies = data\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=500, width=800).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Trigrams with PHP Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_trigrams = pd.Series(nltk.ngrams(shell_words, 3)).value_counts().head(15)\n",
    "\n",
    "data = {p1 + \" \" + p2 + \" \" + p3: v for (p1, p2, p3), v in shell_trigrams.to_dict().items()}\n",
    "\n",
    "frequencies = data\n",
    "\n",
    "img = WordCloud(background_color=\"white\", height=500, width=800).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title('Top 15 Trigrams with Shell Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
